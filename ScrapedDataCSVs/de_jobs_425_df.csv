,company,industry,rank,job_title,location,salary_range,link,description,search_city,search_job
0,Deloitte,Accounting & Legal,3.9,Data Engineer,"Austin, TX",$92K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1008783&s=149&guid=000001790995606ab12fc72e4ee2c9a4&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_cdcf66c4&cb=1619363455660&jobListingId=4070112338,"Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with Project Delivery Practice.The teamAnalytics & CognitiveIn this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.The Analytics & Cognitive team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.Analytics & Cognitive will work with our clients to:Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platformsLeverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actionsDrive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvementsWork you'll doSupport the implementation of data integration requirements and develop the pipeline of data from raw to curation layers including the cleansing, transformation, derivation and aggregation of data.Communicate effectively (written and spoken) and work with the multi-location development teams and self-manage own workSupport in the development of technical solutions to business problemsQualificationsRequiredBachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience5+ years of hands-on experience as a Data Engineer or Big Data developer5+ years of experience in Core JAVA and SQL3+ years of experience in building scalable and high-performance data pipelines using Apache Hadoop, Apache Spark, Pig or Hive3+ years or experience in Python / Unix Shell ScriptingExperience with bigdata cross platform compatible file formats like Apache Avro & Apache ParquetHands on big data/ Hadoop performance tuning and optimization experienceStrong SQL knowledge with ability to work with the latest database technologies.Strong data & logical analysis skillsLimited immigration sponsorship may be availableTravel up to 25% (While 25% of travel is a requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice.)Optional / Nice to Have (but not required)Experience in Map Reduce is a plusAdditional RequirementsMust be willing to live and work in the Greater Austin, TX area (preferred) or San Jose, California. Relocation assistance provided to qualifying candidates.",aus,de
1,DriveCentric,Information Technology,4.3,Data Engineer I/II,"Austin, TX",$71K - $88K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044077&s=149&guid=000001790995606ab12fc72e4ee2c9a4&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_cb2d2d65&cb=1619363455660&jobListingId=4070060093,"Are you tired of not being challenged, not having a voice, or having to work with outdated technologies? Do you want to be a direct contributor in a company that is an innovation leader and has the awards to prove it? Do you want your fair share of the profits from a fast-growing company that’s doubling its customer base year-over-year?A Data Engineer I/II develops and performs data migration / ETL processes for store launches, investigates and fixes data issues, monitors and optimizes database performance, and assists in the administration of databases and data warehouses.Responsibilities:Write, execute, and validate DML, DDL, and DCL scripts to meet business and customer needs.Coordinate and perform data imports, data modifications, database maintenance, etc. outside of business hours, as needed.Assist Customer Support and Development by analyzing data to troubleshoot application issues.Manage SSIS packages for customer onboarding ETL processes.Onboard new customers by scrubbing data and importing from multiple data sources.Requirements:2+ years of experience writing DML and DDL, with 1+ years of hands-on experience with T-SQL.1+ years of hands-on Microsoft SQL Server 2012+ experience.Ability to balance business and technical objectives when making decisions.Ability to balance multiple assignments in a fast-paced environment.Exceptional communication, problem-solving, and analytical skills are a must.Have a positive, can-do attitude.Pluses:1+ year of scripting and managing ETL packages, with SSIS or other tools.Hands-on experience with Database Administration (SQL Server)Hands-on experience with PostgreSQL.Benefits:Competitive salaryHealth, Vision, and Dental Insurance (eligible on day 1)401K with matching up to 4%9 company holidays + 12 vacation days in first yearAmple professional growth opportunitiesJob Type: Full-timePay: $70,000.00 - $100,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insurancePaid time offVision insuranceSchedule:Monday to FridayWork Location:One locationVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:Open to applicants who do not have a college diplomaCompany's website:https://drivecentric.com/Company's Facebook page:https://www.facebook.com/DriveCentric/Work Remotely:Temporarily due to COVID-19",aus,de
2,Applied Information Sciences,Information Technology,4.4,Data Architect,"Austin, TX",$73K - $124K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_2a8ba084&cb=1619363455660&jobListingId=4039548178,"Intro (Use Font Arial 12):As a Data Architect, you will use cutting edge cloud and data technologies to power the mission of our clients and streamline services. Join our team of Data and Cloud professionals and accomplish what others only dream of.What You'll Be Doing:Work in a team with other smart AIS employees and use cutting edge technologies to solve challenging enterprise problemsApply your skills in Azure Cognitive Services, Azure PaaS, data science, data analytics, and data warehousing to pioneer Azure cloud and data servicesUse experience working with Azure Data & Storage, Azure Analytics & Azure IoT tools, as well as the traditional Microsoft BI stackProvide mentorship to more junior consultantsLocation and Travel Details:This is a remote position but after COVID restrictions lifted must be able to travel occasionally to Kansas and or Georgia.Profile of Success:Minimum of interim Secret requiredAbility to apply your skills in Azure Cognitive Services, Azure PaaS, data science, data analytics, and data warehousing to pioneer Azure cloud and data services within the DoD, bringing Azure Data Factory to IL4 & IL5Work in a team with other smart AIS employees and use cutting edge technologies to solve challenging enterprise problemsUse experience working with Azure Data & Storage, Azure Analytics & Azure IoT tools, as well as the traditional Microsoft BI stackMust possess strong mentorship abilities to train junior colleaguesProven experience developing Big Data solutions in the Azure spaceExperience with the Azure suite (Azure Data Lake, Azure Data Factory, Azure SQL Data Warehouse, Data Lake Analytics, HDInsight, Machine Learning, and Stream Analytics)SQL Server 2014/2016 experienceExperience using Spark, Hive, Pig, and ScalaComfortable with Microsoft Full Stack (SSAS/SSIS/SSRS)In-depth knowledge of Data Warehousing and ETL/ELTProven ability to work with clients to understand requirements and to envision solutionsDesirable Skills:Background with Data Science tools such as R, Python, and SAS is a plusExperience with visualization tools such as Power BI or TableauMicrosoft related certificationsAbout AIS:AIS, Dedicated to Our PeopleAIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee's success; however, they define it.It's our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.We Invest in Individuals Committed to InnovationAIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals.We are looking for:Smart people with a passion for technologyStrong technical capabilities with a consultancy mindsetClose involvement with local technical communitiesA willingness to think outside of the box to provide innovative solutions to clientsAbility to solve challenging technical business problemsSelf-directed professionalsOur Core ValuesClient SuccessContinued Learning and Technical ExcellenceStrong Client RelationshipsCitizenship and CommunityEEO Statement:Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status or any other basis covered by law. Employment decisions are based solely on qualifications merit, and business need.",aus,de
3,Army National Guard,Government,4.1,12Y Geospatial Engineer,"Austin, TX",$36K - $50K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_0b3dda47&cb=1619363455660&jobListingId=4066987299,"Job DescriptionYou can play an important part in disaster relief missions as a Geospatial Engineer for the Army National Guard. In this role, you will extract and supply geographic data that supports military operations of all kinds and help commanders visualize the battlefield during combat.As a Geospatial Engineer, your primary responsibility will be to collect and process military geographic information from decentralized sources (remote sensed imagery, digital data, intelligence data, existing topographic products, and other collateral data sources), present this information to leaders, and return decisions to the field.You may also:Supervise topographic surveying, cartography, and photolithography activitiesAssist in topographic planning and control activitiesAssist in determining requirements and providing technical supervision of geographic intelligence programsJob DutiesCreate geographic data and compile them into mapsCreate and maintain multiple geospatial databasesPrepare military-style briefs covering all aspects of the terrainSome of the Skills You’ll LearnBasic knowledge of Geographic Information SystemsImagery interpretation and exploitationHelpful SkillsInterest in geography, maps, and chartsAbility to demonstrate basic computer skills and work with drafting equipmentConceptualize ideas into computer-generated 2-D/3-D geospatial productsPreference for a technical career fieldThrough your training, you will develop the skills and experience to enjoy a civilian career with construction, engineering, and architectural firms, as well as with government agencies as a surveyor, mapmaker, cartographer, cartographic technician, or photogrammetrist.Earn While You LearnInstead of paying to learn these skills, get paid to train. In the Army National Guard, you will learn these valuable job skills while earning a regular paycheck and qualifying for tuition assistance.Job training for a Geospatial Engineer requires 10 weeks of Basic Training, where you'll learn basic Soldiering skills, and 20 weeks of Advanced Individual Training (AIT) and on-the-job instruction, including practical application of geographic information systems. Part of this time is spent in the classroom and part in the field.Benefits/RequirementsBenefitsPaid trainingA monthly paycheckMontgomery GI BillFederal and State tuition assistanceRetirement benefits for part-time serviceLow-cost life insurance (up to $400,000 in coverage)401(k)-type savings planStudent Loan Repayment Program (up to $50,000, for existing loans)Health care benefits availableVA home loansBonuses, if applicableMost non-prior service candidates will earn between $200 and $250 per drill weekend, subject to changeRequirementsMilitary enlistment in the Army National GuardMust be at least a junior in high school, or have a high school diploma or a GED certificateMust be between the ages of 17 and 35Must be able to pass a physical exam and meet legal and moral standardsMust meet citizenship requirements (see NATIONALGUARD.com for details)Requires military enlistment. Programs and benefits are subject to change. Ask your Army National Guard recruiter for the most up-to-date information. Actual MOS assignment may depend on MOS availability.Other Job InformationJob ID: 1376649ZIP Code: 786173647Job Category: EngineerAge Requirements: Must be between the ages of 17 and 35 administrator map reader aide",aus,de
4,"Southeastern Computer Consultants, Inc.",Information Technology,3.4,Project / Technical Lead 3D Game Development (Computer Engineer Level 4),"Austin, TX",$58K - $102K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044072&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_7c41088f&cb=1619363455661&jobListingId=4041064927,"OverviewSCCI is seeking a Project / Technical Lead 3D Game Development (Computer Engineer Level 4) to support development of advanced 3D gaming simulation and cloud technologies for virtual training of Navy combat systems This position is expected to work closely with the customer and end-users to develop requirements and to lead a cross-functional team of developers, game developers, network engineers, security specialists and Navy system subject matter experts, to design, deliver and support serious gaming. A successful candidate will support a variety of projects and will be responsible for supporting existing products, developing new solutions and integrating technology innovations in training through technology. This position is located in Austin, TX (will also consider Virginia Beach, VA or Dahlgren, VA). This position is contingent upon award of a Government contract and would start approximately January 2022. Responsibilities:Lead a distributed development team in the creation of 3D gaming simulation of combat systemsExecute systems engineering best practices for requirements definition & decomposition, design and implementation of customer & end-user requirementsAssess operational performance criteria and provide input for improving performanceDevelop and communicate system plans, progress and performance results both orally and in writing Essential Skills and Experience:Must be a U.S. Citizen and be able to obtain and maintain an active Secret Security ClearanceMaster's level degree in one of the following disciplines:Computer or Electrical or Electronics EngineeringComputer ScienceInformation Systems ManagementSystems EngineeringTen (10) years of full-time professional experience in one or more of the following fields:Software developmentComputer NetworksInformation and/or Database ManagementComputer Engineering with an emphasis on software development and integrationDemonstrated experience managing DOD software projects through entire software development life cycleDemonstrated experience with Unity or other modern 3D game development engineDemonstrated extensive experience with Unity, Unreal or other modern 3D game developmentDemonstrated experience successfully leading a team in a local and/or geographically dispersed environmentDemonstrated experience developing software in AgileDemonstrated experience managing software version control and/or software source code base managementDemonstrated experience with DoD training systems and training tool developmentDemonstrated experience leading requirements generation events Preferred Skills and Experience:Demonstrated experience with software emulation of Navy Combat SystemsDemonstrated experience with Learning Management Systems and their architecturesDemonstrated experience planning for and executing modifications of existing software applications at the system or subsystem levelDemonstrated experience with Navy or DoD engineering or software development including:DesignDevelopmentTest and EvaluationLifecycle SupportConfiguration ManagementDemonstrated experience in DoD Contract and/or Program ManagementDemonstrated experience in one or more of the following area:Computer ArchitectureUnix, Linux, or Windows Computer Operating Systems“Real Time” data processingComputer NetworkingAbility to work independently and interface professionally with other government agencies, contractors, military personnelAbility to define task details, estimates, and schedulesAbility to work with others to meet established goals and program schedulesAbility to communicate effectively, both verbally and in writingSCCI is committed to providing a comprehensive and competitive benefits package to meet the needs of employees and their families. EOE of Minorities, Females, Veterans, Disabilities.",aus,de
5,CDK Global,Information Technology,3.6,Sr. Software Engineer,"Austin, TX",$58K - $118K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_a934449a&cb=1619363455661&jobListingId=4042242131,"We're looking for a stellar software engineer to help build our platform, CoEFFICIENT. Versatility will be key in this role, as you will be jumping between frontend and backend programming to deliver a performant and responsive web application for our end users. As an engineer on CDK's Neuron team, you'll collaborate across teams, all the while considering how people will use what you're building. So empathy, approachability, and listening are essential parts of the job! You should also be two steps ahead, understanding how your work impacts other systems, the product, and our vision. A willingness to learn and adapt is vital to thriving in our agile environment. Our software engineers like to solve problems and believe the best work results from finding the simplest path when it comes to difficult challenges.Interested? Keep reading!About YouYou love to code. You not only understand basic design patterns, data structures, and algorithms, you pioneer new design patterns and inspire others to do the same.You're experienced in frontend + backend software engineering, modern, microservice-based architecture, and coaching others to excellence.You know that tech is dynamic, and you have a thirst for learning and understanding current development, best practices, trends, and techniques.You're not married to a particular tech or set of tools. Right now, we're using AngularJS, React, Rails, and following RESTful and Microservice architecture, so experience in any of those areas would benefit you!You're all about digging into complex problems, and you're willing to pitch in where help is needed.You ask questions, are clear with your expectations, and pitch in wherever you can.You've got the grit and resilience to push forward, even when things don't go as planned.You have a positive attitude, a sense of humor, and the ability to thrive in a fast-paced, dynamic environment.We're always looking for people to join and evolve our radical culture + company. We want you to bring your unique experience and perspective, so don't worry about checking all the boxes. If our values and mission resonate with you, please apply!The Good StuffFlexibility -come as you are to work and take time off whenever you need it! You won't need to accrue time off, and you can structure your time to work with your life. We're currently all working from home – once it's safe to return to the office, we can't wait to see you in-person!Diversity +Inclusion - we bring our full selves to work, and you can too! The Neuron team hosts quarterly Radical Girl Crew events, open communication with our leadership team, a mother-friendly office space, and regular pulse surveys so every voice is represented.An ecclectic campus of 1920's craftsman housesin downtown Austin.Team lunches, stocked kitchen + bar, and coffee-snob compliant coffee (we'll even teach you how to use the espresso machine)Bi-annual Hackathons where everyone can think outside of the box + experiment on innovativeideas!All of our benefits are effective the first day of employment! This includes a generous401K matching, flexible paid time off, donate your time to volunteer in your community, and tuition reimbursement for furthering education.The CDK CultureOur culture is at the core of everything we do. As we grow, we're not only looking to hire the best and brightest, but we're also looking for people to share + evolve our values forward.Own It. We seek accountability and act with integrity. We delight in taking responsibility, have positive intent, and we're focused on the outcome of our efforts.Stay Curious. We listen to understand. We're relentless innovators, open to new ideas, and we make decisions based on data.Be Open. We welcome respectful challenge to find new + better ways to work. We thrive on feedback, build open + agnostic technology, and encourage different views.Create Possibilities. We ask “how can we…” to make a difference in the world. We're confident to grow, adapt, and celebrate our achievements.Join Our TeamGrowth potential, flexibility, and material impact on the success and quality of a next-gen, enterprise software product makes CDK an excellent choice for those who thrive in challenging, fast-paced engineering environments. The possibilities for impact are endless. You'll have exceptional opportunities to evolve our industry by driving change through new technology.If you're ready for high-impact, you're ready for CDK.At CDK, we pride ourselves on having a diverse workforce. We value and celebrate the uniqueness of individuals and the different perspectives they provide. We offer equal opportunity employment regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, or protected veteran status. We value what makes us different and want to see how you can make our team better!",aus,de
6,UFCU,Finance,4,Symitar Application Engineer III (Remote Options in Texas),"Austin, TX",$57K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_7bd994e7&cb=1619363455662&jobListingId=4065374162,"JOB SUMMARYThis role focuses on administration, monitoring and maintenance of the Symitar financial core, services and related infrastructure components. This individual will have demonstrated experience in troubleshooting problems, product improvement, and effective communication with both IT and business partners. Personality and team focus are critical to success at UFCU.With limited supervision the candidate must support secure Symitar functions based upon requirements. This candidate must be proactive in delivering successful solutions, including helping define requirements, application deployment, implementing best-practices, supporting testing efforts, and providing documentation while working with business units. This role is also responsible for proactively providing project tasks and status updates. This role may provide guidance to junior team members and can be remote, but requires a residence in Texas, and travel to the Austin, TX area office up to once a month.ESSENTIAL DUTIES AND RESPONSIBILITIESRelative Weight(in %; all functions’ total should = 100%)Essential Function Description50%Application SupportServe as the subject matter expert for Symitar used by UFCU staff and membersAnalyzes, develops, tests, engages with code reviews, and implements code in the Symitar environments including RepGen/PowerOn and other coding tools to create, troubleshoot or repair new applications, products, functionality, create reports/extracts and user input teller screens. Analyzes and maintains code for ease of processing to increase efficiency and automation.Install, configure and maintain Symitar as well as retain application configurationsSupport projects that enhance, upgrade or replace Symitar and other applicationsWork with vendors to support, upgrade and maintain Symitar and other appsDevelop processing schedules and ensure scheduled jobs and automated processes run as designedPerforms a variety of complex programming tasks, such as designing, documenting and coding program logic.Support/develop integrations with internal and external applications via API’sParticipate in after-hours systems support activities and on call rotation20%Service AvailabilitySetup and maintain disaster recovery systems and procedures to support business continuityConduct disaster recovery testing of critical data and systems to assure its readiness when neededDocument application recovery proceduresConduct proactive capacity and performance planning to ensure systems appropriately meet customer demandImplement comprehensive system monitoring to reduce response time and minimize downtime30%Incident Management and Request FulfillmentDemonstrate service excellence with an emphasis on ownership of issues and drive for resultsComplete incident and service request tasks in a timely manner in order to meet service level agreementsTroubleshoot and resolve complex issues.Conduct root cause analysis as needed and take action to prevent future occurrences of incidents100%Performs other duties as assignedAdhere to all company policies, procedures and business ethics codesComplete required regulatory Training as assigned.Maintain strict adherence and compliance to all laws, rules, regulations and internal controls specific to your role, including but not limited to Bank Secrecy Act, Anti-Money Laundering, USA Patriot Act, OFAC and Fair Lending regulationsQUALIFICATIONSEducationAssociate or bachelor degreeExperience3-5 years applied knowledge of RepGen, PowerOn, SymForm, SQL, HTML, CSS, .NET, scripting languages and online/mobile banking platform knowledge.3-5 years financial technologyAbility to work in a fast-paced environmentAbility to engage in problem-solving skills to help identify and resolve issuesCareful attention to detail and time managementEffective communication skillsExperience working for a financial institutionPreferred SkillsPowerOn Language.Net C#/JavascriptSQLAzure DevOpsWriting/Enhancing REST API’sSpecialized Knowledge, Licenses, Certifications, etc.Demonstrated knowledge of IT technologies – server, network and storageSuperb analytical & troubleshooting skillsExcellent customer serviceHigh level of organization and prioritizationDefine and develop complex systemsMust be able to pass a financial and criminal background checkPHYSICAL DEMANDSThe physical demands described here are representative of those that must be met by an employee in order to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.While performing the duties of this job, the employee is regularly required to sit; use hands to finger, handle or feel; reach with hands and arms; and talk or hear.Specific vision abilities required by this job include close vision, distance vision, peripheral vision and ability to adjust focus.The employee is frequently required to stand and walk.Employee will make extensive use of the telephone requiring the ability to effectively and accurately explain complex information.WORK ENVIRONMENTThe work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.This position may involve periodic stressful conditions.May occasionally require an adjusted work schedule, overtime, and evening/weekend hours.May occasionally move from one work location/branch to another.Public contact position, requiring appropriate professional appearance.Frequent computer use at a workstation up to two hours at a time.The noise level in the work environment is usually moderate.CRITICAL JOB COMPETENCIESUFCU Core Competencies. In addition to fulfilling the position’s Essential Duties and Responsibilities, an individual must demonstrate UFCU’s Core Competencies:Leading & Developing SelfOrganizational ImpactNothing in this job description restricts management from changing any or all parts of the job description at any time.INDUFCU#ZR",aus,de
7,SailPoint,Information Technology,4.4,Implementation Engineer - IdentityNow (SaaS) / Identity IQ *Multiple Positions*,"Austin, TX",$40K - $102K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_ac7b2d5f&cb=1619363455663&jobListingId=3756357371,"-Multiple positions available-Consulting positions are available in both our Professional Services and Expert Services Teams. If contacted, please raise your preference!Our Expert Services team supports shorter term change/enhancement related requests. These are typically shorter in duration with an increased variety of work.Our Professional Services team supports defined projects that are typically longer in duration and delivered in a methodical end to end delivery model.What's the secret of SailPoint's success? We believe it's all about the way we work together – and play together. Our culture encourages both independent thinking, and close collaboration. We give people the resources they need to do their jobs yet leave them alone to work in whatever way they do best. We love their intense, day-to-day dedication, and we admire their commitments outside of work. And we appreciate equally their dedication to seeing our company grow and thrive, and to making our community a better place.A passion for what we do. And for what we can do for others.At SailPoint, success is all about our people. SailPoint's employees are:Smart, for starters – We look for people who are the best and the brightest, but who are always looking to learn more.Empowered to succeed – Rather than micromanage, we give people the training and resources they need, and let them work on their own terms.Always in the loop – Our people consistently get open, honest communication about what's happening in our company and industry.Community-conscious – From teaming up to participate in charity benefits, to volunteering individually, our people make SailPoint a model for community engagement.Ready to have some fun – Well, you know what they say about all work. We celebrate our achievements, our birthdays, our business success, our... you get the picture.Implementation EngineerThe Implementation Engineer will be responsible for assisting in the successful installation, integration and deployment of SailPoint IdentityNow SaaS and IdentityIQ software in client environments. This is a client facing role where you will be on the front lines helping SailPoint’s clients turn their Identity dreams into reality.Responsibilities:Installation, integration and deployment of the IdentityNow SaaS and IdentityIQ product in client environments.Working with clients post implementation for user testing, debugging, support and maintenance.Communicating to clients and partners aspects of both the product and the implementation at the technical and/or functional level appropriate for the situation.Post-sales requirements gathering, analysis and documentation.Adhering to project scope, schedule, status and documentation.Developing and delivering technical training designed to enable/educate SailPoint customers and implementation partners.Requirements (The ideal candidate has experience with all of the technologies below. As a recent college grad it’s OK to know a few of these well, as long as you can demonstrate the aptitude to pick up the rest on the job) :Experience with some of the following:Angular JS, Java, BeanShell/JavaScript, JSP/Servlets, SQL.Web technologies: XML, SPML, SOAP, REST, Web / Application Servers, HTML.Setting up and installing software on both Windows and Unix (Linux, Sun, HP, AIX) platforms.Databases (Oracle, Sybase, MSSQL, MySQL).Directories (LDAP, AD).Familiarity with RBAC and Provisioning a plus.QA usability testing, performance testing, automated testing, test scripts, test cases and test plans.Education:Computer Science, Engineering degree, or 4-6 years equivalent experience.Location/Travel:Position is based in Austin, TX. This position requires approximately 25% travel.About UsSailPoint was founded by recognized leaders in the identity management market who have proven track records of delivering innovative solutions that provide real business value and proven return on investment. We're dedicated to helping organizations meet their service delivery requirements, improve internal controls and manage the risks associated with access to sensitive data and applications across the enterprise. Our unique approach empowers businesses to improve visibility and control of their identity environment and manage risk to acceptable levels to the business.SailPoint IdentityIQ provides a complete, unified solution for compliance management and user lifecycle management that reduces deployment cost and complexity. Unlike traditional approaches to identity management which treat governance, compliance, and provisioning as separate activities, often spread across multiple, disjointed products, IdentityIQ provides a unified approach leveraging a common identity governance framework to consistently apply business and security policy, role and risk models across all access-related activities.SailPoint is an equal opportunity employer and we welcome everyone to our team. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",aus,de
8,Confluent Medical Technologies INC,Manufacturing,3.1,Process Development Engineer II,"Austin, TX",$46K - $84K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_0dd4bc05&cb=1619363455663&jobListingId=4040671691,"Confluent Medical Technologies is dedicated to working collaboratively with our customers, taking their projects from rapid prototype into high volume production. Our unparalleled technical expertise, proven experience and partnership with our clients has allowed us to perfect the process necessary to deliver world-class medical devices through innovative material science, engineering, and manufacturing. Our primary capabilities include: Nitinol components, balloon expandable stents and balloon catheters, delivery systems, biomedical textiles, access kits, and guidewires. We take pride in our position as the leader in the medical technology space and are driven by a passion to create products that our clients have envisioned for their customers.We’re looking for a Process Development Engineer II to join our team in Austin, TX. As a uniquely qualified candidate, you will:Responsible for process identification, parameter optimization, proof of concept testing, technology improvements, and process implementation.Responsible for tool and fixture design and qualification used for manufacturing medical devices and components. Must be able to accomplish broad and complex assignments. May provide technical guidance to lower level personnel.Responsible for screening and optimization of process parameters to achieve robust and stable processes and maximize yields, efficiencies and process capabilities.Plans and conducts work requiring judgment in the independent evaluation, selection, and substantial adaptation and modification of standard techniques, procedures, and criteria.Design and perform Process Characterization Study’s & DOE’s, support protocols and reports.Have a firm understanding of validation strategy (IQ/OQ/PQ), support protocols and reports. Independently performs most assignments with instructions as to the general results expected.Works on problems and projects of moderate scope where analysis of situation or data requires a review of identifiable factors. Selects techniques to solve complex problems and make sound design recommendations.Exercises judgment within defined procedures and practices to determine appropriate action. Demonstrates full use and application of standard principles, theories, concepts and techniques. Selects design direction or modifications of components of systems.Receives technical guidance on unusual or complex problems and supervisory approval on proposed plans for projects.Plans, schedules, conduct, and coordinates detailed phases of engineering work in part of a major project or in a total project of moderate scope.Performs work that involves conventional engineering practice but may include a variety of complex features such as conflicting design requirements, unsuitability of conventional materials, and difficult coordination requirements.Practices company safety, quality policies and procedures, actively requires conformance.Responsible for ensuring personal and company compliance with all Federal, State, local and company regulations, policies and procedures for Health, Safety and Environmental compliance.Responsible for the purchase or design of equipment that meets health, safety and environmental standards set by the company.Responsible for performing design reviews and pre-validation assessments to ensure the safe and environmentally sound start-up of new processes.Preferred Qualifications:Strong in SolidWorks, Mechanical Acumen and Hands onHands-on experience with a variety of catheter production equipment, such as: hot boxes, die-bonders, braiders, coil winders, laminators, ovens, UV adhesive light welders, laser welders, and others.Good understanding of materials typical to catheter production: Pebax, Nylon, Polyurethanes, PEEK, PTFE, FEP, CA and UV adhesives, Stainless steel, NiTi, etc.Education and Experience:BS degree in engineering3 - 6 years of experience in Metrology, Optics, Physics, Engineering or equivalentMinimum of 3 years of experience on medical devices or pharmaceutical industry.Formal training and experience with mechanical or electrical design a plusExcellent written and oral communication skills are requiredExperience in performing audits on metrology and quality processes desired - along with root cause analysis of technical discrepancies/abnormalitiesExperience in preparing laboratory documentation (work instructions, calibration procedures, analysis spreadsheet, reference documents and others) in a variety of formats including Word, Excel and PowerPointFamiliarization with method development, calibration, measurement development, laboratory auditing and root cause and Gage R&R analysis desiredWe regret that we are unable to sponsor employment visas or consider individuals on time-limited visa status for this position.Confluent Medical Technologies is an equal opportunity employer.",aus,de
9,SailPoint,Information Technology,4.4,Sr. DevSecOps Engineer,"Austin, TX",$77K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_6f74a28a&cb=1619363455663&jobListingId=3756357298,"We're searching for a Sr. DevSecOps Engineer that will be a key player on the DevOps team servicing SailPoint's suite of SaaS products. You will proactively work with the rest of the DevOps team, the CISO team, Engineering, Product, and other functional departments to design, implement and operate solutions to secure our global customer-facing SaaS infrastructure.Responsibilities:Design, build and maintain tools/processes to effectively secure our cloud-based (AWS) environmentsWork closely with the CISO organization to help establish and ensure corporate guidelines and best practices are followedImplement a program to integrate security into the build/release pipelines to validate our code is secure before it goes to productionAble to build a solution to a problem, rather than buy, when appropriateEvaluate and recommend use of machine learning, AI, and data analytic services to improve the security of our products and environmentsStay current on security industry trends and topics, and evangelize those concepts within the organizationProactively meet standards for information security and compliance, such as ISO27001, SOC2, FedRAMP, etcBackground & Experience:Experience working on a team with security responsibilities for a SaaS or PaaS solution, preferably in AWSExperience creating solutions in languages like Ruby or GoExperience automating and integrating security operations into DevOps processesExperience with SIRP, SIEM, and IDS/IPS/WAF solutionsExperience securing containerized applicationsKnowledge of orchestration and/or configuration management tools (Terraform or Ansible/Chef) and command execution frameworksUnderstanding of how Java and Go applications operate, and how to secure the environment that houses themUnderstanding of industry standard release automation tools and processesStrong interpersonal and teaming skills — this is an extremely collaborative environmentEducation:Bachelor's degree in Computer Science or other technical discipline, or equivalent experience/certificationsSailPoint is an equal opportunity employer and we welcome everyone to our team. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",aus,de
10,"Amazon Web Services, Inc.",Information Technology,3.8,Data Engineer,"Austin, TX",$72K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=133043&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_5be01a0f&cb=1619363455664&jobListingId=4068467902,"Degree in Computer Science, Engineering, Mathematics, or related field4+ years industry experience3+ year of experience in the following: developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQLExperience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQLExperience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solutionFor more than 15 years, Amazon Web Services, AWS has been the world’s most comprehensive and broadly adopted cloud platform. AWS offers over 200 fully featured services to millions of active customers around the world—including the fastest-growing startups, largest enterprises, and leading government agencies—to power their infrastructure. Within the AWS WWCO Commercial Sales organization, the Specialized Sales Operations team is responsible for supporting Leadership, Sales, and Operational teams in achieving organizational objectives and driving continuous improvements in field productivity. We drive effectiveness, predictability, and deliver a “run the business” cadence that allows for the field to serve customers in the way customers want to be served.The AWS Specialized Sales Operations team is looking for an experienced Data Engineer to join the WW Specialist organization. This individual will be responsible for producing data infrastructure that enables insights that is timely, accurate, and actionable. In this role, you will design, develop, implement, test, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. You will build and maintain the infrastructure underpinning all dashboards for thousands of sales and operations team members. You will be implementing data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. You will partner with business analysts & business users to gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. You will evaluate and make decisions around the use of new or existing software products and tools. You will use software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems (e.g. MapReduce, MPP architectures, NoSQL databases).This position must be based near one of the following AWS office locations (Arlington, Atlanta, Austin, Boston, Chicago, Cupertino, Dallas, Detroit, East Palo Alto, Herndon, Houston, Irvine, Minneapolis, Nashville, New York City, Pittsburgh, Portland, San Diego, San Francisco, Washington D.C., Sunnyvale, Santa Monica, Seattle, Tempe). Relocation is offered from within the US to these locations.Graduate degree in Computer Science, Engineering or related technical field.Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Experience in Python and/or other data ingestion languages and tools.Effective analytical, troubleshooting and problem-solving skills.Passion to keep current on emerging technologies in the big data, data science, artificial intelligence and machine learning space.Experience working with sales or financial dataExperience with deploying enterprise grade BI/AI/Machine learning solutions for large scale data environmentsExcellent verbal and written communications skillsAbility to work effectively across internal organizations and various stakeholdersAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https://www.amazon.jobs/en/disability/usP ursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",aus,de
11,"Pilytix, LLC",N/A,3.8,Data Engineer,"Austin, TX",$83K - $102K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=14295&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_a34d80be&cb=1619363455664&jobListingId=3539398125,"Pilytix brings Explainable Artificial Intelligence (XAI) to sales teams so they can be more effective and close more deals, faster. We use best-in-class tools to quickly deliver data-driven insights to all of our clients. Data Engineers will assist in the development of cutting-edge data pipelines to ingest, transform and archive data for our clients and to support our team of Data Scientists.

Responsibilities:

Author and monitor directed acyclic graphs (DAGs) in Apache Airflow to ingest and transform data Build and maintain internal Python packages to streamline ingest processes and add connections for new types of data Manage Kubernetes infrastructure and PostgreSQL databases on Google Cloud Platform Work collaboratively with the development and data science teams to add new data-driven features to our software-as-a-service product Participate in Agile / Kanban processes on a daily basis Comply with change management policies and code reviews to ensure data integrity and system stability

Requirements

BS/MS in a STEM field and 2+ years of industry experience programming and working with data

Exceptional understanding of data architecture and software engineering best practices

2+ years experience with Python (Python 3 preferred) 2+ years experience with SQL (PostgreSQL preferred) 2+ years of experience with Docker 1+ years experience with cloud infrastructure (GCP preferred) 1+ years of server orchestration (Kubernetes preferred) Experience using Apache Airflow or similar data pipeline systems Experience using Git or other DVCS Knowledge of Agile / Kanban processes Entrepreneurial spirit and highly self-motivated

Job is based in Austin TX, but extraordinarily qualified remote candidates (willing to travel to Austin semi-regularly) may apply.

Benefits

Competitive base salary with ability to earn bonuses Professional development and entrepreneurial opportunities Paid time off 401(k) Medical and dental plans
",aus,de
12,"Phunware, Inc",Information Technology,3.4,Data Engineer,"Austin, TX",$76K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=926135&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_c4203e4e&cb=1619363455665&jobListingId=3582439652,"Since our founding in 2009, we’ve relentlessly worked toward a vision of a future powered by Phunware. We spend our days obsessing over how best to design, build, launch, promote and support branded apps that engage, compel and delight the world’s most discerning audiences. For over a decade, we’ve helped Fortune 5000 businesses throughout the mobile app lifecycle with data-backed decisions at every step.

Everything You Need to Succeed on Mobile — Transforming Digital Human Experience

Phunware, Inc. (NASDAQ: PHUN), is the pioneer of Multiscreen-as-a-Service (MaaS), an award-winning, fully integrated enterprise cloud platform for mobile that provides companies the products, solutions, data, and services necessary to engage, manage and monetize their mobile application portfolios and audiences globally at scale. Phunware’s Software Development Kits (SDKs) include location-based services, mobile engagement, content management, messaging, advertising, loyalty (PhunCoin & Phun) and analytics, as well as a mobile application framework of pre-integrated iOS and Android software modules for building in-house or channel-based mobile application and vertical solutions. Phunware helps the world’s most respected brands create category-defining mobile experiences, with more than one billion active devices touching its platform each month.

If you share our passion for innovative mobile app experiences and dream of a world empowered by seamless, one-to-one interactions, we want to hear from you. Get in touch with us today—our Phamily always has room for one more!

Job Summary:

Phunware is seeking a Data Engineer with hands-on experience creating, deploying and optimizing large-scale data systems.

The ideal candidate will bring strong technical skills and be proactive, responsive and very comfortable dealing with ambiguity. He or she will also bring good experience with Big Data systems/technologies and have a strong track record of deployment, maintenance, and optimization of production code.

The ideal candidate is someone who combines an understanding of business processes with knowledge of both client and server-side technical requirements in mobile software projects. They will put the customer first, quickly build strong relationships, learn rapidly, and enjoy autonomy and problem-solving. They must be a gifted leader with a genuine passion for working with high-performance teams, extraordinarily organized., and have a strong work ethic. Additionally, the position may require travel both domestically and internationally.

What You’ll Do:

Create robust, high-volume production systems/architectures, and develop prototypes quickly Work with development teams to design maintenance and support strategies Create optimized workflows using relevant technologies (Spark, Elastic Search, Kafka, Oozie, Hadoop) Create architectural workflows, diagrams, and specification documents to help define platform features/functionality Perform experiments and analyze results to improve the performance and quality of algorithms Work with product management and executive stakeholders to take detailed requirements and implement them using Agile Test Driven techniques Work in an organized team-oriented environment with shared responsibilities

What You’ll Bring:

Bachelor’s Degree or higher in Computer Science or Computer Engineering; Master’s Degree preferred Have previously worked in Big Data technologies and deployed in production environment Strong experience in building highly scalable, available and responsive systems using open-source software tools and technologies 5-10 years of professional software development 5-8 years strong Java development experience Good experience with REST API frameworks Strong SQL skills 1+ years of professional software development experience with some of the big data technologies including: Spark, Map Reduce, Hive, HBase, Hadoop, Kafka, Impala, Cassandra Experience in Elastic Search is highly desirable Some experience with one or more of the following will be an added advantage: statistical analysis, machine learning, natural language processing, predictive modeling Domain experience in one or more of the following: Outstanding skills for interacting with people Responsible, organized and hardworking with excellent communication skills Must be living in the Irvine, CA or Austin, TX area or be able to immediately relocate

Desirable:

NoSQL or similar DB design/implementation experience with large number of records (i.e. 1 Billion+) Experience with information retrieval, network programming and/or developing large software systems Experience with cloud delivery platforms, ideally Amazon Experience doing Test Driven Development (TDD), Continuous Integration (CI) and test automation Open-source software contributions Track record of success in a start-up or high-growth environment

Compensation and Benefits:

Fun, casual, fast-paced work environment filled with talented colleagues Flexible paid time off Competitive salary Restricted Stock Units Full range of benefits, including 401(k), medical, dental and vision coverage 

Candidates for this position must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future. ",aus,de
13,Cloudflare,Information Technology,4.3,Data Engineer,"Austin, TX",$94K - $165K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=8095&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_bc3f93c1&cb=1619363455665&jobListingId=4043719698,"About Us

At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world's largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare have all web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine's Top Company Cultures list and ranked among the World's Most Innovative Companies by Fast Company.

We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!

About the team

The BI team is small and continually growing as we build and operate the cloud data platform for Cloudflare. We are responsible for building a centralized cloud data platform using open source technologies that will be used by our internal Business Partners and Machine Learning teams. Our goal is to democratize data, support Cloudflare's critical business needs, provide reporting and analytics self-service tools to fuel existing and new business critical initiatives.

About the role

As part of this initiative, we are looking for a Data Engineer and help us build a scalable petabyte scale data lake and Enterprise Data Warehouse (EDW) using modern tech stack from the ground up using open source technologies. Success in this role comes from marrying a strong data engineering background with product and business acumen to deliver scalable data pipelines and analytics solutions that can enable advanced analytics via a self-service user interface.

What you will do

Partner closely with internal stakeholders to gain a strong understanding of business and product data needs
Design, build and support scalable and reliable data solutions that can enable self-service reporting and advanced analytics using open source technologies
Develop technical tools and programming that leverage machine learning and big-data techniques to cleanse, organize and transform data and to maintain and update data structures and integrity on an automated basis
Design application components and evolve architecture: API/Services, data access, integration, application components, etc.
Analyze and support platform requirements for Data Science team
Implement automation tools and frameworks (CI/CD pipelines)
Build tools to automate the monitoring or workload and take proactive measure to scale the platform or to fix the problem

Examples of desired skills, knowledge and experience

Proven ability to work closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality.
2+ years of development experience in Big Data space working with Petabytes of data and building large scale data solutions using Google Cloud Platform, Apache Spark, Airflow, Kafka, Scala, Python, etc.
Experience with API design and development of RESTful web services or GraphQL
Knowledge of and experience with backend frameworks like NodeJS or Golang
Experience with environment and deployment automation, IaaS, deployment pipeline specification and development.
Working experience in Kubernetes, Docker etc.
Bachelor's or Master's Degree in Computer Science or Engineering or related experience required.

What Makes Cloudflare Special?

We're not just a highly ambitious, large-scale technology company. We're a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.

Project Galileo: We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare's enterprise customers--at no cost.

Athenian Project: We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.

Path Forward Partnership: Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.

1.1.1.1: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here's the deal - we don't store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.

Sound like something you'd like to be a part of? We'd love to hear from you!

This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.

Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.

Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.",aus,de
14,A Cloud Guru,Information Technology,4.3,Data Engineer,"Austin, TX",$54K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_10c846d4&cb=1619363455665&jobListingId=4012410509,"The Data Engineer roleCOLLABORATE | OPTIMIZE | EVOLVEAs a Data Engineer at A Cloud Guru, you will ensure the data platform infrastructure and architecture supports the evolving requirements of the Data Engineering and Data Analytics teams as well as other parts of our business! You will work closely with the Director of Data Engineering to develop a strategy for our long term Data Platform architecture to identify gaps in the data processes and drive improvements while mentoring and coaching other team members. Thanks to your contributions, our data platform will continue to optimize and revolutionize. This role reports to the Director, Data Engineering.Hello, we're A Cloud GuruOur friends call us ACG.A Cloud Guru was built by engineers for everyone, everywhere. Here, you’ll have the freedom to follow your curiosity. We’re not afraid to just try, because when you’re working with cutting edge technologies, experimentation and trying out new ideas have to be encouraged and celebrated. Our engineers are building the world’s largest (and most awesome) cloud learning platform. Why? Our mission is to teach the world to cloud. Our fun, practical courses have helped over 2 million people learn to cloud, and we’re just getting started.There aren't many company cultures like A Cloud Guru's in the world. This year, we were awarded the #1 Place to work in Austin, as well as Best Company Culture and Best Companies for Diversity.What makes the Engineering team awesome...We’re not a training company that just decided to sell training courses. We grew up out of the cloud ecosystem. We were a bunch of cloud engineers who pulled people together to create a training platform. That’s why we’re genuinely passionate about what we create. And we are known for practicing what we preach. We’ve built a product using cloud-first Serverless Architecture with tools like Lambda, API Gateway, GraphQL and ReactJS. All that aside, we're a friendly, down-to-earth, and collaborative group. There are no high-performing jerks and no heroes. Just great teams.You'll do well at ACG if you're open to learning and trying new things, and you like to be surrounded by other friendly, passionate and driven people. –Natasja, Makeup Guru (and Software Developer)As a Data Engineer at ACG, you’ll get to:Be an essential part of designing and building ACG’s new data platform, as we evolve the existing databases into a cutting-edge solution to meet the needs of our 2021 data plans and beyondExplore and contribute to discussions around technologies under consideration, such as Snowflake, Kappa/Lambda architecture, Delta Lakes and Data VaultDevelop, test and maintain existing architecture, including databases, data pipelines and large-scale processing systemsCollaborate with the Analytics team on transformation processes to populate data modelsRecommend ways to improve data reliability, efficiency and quality of the data platform and optimise for performance, scalability and costDiscover opportunities for data acquisition and explore new ways of using existing dataIdentify gaps in data processes and drive improvementsCoach and mentor other team membersWhat you bring to the tableWe focus on hiring values-aligned people, because we believe the right person can learn all the things to be successful in their role. Self-belief plays a big part in what you apply for. We encourage all job applicants to apply even if they are nervous to do so. Uni degrees aren't required for any roles, and career gaps or switches are totally welcome.2+ years of Data Engineering, Data Warehousing, or related experience2+ years of development experience with Python or similar scripting language2+ years of SQL experience, including experience with schema design and dimensional data modellingExperience working with AWS services such as DynamoDB, Glue, Lambda, Step Functions, S3, CloudFormation or RedshiftExperience with ETL development, metadata management, and data qualityKnowledge of software engineering best practices with experience with implementing CI/CD, monitoring & alerting for production systemsExperience with complex data structures and No-SQL databasesExperience with open source orchestration platforms (e.g. Airflow)We want the people who care about doing a good job. The ones who have the humility and hunger to learn. - Sam Kroonenburg, Co-Founder and CEOMore than a jobWhere you work isn’t just a career decision — it’s a life decision. Everyone has family, friends and interests outside of their careers, so we offer perks and benefits to make work, work better for you.4 weeks PTO, plus 10 sick days, and holidays. Because even when your office is your living room, we all need time to unplug.Remotely awesome. Get $500 to level up your home office, monthly snack boxes, free Headspace access, weekly lunch funds, and $50 monthly for internet.Human connection. Get to know the Gurus with good times and get-togethers inspired by our values, virtual happy hours, lunchtime trivia, or a socially distanced drive-in movie.Gender-neutral paid parental leave. Expanding your family? We offer 12 weeks of gender-neutral paid parental leave, and reimburse up to $10,000 for eligible adoption expenses.$1,000 continuing education budget. All Gurus get $250 a quarter to spend on personal development, and 2 hours each week reserved for learning something new.What’s the interview process like at ACG?Applying for a job can feel intimidating and like a full-time job of its own. You shouldn’t have to burn through a week of sick time or all your best out-of-office excuses just to put feelers out for a new career opportunity. We want to be as transparent about the process as possible to help ease your mind. It’s our goal to provide you a fair, efficient interviewing experience that respects you and your time — and to do it all with a sidecar of delight.Once you submit an application, we’ll review it. If you’re a good fit, you’ll have an initial chat with a recruiter over the phone. A phone interview with a manager typically follows. Depending on your role, you might then be asked to do a little homework (but nothing too time consuming). Then we’ll schedule a Zoom call to meet other members of the team, answer any questions you have, and give you a feel for what it’s really like to work at ACG. If you're on the fence, just give it a try.Keep being awesome, Cloud Gurus.",aus,de
15,IBM,Information Technology,3.9,Data Engineer,"Austin, TX",$79K - $108K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_d87fc6fc&cb=1619363455666&jobListingId=4039683771,"IntroductionHave you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.Your Role and ResponsibilitiesKey Responsibilities:Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical requirements and support their data infrastructure needs.Provide the ability to work within agile development methodology and collaborate effectively with multi-disciplinary teamsBuild modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements.Understand data architecture, build large-scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow.Have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Have expertise in data persistence solutions, experience with the latest (NoSQL) database technologies, and experience with building complex SQL queries using various (NoSQL or RDBMS) databases such as MongoDB or DB2Experience in software engineering with object-oriented design, coding and testing patterns on large-scale data infrastructuresUse DevOps best practices such as continuous integration, continuous delivery in the production implementation.GarageIBMReferred_NorthAmericaRequired Technical and Professional ExpertiseDevelop code using Python, Scala, R languagesExperience with relational SQL and NoSQL databases, including Postgres and Cassandra3+ years design & implementation experience with distributed applications3+ years of working experience in database architectures and data pipeline developmentDemonstrated knowledge of software development tools and methodologiesComputer Science with software engineering and Math background desiredPreferred Technical and Professional ExpertiseExperience with big data tools: Hadoop, Spark, Kafka, etc.Familiar with big data solutions with experience on Hadoop based technologies such as MapReduce, Hive MongoDB or Cassandra.Experience with stream-processing systems: Storm, Spark-Streaming, etc.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.Knowledge of cloud technologies such as Kubernetes, Cloud Foundry, PaaS, and IaaS (SoftLayer)NONEAbout Business UnitIBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.Impact. Inclusion. Infinite Experiences. Do your best work ever.About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.Location StatementIBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to:12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.Well-being programs to support mental and physical health.Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).Select educational reimbursement opportunities.Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.Giving and volunteer programs to benefit charitable organizations and local communities.Discounts on retail products, services, and experiences.This position is eligible for participation in an IBM sales incentive plan. Actual incentive opportunity will be based on performance and the eligible Target Incentive, as addressed in the applicable plan, all of which is subject to change.We consider qualified applicants with criminal histories, consistent with applicable law.IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",aus,de
16,"Double Line, Inc.",Business Services,3.8,Data Engineer,"Austin, TX",$103K - $184K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=4341&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_e433c9a0&cb=1619363455666&jobListingId=4040987570,"Feeling underappreciated? Underutilized? Want to be a part of a specialized team with exposure to a wide variety of data puzzles to solve, while using your skills to improve education? Come join a team where you can Fly the Plane, not just be a passenger in the back. We're a growing company focused on expanding our Operations team with a solutions-focused Data Engineer. Sound interesting?

If so, we're looking for a motivated and driven person like you who can:

Think creatively and help other data experts on the team figure out the solution to really tough data load or transformation problemsLeverage SQL and/or ETL development, data mapping, and data modeling experience to manage and organize our customer education dataBe obsessed about continuously improving our approach and doing it better and faster the next time

Bonus points if you're bringing knowledge of or really want to learn the following:

Consultancy experience with a focus on Agile practicesAWS and Azure CloudPython or similar scripting languagesAWS Quicksight, Tableau, Power BI, or other visualization tools

We do not want you to make the leap without knowing what we need, so here is how we define success for this position:

Soak up knowledge from the existing team of experts in the first 30 daysBring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 monthsGrow your skills so much that you're ready to teach the next new hire by 2022

In return, we offer:

A mission-driven company with a long-term focus on helping the world by untangling the technical messes that hold back education in our countryA home where your voice matters, and you can effect real changeA company who cares about you, makes sure you're engaged with exciting work and provides a robust benefit offer, 401k with employer match and a great culture.

We need to know - can you make this happen? If so, we definitely need to talk to you.
We value diversity at Double Line. We hire, recruit, and promote without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, pregnancy or maternity, veteran status or any other status protected by applicable law. We understand the importance of creating a safe and comfortable work environment and encourage individualism and authenticity in every member of our team. Double Line does not sponsor applicants for work visas at this time.
Powered by JazzHR",aus,de
17,Splunk,Information Technology,4.2,Data Engineer,"Austin, TX",$122K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=4128&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_fd136b26&cb=1619363455667&jobListingId=4069269172,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.

Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.

Requirements: I’ve already done that or have that!

5+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data ScientistSavviness with complex SQL queries and knowledge of database technologies including window and analytical functionsExperience with Python analytic libraries and Business Intelligence tools such as Tableau.An ability to provide technical guidance, direction and problem solving to data engineering team members.Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.A familiarity working with an AGILE/SCRUM process management.

Preferred knowledge and experience: These are a huge plus.

Knowledge of Splunk productsAgile certifications

Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.

A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.A stable, collaborative and supportive work environment.

We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",aus,de
18,Balyasny Asset Management,Finance,4.2,Data Engineer – Data Acquisition,"Austin, TX",$103K - $184K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=242900&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_a376a8f6&cb=1619363455667&jobListingId=4014237262,"The Job Details are as follows:

The Data Intelligence Group (DIG) is a key part of BAM’s continued growth. Year over year, the knowledge needed to leverage data plays an increasingly important role in the firm’s core business. The analysis, services, software, and operational expertise that DIG provides are part of BAM’s competitive advantage.

Role Overview

We are looking for creative and enthusiastic Data Engineers to join our team in building the best Data Platform on the street. We’re responsible for managing the flow of data into the firm, maintaining the data lake, creating analytics-ready datasets, and building the APIs that make everything accessible to our clients. Our singular goal is to help our investment teams use data to make better investment decisions.

Our analysts and systematic trading teams rely on us to provide analytics-ready datasets. For each dataset we must consider the implications of point in time storage, optimize for our users’ access patterns, and create useful aggregations/slices. Our ideal candidate will have experience with storing, transforming, and modeling big data. In this role, you will:

Develop cloud-first data ingestion processes using Python, SQL, and SparkEngineer data models and infrastructure for a wide variety of market and alternative datasetsDesign and build services and plugins to enhance our Data Acquisition PlatformMaintain alerting systems to ensure smooth day-to-day operations for hundreds of datasetsAuthor tests to validate data quality and the stability of the platformInvestigate and defuse time-sensitive data incidentsCommunicate with data providers to onboard new datasets and troubleshoot technical issuesEvangelize best practices to our partners throughout the firmWork directly with Analysts, Quants, and Portfolio Managers to understand requirements and provide end-to-end data solutions

WHAT YOU’LL BRING

Bachelors/Masters degree in Computer Science or a related fieldStrong analytical, data, and programming skills (Python/SQL/NoSQL)3+ years of experience with at least one of Spark/Hive/Hadoop2+ years of experience orchestrating pipelines with a technology like Airflow/Luigi/Oozie/Nifi1+ years of experience with cloud technologies ( AWS / Azure / Google Cloud )Solid understanding of time series data and temporal queriesExperience with large data sets and techniques to architect them for performanceAbility to understand and contribute to our existing data system softwareAptitude for designing infrastructure, data products, and tools for Data Scientists a plusFinancial industry experience is a plusStrong oral and written communication skills, most importantly, must be a team player
",aus,de
19,Ascension,Health Care,3.5,Senior Data Engineer,"Austin, TX",$86K - $152K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_caa9b63a&cb=1619363455667&jobListingId=4042230298,"We Are Hiring:Ascension is a faith-based healthcare organization dedicated to transformation through innovation across the continuum of care. As one of the leading non-profit and Catholic health systems in the U.S., Ascension is committed to delivering compassionate, personalized care to all, with special attention to persons living in poverty and those most vulnerable. In FY2019, Ascension provided $2 billion in care of persons living in poverty and other community benefit programs.Ascension includes more than 150,000 associates and 40,000 aligned providers. The national health system operates more than 2,600 sites of care – including 150 hospitals and more than 50 senior living facilities – in 20 states and the District of Columbia, while providing a variety of services including clinical and network services, venture capital investing, investment management, biomedical engineering, facilities management, risk management, and contracting through Ascension’s own group purchasing organization.What You Will Do:Responsible for construction and development of large-scale cloud data processing systems.The Data Engineer must have considerable expertise in data warehousing and job requires proven coding expertise with Python, Java, SQL, and Spark languages. Must be able to implement enterprise cloud data architecture designs, and will work closely with the rest of the scrum team and internal business partners to identify, evaluate, design, and implement large scale data solutions, structured and unstructured, public and proprietary data. The Data Engineer will work iteratively on the cloud platform to design, develop and implement scalable, high performance solutions that offer measurable business value to customers.Required Work Experience:Four to seven years of experience required.Some of the minimum experience requirement may be met with Masters or other advanced degreeCloud Experience RequiredCoding experience with Python, Java, Spark, and SQLStrong Linux/Unix background and hands on knowledge.Past experience with big data technologies including HDFS, Spark, Impala, Hive,Experience with Shell scripting and bash.Experience with version control platform git-hubExperience unit testing code.Experience with development ecosystem including Jenkins, Artifactory, CI/CD, and Terraform.Works on problems of diverse scope and complexity ranging from moderate to substantialAssists senior professionals in determining methods and procedures for new tasksLeads basic or moderately complex projects/activities on semi-regular basisMust possess excellent written and verbal communication skillsAbility to understand and analyze complex data setsExercises independent judgment on basic or moderately complex issues regarding job and related tasksMakes recommendations to management on new processes, tools and techniques, or development of new products and servicesMakes decisions regarding daily priorities for a work group; provides guidance to and/or assists staff on non-routine or escalated issuesDecisions have a moderate impact on operations within a departmentWorks under minimal supervision, uses independent judgment requiring analysis of variable factorsRequires little instruction on day-to-day work and general direction on more complex tasks and projectsCollaborates with senior professionals in the development of methods, techniques and analytical approachAbility to advise management on approaches to optimize for data platform success.Able to effectively communicate highly technical information to numerous audiences, including management, the user community, and less-experienced staff.Consistently communicate on status of project deliverablesConsistently provide work effort estimates to management to assist in setting prioritiesDeliver timely work in accordance with estimatesSolve problems as they arise and communicate potential roadblocks to manage expectationsAdhere strictly to all security policiesDesired Work Experience:Proficient in multiple programming languages, frameworks, domains, and tools.Coding skills in ScalaExperience with GCP platform development tools Pub/sub, cloud storage, big table, big query, data flow, data proc, and composer desired.Strong Linux/Unix background and hands on knowledge.Knowledge in Hadoop and cloud platforms and surrounding ecosystems.Experience with web services and APIs as in RESTful and SOAP.Ability to document designs and conceptsAPI Orchestration and Choreography for consumer appsWell rounded technical expertise in Apache packages and Hybrid cloud architecturesPipeline creation and automation for Data AcquisitionMetadata extraction pipeline design and creation between raw and finally transformed datasetsQuality control metrics data collection on data acquisition pipelinesAble to collaborate with scrum team including scrum master, product owner, data analysts, Quality Assurance, business owners, and data architecture to produce the best possible end productsExperience contributing to and leveraging jira and confluence.Strong experience working with real time streaming applications and batch style large scale distributed computing applications using tools like Spark, Kafka, Flume, pubsub, and airflow.Ability to work with different file formats like Avro, Parquet, and JSON.Managing and scheduling batch jobs.Hands on experience in Analysis, Design, Coding and Testing phases of Software Development Life Cycle (SDLC).Qualifications and Education:Master level technology degree preferredWhat You Will Need:Education:High school diploma/GED with 2 years of experience, or Associate's degree, or Bachelor's degree required.Work Experience:1 year of experience required.4 years of experience preferred.2 years of leadership or management experience preferred.Why Join Our Team:Ascension is a faith-based healthcare organization dedicated to transformation through innovation across the continuum of care. As one of the leading non-profit and Catholic health systems in the U.S., Ascension is committed to delivering compassionate, personalized care to all. In FY2020, Ascension provided $2.4 billion in care of persons living in poverty and other community benefit programs. Ascension includes more than 160,000 associates and 40,000 aligned providers across a national network of ministries. We offer rewarding careers across more than 2,600 sites of care – including 146 hospitals and more than 50 senior living facilities – in 19 states and the District of Columbia.Equal Employment Opportunity Employer:Ascension Technologies is an equal opportunity employer (EEO) and affords equal opportunity to all associates and applicants without regard to race, color, religion, national origin, gender identity, sexual orientation, age, physical or mental disability, veteran status, genetic data, or other legally protected status. For further information regarding your EEO rights, click on the following link to the “EEO is the Law” poster:http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdfEEO is the Law Poster SupplementPlease note that Ascension will make an offer of employment only to individuals who have applied for a position using our official application. Be on alert for possible fraudulent offers of employment. Ascension will not solicit money or banking information from applicants.",aus,de
20,Stamps.com,Information Technology,4,Data Engineer,"Austin, TX",$70K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=4120&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_0cdf62e4&cb=1619363455667&jobListingId=4069899712,"The Analytics team is responsible for making Auctane’s data reliable, trustworthy and easy to use. We do this by creating a data ecosystem that enables Auctane to use data to make our product better, facilitate decision making, and help drive business value. In addition, the Analytics team partners with stakeholders from across the business to deliver both standardized & ad-hoc reporting, analysis & insights to drive business decisions.

Strategic Imperative:

The Data Engineer will maintain our existing integrations as well as build new ones as the company adopts new software systems to meet its needs. Data from these integrations needs to be ingested, transformed, and combined in order to provide valuable insights to stakeholders across the organization. Sales, Marketing, Customer Support, and the Product teams currently use a variety of systems that have limited ability to talk to communicate with each other. By consolidating this data into one data warehouse, the various teams can see how their work affects customers and the company.

Primary Objectives:

Build integrations for all relevant internal systems
Ensure high level of data quality in data warehouse
Monitor and support ETL processes
Provide data to various stakeholders across the company through BI tools and operational applications

Qualifications - To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Essential Position Duties (typical monthly, weekly, daily tasks):

Manage new data integration projects



Identify relevant data which needs to be extracted
Create necessary infrastructure to support integrations
Transform data to increase usability for stakeholders


Support existing system integrations



Ensure that integrations are ingesting correct data
Ensure that integrations run on a regular schedule
Fix issues in pipelining processes as they arise


Communicate changes in data warehouse and integrations to relevant parties across the company



Know which stakeholders need information from which integrations
Communicate any changes or outages to relevant parties



Skills and Knowledge:

Proficient in Python
Hands-on experience implementing ETL (or ELT) best practices at scale.
Hands-on experience with data pipelining tools (Airflow, Dagster, Prefect, dbt, Meltano)
Have a deep understanding of SQL, data modeling, and analytical data warehouses, such as Redshift or BigQuery.
Proactive communicator who can translate between technical and non-technical stakeholders
Team player who gives and takes feedback in a thoughtful way, and loves to help others.
Thrive on autonomy and have experience driving long-term, cross-functional projects to completion.
Use distributed source control such as Git proficiently

Education and/or Experience:

Bachelor’s degree in Computer Science or Engineering or equivalent years’ experience.
At least two years’ experience in data engineering or ETL/ELT processes.

Preferred Experience:

Experience with the specific tools we currently use



Airflow, Kafka, dbt, Amazon Redshift


Experience orchestrating machine learning

Computer/Software/Application Proficiency:

Python, SQL
Github, Atlassian Jira

Travel Requirements:

10% or less

Additional Position Duties: – (The following is a list of what all employees, except those with medical accommodation, may be regularly required to do.)


Sit for prolonged periods of time
Utilize wrist and hands for a prolonged period of time
Walk short distances
Stand for short periods
Speaking and conversing with others
Lift up to 25lbs without assistance up to chest height

Equal Opportunity Employer/Veterans/Disabled

If you are based in California, we encourage you to read this important information about the ShipStation Privacy Policy for California residents linked here.

#LI-MF1",aus,de
21,Jobot,Business Services,4.8,Data Engineer,"Austin, TX",$88K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=798489&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_737f3c6d&cb=1619363455667&jobListingId=4064678699,"Growing Financial Services Company Seeks a Data Platform Engineer / Data Analyst in Austin!This Jobot Job is hosted by: Reed KellickAre you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.Salary: $100,000 - $160,000 per yearA bit about us:Based in Austin, we are a rapidly-growing financial services company that is looking to expand its data and analytics team. As a Cloud Data Engineer / Big Data Software Engineer on our team, you will help modernize our solutions to the next-generation cloud platform.Why join us? Competitive Base Salary between $100k and $160k, depending on experience! 15% annual bonus! $2k - $5k relocation assistance! 401k match up to 3%! 18 days PTO per year! 11 paid holidays per year! Very competitive benefits package: health / dental / vision! High-growth company! Backed by best Private Equity firm! Strong strategy and execution! Fast-paced agile team environment! Opportunity to learn! Working with latest and greatest technologies! Flexible work options in the near future (week on/off for in-office/remote)! Modern workspaces! Car parking spaces! Fantastic city!Job DetailsAs a Big Data Engineer / Software Engineer on our team, we are looking for: Strong experience with NoSQL database, including Postgres Background in working with Azure Cloud Services: Data Factory, SQL database, Functions, Data Lake, Databricks, Logic Apps, and Azure Automation. Fluent in object-oriented and functional script language: Python, Scala, and C#. Advanced working knowledge of SQL Server database - writing advanced SQL script, profiling, and optimization. Working knowledge of Business Intelligence tools: Microsoft Integration Services, Reporting Services, and Analysis Services, as well as PowerBI. Experience with other Big Data tools such as Spark, Snowflake, and Kafka Bachelor's or Master's in Computer Science or related would be preferred Financial industry background would be helpful, but not necessaryInterested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",aus,de
22,REX,Real Estate,4,Data Engineer,"Austin, TX",$75K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c4a2d570&cb=1619363455667&jobListingId=3809203543,"At REX, we are growing fast and hiring passionate, intelligent people to join us on our mission of becoming the BEST company in the world! We are changing the way people buy and sell homes by using technology to make the process more convenient and transparent. Come work with a company that is passionate about putting the consumer first as well as your career growth.About REXREX is a well-funded, game-changing real estate technology startup with offices in Austin, Los Angeles, and the Bay Area. With the goal of improving the lives of homebuyers and sellers, REX created a digital platform and real estate service that eliminates traditional agent commissions and shifts control away from agents over to those who matter most: consumers! REX saves homesellers thousands of dollars in fees by going around the MLS to target home-buyers directly with sophisticated marketing that has never been used in real estate. Since its launch in Southern California, REX has expanded to 17 states and over 250 employees. Throughout the years, REX has represented homes cumulatively valued at over $1 billion and in the process, saved customers over $20 million in fees they otherwise would have paid traditional brokers.About the PositionAs a DevOps Engineer, you’ll work on solving scalability, performance, and automation problems, and helping us to grow our business. You’ll be responsible for both customer-facing and internal systems. You’ll also be responsible for working with, helping, or teaching other engineers about how to run systems that are reliable, performant, scalable, and automated. You’ll be flexible and open-minded about using a wide variety of tools and will focus on getting the job done right, not on processes and rules. You’ll add, create or enforce formal processes only when it helps us to move faster.As a Data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.Experience & QualificationsOur ideal candidate brings the following:Significant experience with multiple data platforms, including SQL and NoSQL systems.Experience with ETL pipelinesComfortable coding in backend languages such as Java, Python, and GoAWS experienceExperience with distributed batch data-processing techniques and toolsBonus Points:Experience with web-scale architecturesKafkaSparkMap-Reduce, Hive or any big data technologyDRUIDJava proficiencyPython proficiencySocial Mission:REX sets aside a portion of all income from selling homes to fund homes for families in dire need. It is our mission to contribute one home for every 50 homes we sell. We started in Sihanoukville, Cambodia, where we partnered with World Housing and the Cambodian Children's Fund to help homeless families get back on their feet.Perks and BenefitsAt REX, we appreciate diverse perspectives and want each person to feel valued and impactful in their work. We believe in nurturing your career growth at a fast pace and giving recognition where it's due!Listed below are just some of the awesome perks available when joining REX:Competitive base & bonus packages plus stock optionsOpen and flexible PTO planBenefits, including medical, dental & vision insurance, as well as 401(k)Career growth opportunitiesCell phone & Internet reimbursement for some rolesParental leaveEmployer discounts on select home servicesSome perks do not apply to contract workers or internsAdditional InformationAs a pioneer in our industry, REX is setting new standards in the marketplace – for quality, innovation, integrity, professionalism, drive, consumer happiness, and social good. Our culture, together with our business vision and goals, serve as an orientation for leadership and a guide for how we conduct ourselves in day-to-day business. They also form the foundation for hiring, encouraging and rewarding great people. In addition, REX has been committed to doing good things for real estate consumers and to providing homes for those in the greatest need, wherever they may be. For every 50 homes we sell, we provide a home for a family in need. We started by funding the construction of a home for a family in Cambodia at the end of 2015. In addition to funding homes, the REX team regularly provides hands-on support to local nonprofits that provide shelter to families.DrXhLjoF6s",aus,de
23,Babylon Health,Information Technology,3,Data Engineer,"Austin, TX",$91K - $129K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_4888c2b8&cb=1619363455667&jobListingId=4015471271,"We are a team on a mission, to put accessible and affordable healthcare in the hands of every person on earth. Our mission is bold and ambitious, and it’s one that’s shared by our team who shares our values, to dream big, build fast and be brilliant.To achieve this, we’ve brought together one of the largest teams of scientists, clinicians, mathematicians and engineers to focus on combining the ever-growing computing power of machines, with the best medical expertise of humans, to create a comprehensive, immediate and personalized health service and make it universally available.At Babylon our people aren’t just part of a team, they’re part of something bigger. We’re a vibrant community of creative thinkers and doers, forging the way for a new generation of healthcare. We’re only as good as our people. So, finding the best people is everything to us.We serve millions, but we choose our people one at a time…We are looking for a unique Data Engineer who will build, test and refine data pipelines for data analytics and business intelligence (BI). We are looking for a highly motivated data engineer that can help implement methods to improve data reliability and quality. You will combine raw information from different sources to create consistent and analytics ready data sets. You will work intimately with the analytics team and across multiple product and technical teams in order to help us build the first digital general practice that can support millions of patients.ResponsibilitiesBuild, test and refine data pipelines for data analytics and business intelligence (BI)Data modeling, process design and overall data pipeline architectureEnsure the data quality and consistency with monitoring support, and play an active role in establishing data governance around company KPIsWork closely with the business intelligence teams to design, build and test end-to-end solutionsWork closely with the data science team to support processing data into a form suitable for machine learning modelsChampion SSDLC (secure software development lifecycle) within analytics and data science and lead by example in building self-service, well tested solutionsChampion high engineering standards through comprehensive testing, code reviews, continuous integration and continuous deployment across the teamOur technology stack includes Python, dbt, Airflow and a host of Google Cloud products that run on a range of technologies (GCP/AWS, Docker, GitHub, CircleCI & Jenkins)RequirementsBachelor’s degree in computer science or related fieldProven ability of looking at solutions unconventionally and explore opportunities and devise innovative solutionsExcellent communication skills (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teamsExperience gathering complex business requirements and identifying data needsExperience with design and development of relational databases and data warehousesAdvanced level of proficiency in SQL developmentKnowledge and expertise with Python, Shell, Java ScriptingETL development experience with large-scale databases or big data systems such as Hive, BigQuery, AWS Redshift, Snowflake, etc.Experience using data transformation tools such as dbtExperience using data orchestration tools such as Apache Airflow or Apache BeamExperience with using a cloud platform provider (such as AWS/GCP) to develop tools and infrastructureExposure to a BI reporting tool (such as Tableau, Looker or PowerBI) with an understanding of why they are an important part of the analytics stackExperience analyzing data to identify deliverables, gaps and inconsistenciesNice to have: experience working in a start-upWe believe that difference inspires a better, healthier world. That’s why it’s at the heart of everything we do. From our people to our products, difference enriches every part of our business and creates a culture based on equality of opportunity, and in which all Babylonians can progress their careers. We’re committed to creating an environment of mutual respect where equal employment opportunities are available to all applicants without regard to race, colour, religion, sex, pregnancy status, national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information, and any other characteristic protected by applicable law.At Babylon, we have Power of Diversity groups (PODs) to drive positive engagements that create and foster a diverse and inclusive environment and we seek to recruit, develop and retain the most talented people from a diverse pool of candidates.Our mission is to put an accessible and affordable health service in the hands of every person on earth. Diversity and inclusion play a key role in helping us bring this mission to life and create a true sense of belonging for all.",aus,de
24,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,Staff Chemical Engineer,"Austin, TX",$56K - $93K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_93b7b81e&cb=1619363455667&jobListingId=4070655703,"How will you make an impact?When you’re part of the team at Thermo Fisher Scientific, you’ll do important work, like helping customers in finding cures for cancer, protecting the environment or making sure our food is safe. Your work will have real-world impact, and you’ll be supported in achieving your career goals. The Staff Chemical Engineer is a key to defining and developing instrument and consumable products in the Biosciences Division. This individual will assist with leading system definition & system integration aspects of product development in collaboration with highly technical and specialized engineering professionals and scientists to develop instruments and applications for our world class Automated Sample Prep and qPCR platforms in both RUO and IVD markets.What will you do?Understand clinical customers and effectively translate their needs to product requirementsPartner with our Product Management teams to define system architecture and integration design, development, feasibility testing.Work with cross-functional subsystem owners to design and develop integrated systems from beginning to end of the clinical sample workflow(s) including leading stage gate design reviews, d/pFMEA processes, and design documentation.Plan, develop, and analyze system integration in order to maintain requirement traceability through various subsystems and verification activities in collaboration with subsystem requirements ownersContribute to data-driven decision making by designing experiments, analyzing, and presenting resultsWork together with the Operations team to transfer your products into manufacturing or other R&D teams.How will you get there?Education / ExperienceBS/MS. degree in an Engineering, Applied Physics or Molecular Biology or other scientific discipline.7+ years’ experience in a life science instrumentation, consumables, and assays in R&D setting, preferably in genomicsExpertise with automated liquid handlers such as Hamilton systems including programming/scripting liquid handling systems3+ years’ experience as technical lead in new product developmentpreferably 3+ years’ experience serving regulated markets in a commercial environmentTrack record of delivering successful RUO and IVD products with a thorough understanding of quality systemDemonstrated success working in a global matrixed environment & willingness to travel up to 25%, domestic or internationallyDemonstrated ability to effectively build and manage internal and external relationships at senior levelsKnowledge, Skills, Abilities:Considerable experience in developing moderate complexity integrated life sciences or clinical instrumentation, consumables, and software in an IVD environmentDemonstrable expertise in systems engineering processes, from requirements gathering and risk analysis to statistical power in validationA solid understanding of genetic analysis tools, workflows, and chemistry in at least one of these areas: qPCR and sample preparationDemonstrated experience working across multi-disciplined teams / cross - functional teams –scientists, engineers and software personnel. Demonstrated success at networking across the company.Excellent organizational skills, including the ability to efficiently evaluate, prioritize and handle multiple and changing programs/projects and priorities.Experience in working with regulatory teams and knowledge of regulatory agency requirements. This includes, QSR - 21 CFR 820.30, 21CFR Part 11, ISO13485, ISO62304, and international regulatory requirementsKey people attributes:Fosters collaborative relationships and builds credibility across functions/teamsInspires, influences, and empowers employees across a global matrix to achieve goalsAble to decisively lead and empower teams to develop impactful strategies and plansMaintains a high level of professional expertise through familiarity with current engineering/scientific literature, competing technologies, and/or products as well as attendance of seminars and meetings.",aus,de
25,Marsh and McLennan,Insurance,3.9,Data Engineer,"Austin, TX",$66K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_7c29e745&cb=1619363455668&jobListingId=3761404744,"Marsh is seeking candidates for the following position based in the Austin or Toronto OfficeData EngineerWhat can you expect?The Data Engineer is responsible for providing technical design, governance and technical delivery of data related solutions. Typical projects involve Master Data, Management Information and analysis solutionsThe role holder will be a self starter able to work on their own initiative following the strategic guidelines laid down by the MMC and Marsh architects.Guide and assist the business and IT delivery teams to help define and deliver Marsh’s change pipeline.What is in it for you?Competitive Health, Wealth and Vacation BenefitsExposure to strong senior leadership, at the forefront of new decisions, opportunity for advancement on many career paths,Be part of a growing teamWe will count on you to:Solution design and development using appropriate technologies.Manage the data domain and associated metadata as part of a continuous process.Design and develop data related solutions. Key emphasis on business delivery with one eye on quality code, automation and industry best practices.Understand how to communicate data as information and appreciate the key aspects of data quality and data visualization.Understand the need for data management policies, guidelines and protocols when handling data. An understanding of data related regulation would be an advantage.Proactively contribute to the information and system architecture and toolset choices.Develop and provide guidance on coding and reporting standards.Understand different project methodologies and be comfortable working in any of agile, waterfall or DevOps.Collaborate with Product Owners and architects to ensure the right solutions are designed and implemented.Implement where possible; build, test and deployment automation for solutions.Strong functional and data analysis skillsAbility to debug and fix software.Produce and be responsible for solution architecture and design documentation.Govern solutions where other developers and testers are involved.Enforce architecture best practice, standards and strategy.Understand the concept of technical debt and manage it effectively to conclusion.Understand commercial drivers, benefits and constraints for projects.What You Need to HaveBachelor’s degree or equivalent.Relevant experience in the insurance industry.3-5 years experience as a developer/data architect with current development skills. Ideally in a lead capacity within the team.Self starter, able to work independently and be comfortable with ambiguity.An understanding of the commercial implications of decisions made at all project lifecycle stages.Proven experience working in with third party service providers including offshore resources on delivery programs and projects.Knowledge of all SDLC phases in a variety of project methodologies.Data Processing Technologies: AWS, Hadoop/Hive/Presto, Dremio, MongoDB, Oracle, Postgres, MS SQL Server, DB2Data Management and BI Technologies: Qliksense/Qlikview, Tableau, PowerBI, Business Objects, Crystal Reporting, Erwin, Informatica BDM/Powercentre, Informatica DQ/EDC, PythonSoftware management: BitBucket, Jira, Confluence, CI/CD pipelines (Jenkins)Others: Enterprise Architect, XMLSpy, Javascript, Java 8 (Spring, Hibernate, Maven, REST API’s) JSON, XML/XSDMarsh is the world’s leading insurance broker and risk adviser. With over 35,000 colleagues operating in more than 130 countries, Marsh serves commercial and individual clients with data driven risk solutions and advisory services. Marsh is a business of Marsh & McLennan Companies (NYSE: MMC), the leading global professional services firm in the areas of risk, strategy and people. With annual revenue approaching US $17 billion and 76,000 colleagues worldwide, MMC helps clients navigate an increasingly dynamic and complex environment through four market-leading businesses: Marsh, Guy Carpenter, Mercer, and Oliver Wyman. Follow Marsh on Twitter @MarshGlobal; LinkedIn; Facebook; and YouTube, or subscribe to BRINK.Marsh & McLennan Companies and its Affiliates are EOE Minority/Female/Disability/Vet/Sexual Orientation/Gender Identity employers.T",aus,de
26,Dealerware,Information Technology,4.7,Lead / Senior Data Scientist,"Austin, TX",$137K - $175K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1044074&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_7257d571&cb=1619363455668&jobListingId=4013687804,"About Dealerware:Dealerware is modern fleet management for the modern retailer. We are proud to be one of the hottest software companies in the automotive sector. By combining a modern-approach with fresh design thinking, Dealerware’s industry-leading SaaS platform enables best-in-class fleet management and mobility for top automotive dealerships and manufacturers. Three years ago, we burst onto the scene with a promise to reduce costs and elevate the customer experience at automotive dealerships. Today, we’re experiencing 100% YOY growth and are positioned to truly change the way the world hits the road. Across the automotive ecosystem, there’s hundreds of billions of dollars at stake. And we’re right in the swell of it.Dealerware is looking for a Lead/Senior Data Scientist to apply their leadership and experience in data science development to manage and grow a small team of data scientists to innovate in the fleet management and connected car space. They will need a deep understanding of statistics analytics, machine learning, and programming to discover hidden opportunities, trends, and patterns. Working cross-functionally with our team they will understand the data science and analytics and business requirements that will help our product unlock data insights for our customers. We are looking for a strong self-starter who will work closely with product management, engineering, design, and research to co-create and drive a culture of curiosity and experimentation.As a Lead/Senior Data Scientist, you will: Lead and grow a small team of data scientists to use Dealerware's data and connected car data to deliver insights using machine learning and statistics to our customers and internal stakeholders Work cross-functionally to establish a data science process for product development to understand requirements and opportunities to implement data science to improve existing features and innovate towards future features Collaborate with data engineers and data architects to implement needed data pipelines for data science-related features and a robust data ecosystem Clearly define the scope of work and deliverables for business requirements Lead all phases of the model development process from data processing, feature selection, engineering, model training and testing, and synthesizing information in reports Identify key product KPIs and analytics, and develop experiments to thoroughly test and validate development team’s output based on business requirements Synthesize large sets of structured and unstructured data from disparate sources Ability to translate complex problems/concepts and synthesize into easily communicable findings to a variety of stakeholders using visualization and other means Develop benchmarks that measure the performance of our algorithms and telematics/connected car device services Be a thought leader in innovation and planning for the future data-driven capabilities in Dealerware Research and communicate to leadership new machine learning and artificial intelligence possibilities that can be applied in the connected car and fleet management spaceYour peers would say you: Are a strong writer and communicator, and feel at home in the product & design team Make things work, get things done, and are a great team player You are self-motivated, detail-oriented, and can successfully navigate complexity and ambiguity Go above and beyond to make sure the team is successful Make informed decisions and know when to ask for advice You apply the latest methodologies and keep up to date on your craft and practice You love working with diverse teams and personalities Leave things better than you found themPreferred qualifications: PhD or Masters in a quantitative field such as Mathematics, Physics, Life Sciences, or Computer Science 2 years experience hiring, building, and leading a small team of data scientists including helping them grow their skills and careers 3+ years of experience using statistics and machine learning algorithms for forecasting, time series, anomaly detection, and classification to understand business data Strong skills in Python and a good understanding of the Python data science ecosystem and how to scale data science for a production environment Understanding of data modeling for relational databases, data warehouses, and SQL Ability to understand and work across complex systems to outline data requirements from the systems Demonstrated ability to work cross-functionally including strong presentation and data visualization skills Experience clearly distilling information about data analytics, data science, and data products to designers, product managers, engineers, and company leadership Familiarity with working in an Agile development environment and working data science development into an iterative process to facilitate incremental improvements in the productDealerware offers you: Competitive base salary with bonus incentive eligibility Full benefits (medical, dental, vision, 401K) + FREE telehealth (includes therapy visits) Training for all employees provided in Udemy Tuition Reimbursement and continuing education Unlimited paid vacation policy Generous Paid Parental Leave program 100% remote work (during COVID). Hybrid model anticipated post-COVID Modern office and a dynamic team in downtown Austin with free parking Friendly, small company environment with a progressive culture and somewhat flexible hours Backed by Audi, a 111-year-old automotive industry leader Semi-flat organizational structure that ensures your influence on products we build Discounts on Silvercar rentals and participation in an Audi Lease ProgramIND456Dealerware is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and pregnancy-related conditions), gender identity or expression (including transgender status), sexual orientation, marital status, military service and veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable federal, state or local laws and ordinances. Dealerware's management team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities, access to facilities and programs and general treatment during employment.We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.",aus,de
27,Teladoc Health,Health Care,3.9,Senior Data Engineer,"Austin, TX",$100K - $176K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2f04f3cb&cb=1619363455668&jobListingId=3733729671,"RemoteThe OpportunitySimply stated, Teladoc Health exists to empower people with chronic conditions to live better and healthier lives. Teladoc Health is seeking an engineer with an emphasis on data processing, transformation, fidelity and scalability. The applicant should have a strong interest in the interface between real-time and reporting systems, pulling data from multiple sources into central data storage, and collaborating with internal Livongo teams to help provide for their data needs.What makes a Senior Data Engineer at Teladoc Health different?It is engineering! Members are why we come to work every day and our engineers design and developing the product, product features, and tools for members to have a best in class health consumer experience throughout their journey with LivongoStrong communication skills especially around collaboration with internal Livongo teamsAfter our Members, data is pretty significant at Livongo and our engineers design and develop data pipelines to manage how data flows between our disparate systemsDevelop real time member registration with our CRM, integrating data systems across businesses like MyStrength, Retrofit, Livongo, etc.Work with Scala, Python, Tensorflow, Keras, SKL (or Scala/DL4J) to build production-grade machine learning (ML) pipelines and toolsCreate tools and data sets to assist data sciencePerform continuous integration to ensure that every step of an ML pipeline is testable and automatedAssist in maintaining data integrity in production systemsUse trained models to enable rapid experimentationParticipate in Agile planning around data feature requests and advocate for the best data engineering projects in priority planning.Collaborating closely with Teladoc Health's ML experts, Data Scientists, Product Managers and clinical researchers to build products that help people live better lives Candidate ProfileExperience with big data technologies such as Hadoop and Spark, and a strong depth of expertise with at least one of theseUnshakeable (nearly innate) grasp of software engineering fundamentalsSpecific experience creating and maintaining production pipelinesKeen attention to detail and a knack for prioritizing competing objectivesThe ability to solve real-life business problems with dataA passion for using your work to improve livesBS degree in Engineering, Computer Science or a related field. In lieu of degree, relevant work experience and/or trade school is acceptable7+ years' experience in software development3+ years in a data engineering roleStrong SQL development experience (Postgres / AWS Redshift/MySQL)Expertise in Scala, Java, or PythonPeople and culture are Teladoc Health's greatest and most valued assets! We've built a culture we are proud of that reflects our values of diversity and inclusion where everyone's voice is equally important.Our Benefits IncludeCompetitive compensation packagesComprehensive medical, dental, vision and 401KGenerous PTO policy10 paid holidays each yearLunch provided Monday through Thursday (in office)An endless variety of healthy snacks and beverages to fuel your creativityEmployee Stock Purchase PlanEmployee Referral Bonus ProgramTeam events and social gatheringsPet-friendly environment in Mountain View, CA and DenverDiabetes Care Prescription ReimbursementDiscount/Subsidy program for gym membershipProvide the full line of Livongo programs and services to all employees and their familiesWhy Join Teladoc Health?A New Category in Healthcare: Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person's health journey.Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.Focus on PEOPLE: Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.Diversity and Inclusion: At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.Growth and Innovation: We've already made healthcare history, yet we remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding – we have a mother's room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.#LI-Remote",aus,de
28,Expedia Group,Information Technology,4,Data Engineer III,"Austin, TX",$127K - $144K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_219421df&cb=1619363455668&jobListingId=4043800546,"Expedia Group (EG) revolutionizes travel through the power of technology. Across the globe, our brands make travel easier for millions of people who want to step out of their homes and into the world. We’re a hardworking and focused team from all over the world – with 20,000 + employees, in over 30 countries. Together we seek new ideas, innovative ways of thinking, diverse backgrounds, and approaches because averages can lie and sameness is dangerous.We at Cost Transparency Team is looking for an experienced Data Engineer to build and support our Cloud Cost Platform which powers cloud cost analytics, governance and optimization for all the Expedia brands. Your main responsibility will be working with the team and partners to define, design, and implement next-generation cloud finance management solution, apart from maintaining and growing the existing business needs.What will you doYou will build/extend our full stack cloud cost management suite which includes a large scale data pipeline, APIs, Web UI and analytics dashboardsBuild solutions to help improve the unit economics for Expedia Group by providing deeper visibility into cost of our platforms at transactional levelInteract with our platform teams and peer groups to understand technical/business requirements and implement end-to-end solutions for themDrive data investigations across organization inside and outside of team to deliver a resolution of technical, procedural, and operational issuesYou will influence large scale projects to set the future direction for cloud finance management and analytics across Expedia GroupWho you are2+ years of hands-on experience designing and operating data pipelines using Spark, Hive, MySQL, Airflow or similar frameworksAbility to work with Java, Scala, Python or similar programming languages and experience in Maven, SBT, Git, JenkinsHave basic understanding of OOP, SOLID and other commonly used design principles with ability to write clean unit testable codeSpecialist in SQL. Good understanding of Data Warehousing and ETLGood understanding of BigData Technologies like Hadoop, Spark, Hive, Kafka etcPrior experience in API/UI development using any language framework is a huge plusQubole, Airflow, Dremio, Presto, BI tools (Tableau, Looker, Superset) knowledge is a plusExperience in implementing SDLC methodologies and working in Agile SCRUMBS in Computer Science, Mathematics, Statistics, or related fieldBackground in cloud billing, financial systems, e-commerce, or a comparable reporting and analytics role would be a plusWhy join usExpedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, hardworking, and creative people in our business. Our brands recognize the ability of travel to break down barriers and make people's lives better – that responsibility encourages us to be the place where remarkable people want to do their best work and to provide them with tools to do so.Whether you're applying to Engineering or Customer Support, Marketing, or Lodging Supply, at Expedia Group we act as one team, working towards a common goal: to bring the world within reach. We strive passionately for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground, so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.If you have a hunger to make a difference with one of the most loved consumer brands in the world and to work in the dynamic travel industry, this is the job for you.Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age. Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.",aus,de
29,Sense Corp,Business Services,4.2,Senior Data Engineer,"Austin, TX",$94K - $170K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=14295&s=58&guid=000001790995606a828109df74cdc722&src=GD_JOB_AD&t=SR&vt=w&cs=1_659fc406&cb=1619363455668&jobListingId=4066115128,"Sense Corp is seeking a brilliant, creative, fun, and passionate Senior Data Engineer. Our Data Engineers work with cross-functional teams and stakeholders, are passionate about data accuracy and reliability and are always looking for new and more efficient ways to extract, process, and transform data. As part of our Technology division, you will collaborate with the team while individually contributing to project deliverables that meet our clients’ needs.

Lead technical teams and developers to design, implement, and operationalize advanced data pipelines for reporting, machine learning, and other business critical applications Define customer and business requirements to implement robust cloud-based technical architectures and solutions for end users. Regularly interface with client sponsors and team members to meet project deadlines and provide clear communication with the team Provide documentation and explanation of technical solutions in a professional manner Collaborate and closely align with solution architects, data analysts, and cloud engineering teams

Requirements

Deep expertise and hands-on experience developing and deploying SQL, Python, and Spark-based data pipelines into production environments Deep experience with OLTP (MS SQL Server, Oracle, MySQL, PostgreSQL) and OLAP (Redshift, Snowflake, BigQuery, Synapse) database technologies Significant hands-on technical experience with DevOps and CI/CD processes and tools, such as Azure DevOps, Jenkins, AWS CodePipeline, and Google Cloud Build Strong experience with major cloud platforms and tooling, especially Azure, AWS, and Google Cloud Strong interpersonal skills, presentation, and data narration / storytelling abilities with demonstrated ability to present to executive audiences Strong experience using data manipulation tools to source, transform, and blend data from multiple different data sources US Citizen or GC Holder

Preferred

Having examples of scaling production-facing applications in large enterprise environments 3+ years of consulting experience Experience in mentoring and career development for junior resources 

Experience using Big Data or Cloud integration technologies such as Databricks, Matillion, Azure Data Factory, AWS Glue, AWS Lambda, etc.

Exposure with AI and automation (ex. RPA) tools and processes

Benefits

Sense Corp has a proud history of ranking among both the Best Places to Work, Best Place for Working Parents, and Healthiest Employers in Austin, Dallas, Houston, and St. Louis. We offer a variety of ways to LEARN, SERVE, GIVE, RELATE, and GROW.

Extensive Training Opportunities Wellness Program Leadership & Professional Development Mindfulness Program Employee Driven Centers of Excellence Social & Educational Networks Enterprise Diversity & Belonging Program Cultural Observance Days Community Outreach

About Sense Corp

Sense Corp is a leading professional services firm focused on transforming organizations and government agencies for the digital era. We deliver tailored solutions to help clients solve their most complex challenges and maximize potential. Founded in 1996, Sense Corp maintains operations in Austin, Columbus, Dallas, Houston, Minneapolis, and St. Louis and serves mid-market to Fortune 50 companies.

The Sense Corp Compass

We may be the only consulting firm in the country where being brilliant isn’t enough to land you a job. Sense Corp employees must be brilliant, creative, human, and fun all at once. In other words, we hire terrific, well-rounded people. It’s one reason clients love working with us. And it’s why we enjoy working with each other. Regularly recognized as a Best Place to Work and Healthiest Employer, Sense Corp is driven by a company culture that aims to help employees be the best version of themselves.

Visit us at www.sensecorp.com.

#LI-JP1",aus,de
30,DriveCentric,Information Technology,4.3,Data Engineer I/II,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1110586&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a134eda5&cb=1619363520478&jobListingId=1007020433888&cpc=8795CF9063CD573D&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-7ff975e0173a6751&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMUEFYbF9JR2dDbDBBUFhxQVcycG8yWm5COU9VelhxeUQ4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlPdG9nQ3V3ZnNQWWMyUWxTMlF4bUZ5QW9wUTY1VzlzMUlMb0QxTXp0Q1FHNVFNNnd0eDNQSkhYQTRJb0xrT0dWaGxEX3pqYzFFSHN3WGFObkx0Z1pSc3RCSC1wN3FoektONFJZQXA2eXlOSzh5NTlXVG1Nd0JzUXg2MHdJcWRfYVc0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVmdzWGJvdzE4UUlXWFY2S1h3SGxxN2RWaC11b29UdHJjZEZZQ2ZIUmZycEVLNkdZaVRiQ05DdEw4SGZUVGJWc2NOX01LaV80a2NFRVk4MkJPNllDcDNMLTZBQVVURTBkSDBydFlrQ2xZUjN5dFhtdENQZGpmWmxsRGZpYkJrUzF4QVRWTGxFSnlvbkkyYmNqN2pyaV9XcTYxa01PMVNrN0ZwWUZpNmlocTB3T29DSWtHeF9pRFhGbHFnYm5waEYtdE9yODVxcEl5dDVrTDg2SHVqYzB2cEdpY0JWMmJVTHI1bkdaYXlPQUVzcHVUMElMVFY0SGNRczNrR0pPR3Z0V0hKVnI0QkNNc1R6X2p6b05DSXhQZnFoS0c5ZC0zeW1GSlFmUGtGbDFHMHdWcVhrNF9KdUJ4dXpiSm85SGxFMFhhSzJsVEFTaVlWOU5TblI3QllNRWk0d1lnTUNBVkNUZi0,"Are you tired of not being challenged, not having a voice, or having to work with outdated technologies? Do you want to be a direct contributor in a company that is an innovation leader and has the awards to prove it? Do you want your fair share of the profits from a fast-growing company that’s doubling its customer base year-over-year?A Data Engineer I/II develops and performs data migration / ETL processes for store launches, investigates and fixes data issues, monitors and optimizes database performance, and assists in the administration of databases and data warehouses.Responsibilities:Write, execute, and validate DML, DDL, and DCL scripts to meet business and customer needs.Coordinate and perform data imports, data modifications, database maintenance, etc. outside of business hours, as needed.Assist Customer Support and Development by analyzing data to troubleshoot application issues.Manage SSIS packages for customer onboarding ETL processes.Onboard new customers by scrubbing data and importing from multiple data sources.Requirements:2+ years of experience writing DML and DDL, with 1+ years of hands-on experience with T-SQL.1+ years of hands-on Microsoft SQL Server 2012+ experience.Ability to balance business and technical objectives when making decisions.Ability to balance multiple assignments in a fast-paced environment.Exceptional communication, problem-solving, and analytical skills are a must.Have a positive, can-do attitude.Pluses:1+ year of scripting and managing ETL packages, with SSIS or other tools.Hands-on experience with Database Administration (SQL Server)Hands-on experience with PostgreSQL.Benefits:Competitive salaryHealth, Vision, and Dental Insurance (eligible on day 1)401K with matching up to 4%9 company holidays + 12 vacation days in first yearAmple professional growth opportunitiesJob Type: Full-timePay: $70,000.00 - $100,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insurancePaid time offVision insuranceSchedule:Monday to FridayWork Location:One locationVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:Open to applicants who do not have a college diplomaCompany's website:https://drivecentric.com/Company's Facebook page:https://www.facebook.com/DriveCentric/Work Remotely:Temporarily due to COVID-19",aus,de
31,CyberCoders,Business Services,4,Data Engineer,"Austin, TX",$55K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1110586&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_56294689&cb=1619363520478&jobListingId=1007022616397&cpc=F4EED0218A761C36&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-68e475c789aac3b8&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT03aUFqZWNQZXcxMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLeXZxX1JOUTFnb2ZWTS1QaWdORkd4Z284ajltUGJiWUQ4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWhQelEzSXN5NFlBVjluelczWTNkcDJUSW1NWnlzS0Q5YWJwUmVmZjF3V3dFRFBFdURxdlhMeFc3MUQxQVF2cVNQOU5rX2NuMmc2RjBzaFotajYwVXQtWDFIem1BN2hnWFR4alpjRWJ5QkZXcjJFNVVKN080MnRwUm1Ib1lZTlZ0TGhUakNfeTg3ZjVjY3NJNHhlUFo1b3NaZF8xUy1UU3dmWTNKLTI3dEluVkVGbTVIYmhKeEx3RjFKeUt1Q2R3LThCYTRuMFJ5MFp5MkR6LVZqdnNwaENBcDNSUXgyWGRrOWpyRm1pUWVBMjhYS084RFY5RlFsVzJkYjBNc3ZUVHlIRUhmOXVIMl9JMmMyaXdFTGl6ZnhEQThOQXpELWxZMkNoNXo5WHF3eDJVaTlpdE04Tkdad2N3TVFpZWdzZzgwSXBEbHRnVG13cUxaWk9ZSE94QURrR0JicGt1c3l0MTM1RmNQNXpUVWVtcktWaDZ1aGs2dEgzMHFsTWRnOUx3N2ozRjU2M0Q1aXN2Zl93cWlONzEyWE0wN2tqNkF3bXlpN1o3UU9kMmFRWldUNTUzd3FUQlNITmk5LTQyd1lMM1hRdnhodFkweS1tVjktYm8yT0Zsc1pnZmwxdkRTdG5FbmlQM2FyQTZKaGdUN1VzU3VoN0tFbXVHZmVUMDY2LVFnVHF3WUUxMG5hOTJxZWNUeTRfQXZOc0U2ZE5pdTlUZmFEbHI4WGE5bWR1Wjk0UllBcDZ5eU5LOVJDWVRFZ1NxOU9wN1h6UGVUQU1WSzRzem5DS3RfdDhmX2szeVhTbHFEdHUtbzVFQXJSckctNGI5VDMzd0tGYTdxN0RkUG5nLVlvaGh6Yy10VnRDcVZtS2dza0JHYjRjMGFIcWk0VFotV2hxbmlRMzZzVmJDLTNZTjVPMUFnQTEtNkpFVWZ0c2xhU2U3bmNSdGs3Vk1jTE5xOVNuNEdMRHRGOFo1TVF1UWJWVzhCejliQm9UUDFQUkJoVHA1LTQ3VXpRQ3VGeERnME02SGZfZ29ka1diZDFvSHdqeTJkTjlJc2doUTRzTDd0a0pMY1V3bWFnVFBVMDRLVFEzZTRQcldZeklnVHhIX0RXUEhycndiMlZWODNRZXBKb05tOWF5cWxLSEhIQ3FYczBFbWozZ3R3djA2dEJvaTlUVlh5RlhaMU4xUkk0ZlFzWmg0U2c0c3lNNjJhY0FKZjhuS0hGTVdkV2NYQjhiZVBuNk1JMDhyVnJfbE9TckZsWDVJWk1PcXBCTlM0bW9aNTBFVGN0V2xDaWlTazJ5YVBSNVJORjJpdHBVd0VvbUZmVGxzTG9KQ1l6ZEg1Vm9OYjZFZG92QlVnYVVjcjM3Q2o0ZnNwUXhmYUZTaUNOZVhlSGdQUWY4cTBzVDZocmtfSE9fVHBtYjkzbWF3aHE4R3praURoUy1R,"Data Engineer
Job Title: Data Engineer (Must live Texas to work remote)
Job Location: Remote (Must reside in TX to qualify for this role)
Job Salary: $55K - $100K
Requirements:

1.) 3+ years in Data Engineering (ETL Developer or Data Developer)
2.) Expert with SQL - Design and database experience
3.) ETL, Talend, SSIS, Informatica, or Bids

4.) Python Experience
Top Reasons to Work with Us
Who Are We: We are a thriving Technology Org that services the Financial Industry
What Do We Do: We create Technology tools for our clients so they can drive their business and manage their clients more effectively
Why Are We Hiring: Our team is in need of help from a strong Data Engineer. We're growing and we are at the tip of creating something amazing
What Is In This For You: Join a a reputable business during a thrilling time. Build your career with working on top-notch technologies

APPLY NOW: If you are looking for your next incredible challenge that not only will help your skills develop but will help your career move up, this is the place for you!


CONTINUE READING AND APPLY TODAY!
What You Will Be Doing
As a Data Engineer, you will be leading SQL & Python projects and assisting with programming issues, such as Python, C#, VB or Java.

Job responsibilities:
50% SQL
50% Python
What You Need for this Position
Requirements:

1.) 3+ years in Data Engineering (ETL Developer or Data Developer)
2.) Expert with SQL - Design and database experience
3.) ETL, Talend, SSIS, Informatica, or Bids

4.) Python

Bonus Skills:

1.) Python Programming
2.) Tableau

Keywords:

Data EngineerETL DeveloperProgrammingSQLETLC#ELTInformaticaBidsJava
What's In It for You
Competitive salary ranging from $55,000 - $100,000 depending on experience
Must live in the state of Texas as a remote employee
Must be comfortable visiting on-site when needed in Utah per quarter
So, if you are a Data Engineer with expert SQL skills and Python exposure, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",aus,de
32,signature consultants,Business Services,4.2,Data Engineer,"Pflugerville, TX",$55K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1110586&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_90461ec7&cb=1619363520479&jobListingId=1007020959878&cpc=D2F1DE17EE1F43B9&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-cfa32681ae0bd40c&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT05ajJEdzFTanhOTzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKZFJFU05rT3JOWjJQZ0JadkQ2M29RQllUeXF1RERUTFQ4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOGhTbUY5YlpBRVNybEZWaC1ZblktZG9mdHFLSHVEcXduUE00ZGZuanNTOWRwNmFVQUF3M3NFcmE2UEU4YnNPZGpFNjY0Wk1RVml5TzdGT3E4anNaZEEwbF9jUXhhcE9NMWNjd1lDLWFVYXZoNlItRVN0ak5lWm9DU3RVSnJRZUFrbU9rLVJ2LXRZMGJOMnFHSnEzd1VyUVllajFyN0U0QkNRUzdyNFREbVNOTkhTMjFsZnBlUHR1dE1HR2hlb09RdXI4bDFfZHdyWnNaMVpRZ1ZUOG5KSXdIMmFvSnRfemRncFY0VU9VZVFvYkozY0VLVkJVbjEtMHI3UmpsWUJfRUNrNTRBUm5BcktyTkZVdEkzai1Wc2M3anY4OG5qT1hJR2dHUEdmdUFiMTVmenFzaGczbW1aRzNpTWNNc3hWUlliQ2NsWWgxenBacENYRGFLdC1lVngwTllWQWo5SDJDUWZlRXBVSXlFZkU2eGdWVFZQSWZhWGNidU5NclBtUjc1Z2FJRDFqT2JiT0RsOERrbmp0U2JsaXJObUhtaWhETzVpdWo5c2ZVYXMxOHFraHZNYzR5Y0xEbTFaVHBjX25ibHdaY1hjTkFtZ0dPY2lRZnBnUi1JZjltaUxfaGRyQlpoQmJPYnZ5dVBTbGFTclFoSXVZR3hORk5CWU5SSUFQb1BDVG1vdmVoTU1TWk1pWVpGc1h0UG5Pd2tYNndkUjJTNk5uQlJQbkZ4emV6T0ptM3k0R0pUVzdHR1JxczJHMUViWkpZcHJMeXZ4d2tIR3RzWXdPY3VFQnFVb2NjY0twZXpTQ0FSZE1vN2hjdFFpeThuakFwS1YxSmkxMy1VMFdUSVUyeWFQUjVSTkYyaXRwVXdFb21GZlRPMUtIdU42OFVvVExIbmNwUUlic2ExV2cxdm9SMmk4RlNCcFJ5dmZzS1BodS1iTTVlbC1GM0E,"Job Summary:
Signature Consultants is seeking a Data Engineer for an opportunity with a client located in Pflugerville, TX. The client is interested in an eCommerce data and operations engineer to help build new eCommerce data processes and operations for various internal and external projects.
This person would be responsible for maintaining large data sets, defining data structures, analyzing large data sets, and finding new ways to automate the flow of data between various teams and systems. Candidates with experience in eCommerce catalogs, assortment data, pricing, eCommerce content data sets, or large-scale content publishing processes are ideal. Candidates who have experience with SQL, eCommerce APIs, product information management systems, digital asset management tools, and web data extraction are also well-suited for this role.
Responsibilities:
Responsible for the design, development and deployment of systems components, including enterprise infrastructure
Projects are typically focused on both software and hardware components
Evaluates existing systems to understand capabilities and recommend solutions
Work with non-technical business owners to understand needs and develop a technical solution
Participates in the layout design and installation of new systems or modification of existing systems
Develop and manage systems integration projects
Identifies and resolves existing system deficiencies
Must have strong communication skills to interact with business counterparts
Prior systems engineering experience in large enterprise environments is required
Desired Skills:
advanced excel
web data collection
SQL
digital asset management
product information management (PIM)
eCommerce content operations
APIs,
data exchange
database architecture
scripts
AI Workflow Tools
IBM Watson
BOX automation
SaaS digital content tools
MacOS ios 0-2 years experience
Bachelors degree or equivalent work experience preferred
About Signature Consultants, LLC
Headquartered in Fort Lauderdale, Florida, Signature Consultants was established in 1997 with a singular focus: to provide clients and consultants with superior staffing solutions. For the ninth consecutive year, Signature was voted as one of the ""Best Staffing Firms to Work For"" and is now the 14th largest IT staffing firm in the United States (source: Staffing Industry Analysts). With 28 locations throughout North America, Signature annually deploys thousands of consultants to support, run, and manage their clients' technology needs. Signature offers IT staffing, consulting, managed solutions, and direct placement services. For more information on the company, please visit www.sigconsult.com. Signature Consultants is the parent company to Hunter Hollis and Madison Gunn.
EEO Employer
Signature Consultants is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Signature will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or 888.838.1020.
To apply please email your resume to: Hrichards.40883.4707@signature.aplitrak.com",aus,de
33,New Relic,Information Technology,4.2,Senior Software Engineer - Data Platform (Remote),"Austin, TX",$55K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1110586&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_b068a659&cb=1619363520479&jobListingId=1007019776192&cpc=F4EED0218A761C36&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-168e93c9cbc0558d&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpJQU1ZbUhkMVhoZE81Z1pTaGZfb3UwWTNXSEJZbm51TGo4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOG1JYUJ1cUVaajdrT3FKWmUwTnlFb1hYYjQ3YVJfTE1fY3VFWFI4MWJEbEFqY1JxX0RUVlV1c0ZnWmtGV1N4NGdTYlgwelNwUnZHR2NFbDR1ZTRnVFE2RnVFNXJfc1RDanlvWEc3ZTlwcFpmd0t6M2UxZml0QlpJRUg4NTNYSG54c2lpbmM4N1ZZUExaQ3RXOUh5SUozR3lBT2RRVk1vYTdTcmhHQXpYOGkwNmIyRS1EQnRGTmRKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSSXpfQ2c2TnhHQmZHUjUxUG03ZC1QX2pHSnNhN25XbjhjR0QzV3RBRFNpY3VZZ2xjdzFZYjZNbVZCenV5MGlwRVBILUVqdktLVGhJWmNYY05BbWdHT2ZHTGJzZ1VQWjJuaWM1dmMzRlFISG1QOUFobUV5Ylk3NlZZOGpKLWNGV2ZnLVBwUFNZbnhmeUkyb1VaenhWbzFPM3E2STVvVlM2bFQ0TDFabjFKcjQ5aHpVS2xjU2IydGJIa1NmOUw5UU9mU0M2Y2h2QUphSDFiQUlVdEpSZlBxNFlsaDBvY2NOSWU4ZzgyWExxM1F4WmlVcUM3Wk9zY2d0WHdsWEVnd3oweWh1UVRhcDMzYUdscW80MGlWSkZhdFVhZVQ3NkxZem5yMGd6cTBuXzBwZlpwSkhSbzRuaFRiYzNrR0pPR3Z0V0hLOFVXc0FVZlQtdFNmeTExbWlDTUdR,"Please note that visa sponsorship is not available for this position
We are excited to consider a remote engineer for this role! Remote team members will be expected to work out of their home office.
Your Opportunity
The Data Platform group at New Relic builds the foundation for all of our products: data ingest, storage, and query. As an engineer on the Ingest Team, you’ll get a chance to work on some of the fastest and highest throughput microservices in the company. You will be developing automation for and operating horizontally-scalable systems at the core of New Relic's business.
We own our software from top to bottom and are directly responsible for its quality and reliability. Each member of the team shares our pager rotation and will occasionally be on-call to respond to system failures; so we prioritize work that keeps the lights on and the pager quiet, in addition to the work that powers all of our new products and streams of data. The opportunity to work from a remote office may be available depending on your location in the US.
As with most development teams, communication is of central importance to us. We mostly work independently, but we pair-program on occasion, and we do a lot of collaborative design. We value the ability to think creatively and work collaboratively to tackle hard problems in a resource-efficient manner.
What You’ll Do
Automate and operate our 10+ microservices for high-speed ingest and high availability.
Participate in the team’s on-call rotation for our services, ensuring that we’re meeting our SLAs.
Give and receive feedback on Pull Requests as well as writing and commenting on designs.
Your Qualifications
Must-have:
3+ years experience in software development.
An understanding of Computer Science.
Fluency in Java.
Ability to go deep on the command-line and fix things when they’re broken.
Nice-to-have:
5+ years of experience developing and operating within a 24x7 SaaS business.
Experience working in AWS.
Experience in high-throughput software development.
Our architecture is built around Apache Kafka, and every single one of our services interacts with Kafka in one way or another. Experience with Kafka or other data pipeline technologies is a plus, but not required.
Experience on distributed teams. An ability to work well asynchronously and share your thoughts in writing will be a big asset.
Please note that visa sponsorship is not available for this position
About Us
New Relic (NYSE: NEWR) is a cloud-based observability platform that gives developers, engineers, operations, and management a clear view of what’s happening in today’s complex software environments. So they can find and fix problems faster, and deliver delightful experiences for their customers. That's why the world’s best engineering teams rely on New Relic to visualize, analyze, and troubleshoot their software. It’s the simplest, most powerful cloud-based observability platform, built to create more perfect software. All from one place.
Founded in 2008, we’re a global company passionate about building a culture where all employees feel a deep sense of belonging, where every ‘Relic’ can bring their whole self to work and feel supported and empowered to thrive. We’re consistently recognized as a distinguished employer and are committed to building world-class products and an award-winning culture. For more information, visit newrelic.com.
Our Hiring Process
New Relic takes seriously our stewardship of the data of our thousands of customers worldwide. In compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification.
We will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance. https://sfgov.org/olse/sites/default/files/FCO%20poster2020.pdf
Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic.
New Relic is an equal opportunity employer. We eagerly seek a diverse applicant pool and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities (or disability), age, sexual orientation, veteran status, or any other characteristic protected by law.
Interested in the details of our privacy policy? Read more here: https://newrelic.com/termsandconditions/applicant-privacy-policy",aus,de
34,CyberCoders,Business Services,4,Senior Data Engineer,"Austin, TX",$100K - $150K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1110586&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_0d7683d1&cb=1619363520480&jobListingId=1007022008822&cpc=F4EED0218A761C36&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-df5ce2deb209073a&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT03aUFqZWNQZXcxMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMVF9YU1RMREFsNTlYNlRNLVBmbUxSTFBuY2FIdDRtZ2I4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWhCUUctbW9ReTltOV9VdXJYRXNaS1JYT0pVTDZ3WldDQzFwRjdaNERDZ0I2bHVOQ1NhWWdyc2xuSkhoYl92NkxQOU5rX2NuMmc2RjBzaFotajYwVXQtWDFIem1BN2hnWFR4alpjRWJ5QkZXcjJFNVVKN080MnRwUm1Ib1lZTlZ0TGhUakNfeTg3ZjVjY3NJNHhlUFo1b3NaZF8xUy1UU3dmWTNKLTI3dEluVkVGbTVIYmhKeEx3RjFKeUt1Q2R3LThCYTRuMFJ5MFp5MlFqSVltR0dMZU5MbDVBLVZlWHJDbmtOc0EwcFpLUXM5QnZMM043aS00T0lROHRreTExZ3lUVGtlT1hoOFBUcTlVLWFreDNXUnIyU0pXNHlSUmlDZ1k0NWJtSURBQTN1NjlpdE04Tkdad2N3TVFpZWdzZzgwSXBEbHRnVG13cUxaWk9ZSE94QURrR0JicGt1c3l0MTM1RmNQNXpUVWVtcktWaDZ1aGs2dEgzMXo5YUpkOXNyOUxNNzRKZVdreExwUm40bjJNNEFaN0NWeUxUS1VxX0dzNTZ6aXJ2WjZJVW1xQTZkLU1rLXNwRVM5LTQyd1lMM1hRdnhodFkweS1tVjktYm8yT0Zsc1pnZmwxdkRTdG5FbmlQM2FyQTZKaGdUN1VzU3VoN0tFbXVHZmVUMDY2LVFnVHF3WUUxMG5hOTJxZWNUeTRfQXZOc0U2ZE5pdTlUZmFEbHI4WGE5bWR1Wjk0UllBcDZ5eU5LX25uZUtjZ2VxcGY2Q3ZjQkhoeHhwcTRzem5DS3RfdDhmX2szeVhTbHFEdHUtbzVFQXJSckctNGI5VDMzd0tGYTdxN0RkUG5nLVlvaGh6Yy10VnRDcVZtS2dza0JHYjRjMGFIcWk0VFotV2hxbmlRMzZzVmJDLTNZTjVPMUFnQTEtNkpFVWZ0c2xhU2U3bmNSdGs3Vk1jTE5xOVNuNEdMRHRGOFo1TVF1UWJWXzNCNzZfYk95bTdqbnIxVmRqZHFReVBNRlk5Vy1Fa1Y2SGZfZ29ka1diZDFvSHdqeTJkTjlJc2doUTRzTDd0a0pMY1V3bWFnVFBVMDRLVFEzZTRQcldZeklnVHhIX0RXUEhycndiMlZWODNRZXBKb05tOWF5cWxLSEhIQ3FYczBFbWozZ3R3djA2dEJvaTlUVlh5RlhaMU4xUkk0ZlFzWmg0U2c0c3lNNjJhY0FKZjhuS0hGTVdkV2NYQjhiZVBuNk1JMDhyVnJfbE9TckZsWDVJWk1PcXBCTlM0bW9aNTBFVGN0V2xDaWlTazJ5YVBSNVJORjJpdHBVd0VvbUZmVGxzTG9KQ1l6ZEg1Vm9OYjZFZG92QlVnYVVjcjM3Q2o0ZUFFdTMtWElaUmlOZVhlSGdQUWY4cTBzVDZocmtfSE9fVHBtYjkzbWF3aHE4R3praURoUy1R,"Senior Data Engineer
If you are a Senior Data Engineer with experience, please read on!

Based in Austin, we're a machine learning-powered trading platform for renewable energy. We're on a mission to facilitate the global transition to renewable power. We're looking to add mid and senior-level Data Engineers to our rapidly growing team!

Work onsite in Austin or remote.
What You Will Be DoingDevelop microservices, trading system components, and ETL processes for our trading platformWork in a cross-functional team with engineers, business analysts, traders, and data scientistsMentor junior members on the team through pull requests and code reviews
What You Need for this Position5+ years of experience in Python (Flask preferred)Experience developing microservicesExperience building ETL pipelines
Bonus points for:
PandasRedisAirflowPysparkFargateDockerAWSRabbitMQ
What's In It for You
Salary: $100,000 - $150,000 DOE
Health, Dental, and Vision401KPTORemote or onsite in Austin
So, if you are a Senior Python Engineer with experience, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",aus,de
35,IBM,Information Technology,3.9,Entry Level Data Engineer (Watson Advertising & Weather),"Austin, TX",$100K - $150K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_b24a9f51&cb=1619363520479&jobListingId=1007021849772&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-b3a68e7d2af9dbc7,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities
Please note, this position will be located in either Brookhaven, GA, or New York City, NY.

The Data Platform Engineering and Operations team within IBM' Watson Advertising and Weather unit is seeking an Entry Level Data Engineer. We solve complex problems for our Users and Partners using modern technologies and Big Data. We are looking to add a results-oriented individual to join us and help develop and maintain the data pipelines that fuel our data and machine learning platforms which drive business results.
As a team member you will be:
Passionate about solving complex problems with data
Building new data ingestion pipelines, and adapting existing ones to changing data sources, and changing data requirements
Working with others to design new ways of ingesting data that makes it faster and easier
Knowledgeable and skilled with one or more languages like Python, Java, and Scala
Knowledgeable and/or willing to learn about different database technologies, Spark and Cloud development, and delivery
Conscientious about deadlines and deliverables
Excited to continue to learn and develop new skills
Contributing to the governance and curation of the data, and tooling to support these activities
Required Technical and Professional Expertise

Basic knowledge in one or more of the following languages: Python, Java, and Scala
Basic knowledge in database technologies
Basic knowledge in Spark or other distributed technologies
Preferred Technical and Professional Expertise

Previous internship or co-op experience in a similar role
About Business UnitIBM’s Cloud and Cognitive software business is committed to bringing the power of IBM’s Cloud and Watson/AI technologies to life for our clients and ecosystem partners around the world. IBM provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments—with complete software solutions for business and IT operations, development, data science, security, and management. Our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their IT estate, and automate operations with management visibility. With IBM, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners.

Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location StatementIBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

IBM intends this job to be performed entirely outside of Colorado.

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",aus,de
36,CyberCoders,Business Services,4,Senior Data Engineer (Remote),"Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1110586&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4dbc7d4b&cb=1619363520549&jobListingId=1007022615997&cpc=6FC5BA77C9A4CD78&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-727d8b73c2280ccb&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT13MXNxczYzWkdyaTgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpJR19OU2o1YnoxTUxzTVdkNVZBOXVzVm1NUUdtcEptbVg4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWhrRUhaZDdzVmhlNTBtb214SG43bzNNcUdJbThRNzFwSzVveU9hazc4MXlIcnRFSGF5eWpHd0VJS2treVhwdHBHTjRHWVpDaGd6VHlXVUNKWlhTVXRtUWRfZGZhb3BPaW4zaGR4eDh4c2Y4NEtHeGpOYkdQOWtwcnNrMzZxX0tBY2Z1cDBEWG54cF9Lb3l0cnloWlZnYTU1ekhDaDIxNy0xWHdlaklSdDBWM0pjMDZLeUZ2UnFKX0VJcUpnVm1wTG5fQVNIZXFqWW1PeGM2UWdEbXpoNDFIU1pzek8xckQ2ckpna3MtRHhGaU1qMkFWNjJ0UWttWUIzclpfT2pwNUQzaUx3eWpKT2RycEdncWxld1J2ZjZFQkFNOVFUX3hTby1RTkYzMGVmdm5Ta1NHWjJfSjBhS1dvV0VkeWhQdHZTRWxVeVlDOEtsY0hLelExR0NteEhuX1hpVzlveWxVQk5YUzVOUmR0WnFLcjBxTjAtMFVXSzNCLUVXaHNGYVVGcXRuT29PRmhzMmx3c2hPRGFGemRvaDdoQWpKOTVfRU9jZG92UU9ud3QtM0Y4MkN5RTB6VXYxMlhMY25xb21ub3RZZnFKbU1Tc3F1MWtzTFdGdXhScFVZV2dZRVFIS21WVjVWNkdsMzl0M3Y2aHhPV0hsaWRsQmRXTTRCVVF6bkJ0bkFIRExXamJpc1FEVTFlMFRralVfUTJ2dDZrOUNIY2ZtMVZlbF9SWHF3MWZ3UGVtaTU5aDdESXhmUG4tUFN6akFvX1FYOENlUVhLeTJoVE5ISmk0YWRTQ1Z2OXlKb2hmekptNm8yNE5xZ0d3d3BrZE9PRklhR25lTkpMek8tSEt4X0JYcjB1dExWY1FqR1RsSkRDQUxWQjF2RERqWlBmQW1xbUs0U0FPYXNZaTBkZ0hsZ1JiU0xSZWE3RFlZUnFhRU1idzdOVjItUlhFX0RENzFGemJkOWFzbFozUmVuSksxZ01pYjFTcEU4WDR3OTRzVHdDUUdVY0JNQmM4bnFRc1JyNmZzbnluLThfSURaYm5PZDZTVWhMcWJDaXJkbzcyTUJFTElIMkxwSjNmN1E5TExoZl9DYUdTNEl6N2dsSTdjR1BOZ1R1bUFxZHlfdWdBRkV4TkhSOUs3V0pBcFdFZDhyVjVyUWozWTMyWlpRMzRtd1pFdGNRRTFTNVJDY3FKeU5tM0ktNDY0djFxdXRaRER0VXBPeGFXQll1b29hdE1EcUFpSkJzZjRnMXhaYW9HNTZZUmZyWGJJYTFrN2tnU1dtZEZGdm9feFh6bmFiaE1iSU9nQ0xKUEk3TDFMWFlsOFB2R2ZNYW9XVlR0Vm9OYjZFZG92QlVnYVVjcjM3Q2o0aE02MFBob2dPWDZ0TEUtb2E1UHh6cDJ0OTc1clBzM0hQc2xZaHhrUWk4R2ljSEszaXo4MzZRaXk4bmpBcEtWMWxzbWRxN0ZYNXdQelpJX2U2SGRVblE,"Senior Data Engineer (Remote)
Title: Software Data Engineer
Salary: $140,000 - $160,000

Requirements: 5-10+ years as a Data Engineer + Docker/Kubernetes + Python (or Java) + AWS

We are a SaaS healthcare technology company that has seen very constant growth for the past 5 years and are the recent recipient of another Best Places to Work award.

We're huge on promotions, and can proudly say that we have promoted 50% of employees with over 1 year of tenure. If you have this experience, please apply immediately.
Top Reasons to Work with Us
- Competitive salary ($140k - $160k)
Work w/ Industry Pros who have a few impressive exits under their beltsFull Benefits (health, dental, vision, etc.)Strong GlassDoor ratingHave your voice be heard in and play a role in company directionVery low turnover rateHuge opportunity for career and personal growth
What You Will Be DoingCreate and maintain optimal data pipeline architectureIdentify, design, and implement internal process improvementsAssemble large, complex data sets that meet functional / non-functional business requirementsHandle production issuesEnsure code is high quality through automated tests, monitoring, etc.Collaborate with team to provide visibility into the data layer and related pipelines
What You Need for this Position
5-10+ years as a data engineer

Python or JavaAWSDocker / KubernetesData lake solutions like Hadoop, Hive, Spark, DatabricksExperience in the healthcare industry is a plusBS in CS (or related) is preferred
So, if you are a Senior Data Engineer (Remote) with experience, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",aus,de
37,Splunk,Information Technology,4.2,Data Engineer,"Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_f10dd731&cb=1619363520480&jobListingId=1007019770584&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-2517b426aad9bc96,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.
As the Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.
What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
5+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist
Savviness with complex SQL queries and knowledge of database technologies including window and analytical functions
Experience with Python analytic libraries and Business Intelligence tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!
Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.
What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment
This isn’t a job – it’s a life changer – are you ready?
Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.
Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",aus,de
38,IBM,Information Technology,3.9,Data Engineer,"Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_b814e850&cb=1619363520481&jobListingId=1007021850144&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-5270e56e7bdef3e6,"Introduction
Have you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.

Your Role and Responsibilities

Key Responsibilities:
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical requirements and support their data infrastructure needs.
Provide the ability to work within agile development methodology and collaborate effectively with multi-disciplinary teams
Build modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements.
Understand data architecture, build large-scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow.
Have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Have expertise in data persistence solutions, experience with the latest (NoSQL) database technologies, and experience with building complex SQL queries using various (NoSQL or RDBMS) databases such as MongoDB or DB2
Experience in software engineering with object-oriented design, coding and testing patterns on large-scale data infrastructures
Use DevOps best practices such as continuous integration, continuous delivery in the production implementation.
Garage
IBMReferred_NorthAmerica

Required Technical and Professional Expertise

Develop code using Python, Scala, R languages
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra
3+ years design & implementation experience with distributed applications
3+ years of working experience in database architectures and data pipeline development
Demonstrated knowledge of software development tools and methodologies
Computer Science with software engineering and Math background desired
Preferred Technical and Professional Expertise

Experience with big data tools: Hadoop, Spark, Kafka, etc.
Familiar with big data solutions with experience on Hadoop based technologies such as MapReduce, Hive MongoDB or Cassandra.
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Knowledge of cloud technologies such as Kubernetes, Cloud Foundry, PaaS, and IaaS (SoftLayer)
About Business UnitIBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.

Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location StatementIBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to:


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.Well-being programs to support mental and physical health.Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).Select educational reimbursement opportunities.Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.Giving and volunteer programs to benefit charitable organizations and local communities.Discounts on retail products, services, and experiences.
This position is eligible for participation in an IBM sales incentive plan. Actual incentive opportunity will be based on performance and the eligible Target Incentive, as addressed in the applicable plan, all of which is subject to change.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",aus,de
39,"Esolvit Inc.,",Business Services,4.3,Data Engineer for Platforms & Infrastructure,"Austin, TX",$72 - $77 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4043d614&cb=1619363520484&jobListingId=1007010768200&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-bc6a18a5998c84de,"Required Skills: · 6 years of experience in large-scale IT Project/Product delivery with at least 2 years of work experience in current data streaming, messaging, management, and database technologies· 6 years of ability to establish and always maintain effective and professional working relationships with others in the course and scope of conducting business· 6 years of excellent communication, problem-solving, and organizational skillsPreferred Skills: · 4 years of strong data integrity, analytical, and multitasking skills· 4 years of Graduation from an accredited four-year college or university with major coursework in Computer Science or Engineering· 2 years of experience with designing and building data platforms and setting up data tools· 2 years of experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)· 2 years of experience in tuning and troubleshooting streaming/messaging platforms· 2 years of experience creating producer and consumer applications with Kafka· 2 years of experience coding and scripting (Python, Java, Scala) and design experience· 2 years of experience with ELT methodologies and tools· 2 years of hands-on experience with AWS and/or Azure· 2 years of experience with KStreams and KSQL· 2 years of experience with designing and automating build and deployment solutions/process for data solutions/tools/platforms· 2 years of familiarity with data management, visualization, warehouse, and analytics tools/platforms such as Qlick, SAS Viya, Kibana, Snowflake, Qualtrics, and Spirion· 1 or more years of basic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)· 1 or more years of able to work independentlyJob Types: Full-time, Part-time, ContractPay: $75.00 - $80.00 per hourBenefits:Health insuranceSchedule:Day shiftEducation:Bachelor's (Required)Work authorization:United States (Required)COVID-19 Precaution(s):Remote interview processTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in placeSpeak with the employer+91 # (512)-333-2908",aus,de
40,SAM NETWORK SYSTEMS LLC.,N/A,-1,Data Engineer for Platforms & Infrastructure,"Austin, TX",$58 - $64 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_77dd8a94&cb=1619363520481&jobListingId=1007016594483&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-1d2811c054ccddd2,"Working as part of the Platform & Infrastructure Data Engineering team to engineer, install, configure, standardize, and automate best in class data services and capabilities in a secure fashion for the organization. The ideal Advanced Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data management systems. You are committed to data automation and integrity, are highly analytical, and can work on multiple projects at once.You will use your skills to engineer, automate, and manage data systems across multiple cloud services platforms and toolsets. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards.The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by Texas OAG are core reasons people enjoy working as part of the Data Division.Experience and Qualifications -Experience in large-scale IT Project/Product delivery with at least 2 years of work experience in current data streaming, messaging, management, and database technologiesAbility to establish and always maintain effective and professional working relationships with others in the course and scope of conducting businessExcellent communication, problem-solving, and organizational skillsStrong data integrity, analytical, and multitasking skillsGraduation from an accredited four-year college or university with major coursework in Computer Science or EngineeringExperience with designing and building data platforms and setting up data toolsExperience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)Experience in tuning and troubleshooting streaming/messaging platformsExperience creating producer and consumer applications with KafkaExperience coding and scripting (Python, Java, Scala) and design experienceExperience with ELT methodologies and toolsHands-on experience with AWS and/or AzureExperience with KStreams and KSQLExperience with designing and automating build and deployment solutions/process for data solutions/tools/platformsFamiliarity with data management, visualization, warehouse, and analytics tools/platforms such as Qlick, SAS Viya, Kibana, Snowflake, Qualtrics, and SpirionBasic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)Able to work independentlyJob Types: Part-time, ContractPay: $60.00 - $67.00 per hourSchedule:8 hour shiftMonday to FridayEducation:Bachelor's (Preferred)Contract Length:3 - 4 monthsVariesFull Time Opportunity:NoWork Location:One locationHours per week:30-39Visa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:A job for which all ages, including older job seekers, are encouraged to applyWork Remotely:NoCOVID-19 Precaution(s):Remote interview process",aus,de
41,Winwire Technologies,Information Technology,4.3,AWS Data Engineer,"Austin, TX",$67 - $77 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a74df6d2&cb=1619363520481&jobListingId=1007011945153&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-a879cbbbebc62146,"Role : Data EngineerLocation : Austin, TXDuration : 6+ Months of contract NEED USC/GCTop 5 Must Haves: .. Need strong PL/SQLUnderstanding of ETL and ELT processesData Warehousing experience, including Snowflake or other data warehousing toolsAWS/Cloud experienceProgramming experience with data sets in Python, Scala, Java or C#Apache Spark experienceJob Types: Full-time, ContractPay: $70.00 - $80.00 per hourSchedule:8 hour shiftWork Remotely:Temporarily due to COVID-19",aus,de
42,Stamps.com,Information Technology,4,Data Engineer,"Austin, TX",$67 - $77 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_a9e217d3&cb=1619363520481&jobListingId=1007020968564&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-b34fc07e54dda8f5,"The Analytics team is responsible for making Auctane’s data reliable, trustworthy and easy to use. We do this by creating a data ecosystem that enables Auctane to use data to make our product better, facilitate decision making, and help drive business value. In addition, the Analytics team partners with stakeholders from across the business to deliver both standardized & ad-hoc reporting, analysis & insights to drive business decisions.

Strategic Imperative:

The Data Engineer will maintain our existing integrations as well as build new ones as the company adopts new software systems to meet its needs. Data from these integrations needs to be ingested, transformed, and combined in order to provide valuable insights to stakeholders across the organization. Sales, Marketing, Customer Support, and the Product teams currently use a variety of systems that have limited ability to talk to communicate with each other. By consolidating this data into one data warehouse, the various teams can see how their work affects customers and the company.

Primary Objectives:

Build integrations for all relevant internal systems
Ensure high level of data quality in data warehouse
Monitor and support ETL processes
Provide data to various stakeholders across the company through BI tools and operational applications

Qualifications - To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Essential Position Duties (typical monthly, weekly, daily tasks):

Manage new data integration projects
Identify relevant data which needs to be extracted
Create necessary infrastructure to support integrations
Transform data to increase usability for stakeholders
Support existing system integrations
Ensure that integrations are ingesting correct data
Ensure that integrations run on a regular schedule
Fix issues in pipelining processes as they arise
Communicate changes in data warehouse and integrations to relevant parties across the company
Know which stakeholders need information from which integrations
Communicate any changes or outages to relevant parties

Skills and Knowledge:

Proficient in Python
Hands-on experience implementing ETL (or ELT) best practices at scale.
Hands-on experience with data pipelining tools (Airflow, Dagster, Prefect, dbt, Meltano)
Have a deep understanding of SQL, data modeling, and analytical data warehouses, such as Redshift or BigQuery.
Proactive communicator who can translate between technical and non-technical stakeholders
Team player who gives and takes feedback in a thoughtful way, and loves to help others.
Thrive on autonomy and have experience driving long-term, cross-functional projects to completion.
Use distributed source control such as Git proficiently

Education and/or Experience:
Bachelor’s degree in Computer Science or Engineering or equivalent years’ experience.
At least two years’ experience in data engineering or ETL/ELT processes.

Preferred Experience:
Experience with the specific tools we currently use
Airflow, Kafka, dbt, Amazon Redshift
Experience orchestrating machine learning

Computer/Software/Application Proficiency:
Python, SQL
Github, Atlassian Jira

Travel Requirements:

10% or less

Additional Position Duties: – (The following is a list of what all employees, except those with medical accommodation, may be regularly required to do.)

Sit for prolonged periods of time
Utilize wrist and hands for a prolonged period of time
Walk short distances
Stand for short periods
Speaking and conversing with others
Lift up to 25lbs without assistance up to chest height

Equal Opportunity Employer/Veterans/Disabled

If you are based in California, we encourage you to read this important information about the ShipStation Privacy Policy for California residents",aus,de
43,"Genuent Employment, LLC",N/A,-1,Consultant – Junior Data Engineer,"Austin, TX",$60K - $65K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_be2b487e&cb=1619363520482&jobListingId=1007021613113&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-e8e831ff4866ffe8,"Salary: $60,000-$65,000/annually

Job Type: Full-time

Number of Hires for this role: 20

Location: Nationwide; Temporarily remote, until placed, relocation may be required

Consultant – Junior Data Engineer


WE ARE HIRING! Talent Path is a talent accelerator and IT consulting firm looking for IT Consultants who are ready to launch their technology careers. Talent Path Consultants are hired as staff employees and complete a paid immersive training to tackle the requirements of the current market and demands of our clients.


Are you interested in Big Data & Data Engineering? Are you interested in learning and working in a collaborative, nurturing environment that will give you the skills in technology and business to excel your career path? If that's you, good news! We're looking for individuals who are ready to launch their career as a Junior Data Engineer!


What You’ll Do

Collaborate with clients and internal teams to analyze, design, and deliver innovative solutions for a wide variety of business topics and industries.
Design and develop insightful analytics deliverables via a variety of techniques, including requirements gathering, data profiling, data analysis, statistical analysis, predictive modeling, use case definition, data storytelling, database administration, provisioning and deploying SQL servers.
Produce documentation to aid both business and technical users related to the solutions produced.


What You’ll Bring

Intermediate knowledge of database objects, writing SQL queries, logic-building skills.
Experience with database administration/data analytics/cloud data warehousing a plus (SQL, Azure, AWS).
Strong systemic/analytical thinking and problem-solving approach.
Exceptional interpersonal communication skills, both written and verbal.
Professional business acumen and appearance.
Adaptable & highly self-motivated in ambiguous or rapidly changing environments.
Commitment to learning and growing professionally.


Requirements:

Bachelor’s degree(technical degree / background preferred)
Legally authorized to work in the United States on an on-going basis without sponsorship
Must be willing to relocate
Ability to start on May 17, 2021


What We Offer:

Paid immersive training& certification in either AWS or Azure
Competitive compensation& relocation assistance
Comprehensive benefits package, 401K, Paid Time Off
Health & Wellness Program
Employee Engagement Communities
Continuous mentoring and support


Does this sound like you? Apply today and let’s discuss how Talent Path could be the perfect opportunity for you!


About Talent Path

Talent Path provides a development program designed to coach and mentor high-potential, technology-minded professionals, giving the experience and opportunity to work on exciting and innovative projects across multiple industries.",aus,de
44,SAM NETWORK SYSTEMS LLC.,N/A,-1,Senior Data Engineer,"Austin, TX",$67 - $72 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_02d92983&cb=1619363520482&jobListingId=1007016598210&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-eb39e3b48554a849,"Job DescriptionThe Data division is part of the OAG’s technology organization and is responsible for building data assets to provide value added products and services to drive innovation for our partners and clients. As a Senior Data Engineer, you will help design, enhance and build solutions dealing with real-time data in a fast-paced environment working with/on cutting-edge data and cloud technologies. You will work with colleagues who will support and challenge you daily. We believe in self-managing Agile teams who build products end to end, focusing on unit testing, code reviews and continuous integration for excellent code quality.The ideal Senior Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data focused applications. You are committed to data automation and integrity, are highly analytical, and can work on multiple projects at once. You will use your skills to engineer, automate, and manage data systems across multiple cloud services platforms and toolsets.Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by Texas OAG are core reasons people enjoy working as part of the Data Division.CANDIDATE SKILLS AND QUALIFICATIONSExperience in large-scale IT Project/Product delivery with at least 3 years of work experience in current data streaming, messaging, management, and database technologiesAbility to establish and always maintain effective and professional working relationships with others in the course and scope of conducting businessExcellent communication, problem-solving, and organizational skillsStrong data integrity, analytical, and multitasking skillsGraduation from an accredited four-year college or university with major coursework in Computer Science or EngineeringExperience creating producer and consumer applications with KafkaExperience with designing and building data platformsExperience in tuning and troubleshooting streaming/messaging platformsExperience coding and scripting (Python, Java, Scala) and design experienceExperience with ELT methodologies and toolsHands-on experience with AWS and/or AzureExperience with KStreams and KSQLExperience with designing and automating build and deployment solutions/process for data solutionsFamiliarity with data visualization, warehouse, and analytics tools/platforms such as Qlick, SAS Viya, Kibana, SnowflakeExperience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)Basic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)Able to work independentlyJob Types: Part-time, ContractPay: $70.00 - $75.00 per hourSchedule:8 hour shiftMonday to FridayEducation:Bachelor's (Preferred)Contract Length:3 - 4 monthsVariesFull Time Opportunity:NoWork Location:One locationHours per week:30-39Visa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:A job for which all ages, including older job seekers, are encouraged to applyWork Remotely:NoCOVID-19 Precaution(s):Remote interview process",aus,de
45,Intone Networks,Information Technology,4.4,Big Data Engineer,"Austin, TX",$67 - $72 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_4d7dfb0b&cb=1619363520482&jobListingId=1007016346239&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-9a722b526d227532,"Mandatory Required Skills (years): 6, experience in large-scale IT Project/Product delivery with at least 2 years of work experience in current data streaming, messaging, management, and database technologies 6, ability to establish and always maintain effective and professional working relationships with others in the course and scope of conducting business 6, excellent communication, problem-solving, and organizational skills Preferred Skills (years): 4, strong data integrity, analytical, and multitasking skills 4, graduation from an accredited four-year college or university with major coursework in Computer Science or Engineering 2, experience with designing and building data platforms and setting up data tools 2, experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch) 2, experience in tuning and troubleshooting streaming/messaging platforms 2, experience creating producer and consumer applications with Kafka 2, experience coding and scripting (Python, Java, Scala) and design experience 2, experience with ELT methodologies and tools 2, hands-on experience with AWS and/or Azure 2, experience with KStreams and KSQL 2, experience with designing and automating build and deployment solutions/process for data solutions/tools/platforms 2, familiarity with data management, visualization, warehouse, and analytics tools/platforms such as Qlick, SAS Viya, Kibana, Snowflake, Qualtrics, and Spirion 1, basic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.) 1, able to work independently",aus,de
46,Deloitte,Accounting & Legal,3.9,Data Engineer,"Austin, TX",$67 - $72 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_10dfdcf8&cb=1619363520483&jobListingId=1007018022400&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-0a32355625309232,"Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with Project Delivery Practice.
The team
Analytics & Cognitive
In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.
The Analytics & Cognitive team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.
Analytics & Cognitive will work with our clients to:
Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms
Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions
Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements
Work you'll do
Support the implementation of data integration requirements and develop the pipeline of data from raw to curation layers including the cleansing, transformation, derivation and aggregation of data.Communicate effectively (written and spoken) and work with the multi-location development teams and self-manage own workSupport in the development of technical solutions to business problems
Qualifications
Required

Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience5+ years of hands-on experience as a Data Engineer or Big Data developer
5+ years of experience in Core JAVA and SQL3+ years of experience in building scalable and high-performance data pipelines using Apache Hadoop, Apache Spark, Pig or Hive3+ years or experience in Python / Unix Shell ScriptingExperience with bigdata cross platform compatible file formats like Apache Avro & Apache ParquetHands on big data/ Hadoop performance tuning and optimization experience
Strong SQL knowledge with ability to work with the latest database technologies.Strong data & logical analysis skillsLimited immigration sponsorship may be available
Travel up to 25% (While 25% of travel is a requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice.)
Optional / Nice to Have (but not required)
Experience in Map Reduce is a plus
Additional Requirements
Must be willing to live and work in the Greater Austin, TX area (preferred) or San Jose, California. Relocation assistance provided to qualifying candidates",aus,de
47,Ascension,Health Care,3.5,Senior Data Engineer,"Austin, TX",$67 - $72 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_0711f84b&cb=1619363520483&jobListingId=1007016591105&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-cda96fa3f9de6c32,"We Are Hiring:

Ascension Information Services is one of the nation’s largest healthcare information technology services organizations.
We provide Ascension and its subsidiaries low-cost, high-value IT infrastructure and software application services that:
Support rapid and effective clinical decision makingImprove efficiency and care transitionsFoster information sharing across the continuum of careMake knowledge and data actionable, leading to improved patient outcomes
What You Will Do:

Responsible for construction and development of ""large-scale cloud data processing systems"" The Data Engineer must have considerable expertise in data warehousing and job requires proven coding expertise with Python, Java, SQL, and Spark languages. Must be able to implement enterprise cloud data architecture designs, and will work closely with the rest of the scrum team and internal business partners to identify, evaluate, design, and implement large scale data solutions, structured and unstructured, public and proprietary data. The Data Engineer will work iteratively on the cloud platform to design, develop and implement scalable, high performance solutions that offer measurable business value to customers.
Required Work Experience:
Four to seven years of experience required.
Some of the minimum experience requirement may be met with Masters or other advanced degreeCloud Experience Required
Coding experience with Python, Java, Spark, and SQL
Strong Linux/Unix background and hands on knowledge.
Past experience with big data technologies including HDFS, Spark, Impala, Hive,
Experience with Shell scripting and bash.
Experience with version control platform github
Experience unit testing code.
Experience with development ecosystem including Jenkins, Artifactory, CI/CD, and Terraform.
Works on problems of diverse scope and complexity ranging from moderate to substantial
Assists senior professionals in determining methods and procedures for new tasks
Leads basic or moderately complex projects/activities on semi-regular basis
Must possess excellent written and verbal communication skills
Ability to understand and analyze complex data sets
Exercises independent judgment on basic or moderately complex issues regarding job and related tasks
Makes recommendations to management on new processes, tools and techniques, or development of new products and services
Makes decisions regarding daily priorities for a work group; provides guidance to and/or assists staff on non-routine or escalated issues
Decisions have a moderate impact on operations within a department
Works under minimal supervision, uses independent judgment requiring analysis of variable factors
Requires little instruction on day-to-day work and general direction on more complex tasks and projects
Collaborates with senior professionals in the development of methods, techniques and analytical approach
Ability to advise management on approaches to optimize for data platform success.
Able to effectively communicate highly technical information to numerous audiences, including management, the user community, and less-experienced staff.
Consistently communicate on status of project deliverables
Consistently provide work effort estimates to management to assist in setting priorities
Deliver timely work in accordance with estimates
Solve problems as they arise and communicate potential roadblocks to manage expectations
Adhere strictly to all security policies
Desired Work Experience:
Proficient in multiple programming languages, frameworks, domains, and tools.
Coding skills in Scala
Experience with gcp platform development tools Pub/sub, cloud storage, big table, big query, data flow, data proc, and composer desired.
Strong Linux/Unix background and hands on knowledge.
Knowledge in Hadoop and cloud platforms and surrounding ecosystems.
Experience with web services and APIs as in RESTful and SOAP.
Ability to document designs and concepts
API Orchestration and Choreography for consumer apps
Well rounded technical expertise in Apache packages and Hybrid cloud architectures
Pipeline creation and automation for Data Acquisition
Metadata extraction pipeline design and creation between raw and finally transformed datasets
Quality control metrics data collection on data acquisition pipelines
Able to collaborate with scrum team including scrum master, product owner, data analysts, Quality Assurance, business owners, and data architecture to produce the best possible end products
Experience contributing to and leveraging jira and confluence.
Strong experience working with real time streaming applications and batch style large scale distributed computing applications using tools like Spark, Kafka, Flume, pubsub, and airflow.
Ability to work with different file formats like Avro, Parquet, and JSON.
Managing and scheduling batch jobs.
Hands on experience in Analysis, Design, Coding and Testing phases of Software Development Life Cycle (SDLC)..
Qualifications and Education:
Master level technology degree preferred
Technology certifications preferred
Bachelor's in computer engineering or equivalent field or equivalent foreign degree required
What You Will Need:

Education:
High school diploma/GED with 2 years of experience, or Associate's degree, or Bachelor's degree required.
Work Experience:
1 year of experience required.4 years of experience preferred.2 years of leadership or management experience preferred.
Additional Preferences:

No additional preferences.
Why Join Our Team:

Ascension is a faith-based healthcare organization dedicated to transformation through innovation across the continuum of care. As one of the leading non-profit and Catholic health systems in the U.S., Ascension is committed to delivering compassionate, personalized care to all. In FY2020, Ascension provided $2.4 billion in care of persons living in poverty and other community benefit programs. Ascension includes more than 160,000 associates and 40,000 aligned providers across a national network of ministries. We offer rewarding careers across more than 2,600 sites of care – including 146 hospitals and more than 50 senior living facilities – in 19 states and the District of Columbia.
Equal Employment Opportunity Employer:

Ascension Technologies is an equal opportunity employer (EEO) and affords equal opportunity to all associates and applicants without regard to race, color, religion, national origin, gender identity, sexual orientation, age, physical or mental disability, veteran status, genetic data, or other legally protected status. For further information regarding your EEO rights, click on the following link to the “EEO is the Law” poster:
http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf
EEO is the Law Poster Supplement
Please note that Ascension will make an offer of employment only to individuals who have applied for a position using our official application. Be on alert for possible fraudulent offers of employment. Ascension will not solicit money or banking information from applicants.",aus,de
48,Dutech Systems Inc,Information Technology,4.9,Sr. Data Engineer,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_33ac4895&cb=1619363520485&jobListingId=1007015990325&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-1584dd4ba59218c5,"Hiring for our client.Contract on w2The Data division is part of the OAG’s technology organization and is responsible for building data assets to provide value added products and services to drive innovation for our partners and clients. As a Senior Data Engineer, you will help design, enhance and build solutions dealing with real-time data in a fast-paced environment working with/on cutting-edge data and cloud technologies. You will work with colleagues who will support and challenge you daily. We believe in self-managing Agile teams who build products end to end, focusing on unit testing, code reviews and continuous integration for excellent code quality.The ideal Senior Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data focused applications. You are committed to data automation and integrity, are highly analytical, and can work on multiple projects at once. You will use your skills to engineer, automate, and manage data systems across multiple cloud services platforms and toolsets. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by Texas OAG are core reasons people enjoy working as part of the Data Division.Minimum Requirements: Years Required/Preferred Experience8 Required Experience in large-scale IT Project/Product delivery with at least 3 years of work experience in current data streaming, messaging, management, and database technologies8 Required Ability to establish and always maintain effective and professional working relationships with others in the course and scope of conducting business8 Required Excellent communication, problem-solving, and organizational skills5 Required Strong data integrity, analytical, and multitasking skills4 Preferred Graduation from an accredited four-year college or university with major coursework in Computer Science or Engineering3 Preferred Experience creating producer and consumer applications with Kafka2 Preferred Experience with designing and building data platforms2 Preferred Experience in tuning and troubleshooting streaming/messaging platforms2 Preferred Experience coding and scripting (Python, Java, Scala) and design experience2 Preferred Experience with ELT methodologies and tools2 Preferred Hands-on experience with AWS and/or Azure2 Preferred Experience with KStreams and KSQL2 Preferred Experience with designing and automating build and deployment solutions/process for data solutions2 Preferred Familiarity with data visualization, warehouse, and analytics tools/platforms such as Qlick, SAS Viya, Kibana, Snowflake2 Preferred Experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)1 Preferred Basic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)1 Preferred Able to work independentlyJob Types: Full-time, ContractPay: $60.00 - $70.00 per hourBenefits:Health insuranceSchedule:Monday to FridayApplication Question(s):can you work on w2?Education:Bachelor's (Required)Experience:coding with python or java: 2 years (Required)Contract Length:3 - 4 monthsWork Location:One locationCompany's website:dutechsystems.comWork Remotely:Temporarily due to COVID-19",aus,de
49,Logic20/20,Business Services,3.8,PySpark Data Engineer,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_7912efc8&cb=1619363520483&jobListingId=1007016645767&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-4f5adde358f1da97,"This position is a remote opportunity.

In a nutshell...
Our Advanced Analytics team is looking for a PySpark Data Engineer to design and develop a scalable data processing infrastructure for our client in the utilities industry. You’ll work closely with our team of analysts, TPMs, and data scientists to enable data-driven decision making and build solutions that have a real-world impact on public safety, customer experience, and environmental protection.
At the same time, you’ll be joining a five-time Best Company to Work For, where super-smart, talented people come together to do outstanding work—and have a heck of a lot of fun while they’re at it. Because we’re a consulting shop with a diverse clientele, you can count on a steady stream of opportunities to work with cutting-edge technologies and different types of data on projects that make a real difference.

We are...
The Logic20/20 Advanced Analytics team is where rock stars in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.
“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Director, Advanced Analytics
About you
You’re the perfect person for the job if you’re a big-data engineering ninja with …
A nose for uncovering business needs and pain points in partnership with executive management
A talent for communicating engineering concepts to non-techy business stakeholders
A passion for building large-scale machine learning pipelines
A knack for developing and iterating solutions at record speed
What you’ll be doing
Joining forces with internal and external teams to understand the client’s business needs
Designing and developing a scalable data processing infrastructure
Helping the client better understand their core needs, with a keen awareness of technical limitations.
Your qualifications
Strong understanding of high-performance ETL development with Python
5+ years of data engineering, 3+ years of PySpark
Data engineering implementation experience with some of the following technologies:
Python
Spark and PySpark
SparkSQL
Advanced engineering skills with Python
Comfortable working with very large data
Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule
Strong communication and interpersonal skills
Ability to work both independently and as part of a team
Work across team to solve technical roadblocks for our customers.
An undergraduate degree in technology or business is required
We'd be super impressed if you had...
Experience building data and computational systems that support machine learning
Knowledge of AWS services
Experience with modern software delivery practices, including source control, testing, continuous delivery
Experience delivering product with Agile methodologies
Experience with streaming data in Spark
More reasons to work with Logic20/20
Recognition by Seattle Business as a Best Company to Work For—five years in a row
Benefits including medical, dental, vision, life insurance, EAP, 401(k), and more
Training, certification, career management, and mentorship programs to keep your brilliant career moving forward
Flex time and remote-work options, depending on the project
Paid time off to enjoy your life outside work (yes, we know you have one)
Company-sponsored volunteer events where you can give back while having fun",aus,de
50,Logic20/20,Business Services,3.8,"Data Visualization Engineer, Power BI","Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_3fecd7f0&cb=1619363520484&jobListingId=1007016645806&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-c9825192308cd907,"Data Visualization Engineer, Power BI


About the Role . . .
Our Advanced Analytics team is looking for a seasoned Power BI Data Visualization Developer.
At the same time, you’ll be joining a five-time Best Company to Work For, where super-smart, talented people come together to do outstanding work—and have a heck of a lot of fun while they’re at it. Because we’re a full-service consulting firm with a diverse clientele, you can count on a steady stream of opportunities to work with cutting-edge technologies on projects that make a real difference. Logic20/20's Global Delivery Model creates a connected experience for Logicians across geographies. You'll have access to projects in different locations, the technology to support Connected Teams, and in-person and online culture in our Connected Hub cities.

Primary Skills:
5+ years of analytics experience
Deep Power BI skills & expertise
Ability to operate independently
Great communication skills
Experience with the following visualization tools including:
Power BI
DAX
MDX
SQL
Secondary Skills
Basic relational database theory knowledge
Basic understanding of data modeling
Ability to query, load, and analyze data with the intent to identify patterns
Experience writing SQL to query databases, structure and modify data
Business domain knowledge in procurement, supply chain, telecom
Experience modeling data in either a database or visualization tool
Understanding of Reporting Lifecycle including adoption, training, and change management
An undergraduate degree in technology or business is preferred
About Logic20/20
The Logic20/20 Advanced Analytics team is where rock stars in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.
“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Director, Advanced Analytics",aus,de
51,Intone Networks,Information Technology,4.4,Sr. Data Engineer,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_43b8e2f7&cb=1619363520484&jobListingId=1007018209425&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-601b2d7e01773805,"Our Engineers are energetic influencers who thrive on designing simple and scalable solutions to complex problems and delivering leading edge software products for our customers. We are looking for exceptionally ambitious and communicative hands-on individuals who are comfortable collaborating within the Agile methodology as part of a cross-functional team, have experience working in fast-paced environments, and who have the passion and skills to take our product offerings to the next level. As a Senior Data Engineer, you will be a technical leader in a collaborative team environment that encourages you to perform at your best, while contributing to the engineering efforts of one of our data scrum teams. You will be challenged to engineer right-sized solutions for complex business problems focused on building patterns to support data pipelines, data warehousing, and data transformations. You will apply your knowledge of modern software design, best practices, design patterns, and frameworks, with an understanding of application performance and maintainability. You will aspire to use new technologies and challenge yourself to develop innovative solutions. You will work alongside developers and technical leads on a team where collaborative programming and mentoring is regularly practiced. Technologies we use • .NET Core, C#, Python • Oracle, Snowflake • Apache Spark • AWS o Compute: EC2, Lambda o Containers: ECS, EKS, Fargate, ECR o Data: S3, RDS, Aurora, DynamoDB, ElastiCache, DMS o Analytics: EMR, Elasticsearch o Networking: VPC, Route 53, API Gateway, Direct Connect o DevOps: CodeBuild, CodePipeline, CloudWatch o Messaging: SQS, SNS • Terraform • Tableau Your Role: • Display a high level of critical thinking in bringing success to the organization • Influence technical solutions while coaching newer or less experienced members on your Scrum team • Construct and manage services which extract data from disparate databases, transform the data and loads into a Snowflake data warehouse • Collaborate with team members on best practices, code reviews, internal tools and process improvements • Evangelize new ideas within your team as well as across teams • Develop high performing, scalable and secure solutions • Plan and deliver core technology upgrades • Diagnose, design, and implement solutions to key technology or application problems Qualifications: Required • 5+ years of professional software development experience • BA/BS degree in Computer Science or related field (or equivalent work experience in lieu of education) • Understanding of ETL and ELT processes • Data Warehousing experience, including Snowflake or other data warehousing tools • AWS/Cloud experience • Programming experience with data sets in Python, Scala, Java or C# • Understanding of SQL, relational databases, columnar data warehouses, and data modeling • Apache Spark experience • Experience with automated infrastructure tooling • A history of taking applications from conception/design to implementation/support • Experience designing and implementing applications with highly optimized and scalable architectures Preferred • Experience with CDC (Change Data Capture) and parquet formats • Experience with data replication tools (Attunity, DeltaLake, or Hudi) • AWS Data Migration Services (DMS) • Amazon EMR • Experience developing on Oracle databases • Work monitoring and tuning EMR/Spark/YARN • Experience working with/implementing CI/CD pipelines • Experience with Terraform • Familiarity with BI tools such as Tableau • Strong understanding of industry development, deployment processes and agile development methodologies • Advanced degree in Computer Engineering/Science or related field What We Look For • Ability to work on multiple projects and be flexible to adapt to changing requirements • Ability to turn high-level requirements into a working system through iterative development • Proven ability to work collaboratively and independently to design, develop and deploy solutions • High energy, confident, ambitious and self-motivated individual • Must be an effective communicator",aus,de
52,MW Partners,Information Technology,4.2,Azure Data Engineer,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_efd5aff3&cb=1619363520484&jobListingId=1007020706175&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-f81bb9d46c13d836,"Azure Data Engineer requirements are:We are looking for a senior Azure Data Engineer to join the data modernization project team. The senior data engineer should have skills and experience building data analytics pipelines using Azure Data Lake Gen2 (Blob Storage), Azure Data Factory (Pipelines and Data Flows), Azure Data Catalog, Azure Event Grid, Azure Service Bus, Azure SQL Database, and Synapse Analytics.The agency is implementing a new data pipeline in the Azure cloud environment.Senior data engineer with skills and experience building data analytics pipelines using Azure Data Lake Gen2 (Blob Storage), Azure Data Factory (Pipelines and Data Flows), Azure Data Catalog, Azure Event Grid, Azure Service Bus, Azure SQL Database, Synapse AnalyticsAbility to assist the Senior Director, Cloud Development in planning and designing the overall architecture, completes complex project work, including troubleshooting and correcting errors/issues. Provides status updates on work assignments and any technical issues that present risk to project timeline as required by selected project framework.The senior data engineer will be working on a 6-member scrum team to support the agency's data modernization project.The data engineer will be building data analytics pipelines using Azure Data Lake Gen2 (Blob Storage), Azure Data Factory (Pipelines and Data Flows), Azure Data Catalog, Azure Event Grid, Azure Service Bus, Azure SQL Database, Synapse AnalyticsJob Type: Full-timeSchedule:8 hour shiftWork Remotely:Temporarily due to COVID-19Speak with the employer+91 6055974003",aus,de
53,IBM,Information Technology,3.9,Data Operations Engineer Summer Intern 2020 (AI Applications),"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_59f361ba&cb=1619363520484&jobListingId=1007016109645&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-8210046d881cc010,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities
Ready to change the world? Climate change, weather forecasts and agricultural productions are just some of the challenges taken on by IBM. Our team uses geo-spatial analytics, Big Data and data science to address these real-world problems that affect us all. We are looking to add a results oriented individual to join us and help develop, advance and maintain the geospatial analytics infrastructure that serves up over 6 Petabytes of information for our customers.


As a team member you will be:
Passionate about each client and their successBuilding and refactoring our environment to leverage the latest cloud and DevOps infrastructureWorking closely with data scientists to design new ways to efficiently and effectively work with our geospatial engine.Knowledgeable and skilled with one or more languages like Python,
Java, and C. User Interface skills like node.js or Angular is a plus.
Knowledgeable and skilled with cloud tools such as Docker and Kubernetes, and willing to
learn other tools like Jenkins
Knowledgeable and/or willing to learn about different database
Technologies (PostgreSQL, Hadoop)

Knowledgeable and/or willing to learn about data science and
Conscientious about deadlines and deliverablesExcited to continue to learn and develop new skills
Dates for this summer internship are May/June - August (12 weeks).


Required Technical and Professional Expertise

Knowledgeable and skilled with one or more languages like Python, Java, and/or C.
Knowledgeable and skilled with cloud tools such as Docker and Kubernetes, and willing to learn other tools like Jenkins
Knowledgeable and/or willing to learn about different database technologies (PostgreSQL, Hadoop)
Currently enrolled in an undergraduate degree program
Preferred Technical and Professional Expertise

User Interface skills like node.js or Angular
Previous Intern/Co-Op experience
About Business UnitIBM’s Cloud and Cognitive software business is committed to bringing the power of IBM’s Cloud and Watson/AI technologies to life for our clients and ecosystem partners around the world. IBM provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments—with complete software solutions for business and IT operations, development, data science, security, and management. Our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their IT estate, and automate operations with management visibility. With IBM, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners.

Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location StatementIBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

IBM intends this job to be performed entirely outside of Colorado.

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",aus,de
54,"Advanced Micro Devices, Inc.",Information Technology,4.1,Data Engineer - 92134,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_3d2f24bf&cb=1619363520484&jobListingId=1007014702159&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-d33817d3cf135285,"What you do at AMD changes everything
At AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies – building blocks for gaming, immersive platforms, and the data center.
Developing great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the “extra mile” to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.
Data Engineer - 92134
The Role:
Are you a Data Engineer, passionate about analysis and report engineering?
We are looking for an Engineer in our Systems Power and Performance Attainment team. Drive balanced, scalable, and automated solutions for our Performance, Power, and Stability data analysis capability. In this high visibility position, your software systems engineering expertise will seek data flow challenges from the System Under Test to the Cloud and back to the Engineers. Ability to work multi-functionally will ensure full engagement with our core automation, product engineering, & other teams, and software program management skills will help provide a tactical execution structure for your Blueprint.
The Person:
Curiosity will drive learning to improve how we as a group, and an organization, can get better every day, and your peers will provide a diverse and encouraging environment for career growth, driving the opportunity to be a part of Delighting Our Customers.
We at AMD are Gamers and Performance Enthusiasts at heart, so if you like Acute Performance and seeing your work provide direct benefits to our customers’ quality of computing life, you would love our team.
Key Responsibilities:
Be accountable for the automated monitoring of data store health and readiness
Own data automation for our team, including generation, ingress, conversion, egress, report outs, and documentation to enable rationalized summaries of product and process health
Optimize data processes & transformations to improve efficacy and efficiency of both staff and compute resources, defining and publishing critical metrics where appropriate
Engage with multi-functional leadership & teams to integrate your output with other project work streams
Hands-on debug to root cause performance and data/analysis flow & delivery challenges; collaborate with peer teams to analyze and resolve issues.
Assist multi-functional technical teams with targeted ad hoc analyses methodologies
Make an impact by collaborating with other specialists on common program test & debug activities and process improvements
Preferred Experience:
Languages – Primary : SQL, JSON, Python
Secondary : .Net, Java, JavaScript, C#, XML, etc.
Databases/BI Tools: SQL and No-SQL, Looker, PowerBI, Sigma, Excel, etc.
Process Flow – GitHub, Nifi, ADF, Azure DevOps, Snowflake ELT, etc.
SCADA – automation systems, test device endpoint control, & API experience preferred
Academic Credentials:
Bachelor’s or Master’s degree in Computer Science or Computer or Electrical Engineering preferred with 5-7+ years validated experience
Location:
Austin, Texas
Outstanding relocation and employee benefits offered!

#LI-AG1

Requisition Number: 92134
Country: United States State: Texas City: Austin
Job Function: Design

AMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.",aus,de
55,Bright Health,Health Care,3.4,Software Engineer - Data Platform,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_198dcea4&cb=1619363520484&jobListingId=1007016186283&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-fb3a43a1c43b906a,"“Making Healthcare Right. Together.” is the cornerstone of all we do. Our vision is to deliver the best healthcare experience by putting brilliant minds, empathetic hearts and personalized technology to work to create meaningful relationships between our members and Care Partners. To successfully achieve our mission and vision as we operate in a dynamic health care environment, we expect Bright People to embody and uphold our core values in work and interactions, both internal and external: Be Purposeful, Be Authentic, Be Brave, Be Positive, Be Respectful, and Be Accountable.
The Software Engineer 2 is responsible for implementation and delivery of backend services and data platform frameworks. They will leverage PaaS and IaaS cloud offerings to build services that support data management, infrastructure, AI services, and industry interoperability. They should contribute to projects and development efforts using agile methodologies.
YOUR RESPONSIBILITIES:
Write traditional code and server-less functions using the language best suited for the task, which typically include C#, T-SQL and PowerShell
Apply Cloud and Object Oriented design and resiliency patterns
Build APIs and data microservices to share our data with internal and external partners, and write interfaces to public data sets to enrich our analytics data stores
Participate in building and owning a culture of DevOps and Quality Assurance
Continuously document your code, framework standards, and team processes
EDUCATION, TRAINING, AND PROFESSIONAL EXPERIENCE:
Two (2) - Five (5) years of experience in an enterprise or commercial software development environment. Healthcare IT background is highly preferred
Enterprise development experience coding in at least one, but preferably more than one, procedural/OO or functional programming language, including C#, Scala, Java, Python, PowerShell
Experience deploying and running cloud-native, elastic application and data solutions (AWS, GCP, Azure).
Experience using query languages like SQL for relational and / or nonrelational data stores.
Understanding of performance and scaling, as applied to backend/data stores
Software testing fundamentals including automated unit and integration testing (we're big on TDD).
PREFERRED QUALIFICATIONS:
Experience building streaming data pipelines using Kafka or Spark Streaming.
Experience with functional programming in Scala
Experience with API design.
Experience building distributed systems with microservices and/or service-oriented architectures
Familiarity with containerization/virtualization, e.g., Docker, Kubernetes
Familiarity with CI/CD best practices
Hands on Azure admin and devops experience
BONUS POINTS!
Experience engineering big-data solutions using technologies like Databricks, Hive, and Spark.
Scala and C#
PROFESSIONAL COMPETENCIES:
Team player who is not afraid to ask questions, take risks, share in owning team victories as well as team failures
Good communicator – both written and verbal – with high emotional intelligence
Ability to focus on MVP and shipping software while remaining cognizant of the long-term costs of technical debt
 We’re Making Healthcare Right. Together.
We've won some fun awards like: Great Places to Work, Modern Healthcare, Forbes, etc. But more than anything, we're a group of people who are really dedicated to our mission in healthcare. Come join our growing team!
Check out this great video showcasing just some of the fantastic Technology Team broadcasting from our ATX office!

As an Equal Opportunity Employer, we welcome and employ a diverse employee group committed to meeting the needs of Bright Health, our consumers, and the communities we serve. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.",aus,de
56,Invitae,Biotech & Pharmaceuticals,4.1,Infrastructure Engineer (Data),"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5eaeaa3f&cb=1619363520485&jobListingId=1007021712764&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-679d8a107e13d916,"Invitae is a healthcare technology company that leverages genetic information to empower doctors and patients to make informed medical decisions. Our software engineers work on a variety of projects ranging from innovations in healthcare systems to taming the chaos of biology. We're constantly improving our tools and technologies to deliver the highest quality actionable information for the patient.

Our Data Infrastructure Team manages the underlying infrastructure upon which we build our data ingestion pipelines and data platform architecture to support business, data science, and engineering stakeholders across Invitae. This is a hands-on role.

What you will do:

Support a rapidly growing team of engineers by automating operational tasks, allowing more creating and less debugging
Work within our AWS-based streaming data platform to ensure uptime, reliability, efficiency, and ease of use through automation, industry-standard best practices, and new and bleeding edge solutions, keeping security top of mind
Take ownership of our architecture, manage our infrastructure with Terraform, and strive every day to make it better (more reliable, scalable, etc.)
Manage and continuously improve our build and data pipeline system, including Kubernetes, Kafka, Spark, Snowflake, and CI/CD Pipelines
Improve our data platform's observability utilizing custom metrics and/or integrations (e.g. Prometheus, Grafana)
Understand and contribute to our complex data ecosystem, promote solutions to other teams, and communicate any impactful changes to stakeholders

We look for engineers who:

Are self-starters and can work towards a larger goal with minimal guidance
Have strong written and verbal communication skills
Have an extensive understanding of AWS applications and principles
Have architected distributed systems with infrastructure automation, monitoring, logging, and alerting
Have a proven track record of improving systems in secure, reliable, and reproducible ways
Have mastery of at least one coding language (e.g. Python, Scala, Golang)
Are curious about how things work at a fundamental level and strive to automate themselves out of a job
Are lifelong learners, always pushing themselves, their teammates, and their systems to be the best they can be.

Nice to Haves:

Proven experience deploying and managing complex Kubernetes clusters
Experience with other CNCF projects like Flux, Helm, Prometheus, etc.
Strong SQL experience
Experience with Linux systems (e.g. Ubuntu, Amazon Linux) and Bash
Experience with CI/CD pipelines (e.g. Jenkins, GitHub Actions)
BONUS: Prior experience utilizing data warehousing or building out data warehouses
BONUS: Hands-on experience working with large datasets, pipelines, and their supporting infrastructure

At Invitae, we value diversity and provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.",aus,de
57,Logic20/20,Business Services,3.8,Senior Data Engineer,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_35870f58&cb=1619363520485&jobListingId=1007016645760&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-2c8cd5f4e906993f,"Senior Data Engineer

About the Role. . .
Our Advanced Analytics team is looking for a seasoned Data Engineer with Cloud Solutions background to add to our team. This engineer is responsible for building a large-scale data pipeline in cloud platform. This may involve in automation of manual processes to cloud environment. This engineer would direct the initiatives for creation of data sets and delivering client value while ensuring high client satisfaction.
At the same time, you’ll be joining a five-time Best Company to Work For, where super-smart, talented people come together to do outstanding work—and have a heck of a lot of fun while they’re at it. Because we’re a full-service consulting firm with a diverse clientele, you can count on a steady stream of opportunities to work with cutting-edge technologies on projects that make a real difference. Logic20/20's Global Delivery Model creates a connected experience for Logicians across geographies. You'll have access to projects in different locations, the technology to support Connected Teams, and in-person and online culture in our Connected Hub cities.
Core responsibilities for this position include, but are not limited to the following. . .
Extracts data from various databases; perform exploratory data analysis, cleanses, massages, and aggregates data
Employs scaling & automation to data preparation techniques - Introduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveries
Researches relevant emerging empirical methods and quantitative tools
Possesses in-depth business knowledge in order to initiate and drive discussions with business partners to identify business issues needing analytic solutions
Leads innovative packaging and presentation of insights to business and broader analytics community
Develops processes to automate and scale insights operationalization
Develops and drives multiple cross-departmental projects
Establishes brand and team as subject matter experts in advanced analytics across departments.
Mentors data scientists in pioneering techniques and business acumen
Qualifications . . .
Cloud solution implementation experience with Azure Data Lake and Spark preferred
Minimum 5 years hands-on experience with SQL
At least one year of experience in scripting languages such as Python
Demonstrated experience in a cloud-based -computing environment such as AWS, Azure, or Google Cloud Platform
Big data processing techniques, preferred
Can work independently in ambiguous environment
About Logic20/20 . . .
The Logic20/20 Advanced Analytics team is where rock stars in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.
“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Director, Advanced Analytics",aus,de
58,Spreetail,Retail,3.1,Sr Data Science Engineer,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_56289d24&cb=1619363520485&jobListingId=1007019310813&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-1ffcb5ec8228ad28,"Spreetail is an ecommerce company that connects brands with customers wherever they love to shop online. We delight our customers every day by putting our technology, marketing, and supply chain to work for them behind the scenes. Born and raised in Lincoln, Nebraska, Spreetail has grown into offices and fulfillment centers in 8 cities across 6 states.
Life at Spreetail
Working at Spreetail is a once-in-a-lifetime opportunity to help build one of the fastest-growing ecommerce companies in history. We take on challenges that others would call impossible because we have a team of amazing, talented people who collaborate and think bigger together. At Spreetail, you’ll create deep, personal connections and challenge yourself to achieve your most ambitious goals.
As a Sr. Data Science Engineer you will:
Build analytical models and algorithms that surface business insights at massive scale
Create models that are flexible and responsive to fast-changing variables or a significant influx or departure of variables from the model
Develop models that are trained, tested, and deployed with quality and efficiency
Break down major initiatives and insights needs into smaller components and tasks.
Build models that can be operationalized into existing analytical systems.
Build systems that are documented and easily explained to your business and Technology stakeholders.
Who you are:
Bachelor’s or graduate degree in computer engineering, economics, statistics, or mathematics preferred
2-5 years of experience in a data science/modeling role
2-5 years of experience working in a data engineering lifecycle
1-3 years of experience with machine learning models and techniques required
Experience in product marketing, market research, supply chain, or other ecommerce domain preferred
Intermediate SQL extract (SELECT statements) skills required; expertise preferred
Advanced-to-expert level skills in statistical programming languages (Python, R, etc.)
Intermediate experience with “big data” storage and processing technologies (Hadoop, Apache Spark, Azure Synapse, Snowflake, etc.) required
Quick to learn and adapt to new technologies
Benefits
Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team performanceCompany Bonus: Up to 5% of yearly salary; based upon company and team performanceHealth Insurance: Spreetail offers two plans:Aetna PPO: Spreetail covers 100% of premiums for employees and 50% for your spouse and dependents included on the plan.Aetna HDHP HSA Plan: Spreetail will contribute $500 to an HSA for an employee-only plan or $1000 for your spouse and dependents included on the plan.Dental Insurance: Spreetail will pay half of the dental coverage for you/spouse/family plans401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan optionsPaid Time Off: untracked time offWedding Week: Enjoy an additional 5 paid days off before or after your weddingCreating a Home: After 2 years of employment, Spreetail will give you $5,000 when you buy a homeYear 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive vacationYear 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid sabbaticalDonation Matching: Spreetail will match your donation dollar for dollar, up to $250 a
year and up to $1,000 if you've been here for 5 yearsCommunity Involvement: Spreetail encourages employees to take time off for volunteer opportunities throughout the year, including a semi-annual volunteer week in every community we serveProduct Discount: Enjoy a 20% discount on the products we sell
Equal Opportunity Employer
Spreetail is an equal opportunity employer that hires based on stellar qualifications, positive attitude, and exemplary work ethic rather than factors like age, gender identity, race, nationality, religion, or sexuality.",aus,de
59,Wayfair,Retail,3.5,Data Engineer 3 - Customer Service,"Austin, TX",$58 - $67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136043&s=58&guid=0000017909965e85bf3038f09eaecc00&src=GD_JOB_AD&t=SR&vt=w&cs=1_ea4b4d59&cb=1619363520485&jobListingId=1007016951292&jrtk=1-1f44pcnlbu4nu801-1f44pcnm0u2gh800-884abcc4bc5a7413,"Wayfair Data Solutions is the engine that powers an enterprise obsessed with data. We move fast, iterating quickly on big business problems. We work smart, applying technology to unlock insights and provide outsized value to our customers. We swing big, knowing our customers won’t benefit from micro optimizations. Leveraging the largest data set for products sold in the Home space, this team treats data as an asset and determines how to maximize its business value and extend our competitive advantage.

As a Data Solutions Engineer, you will be a hands-on technical leader who design and delivers Business Intelligence, Data Warehousing and Big Data Solution for our Customer Service Organization.

You will be responsible for driving the Wayfair Customer Service Transformation. You will be instrumental in building out our underlying data layer that will ensure Wayfair captures everything involved in the customer experience both on-site and during a support call/chat. Capturing the full life cycle of an incident, what that incident entails, and ultimately the resolution.
What you'll do:

Own and develop technical architecture, design and implementation of big data platforms and business analytics solutions to empower your stakeholders to solve their data driven analytics and reporting needs
Build, schedule, and manage data movement from application origin through batch and streaming systems to make it available for key business decisions.
Develop a robust, sustainable plan for the data area going forward, including projecting space requirements, procuring technology, and partnering with engineering on improvements to the data, 100TB+ highly desired.
Ensure data products are aligned with the rapidly evolving needs of a multi-billion-dollar business.
Provide consulting to application and data engineering organizations on best practices for designing applications to enable easy analytics; be an expert on large-scale data processing.

Who you are:

A true expert on big data, comfortable working with datasets of varying latencies and size and disparate platforms.
Excited about unlocking the valuable data hidden in inaccessible raw tables and logs.
Attentive to detail and with a relentless focus on accuracy.
Excited to collaborate with partners in business reporting and engineering to determine the source of truth of key business metrics.
Familiarity with distributed data storage systems and the tradeoffs inherent in each one.

Who you are:

Minimum 5+ years of relevant experience
Data modeling, extensive experience with SQL, Python, and exposure to cloud computing (AWS, Azure or Google, Google Cloud Preferable).
Experience with one or more higher-level JVM-based data processing tools such as Beam, Dataflow, Spark or Flink.
Experience designing and implementing different data warehousing technologies and approaches, such as RDBMS and NoSQL, Kimball vs. Inmon, etc. and how to apply them.
Experience scheduling, structuring, and owning data transformation jobs that span multiple systems and have high requirements for volume handled, duration, or timing.
Prior projects working with optimizing storage and access of high volume heterogeneous data with distributed systems such as Hadoop, including familiarity with various data storage mediums and the tradeoffs of each
Prior data infrastructure experience in support to a Service driven organization is a plus but not essential.
Bachelors or Masters in Computer Science, Computer Engineering, Analytics, Mathematics, Statistics, Information Systems, Economics, Management or other quantitative discipline fields with a strong academic record

About Wayfair Inc.

Wayfair is one of the world’s largest online destinations for the home. Whether you work in our global headquarters in Boston or Berlin, or in our warehouses or offices throughout the world, we’re reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you’re looking for rapid growth, constant learning, and dynamic challenges, then you’ll find that amazing career opportunities are knocking.

No matter who you are, Wayfair is a place you can call home. We’re a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair – and world – for all. Every voice, every perspective matters. That’s why we’re proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, or genetic information.",aus,de
110,Stamps.com,Information Technology,4,Data Engineer,"Austin, TX",$70K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=0000017909988a289ec34f63b31636e0&src=GD_JOB_AD&t=SR&vt=w&cs=1_ba52ef34&cb=1619363662965&jobListingId=4070406186,"The Analytics team is responsible for making Auctane’s data reliable, trustworthy and easy to use. We do this by creating a data ecosystem that enables Auctane to use data to make our product better, facilitate decision making, and help drive business value. In addition, the Analytics team partners with stakeholders from across the business to deliver both standardized & ad-hoc reporting, analysis & insights to drive business decisions.Strategic Imperative:The Data Engineer will maintain our existing integrations as well as build new ones as the company adopts new software systems to meet its needs. Data from these integrations needs to be ingested, transformed, and combined in order to provide valuable insights to stakeholders across the organization. Sales, Marketing, Customer Support, and the Product teams currently use a variety of systems that have limited ability to talk to communicate with each other. By consolidating this data into one data warehouse, the various teams can see how their work affects customers and the company.Primary Objectives:Build integrations for all relevant internal systemsEnsure high level of data quality in data warehouseMonitor and support ETL processesProvide data to various stakeholders across the company through BI tools and operational applicationsQualifications - To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.Essential Position Duties (typical monthly, weekly, daily tasks):Manage new data integration projectsIdentify relevant data which needs to be extractedCreate necessary infrastructure to support integrationsTransform data to increase usability for stakeholdersSupport existing system integrationsEnsure that integrations are ingesting correct dataEnsure that integrations run on a regular scheduleFix issues in pipelining processes as they ariseCommunicate changes in data warehouse and integrations to relevant parties across the companyKnow which stakeholders need information from which integrationsCommunicate any changes or outages to relevant partiesSkills and Knowledge:Proficient in PythonHands-on experience implementing ETL (or ELT) best practices at scale.Hands-on experience with data pipelining tools (Airflow, Dagster, Prefect, dbt, Meltano)Have a deep understanding of SQL, data modeling, and analytical data warehouses, such as Redshift or BigQuery.Proactive communicator who can translate between technical and non-technical stakeholdersTeam player who gives and takes feedback in a thoughtful way, and loves to help others.Thrive on autonomy and have experience driving long-term, cross-functional projects to completion.Use distributed source control such as Git proficientlyEducation and/or Experience:Bachelor’s degree in Computer Science or Engineering or equivalent years’ experience.At least two years’ experience in data engineering or ETL/ELT processes.Preferred Experience:Experience with the specific tools we currently useAirflow, Kafka, dbt, Amazon RedshiftExperience orchestrating machine learningComputer/Software/Application Proficiency:Python, SQLGithub, Atlassian JiraTravel Requirements:10% or lessAdditional Position Duties: – (The following is a list of what all employees, except those with medical accommodation, may be regularly required to do.)Sit for prolonged periods of timeUtilize wrist and hands for a prolonged period of timeWalk short distancesStand for short periodsSpeaking and conversing with othersLift up to 25lbs without assistance up to chest heightEqual Opportunity Employer/Veterans/DisabledIf you are based in California, we encourage you to read this important information about the ShipStation Privacy Policy for California residents",aus,de
0,Vertex Pharmaceuticals Inc (US),Biotech & Pharmaceuticals,3.7,AWS Data Engineer,"Boston, MA",$73K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000179099e24918f44c0802ae16961&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_60bf1663&cb=1619364030060&jobListingId=4070498263,"General Summary:The AWS Cloud Senior Data Engineer II will assist in creating an integrated data pipeline, API, and microservices ecosystem using serverless architectures, languages like Python, and AWS capabilities like Athena, DynamoDB, Firehose, Kinesis, Glue, SageMaker, and more.Key Duties and Responsibilities:Build and maintain serverless data pipelines, derived datasets, and data discovery platforms at scale using AWS cloud servicesBuild and maintain serverless APIs and microservices to simplify data mastering, access, interrogation, cleansing, and exchangeDevelop and implement tests to ensure data quality across all integrated data sourcesContribute to software development efficiencies by advancing our agile development practices, automated build & test frameworks, privacy-by-design frameworks, and secure coding expertise.Collaborate directly with technical peers and non-technical end users to understand requirements, invent solutions, and create value quickly.Knowledge and Skills:Experience using AWS cloud services for data processing, storage, computation, monitoring, event processing, machine learning, and messaging such as Glue, Kinesis, Kinesis Firehose, S3, Athena, DynamoDB, Redshift, Athena, Neptune, SageMaker, API Gateway, Lambda, and othersExperience creating, versioning, and supporting RESTful services and APIs at scaleExperience ingesting and integrating data from many sources using streams, flat files, APIs and databasesProficient level understanding of Python and SQL by the ability to understand and apply advanced conceptsExperience determining and using the optimal database (relational, graph, columnar, document, ...) based on requirementUnderstanding of contemporary data file formats like ParquetExperience preparing data for use in a research setting a plusExperience with full stack development a plusExperience in life sciences industry a plusEducation and Experience:Bachelor’s degree in Computer Science or related disciplineTypically requires 4 years of experience or the equivalent combination of education and experience in relevant cloud data engineering or software engineering",bos,de
1,Capital One - US,Finance,4.1,Data Engineer,"Cambridge, MA",$78K - $142K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000179099e24918f44c0802ae16961&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_02236972&cb=1619364030060&jobListingId=4066637640,"314 Main Street (21020), United States of America, Cambridge, MassachusettsData EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 2 years of experience in application developmentAt least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree3+ years of experience in application development1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)1+ years of experience with Ansible / Terraform2+ years of experience with Agile engineering practices2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)2+ years of experience with NoSQL implementation (Mongo, Cassandra)2+ years of experience developing Java based software solutions2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)2+ years of experience developing software solutions to solve complex business problems2+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",bos,de
2,Akamai,Information Technology,4.4,DevOps Engineer II,"Cambridge, MA",$83K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_a1fe5571&cb=1619364030061&jobListingId=4066637830,"Do you like collaborating across teams to solve complex problems?Are you excited to build fault tolerant, highly available systems?Join the Network Systems GroupOur Networks team is responsible for deploying and maintaining our large global network that delivers a high percentage of the internet traffic. We support the various sub-teams within Networks, allowing them to do their jobs more efficiently.Be part of enhancing our organizationAs a DevOps Engineer, you will be responsible for building and maintaining internal services. You will work with various teams to shape our continuous integration and deployment environments.As a Dev Ops Engineer, you will be responsible for:Automating the installation and updating of software as well as maintenance tasks.Building tools to help keep track of server and application healthManaging systems with large amounts of data - both relational and non-relationalImproving system availability, reliability, and performanceDeveloping CI/CD pipelinesDo what you loveTo be successful in this role you will:Have 2 years of relevant experience and a Bachelor's degree or equivalent educationDemonstrate an understanding of data structures and basic algorithmsDemonstrate a solid understanding of networking and internet protocols such as TCP/IP, DNS, and HTTP/HTTPSBe comfortable in a Linux/UNIX environment in a Systems Administration capacityBe self-motivated, highly responsible team player with excellent communication and problem solving skillsPossess experience managing a relational databases such as MySQL or postgresqlHave solid experience with Python, Perl or PHPWork in a way that works for youWe recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone.We are happy to discuss flexible working options in this role, please discuss your requirements with the recruiter when you apply.Working with usAt Akamai, we’re curious, innovative, collaborative and tenacious. We celebrate diversity of thought and we hold an unwavering belief that we can make a meaningful difference. Our teams use their global perspectives to put customers at the forefront of everything they do, so if you are people-centric, you’ll thrive here.Working for youAt Akamai, we will provide you with opportunities to grow, flourish, and achieve great things. Our benefit options are designed to meet your individual needs for today and in the future. We provide benefits surrounding all aspects of your life:Your healthYour financesYour familyYour time at workYour time pursuing other endeavorsOur benefit plan options are designed to meet your individual needs and budget, both today and in the future.About usInnovating on a global scale, we deliver our customers a fast, smart and secure intelligent edge platform. Working against a backdrop of digital collaboration, our highly skilled teams build progressive solutions that have the scope to transform entertainment, business, and life in ways that we have yet to imagine.Join UsAre you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will challenge and inspire you! Akamai Technologies is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of gender, gender identity, sexual orientation, race/ethnicity, protected veteran status, disability, or other protected group status.",bos,de
3,Leidos,Aerospace & Defense,3.8,Technical Solution Sales Engineer,"Boston, MA",$57K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_6e9d980f&cb=1619364030061&jobListingId=4067115824,"Technical Solution Sales Engineer – Electric Utility Spatial AnalyticsNo two career paths will ever look the same. At Leidos, we know the most talented and diverse IT and engineering professionals will always have a multitude of career choices; your time at Leidos will be a wise investment in your career and in yourself.Protect yourself and your family, with the benefits of working for a world-class employer. When you join Leidos, you join a Fortune 500 company and one of Ethisphere Institute’s “World's Most Ethical Companies”.Successful candidates can look forward to a fast paced, diverse work environment & flexible work hours/work arrangements as well as managers who will encourage career development and growth including:Opportunity to lead, grow, and inspire a dynamic teamLeadership trainingManagement opportunitiesIn this role, you can also expect to:Participate in strategic development of solutionsContribute to an expanding portfolio of businessPartner with leading utilities across the nationLeidos fuses technological excellence with decades of operational and management consulting expertise, providing utilities with solutions delivering tangible and meaningful business results. Our expertise in each facet of utility operations is strengthened not only by the skill and experience of our staff, but also by the breadth of our collective capabilities. This perspective drives our experts to frame technological solutions within the business context and incorporate and leverage advanced technologies to meet utilities' challenges and unlock opportunity.Leidos is currently seeking an experienced individual to provide geospatial solution development and sales support as part of our Utility Spatial Analytics team. Preferred locations include Orlando, New Orleans, Washington DC, Boston, Nashville and Denver.Location may be flexible depending on the individual candidates identified. Successful candidates will be part of a team that provides spatial analytic solutions to electric utilities throughout the U.S.A successful candidate will have experience in the electric utility industry and in the development, sale, and/or implementation of technology-forward geospatial solutions that lead to improved electric utility business operations. Extensive travel will be required once client travel restrictions are no longer in place. The successful candidate will be highly self-motivated, articulate, personable, and able to perform with limited direct supervision.Representative services and activities in which successful candidates may be engaged include:Engage existing and potential clients in review of technology-forward geospatial solutions and value propositions.Present Leidos technical capabilities and provide expert insights to support the sale of utility spatial analytics solutions.Translate critical customer needs to technology solutions.Develop next-generation geospatial solutions utilizing advanced sensing technologies combined with AI / ML enhancing environmental and asset awareness.Direct interaction with clients at a high management level, including interpersonal interaction and presentation of information and analyses.Work with Leidos technical staff to refine utility spatial analytics solutions, pricing and scope.Partner with Leidos Commercial Energy business development staff to create a utility spatial analytics sales pipeline and drive opportunities to closure of complex sales opportunities.Monitor ongoing utility spatial analytics programs for effectiveness and client satisfaction and provide input to technical teams.Develop key client plans for the continuation of program development and expansion.Required Qualifications:Bachelors degree and 12+ years of prior relevant experience or Masters and 10+ years of prior relevant experience. Relevant experience includes demonstrated experience in crafting and selling solutions that utilize data analytics, spatial analytics, artificial intelligence/machine learning.Over 5 years experience in, and understanding of, the use of spatial analytics in electric utility operations including: GIS, LIDAR, satellites, and other remote sensing technologies.Demonstrated success marketing and selling complex solutions over a long sales cycleHighly motivated individual with experience articulating value propositions of technically advanced solutions to current and potential clients.Understanding of industry issues and trends and demonstrated ability to explain and assess how those issues impact industry participants.Baccalaureate in engineering, computer science, finance, economics or a related field from an accredited university.Ability to work both independently and in a team atmosphere.Ability to manage multiple time-sensitive priorities without diminished effectiveness.Ability to effectively communicate verbally and in writing to varied audiences.Ability to travel extensively and work overtime hours as needed.Ability and desire to network extensively in marketplace and within organizations.Leidos is a trusted and technology-focused solutions provider. Utilities and mobile operators rely on our Power Delivery Services Team for reliable power and telecommunication expertise, as reflected through our work with more than 50 investor-owned utilities, more than 160 municipals/cooperatives, as well as a growing number of mobile operators, local utility providers and private developers. In addition to providing engineering and project management services, Leidos works with an established group of industry-leading construction partners delivering meaningful Energy Delivery Solutions. Our recognition as an industry leader is confirmed by the latest national rankings by Engineering News-Record (ENR) ranking Leidos within the Top 10 T&D Firms, and Top 10 Power Firms.PowerDeliveryPDSDLINEExternal Referral Bonus:IneligiblePotential for Telework:Yes, 50%Clearance Level Required:NoneTravel:Yes, 25% of the timeScheduled Weekly Hours:40Shift:DayRequisition Category:ProfessionalJob Family:Business DevelopmentPay Range:",bos,de
4,Invata Intralogistics,Transportation & Logistics,4.1,Data Warehouse Developer,"Boston, MA",$71K - $123K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044077&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5ed6cc45&cb=1619364030061&jobListingId=4041711222,"Data Warehouse DeveloperInvata Intralogistics is seeking a Data Warehouse Developer to add to the operations research department’s steady growth. This is a great opportunity to join a fast-growing supply chain automation company that is driven to be the best in its industry and set new standards of excellence. Invata employees enjoy a collaborative working environment toward common goals, in a fun, relaxed atmosphere.The Data Warehouse Developer will be located in Burlington, MA. Responsibilities include establishing ETL procedures, performing data modeling and analytics, optimizing data structures, and building out a business intelligence back-bone for warehouse automation software.About Invata: Invata Intralogistics is an innovative engineering / software development firm specializing in the design, implementation, and integration of technologically advanced warehouse automation systems for use in omni-channel distribution centers, e-commerce fulfillment centers, reverse logistics processing centers, third-party logistics centers, and a wide array of warehousing/distribution operations.Our systems utilize advanced material handling technology along with sophisticated database, warehouse software, and control systems, to ensure constant analysis and optimization of an operation such that leaps in productivity can be achieved and consistently maintained. In doing so, Invata systems often enable our clients to turn cost centers into competitive advantages.A Culture of Inquiry: As a nimble, hard-working team, Invata employees share a relentless conviction to the elegance of simplicity, the efficiency of purpose, and the satisfaction derived from finding the best solution to any logistics challenge we face. As a result, inquiry and constant learning are our drivers and comprehension and task ownership comprise the due diligence required for success.If you are a Controls Engineer or Electrical controls designer who thrives in a fast-paced environment in which your best efforts have real impact on company success, then we look forward to hearing from you.Responsibilities: Perform data integrations and ETLs to pull and push data from multiple data sources into a reporting databaseCreate business or logical modeling on dimensions, schemas, hierarchies and data elementsOptimize database objects and structures for data storage, retrieval and reporting according to project specificationsAnalyze, monitor and troubleshoot data and data loading processes to ensure data integrityInterpret data, identify trends, outliers, and sensitivity to key data variablesDevelop stored procedures to support software development according to user defined functional requirementsBuild client dashboards, KPIs, and other data visualization outputBenchmark equivalent data elements across entire client baseFacilitate development of common visualization objects that can be shared across multiple visualizations to drive development efficiency and user experience consistencyQualifications: Bachelor's Degree with a minimum of 3 years of relevant experienceKnowledge of Relational Databases and SQL Server experience requiredKnowledge of one or more programming languages (i.e. TSQL or .NET C# )Understanding of data integration problems, including validation and data cleansingExperience with PowerBI or similar reporting/BI toolProficient in analytical, critical thinking, and problem-solving skillsAptitude and interest in working with complex situations/problems, systems, and processes.Invata is an Equal Employment/Affirmative Action employer. We do not discriminate in hiring on the basis of sex, gender identity, sexual orientation, race, color, religious creed, national origin, physical or mental disability, protected Veteran status, or any other characteristic protected by federal, state, or local law.Job Type: Full-timeExperience:Software Development: 3 years (Preferred)Benefits offered:Paid time offHealth insuranceDental insuranceHealthcare spending or reimbursement accounts such as HSAs or FSAsOther types of insuranceRetirement benefits or accountsEducation assistance or tuition reimbursementEmployee discountsFlexible schedulesWorkplace perks such as food/coffee and flexible work schedules",bos,de
5,Fresenius Medical Care,Health Care,3.5,Sr. Systems Engineer - NxStage,"Lawrence, MA",$49K - $102K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_9fc8db9e&cb=1619364030062&jobListingId=3735367427,"Job ID 20000JBWAvailable Openings 1Position Specific Information NxStage Medical, a Fresenius Company is on a mission to transform renal care. To do that, we continually seek the best-of-the-best to expand and improve our team of dedicated, innovative professionals. If you share our mission and are committed to improving the lives of renal patients, then we invite you to explore our career opportunities.Position Summary:We are seeking an experienced and creative hands-on Senior Systems Engineer who will effectively work in cross-functional engineering teams. You will play a key role in the design, development, testing, and documentation of next generation dialysis instruments at NxStage Medical. The incumbent will support and/or lead systems engineering related activities on product development programs. You will need necessary experience/skills to work with software, hardware and systems integration teams to implement efficient solutions to address complex analytical/hardware issues. This role will require strong engineering, analytical, troubleshooting and testing skills. You will support the capture and tracking of technical risk parameters, design risks, and track to risk management strategies.Key Responsibilities:Provide technical leadership role in a cross-functional product development environment. Model and analyze complex electro/mechanical medical devices. Provide hands-on support for various engineering aspects of the project, perform feasibility studies for proposed design, systems or processes and prepare technical presentations to development team. Lead proof-of-concept and feasibility efforts from a system perspective, driving studies and experiments. Compile technical data for Design History Files per FDA requirements. Participates in Cross-Functional Teams in efforts relating to system requirements definition, system functional decomposition and requirements allocation, system architecture definition, system modeling, and requirements traceability and compliance including verification plans and reports. Perform Risk Analyses, including Fault Tree Analysis (FTA), Operator Misuse Analysis (OMA), and Failure Mode and Effects Analysis (FMEA) activities. Draft work instructions (WI), SOPs, engineering reports, drawings and necessary documentation in order to release design changes. Designs, defines, implements and / or tests complex system requirements; develops integrated solutions in consideration of scientific, engineering, manufacturing and service disciplines. Analyze complex, multi-disciplinary technical issues encountered during the operation and use of instruments. Develop, test, recommend and implement corrective actions to address these issues.PHYSICAL DEMANDS AND WORKING CONDITIONS:The physical demands and work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.EDUCATION: Systems Engineering, Biomedical Engineering, Electrical Engineering, Computer Science, or Mechanical Engineering (or equivalent in a technical/scientific field); MS preferred. 7+ years experience working as a Systems Engineer in Medical Device Industry.EXPERIENCE AND REQUIRED SKILLS: Strong understanding of medical device product design and regulatory processes. Able to communicate effectively, both verbally and in writing. Experience with medical device design and development processes that conform to standards including: ISO 9000, ISO 13485, IEC 62304, IEC 60601, and ISO 14971. Strong understanding of system design, electronics, mechanical and software integration. Knowledge of design of experiments. Technical understanding of and experience with best-practice product development methodologies. Experience with model bases systems engineering and life cycle management tools such as Enterprise Architect. Experience with software programs such as Phyton, Labview and/or Matlab.EO/AA Employer: Minorities/Females/Veterans/Disability/Sexual Orientation/Gender IdentityFresenius Medical Care North America maintains a drug-free workplace in accordance with applicable federal and state laws.",bos,de
6,Albany Molecular Research,Biotech & Pharmaceuticals,3,Plant Automation Engineer,"Burlington, MA",$53K - $82K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_e4dad27c&cb=1619364030062&jobListingId=4066283824,"Job DescriptionDescriptionPlant Automation Engineer in Burlington, MA AMRI provides global contract research and manufacturing services to the pharmaceutical and biotechnology industries. The Plant Automation Engineer is responsible for developing, maintaining, and improving system/equipment performance using analytical methods and processes. Effectively and efficiently provide project management, technical knowledge and skills, and administrative skills. Provide technical review and counsel on a variety of technical issues. This position will be the SME for utility, process, and facility systems automation controls. Responsibilities include design and operation of instrumentation, I/O devices, PLCs, HMIs, and SCADA/data historians. This position also manages automation aspects of capital projects from design through operation. This person will design and implement new technologies, up-grades, and replacements. This person will also be responsible for software code development, graphics, databases, and configuration of applications. Join our talented workforce, where a commitment to excellence and a customer focused attitude is everything. We pursue excellence because our work has the power to improve patients’ lives with the pharmaceuticals we develop and manufacture.ResponsibilitiesSchedule, manage, and review the work of outside trade or technical firms as well as outside contractors for equipment, facilities, utilities, and other workPrepare project budgets and ensure that activities stay within the budgetary guidelines establishedIdentify and initiate projects for electrical and control changes/improvements within the guidance establishedSupport all engineering documentation efforts including SOP’s, PM’s, and technical documentsProduce drawings and project proposals for review with managementProvide specifications and cost estimates for major equipment acquisitionsProvide programming support of building monitoring systems including HMI displaysAssure that facility/system engineering drawings and associated documentation (including work orders and Change Controls) are effectively and compliantly updated and maintainedDemonstrate strong project management skills to control multiple projects and tasks simultaneouslyIdentify areas of cost effectiveness with outside contractorsIdentify areas for cost containmentQualificationsBachelor Degree in Electrical/Mechanical/Chemical Engineering or similar engineering degreeMinimum of 7-10 years of industrial experience dealing with similar systems and managing projects similar in scope and sizeAbility to organize time in order to successfully manage multiple projects and prioritiesAbility to read, understand, interpret, and implement technical writing and instructionsEffective inter-personal relation skills, while maintaining the adaptability to achieve company goalsDesign of Control systems, PLC programming, Computer networking and interfacing experience highly desired. Knowledge of electrical distribution, load calculations and system one-lines. Computer literate with working knowledge of, MS-Word/Excel/PowerPoint, VISIO or other graphics based software for system description/diagramHands on experience in programming/operation/maintenance of computer systems, HMI, and SCADA componentsKnowledge of S88 GAMP MethodologyExperience with Rockwell ProgrammingExperience with Ladder Logic Programming Structured Text Programming Function Block ProgrammingExperience with Ethernet, DeviceNet and ControlNet Configuration Variable Frequency Drive ConfigurationExperience with Visual BasicExperience with Database SQL 2012 administrationExperience with HMI Graphic DesignExperience with PID Loop TuningExperience with Data Historian (OSI Pi or similarExperience creating and maintaining tagsKnowledge in design of building management systems and cleanroom aseptic facilities preferredKnowledgeable with regulatory agencies (OSHA, EPA, FDA, JP, EU, etc.) requiredExcellent Communication skills, both verbal and written All interested applicants must apply online. AMRI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. #LI-AC1Qualifications~Job: FacilitiesPrimary Location: Burlington, MASchedule: Full timeJob Posting: 03/01/2021Shift Type:",bos,de
7,Liberty Mutual Insurance,Insurance,3.8,Senior Cybersecurity Engineer,"Boston, MA",$112K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_860be642&cb=1619364030063&jobListingId=3762347805,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.Our Cybersecurity Engineers form a diverse team of hands-on technical security professionals who are collectively responsible for designing, implementing, managing, and monitoring the overall security posture of the organization. They partner with teams across the company to continually optimize our security posture while maintaining a hyper-focus on the reliability and stability of our business environments.We’re currently hiring intermediate to advanced Engineers across our global cybersecurity organization.Responsibilities:Support security application development initiatives requiring innovation, automation, and integration.This customer focused role supports security incidents, service delivery, technology configuration and lifecycle, and technical security investigations and forensic collection.Be a member of an agile team focused on analysis, system design, documentation, testing, implementation and support for highly complex security operations and processes.Serve as a leading team member supporting security projects or sub-projects of advanced complexity.Use decision making behaviors that require analytical, interpretative and creative thinking that may not conform to established patterns in order to solve security problems.Experience:3 to 8+ years of professional experience.Bachelor`s or Master`s degree in technical discipline or equivalent experience, technical degree preferred.Security+ or comparable certification/experience is required (must obtain within 6 months if not possessed)Preferred Certifications: GCIH, GCFE, CASS, GWEB, GREM,GCFA, CASE – Java / .NET, SANSProficient in many and expert in some cybersecurity technologies, IT concepts, strategies and methodologies, as well as security aspects of multiple platforms, operating systems, software, communications and network protocols.Collaboration, prioritization, and adaptability skills required.Proficiency across architectural analysis, business analysis and financial disciplines, security and compliance, data integration and analytics, social networking, computational thinking, and mobile competency.Proficiency in dimensional and lateral thinking, application delivery, system and technology integration, system software infrastructure, and workplace adaptability.Programming and scripting skills would ideally include one or more of the following: JAVA, .NET, C#, Python16",bos,de
8,Skyworks,Manufacturing,3.5,Firmware Senior Principal Engineer,"Woburn, MA",$104K - $217K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_7062ebfa&cb=1619364030063&jobListingId=4068652648,"Are you looking for the next step in advancing your career in the world of technology?Skyworks Audio Solutions is at the forefront of audio and voice technology innovation with our analog system on chips (ASoCs), for applications such as smart speakers/microphones, wired/wireless headsets, virtual assistants and intelligent gaming controllers. We are continuously growing our team to develop market specific ASoCs which combine breakthrough ultra-low power analog circuits, highly efficient power management and custom hardware accelerators for smart acoustic signal processing and AI features. Our proprietary technology achieves the highest level of integration in the industry and sets a new performance standard for low power consumption and minimal footprint.Requisition ID: 63535Job DescriptionYour RoleFirmware Senior Principal EngineerWe are a passionate and dedicated team of world-class analog, digital and firmware designers committed to building the next generation of ASoCs. This position is for an experienced and equally passionate firmware designer interested in excellent personal and professional growth opportunities.Your role:You will write firmware for embedded processors controlling radio subsystems in sub-45nm mixed-signal CMOS SOCs. This will include designing and innovating in ICs transferring audio and data in multi-node networks, as well as ensuring that state transitions and link behavior meet specification. You will develop the radio subsystem along with the hardware team, and contribute to system-level testing, silicon evaluation, and application team support.Tasks you will be responsible for include:Work with internal hardware and firmware teams to define system hardware drivers and libraries.Write / develop hardware interface drivers, to be used by application developers or other drivers.Support initial bring up and validation of ASIC hardware components.Development of test applications to support validation of the various library components.Job Requirements:12 or more years of experience in development and/or support of applications in consumer electronicsExperience with Bluetooth Lower Stack preferred including:Baseband/Link Controller/Link Manager/HCIACL/eSCO/L2CAP/SNIFF/PAGE/INQUIRY/PAGE_SCAN/INQUIRY_SCANPiconet clocks (network, local, bt/pt), drift compensationPiconet managementFlush timeoutQoS schedulingDemonstrated ability to architect and design solid/consistent software libraries and interfacesTrack record developing and maintaining firmware over a product cycleStrong C programming skillsStrong embedded programming experienceAbility to debug software/firmware on hardware platforms including basic oscilloscope and other lab equipmentEmbedded debugging skills including on-chip debugger and real time systemsAssembly language programmingDemonstrated experience supporting both internal and external customersRTOS usage experience including design of thread safe driver librariesStrong ability to self-manageDebugging skills including real time and source level debuggingPlus Items:Knowledge of the ARC600 instruction setKnowledge of PythonKnowledge of Audio DSP processors and Audio DSP applicationsFamiliar with audio processing and hardware interfacesFamiliar with Serial Communication interfaces (SPI, TWI, UART, USB)Your ProfileProven track record of exceptional performance in firmware design15+ years (BSEE), 12+ years (MSEE) or 8+ years (Phd) of relevant industry experienceExperience with embedded processor systemsExperience in radio ICsExperience in implementation with C and Assembly languageExperience in producing detailed technical reports and documentationProfessional, open and highly self-motivated attitude#LI-DB1Skyworks is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law.Nearest Major Market: WoburnNearest Secondary Market: BostonJob Segment: Electronics Engineer, Engineer, Firmware, Network, Embedded, Engineering, Technology",bos,de
9,Scully Signal Company,N/A,3.9,Systems Design Engineer,"Wilmington, MA",$47K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044077&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_17253d6d&cb=1619364030064&jobListingId=4067400611,"Scully Signal Company is a leading engineering and manufacturing firm of liquid safety control systems for the fueling, storage, and transport of petroleum and chemicals worldwide. For more information, visit us at our web site, www.scully.com.We are seeking a talented individual to fill the role of Systems Design Engineer. The successful candidate will be responsible for the overall technical direction, design and delivery of important new product development projects based on approved Marketing Requirements. Reporting directly to the Director of Engineering, he/she will successfully execute their job function within a matrix-based organization providing technical leadership to the core-team. Key expectations include developing new products leveraging established Product Development Processes and procedures and/or redesigning existing products. The Systems Design Engineer will also research emerging technologies and develop new capabilities to revolutionize the liquid safety control industry.Essential Job Functions: Lead Scully New Product Introduction (NPI) development in all disciplines of engineering including system integration of electrical, mechanical, software, and product safety approvals.Collaborate with Technical Program Management to create Product Requirements Document (PRD) based on approved Marketing Requirements Document (MRD).Make data-driven technical decisions based on thorough analysis, testing, simulation, and calculations.Lead and participate in the design review process for Scully development programs, effectively incorporating current and appropriate design validation methodologies.Provide guidance for the testing of electro-mechanical designs including debug of physical hardware and Design Verification Testing (DVT).Support Technical Program Management as key member to ensure core-team is synchronized and aligned with design, direction and identified risks, including mitigation plans and strategies.Develop accelerated life, environmental stress, and reliability testing strategies to ensure long term “real-world” product life, as defined in Product Requirements Document.Ensure regulatory and technical requirements are evaluated, understood, planned, and successfully addressed during all phases of the development.Periodically conduct technical market research and evaluate similar products for competitive features and functionality.Education and Experience Required: BSEE/BSME or equivalent related discipline. Master’s Degree preferred.10+ years of hands-on engineering design experience.Broad experience in all related disciplines, and specific hands-on expertise in one or more.In depth knowledge of software development methodologies.Project management experience.Additional Required Skills and Capabilities: Strong problem-solving expertise leveraging appropriate Structured Problem-Solving tools.Applies analytical/data driven decision-making processes.Expertise at sorting through issues and conducting comparative analysis of multiple solutions.The ability to analyze technical requirements, design, test methods and provide guidance to engineers.Ability to anticipate product development issues on multiple projects and have alternative solutions readied.Excellent verbal and written communication skills.The ability to execute effectively within cross functional/core development teams.Additional Desirable BackgroundExperience with Wi-fi / BLE technologies.Experience in product design with particular emphasis in electronic industrial or automotive sensing and controls under harsh environmental conditions.Experience with liquid level sensing products.Experience with HW/SW controls for the fuel delivery industry.Experience with electro-mechanical product design for the tank truck industry.Scully is an Equal Opportunity Employer.Job Type: Full-timeBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceLife insurancePaid time offTuition reimbursementVision insuranceSchedule:Monday to FridayWork Location:One locationCompany's website:www.scully.comCompany's Facebook page:https://www.facebook.com/ScullySignal/Work Remotely:No",bos,de
10,Skyworks,Manufacturing,3.5,Product Engineer,"Andover, MA",$86K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_c0dd1196&cb=1619364030064&jobListingId=4066400554,"If you are looking for a challenging and exciting career in the world of technology, then look no further. Skyworks is an innovator of high performance analog semiconductors whose solutions are powering the wireless networking revolution. At Skyworks, you will find a fast-paced environment with a strong focus on global collaboration, minimal layers of management and the freedom to make meaningful contributions in a setting that encourages creativity and out-of-the-box thinking. Our work culture values diversity, social responsibility, open communication, mutual trust and respect. We are excited about the opportunity to work with you and glad you want to be part of a team of talented individuals who together can change the way the world communicates.Requisition ID: 63911Job DescriptionProduct Engineer position that will be working as a core team member of the product and test engineering team to bring Skyworks RF integrated front end solutions, to high volume manufacturing. You will be working closely with engineers and other specialties across multiple functional teams. You will be required to handle multiple development projects and limited travel.Responsibilities:Characterization, ATE and probe data analysisDeveloping production and characterization test specificationsCreating and managing product documentationProviding product development support which involves interfacing with Design, Test Engineering, Quality Engineering, program management and othersDriving cost reduction activities such as second sources qualification, yield enhancement, test time reduction, etc.Job Requirements:Must have Bachelor’s Degree in Electrical Engineering with at least 5 years working experience with strong exposure to RF parameters.Highly prefer experience in semiconductor or similar electronics manufacturing environment.Candidate should have a good understanding of RF parameters.Must possess strong data analysis skills and the ability to debug production and development issues, such as on ATE or bench characterization equipment.Team player, strong communication skills, ability to thrive in a fast-paced environment.#LI-JR1Skyworks is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law.Nearest Major Market: BostonJob Segment: Manufacturing Engineer, Engineer, Electronics Engineer, Network, Electrical, Engineering, Technology",bos,de
11,Vertex Pharmaceuticals Inc (US),Biotech & Pharmaceuticals,3.7,Principal Genomic Solutions Engineer,"Boston, MA",$108K - $201K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_a985ce1d&cb=1619364030064&jobListingId=4070503985,"Principal Genomic Solutions EngineerVertex currently operates at the forefront of rare disease scientific innovation and has successfully developed and commercialized multiple breakthrough medicines. Cell and genetic therapies (CGT) represent two rapidly emerging therapeutic modalities with the potential to treat — and even cure —several of the diseases Vertex is focused on, including Transfusion Dependent beta-Thalassemia (TDT), Sickle Cell Disease (SCD), Duchenne Muscular Dystrophy (DMD) and Type 1 Diabetes to list a few. At Vertex Cell and Genetic Therapies (VCGT) our research teams are bringing cutting-edge transformative therapies to patients as quickly as possible.The global Scientific Computing team at Vertex are seeking a highly motivated computational scientist to lead delivery of software and data solutions supporting these rapidly expanding cell and genetic therapy efforts. The remit includes end-to-end responsibility for software and data platforms for the new Vertex Cell and Genetic Therapies research site. This includes everything from engaging with scientists and Scientific leaders to define requirements, coordinating across user groups through to leading delivery of software.The Principal Genomic Solutions Engineer will have extensive experience building and delivering exploratory and production software in a scientific or research environment. The successful candidate will be highly communicative, thrives in a collaborative environment, and is eager to identify bold and innovative ways of helping scientists and scientific partners solve key data challenges.Key responsibilities:Build strong relationships with key stakeholders, including scientific leadership and lab scientists, across the new Cell and Genetic Therapies research site, and ensure tight alignment of solutions with business strategyDevelop in-depth understanding of strategic and operational requirements driven by research objectivesDefine a comprehensive computing strategy for the new site, in partnership with colleagues in Scientific Computing, Engineering and ResearchCollaborate with Research leadership to develop short and long-term technology roadmap for genetic and cell therapiesPartner with software and data engineering teams to define and build the data and analytics platform supporting Research activities for the siteWork collaboratively to ensure solutions are interoperable with related tools and systems used by Vertex’s computational groups, such as Computational Genomics and Computational ChemistryBasic Qualifications:Fluency in multiple modern programming languages (Python, Javascript, etc) with the ability to write clear, maintainable, and well-tested code8+ years of Software Development/architecture experience or equivalent12+ years of combined/related experienceExperience in development, testing, and delivery of production-quality software#LIExpertise in Linux/Unix environmentsExperience designing, building and delivering data processing and analysis workflows with large-scale data in a scientific environment (academic or industry)B.S., M.S., or Ph.D. in computer science, computational biology, bioinformatics, or a related fieldPreferred qualificationsStrong communication skills (both written and verbal)Experience leading/managing technical teamsExperience developing software for the cloud (AWS) and fluency with cloud servicesFamiliarity with statistical modelling of scientific data and related software (e.g., R)Experience in developing analysis pipelines for Genomic and related scientific data.",bos,de
12,Leidos,Aerospace & Defense,3.8,Software Engineer,"Tewksbury, MA",$87K - $121K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_849a168e&cb=1619364030065&jobListingId=4071045380,"Leidos is seeking a Software Engineer in the Tewksbury, MA area in support of our Security, Detection and Automation business.As a Software Engineer on our diverse and collaborative team, you will work in functional groups alongside scientists, configuration management personnel, and other engineers. Primary responsibilities include:Design, develop, document, test and debug applications software for analytical instruments, such Ion Mobility spectrometersConduct multidisciplinary research and collaborate with equipment designers and/or hardware engineers in the planning, design, development, and utilization of electronic data processing systems for product and commercial software.Determine computer user needs; analyze system capabilities to resolve problems on program intent, output requirements, input data acquisition, programming techniques and controls; prepares operating instructions; designs and develops compilers and assemblers, utility programs, and operating systemsEnsures software standards are metWork with Engineers to forecast levels of efforts and timetablesResponsible for the implementation of spectra analysis in real time executable codeRequired Education and Experience:Bachelor's degree with 4-8 years of relevant experience, or Master's degree with 2-6 years of relevant experience.Assembly, C, C++, C# with Object Oriented Design (OOA and OOD)Designing, coding, and debugging applications in various languagesWindows 7, Windows XP, Windows 10, LinuxMulti-Threaded programmingReal Time ProgrammingExperience implementing codes into real time run codeWCF, WPF, .NET3.5, .NET4.0, LINQ, T-SQLDevice drivers (windows and Linux)Preferred Skills:Excellent communication a plusFamiliar with phase gate development processGUI development Qt, open GL with GPU programming experience a plusAlgorithm experienceFamiliar with any type of SpectrometryConfiguration Management familiarity a plusAbout Us:Leidos is a Fortune 500™ company aimed at embracing and solving some of the world’s most pressing challenges.Driven by our talented workforce, the Security Detection & Automation Operation is the cornerstone of Leidos’ comprehensive suite of fully integrated security detection and automation solutions for aviation, ports and borders, and critical infrastructure customers around the world, with more than 24,000 products deployed across 120 countries. Leidos is positioned to address emerging and evolving threats through rapid development of innovative solutions for our global customers. Leidos’ SDA Operation, in conjunction with the TSA, also performs on-call, onsite installation servicing of X- Ray Detection Equipment using leading edge technology to ensure the safety of our clients, customer and passengers. The Security Detection and Automation Operation is comprised of four divisions to align with our customers’ missions and needs:CheckpointHold BaggagePorts & BordersGeneral AutomationLearn more about the greater Security Detection and Automation Operation, offering an array of exciting career opportunities for the best in IT and Engineering.SDAS#SDASWExternal Referral Bonus:IneligiblePotential for Telework:NoClearance Level Required:NoneTravel:Yes, 10% of the timeScheduled Weekly Hours:40Shift:DayRequisition Category:ProfessionalJob Family:Software EngineeringPay Range:",bos,de
13,"Lake Shore Cryotronics, Inc.",Manufacturing,4.7,Quality Engineer - (J-742),"Woburn, MA",$63K - $73K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_5589ea26&cb=1619364030065&jobListingId=4065593918,"Quality EngineerLake Shore Cryotronics is an international leader in developing innovative measurement and control solutions, primarily for scientific applications. Our equipment is often used to characterize physical properties of early stage electronic and magnetic materials.As a Quality Engineer, you will support the organization in producing high quality products and processes that help us achieve excellent customer satisfaction. You will do this by developing, implementing, and overseeing quality management system processes; implementing corrective actions and implementing continuous improvements to address deficiencies and improve process performance. This role will rely on strong technical, communication, and interpersonal skills to interact with all areas of the company.Some Primary Duties Include:Working with Operations to identify root cause of rework and non-conforming materialAssisting with corrective action reviews, then following-up and verifying effectivenessSupporting sourcing engineer to investigate quality issues with supplier materialOverseeing incoming inspection and non-conforming materials activities, including inspections of non-conforming materialInterfacing with Sales and Product Development to determine root cause and corrective actions for quality concernsLeading cross-functional teams to investigate and address quality concernsMonitoring key quality performance data to proactively address areas of concern with subject matter expertsSupporting the Director of Quality in overseeing the Quality Management System, including performing internal audits against the ISO 9001 and other standardsReviewing and updating quality policies as required, collaborating with process owners to ensure alignment with ISO requirementsQualified candidates will possess the following:A bachelor's degree in engineering, quality, or relevant fieldKnowledge of electrical engineering/electronicsExperience with ISO 9001 standard requirementsFamiliarity with Quality Tools including audits, data analysis, root cause analysisAdditional Preference will be given to candidates who possess the following:Experience in a manufacturing environmentProven experience using data analysis to identify and solve problems and improve processesMechanical and Electrical/Electronic aptitudeAbility to look at problems as processes, taking them apart to understand them and help identify and implement improvementsLake Shore Cryotronics is located in Woburn, northwest of Boston, MA and offers a work-life balance with challenging assignments, a focus on health and wellness, social activities, and community outreach. We are privately held and celebrating over 50 years in business.We offer our employees a competitive compensation and benefits package (Medical, Dental, Vision, Life, and more). We are a drug and tobacco free company.Learn more about Lake Shore Cryotronics by visiting our website at www.lakeshore.com – and also visit our Facebook and LinkedIn sites.Equal Opportunity Employer of Minorities/Females/Disabled/VeteransPI134481492",bos,de
14,Congruity360,Information Technology,3.6,Sr. Sales Engineer,"Boston, MA",$98K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1044077&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5abd3412&cb=1619364030066&jobListingId=4043723641,"Senior Sales Engineer - Classify 360 Boston, NYC, DC Metro AreasAlways wanted to play a vital part in a company’s success story? As a Senior Sales Engineer at Congruity360 you have the exciting opportunity to help drive growth and shape the future of our market leading Classify360 solution in the USA. To become a part of this, you need to be a great communicator, excel in the technical environment required for this role, as well as love new challenges. Leveraging your excellent soft skills, you will be discussing deployment architectures and security with our contacts, diving into diverse on-prem and cloud data storage environments, and using your architecting, design, and programming/scripting skills to solve a customer problem. At Congruity360 every project and every new scenario offers discovery and insights into a variety of companies and their unique business challenges. No two days are the same, which will always keep your role exciting.Key Responsibilities: · With your strong technical expertise and your hands-on can do mentality, you’ll excel in proof of concepts and work collaboratively with our prospects.· You are the technical point of contact and a reliable, dependable advisor for our prospects and clients for the entire sales cycle of Classify360, starting from design of the architecture, evaluation of new use cases or by applying machine learning.· You conduct technical product presentation and product demos, highlighting the core product features, and emphasizing the technical and business value.Your Profile: · You have extensive experience in a pre-sales technical role.· You are strong with SaaS, security, and rapid prototyping.· You design modern cloud architectures deployable in the AWS/Azure ecosystems.· You apply machine learning, modeling, and other data analytics.· You excel at adapting strong and fuzzy customer business and technical requirements into a winning solution.· You thrive with presenting complex technology to a technical audience and decision makers.· You can code and script.· Identify technical champions and make them successful.· You make it happen.Desired Skills: · Back end: PostgreSQL and Solr Lucene and other databases and search indexes.· Microsoft tech stack: Exchange, SharePoint, Office365, Teams, OneNote, etc.· Programming experience with Java, C#, JavaScript, SQL and scripting.· AWS or Azure certifications.· Isilon, NetApp, Pure, and other file share storage devices.· Computer Science background.About Congruity360: Congruity360 is becoming one of the most exciting software companies in the USA and a global technology leader in the Big Data and Analytics market. Our high-performance, cloud-first Software-as-a-Service (SaaS) data analytics solution gives companies complete understanding of their unstructured data – identifying business valuable data while reducing overall toxic data footprint. With an ambitious international team, we enable companies of all sizes to achieve their business goals with understanding their business data. Our team is characterized by inventiveness, enthusiasm, and curiosity. With our global expansion, we are looking for people who want to make a difference and proactively shape our dynamic growth.Job Type: Full-timePay: $125,000.00 - $150,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceHealth insuranceLife insurancePaid time offVision insuranceSchedule:Monday to FridayEducation:Bachelor's (Preferred)Experience:Technical Sales: 5 years (Preferred)Work Location:Multiple locationsCompany's website:www.congruity360.comWork Remotely:YesCOVID-19 Precaution(s):Remote interview processVirtual meetings",bos,de
15,Superpedestrian,Manufacturing,4.4,Lead Electrical Engineer,"Cambridge, MA",$92K - $170K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044077&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c61245f1&cb=1619364030066&jobListingId=4068864319,"Superpedestrian is looking for an experienced electrical engineer to lead the design, test, and execution of electrical hardware and embedded systems hardware development. The work will require highly integrated and innovative design with the likelihood of generating IP along the way. You should have a solid knowledge of the iterative product development cycle with proven expertise in power train design for battery-powered electric vehicles. Ideally you would also have experience in two or more of the following: DC motor control; analog sensors; design for manufacturing and design for test; radio or IoT design; regulatory compliance. Our ideal candidate is a passionate technical leader who brings the expertise and confidence of a veteran electrical engineer as well as an infectious enthusiasm to create.What you'll do:Lead design and development of all electrical and electronic hardware products associated with our fleet scooter platform.Assist with and contribute to conceptual design and product requirements for novel transportation platforms.Be responsible for all electrical design from concept to detailed design to full-scale manufacturing.Ideate and supervise the appropriate test methods for both prototype and production level hardware.Engage in intra-company collaboration between electrical, firmware, mechanical, product, manufacturing, and operations.Supervise and coach engineers of all experience levels with an eye toward their continued development and the overall performance of the electrical engineering team.What we're looking for:7+ years of relevant experience with a BS in Electrical Engineering or other relevant field.At least 4 years experience in developing electric vehicles or similar products, and a record of launching successful products.Demonstrated successful experience bringing a product or assembly through its entire lifecycle from initial concept to production manufacturing to sustaining support and engineering.Ability to mentor and develop an electrical engineering team.Proficiency in circuit design and layout (Altium experience highly valued).Proficiency in design of wiring, cabling, shielding, noise management, transient suppression, electrical packaging, heat sinking, and analog circuit design.Extensive experience designing microcontroller systems with multiple communication protocols (CAN, I2C, SPI, serial, etc).Experience processing and analyzing data emitted from embedded systems through modern data analysis techniques.Experience bringing products through EMC certification process.Experience designing edge computing platforms for cloud communications is a plus.Working knowledge of C or C++ programming languages in an embedded environment.Experience with hands-on projects and fluency with workshop tools.Excellent communication, teamwork, and leadership skills.Perks:Competitive benefits with company subsidized medical, dental, vision & disability insurance and a 401k plan. Generous time off policy.On the job training with a leadership team that is committed to growth and development of all employees.A team of awesome, like-minded, driven people that support each other, and mentors from across the top echelons of industry.The chance to have your voice heard and help shape Superpedestrian’s future.Equity in a fast growing company.A commitment to an actively anti-racist environment.Job Type: Full-timePay: From $1.00 per hourSchedule:Monday to FridayAbility to Commute/Relocate:Cambridge, MA 02139 (Preferred)Application Question(s):What technologies were present in the last design you were responsible for?What is your platform of choice for both schematic capture and PCB layout?Please describe your experience leading a technical team.Education:High school or equivalent (Preferred)Work Location:One locationCompany's website:https://www.superpedestrian.com/enBenefit Conditions:Only full-time employees eligibleWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",bos,de
16,Recorded Future,Information Technology,4.4,Data Engineer,"Boston, MA",$98K - $183K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=8095&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b306a88d&cb=1619364030066&jobListingId=4011925162,"Are you interested in joining a rapidly growing global organization in the cyber industry? With over 550 employees, $140M ARR, and 1,000 clients, Recorded Future is the largest privately-held security intelligence company! Our intelligence integrates with over 80 security products from industry-leading companies, such as Splunk, ServiceNow, Microsoft, IBM, and AWS. Come jump on the rocket ship and help us protect businesses by disrupting adversaries!
Recorded Future is a guardian of the internet, making it a safer place by giving users the information they need to disrupt adversaries. Our harvesting pipeline reads over 700,000 web sources and structured data feeds, and our real-time multilingual natural language processing technology takes that content from raw text to alerts and visualizations in minutes. As a Data Engineer, you will be responsible for accurate, actionable distillation of this massive data set. The analytical summaries you automate will allow our users to take action based on verdicts for over 2 billion indicators.

What you'll do as a Data Engineer:

Build code to condense massive amounts of data into understandable and actionable summaries at scale.
Thoroughly understand the data we give to clients. Collaborate with your teammates to identify opportunities to improve the data.
Suggest and drive projects to expand the use of modern best practices in our codebase. Work across programming languages to take advantage of the right tools for each job.

What you should bring to the Data Engineer role:

Programming: You are comfortable writing production code in Python and JavaScript. You are familiar with best practices in software engineering and are excited about spreading their use. Bonus for experience with Java-backend JavaScript technologies such as TypeScript, NodeJS, Nashorn, GraalVM, or Rhino.
Curiosity: You enjoy puzzles and are invigorated by the challenge of understanding what a complex piece of code does.
Data: You have some experience working with databases and are comfortable manipulating heterogeneous data sets.
Excellent communication: Your clarity of thought is always apparent in your crisp and articulate emails, Slack chats, phone calls, and in-person conversations.

Why should you join Recorded Future?

From over 35 nationalities, our Futurists are the perfect recipe of humility, accountability, and collaborative attitudes. Our dedication to empowering clients with elite intelligence to disrupt adversaries has earned us a 4.7-star user rating from Gartner and 8 of the top 10 Fortune 100 companies as clients.

Want more info?

Blog & Podcast: Learn everything you want to know (and maybe some things you'd rather not know) about the world of cyber threat intelligence

Instagram & Twitter: What's happening at Recorded Future

The Record: The Record is a cybersecurity news publication that explores the untold stories in this rapidly changing field

Timeline: History of Recorded Future

We are committed to maintaining an environment that attracts and retains talent from a diverse range of experiences, backgrounds and lifestyles. By ensuring all feel included and respected for being unique and bringing their whole selves to work, Recorded Future is made a better place every day.

If you need any accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to our recruiting team at recruiting@recordedfuture.com

Recorded Future is an equal opportunity and affirmative action employer and we encourage candidates from all backgrounds to apply. Recorded Future does not discriminate based on race, religion, color, national origin, gender including pregnancy, sexual orientation, gender identity, age, marital status, veteran status, disability or any other characteristic protected by law.

Recorded Future will not discharge, discipline or in any other manner discriminate against any employee or applicant for employment because such employee or applicant has inquired about, discussed, or disclosed the compensation of the employee or applicant or another employee or applicant.",bos,de
17,Ameriprise Financial,Finance,3.9,Data Scientist Manager,"Boston, MA",$89K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_fca617a5&cb=1619364030066&jobListingId=4069969767,"Job DescriptionPlay an integral role in supporting modeling and data analysis and database needs for assigned line of business. Manage the creation and/or usage of large data sets, providing information-based decision logic and predictive modeling solutions, and translates modeling/analytic output into understandable/actionable business knowledge, insight and applications. Demonstrate strong technical/problem solving skills. Support multiple projects collaboratively.ResponsibilitiesIdentify, develop and implement complex analytical solutions leveraging tools such as predictive modeling, advanced machine learning techniques, simulation, optimization solutions, etc..Manage dataset creation including data extraction, derived and dependent variable creation, and data quality control processes for analytics, model development, and validation. May monitor execution of analytical solutions, including criteria specification, data sourcing, segmentation, analytics, selection, delivery, and back-end data capture results.Under direction of the Sr. Leader, collaborate with business leaders and/or analysts to provide analytical thought leadership and support for business problems. Identify and interpret business needs, define high-level business requirements, strategy, technical risks, and scope. Develop, document, and communicate business-driven analytic solutions and capabilities, translating modeling and analytic output into understandable and actionable business knowledge.Embed analytic programs and tools. Ensure continued accuracy, relevancy, and effectiveness and track process improvements once deployed.Ensure adherence to data and model governance standards that are set and enforced by industry standards and/or enterprise and business unit data governance polices and leaders.Contribute to ongoing expansion of data science expertise and credentials by keeping up with industry best practices, developing new skills, and knowledge sharing. Work cross functionally to develop standardized/automated solutions and adopt best practices.Required QualificationsMasters degree or equivalent in Quantitative Discipline (i.e. Finance, Statistics, Computer Science, Actuarial Science, Economics, Engineering, etc.).3-5 years relative experience.Knowledge of advanced statistical concepts and techniques; skilled in linear algebra.Experience conducting hands-on analytics projects using advanced statistical methods such as generalized regression models, Bayesian methods, random forest, gradient boosting, neural networks, machine learning, clustering, or similar methodologies.Experience with statistical programming (Python,R, SAS SQL etc.) & data visualization software in a data-rich environment.Experience in AWS services such as Redshift, S3, Sagemaker will be an advantage.Proven ability to present/communicate complex, technical materials in a way that facilitates decision making and drives outcomes; ability to communicate to less technical partners.Proven ability to apply both strategic and analytic techniques to provide business solutions and recommendations.Ability to work effectively in a collaborative team environment.Preferred QualificationsPh.D",bos,de
18,DataDog,Information Technology,4.1,Data Engineer,"Boston, MA",$103K - $183K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_10fade16&cb=1619364030067&jobListingId=3701909516,"About Datadog:We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale—trillions of data points per day—providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies. Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way.The team:The Revenue Data Engineering Teams designs, builds and runs the data pipelines and helper systems to accurately and timely manner quantify our customers’ usage across all Datadog products. This team is at the leading edge of any new product we release.The opportunity:As a Data Engineer within the Revenue & Growth group, you will work with Spark and big data tooling to build highly reliable, verifiably-accurate data processing pipelines for a large scale mission-critical process. This team ingests the full firehose of data we receive each day - literally trillions of data points and petabytes of data.You will:Build distributed, high-volume data pipelines that power this core productUse Spark, Luigi and other open-source technologiesWork across the stack, moving fluidly between programming languages: Scala, Python and moreJoin a tightly knit team solving hard problems the right wayOwn meaningful parts of our processing infrastructure, have an impact, grow with the companyRequirements:You have a BS/MS/PhD in a scientific field or equivalent experienceYou have built and operated data pipelines for real customers in production systemsYou are fluent in several programming languages (JVM & otherwise)You enjoy wrangling huge amounts of data and exploring new data setsYou value code simplicity and performanceYou want to work in a fast, high growth startup environment that respects its engineers and customersBonus points:You are deeply familiar with Spark, Hadoop and similar frameworksIn addition to data pipelines, you’re also familiar with Kubernetes and cloud technologyYou’ve built your own data pipelines or data intensive applications from scratch, know what goes wrong, and have ideas for how to fix itEqual Opportunity at Datadog:Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.Your Privacy:For more information on how we maintain the privacy of the information you submit as part of your application, please refer to our Applicant and Candidate Privacy Notice.",bos,de
19,DataKitchen,Information Technology,5,Data Engineer,"Cambridge, MA",$76K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_d1b7952c&cb=1619364030067&jobListingId=3807894913,"DataKitchen has an excellent opportunity for a Data Engineer or Customer Success professional to be part of an exciting, growing company delivering a cloud-based DataOps Solution! We are leading the DataOps movement, making it possible for enterprise data teams to turn data into true business value. DataKitchen was honored as 2019 Gartner Cool Vendor and a CRN Big Data “Start-Up to Watch” in 2020. Our company is profitable, rapidly growing and stock will be part of the package.Day to Day:Develop and maintain data pipelines utilizing our DataOps softwareWrite Amazon Redshift SQL and leverage other AWS products (S3, Lambda, Glacier) and technologies to transform raw data into analytic assetsSelf-manage and lead client projectsRun with open-ended requirements to mockup features for clients and then iterate and improve them over timeCommunicate directly with customers; maintain transparency through Jira ticketing and Confluence documentationWork in an agile working environment: weekly sprints, daily scrumsDesired Tools and Experience:5+ years of hands-on data engineering experienceMS in a quantitative field (Computer Science, preferred)Advanced knowledge of cloud database design, warehousing (AWS, Snowflake, Google Cloud, etc.)Solid experience with at least one object-oriented programming language, preferably PythonStrength communicating technical details, at both a high level and very detailedKnowledge of Commercial Pharmaceutical / Life Sciences data sets (NPP, DDD, Xponent, Plantrak, SPP, Symphony, IQVIA)Why You Should Work at DataKitchenDataKitchen has a culture of trust and transparency. As a Data Engineer at DataKitchen, you will own and take responsibility for the work you do. We pride ourselves on being collaborative amongst the team and with our customers. We are always asking “Is there a better way we can do this?,” refactoring and building on what we have done as a team.We follow agile development practices while embracing our errors and falling forward. We hire the best and brightest and give everyone the opportunity to contribute to the growth of the company.",bos,de
20,Massachusetts General Hospital(MGH),Health Care,4.1,Data Engineer,"Boston, MA",$77K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=25073&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_f3ceaa7c&cb=1619364030067&jobListingId=4070730766,"DATA ENGINEER, CENTER FOR PRECISION PSYCHIATRY

PROGRAM SUMMARY:

The Center for Precision Psychiatry is a new and dynamic interdisciplinary center that integrates research, clinical implementation, education and training to advance the emerging field of precision psychiatry. Precision psychiatry aims to identify and leverage individual differences in biology, lifestyle, environment, and the social determinants of health to improve the prevention, diagnosis and treatment of mental health conditions.

POSITION SUMMARY:

The successful candidate will have demonstrable professional experience in the design, implementation, integration, testing and deployment of backend software and systems, including software development in both team-based and independent projects.

PRINCIPAL RESPONSIBILITIES:

Develop, validate, test, document, deploy, and maintain clinical and research applications for precision psychiatry pathology. Applications may include but are not limited to data management systems analytics pipelines, and clinical reporting tools. Support data engineering efforts, including database and API design, data extraction/transformation/load, and data aggregation/integration.Support data science efforts, including computational statistics, machine learning, deep learning, interactive web-based visualizationSupport high performance computing efforts, including on-premise cluster computing, cloud computing, and Linux container orchestrationSupport data management, including big data storage on premises and in the cloud, life cycle management, archiving, security, and access controlMaintenance of local data/GPU workstations and server software environmentsManagement of user-account/data-privacy/security for the workstations and serversAssist group on medical data science projectsData preprocessing Software development with readable, testable code and good documentationTroubleshoot, debug and upgrade existing systemsEnsure software is updated with latest features

Qualifications

SKILLS REQUIRED:

Proven work experience as a Data Engineer or DeveloperProficiency in SQL Proficiency in setting up and maintaining GPU-capable workstations running on windows/mac/linux operating systems, and GPU-capable linux servers with K8S or SlurmKnowledgeable in statistics/machine learning theories and capability to implement in R and PythonKnowledgeable in common data science packages, such as R: tidyverse and Python: PANDAS, NumPy, Scikit-learnKnowledgeable in deep learning frameworks (preferably PyTorch) with capability to build, train and validate models end-to-endExpertise in computer programming and proficiency in at least one general-purpose programming language (Python, Java, Scala, C/C++, Go or equivalent, experience in Python strongly preferred)Knowledge of Unix/Linux-based operating systems and experience in shell scripting requiredExperience in designing RESTful APIs, architecting robust and scalable systems, and deploying and maintaining web services, including web server configuration (e.g., Apache, NGINX), message queues (e.g., RabbitMQ, Apache Kafka), microservice architectures, proxy servers, sidecar patternsExperience working in a software development team, including agile methodology, unit testing, continuous testing and integration, refactoring, code reviews, version control, release management, packaging, and distributionProven track record of delivering high-quality, production-grade softwareExperience with user interface and web development (e.g., JavaScript, React, HTML, CSS) a plusExperience with SQL as well as NoSQL databases and database management (e.g., PostgreSQL, MongoDB, Apache CouchDB, Apache Cassandra) a plusExperience with Linux containers and container orchestration systems (e.g., Docker, Kubernetes) a plusExperience with cloud computing a plusExcellent oral and written communication skills.Excellent interdisciplinary communication skillsEnthusiasm in healthcare related projects

QUALIFICATIONS AND EXPERIENCE:

BS/MS degree in Computer Science, Mathematics, Physical Sciences, Engineering, or related field

EEO Statement

Massachusetts General Hospital is an Equal Opportunity Employer. By embracing diverse skills, perspectives and ideas, we choose to lead. Applications from protected veterans and individuals with disabilities are strongly encouraged. Partner's Healthcare is acting as an Employment Agency in relation to this vacancy.",bos,de
21,Vertex Pharmaceuticals Inc (US),Biotech & Pharmaceuticals,3.7,Senior Cloud Security Engineer,"Boston, MA",$113K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_7cdc4906&cb=1619364030067&jobListingId=4070504578,"Vertex is a fast-moving organization which depends upon multiple technologies to compel our mission forward. Vertex is in a transformational period where we are accelerating our capabilities, technology and data to augment our scientific mission, enable Vertex to grow in scale, and be on the forefront of science and medicine. We are defining and implementing a step change in science and our ability to help address human disease.Vertex is seeking a unique individual with experience and passion for cutting-edge, cloud-based serverless technology and Data, Technology and Engineering (DTE) security. The Senior Cloud Security Engineer will lead the Cloud team's security architecture and implementation efforts and have the opportunity to pioneer technically excellent security solutions supporting business-impacting initiatives. You will be a key contributing member of the Cloud team, interfacing with other cloud engineers, developers, and automation engineers and utilizing the latest security best practices with a heavy focus on AWS serverless technologies.You will design, build, and deploy security infrastructure and automate security operations across Vertex's cloud systems. Vertex is embracing serverless, managed services, and automation as core principles of our cloud applications, which will be reflected in your solutions. The role will require hands on design and implementation of security logging, monitoring, and response frameworks and tight integration with project teams, helping to review developer design and code to ensure compliance with secure coding practices.Basic QualificationsEnthusiasm for and the ability to quickly learn new technologies and tackle difficult problemsSelf-starter with strong self-motivation and teamwork skillsDemonstrated capabilities in using and evaluating cloud technologiesDemonstrated experience with DTE security, compliance, or risk managementDemonstrated experience with monitoring, logging, and response frameworksHands-on technical expertise in technology automation, implementation, integration, and/or deploymentStrong verbal and written communication skillsBS or BA in Computer Science or other related fieldPreferred Qualifications:Demonstrated capabilities in using and evaluating AWS serverless technologiesDemonstrated experience in scripting languages ( i.e. PowerShell, Python, Node.js, Javascript, Bash, Ruby, Perl, Unix Shell (bash/ksh), etc.)Demonstrated experience with and build/deployment tools like Jenkins, CloudFormation, CodeBuild, etc.Hands-on technical expertise in building security capabilities in code and deploying infrastructure in code#LI-JF1",bos,de
22,Lawrence General Hospital,Health Care,2.8,Nursing Recruiter and Data Analyst,"Lawrence, MA",$49K - $85K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1044077&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4c9e38b1&cb=1619364030067&jobListingId=4070795217,"The Nursing Recruiter and Data Analyst plans and executes work force strategy for nursing and clinical services. This position is responsible for talent acquisition and employee engagement for Nursing (recruitment and retention metrics), and other, select patient care and key, hospital positions. Cultivates meaningful professional relationships to successfully source, recruit, and retain staff. Proactively utilizes workforce analytics to design and implement recruitment and employee engagement initiatives.Bachelor's degree required and Master's degree preferredMust have a proven record and in depth-understanding of workforce analytics and ability to implement data driven initiatives. Must also be proficient with Word, Excel and Powerpoint as well as navigating social media recruitment sites. RN or clinical recruitment experience in a union environment preferred.Lawrence General Hospital is a private, non-profit community hospital providing the Merrimack Valley & southern New Hampshire regions with patient-centered, compassionate and quality health care for the whole family. For over 140 years, the dedicated doctors, nurses, and staff of Lawrence General have been committed to improving the health of the people and communities we serve.LGH offers competitive pay, a robust benefit package, generous paid time off and free parking. We are an Equal Opportunity Employer committed to hiring a diverse workforceJob Type: Full-timePay: Up to $1.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programEmployee discountFlexible scheduleFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offParental leaveProfessional development assistanceReferral programRelocation assistanceRetirement planTuition reimbursementVision insuranceSchedule:Monday to FridayEducation:Bachelor's (Required)Experience:Recruiting: 4 years (Preferred)Work Location:One locationCompany's website:http://www.lawrencegeneral.org/careersWork Remotely:No",bos,de
23,Optimus Ride,Transportation & Logistics,3.7,Data Engineer,"Boston, MA",$73K - $136K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=148364&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_0e1e802f&cb=1619364030067&jobListingId=4041740101,"About Optimus RideOptimus Ride is an autonomous mobility service provider on a mission to drive the future of transportation. We develop and own the full AV tech stack and user experience–algorithms, software, hardware, and system integration–for autonomous, electric rides for communities near and far. We’re focused on driving innovation and delivering convenient, turnkey transportation services for master planned communities, corporate and academic campuses, and mixed use developments. We’re driven to create safe, sustainable, and equitable transportation solutions for all.Optimus Ride is headquartered in the Boston Seaport District, not far from our old stomping ground at MIT. From the boardroom to the test track, our teammates (affectionately referred to as Optimists) bring deep industry and subject matter expertise, a collaborative and focused work ethic, and an optimistic outlook on the future of autonomous, sustainable, community-serving transportation.The RoleOptimus Ride vehicles and systems generate large volumes of rich, complex data that are used both on- and off-vehicle to make decisions with real world consequences. We also need to run simulations at scale as part of our testing and to establish the safety of our vehicle. We are looking for data engineers who are excited by the challenge of implementing and orchestrating complex dataflows to power self-driving vehicles.Our team is focused on a rapid path to market in order to maximize the benefits of self-driving technologies for all. To do this, we need our engineers to be versatile, have leadership qualities, and be enthusiastic about tackling problems across the full range of our systems. Working at Optimus Ride you will innovate with engineers and designers who cumulatively have decades of experience in software development, computer vision, machine learning, sensing and actuation, human-machine interface, and design. You will be creating new technologies through software development that integrates your areas of expertise to enable self-driving systems to be possible today.ResponsibilitiesParticipate in our team’s software development processes, including documentation, automated testing, and source control practicesDesign, implement, and drive large data storage, data processing, and simulation testing projectsTest, debug, and maintain reliable, safe, and production quality codePython DevelopmentRequirementsBS in computer science, a related field, or equivalent experience2+ years experience in Big Data Solutions and ETL pipelines using Cloud Services (e.g. Airflow, BigQuery, etc.)2+ years experience writing production-quality code in PythonExperience with continuous build and deployment process and tools (e.g. Jenkins, git, etc.)Experience with data processing and analysisExperience with databases and SQLInterest and ability to learn additional skills and technologies as requiredBonusExperience in software quality assurance / testingExperience in statistical analysisExperience with C++Experience with data and network security(We are open to reviewing resumes of candidates who may not have these qualities yet, but demonstrate the potential to learn them on the job.)Benefits and Working EnvironmentAt Optimus Ride, we strive to support our employees by offering competitive compensation, comprehensive benefits and a world class working environment that is centered around the team. We nurture creativity and provide expansive opportunities for growth and development.",bos,de
24,Commonwealth Care Alliance,Health Care,3.5,Enterprise Data Engineer,"Boston, MA",$84K - $152K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_30852d58&cb=1619364030067&jobListingId=4069275020,"Why This Role is Important to UsThe Enterprise Data Engineer is a key interface in operationalizing data and analytics that provide business insights management needs. The role will collaborate with CCA data scientists, financial and clinical analysts and other data consumers, to integrate models and algorithms developed by them for favorable clinical outcomes.The role will be part of the Enterprise Data Services team within CCA IT. S/he will collaborate with other IT teams, including BI, to ensure data solutions are designed optimally, perform at maximum throughput and produce results business expects. Enterprise Data E﻿ngineer will also assist in issue resolution, in assessing, measuring and tracking data quality, and in extending the scope of enterprise data warehouse and analytics program.The role will ensure compliance with data governance and security, ensuring anonymized data access, integrated data reuse and vastly improved time-to-solution for CCA’s data and analytics initiatives. The data engineer will be measured on his/her ability to integrate analytics and data science results with CCA’s business processes.What We're Looking ForMinimum of bachelor’s degree (Computer Science, Mathematics, Statistics, Engineering preferred)Advanced degree in Applied Mathematics, Business Analytics, Statistics, Computer Science, or Data Science a plus4 years of experience implementing Data Management solutions or as Data Analyst/Data Architect/Business Systems AnalystMust have a good understanding of Healthcare (Payer, Patient, Care Provider) data models and systemsKnowledge of HC Industry trends such as ACO, HIX, HIE and HC industry solution models (HL7, HIPAA) a definite plusMid-level IT resource with a broad understanding of Database Design and Data Analysis approaches and implementation methodologiesAbility to work with the business as well as IT stakeholdersExperience in large operational and analytical data environmentsDemonstrated experience in data analysis, database design, and performance tuningAdvanced technical skills with proficiency in SQL coding (Teradata, SQL Server, and/or Oracle), Tableau and/or Datawatch, Looker, R, PythonHands-on experience with tools such as SQL Server Management Studio and Oracle SQL DeveloperWorking knowledge of Talend ETL and other utilities such as, MDM a definite plusExperience with Agile/Scrum is valuableAbility to work creatively and analytically in a team environmentExcellent communication and documentation skillsDoes this sound like you? If you’re interested in this opportunity, please apply today.We offer excellent benefits, including:Medical, dental and vision plans with low employee contributionsA generous paid time off program403(b) with company matchLoan Forgiveness ProgramEducational Assistance/ReimbursementThank you for taking the time to learn about this opportunity. We look forward to hearing from you!#zrWhat You'll Be DoingHelp analyze CCA’s master and transaction data to understand how it is created, maintained,﻿ and used in financial, clinical, operational, and analytical reporting.Work with business stakeholders to identify critical data elements and how they relate to each other.Assist in the development of large-scale data structures and processes to organize, collect and standardize data that helps generate insights and addresses reporting needs.Apply understanding of key business drivers to design algorithms, logic and models for key data domains.Work with the Enterprise Architecture group to understand data generating and consuming processes and design data flows that follow them.Work with Integration Analysts to document data flows within point-to-point interface architecture.Assist in drafting and communicating MDM and API-based future data integration strategy and vision.Work with internal/external stakeholders to secure data access ensuring CCA’s data governance policies are strictly followed.Create and maintain appropriate level of system and user documentation.Help maintain data dictionary for all business-critical data domains.Help capture business rules that govern how data is transformed, integrated and used.Identify and help define reactive and proactive alerts and controls to maintain data quality, and for audit reporting.Develop relevant value metrics and tools to measure and track data quality.Identify data inaccuracies (duplicates, incomplete info., inconsistencies etc.) and engage appropriate business teams to address cross-functional data issues and impacts.Record, respond and help resolve data issues in a proactive manner.When reacting to data issues, conduct root cause analyses to ensure the issue does not recur.Develop anticipated queries, reports and related documentation for business communication of both issues and their mitigation.Ensure data standards are followed.Actual Work Location2 Avenue de Lafayette, Boston, Massachusetts 02111-1750All LocationsLafayette City CenterExempt / Not ExemptExempt",bos,de
25,"Draeger Medical Systems, Inc.",Manufacturing,4,Sr. Industrial Engineer,"Andover, MA",$65K - $101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_966e9131&cb=1619364030067&jobListingId=4070544374,"The Job ResponsibilitiesProvides direct, day to day support for the Production lines. Drives continuous improvement activities in Production. Introduces new products and assembly processes including all necessary documentation for production processes, process verification & validation and employee training. Ensures smooth running of production processes with the highest possible efficiency.Production LineDevelops and documents manufacturing methods, material handling methods, improve efficiencies, quality and reliability of processes and / or productsCreates and maintains routing and time standardsPerforms and records Process Verification and Validation activities, including FMEAs Designs and/or procures work-stations, machinery, fixtures and tooling required for either new product lines or for improvement of existing linesInvestigates and resolves production problems using root cause analysis techniquesInterfaces with Design Engineering during new product development or product enhancement projects, to ensure the design is acceptable for manufacturabilityCreates / Maintain Production work area plans and lay-outsInterface with SQA and suppliers to ensure corrective action or problem resolution, delivery reliability, and parts acceptability in cost & quality aspectsSAP Master Data maintenanceRepresents manufacturing in the Product Steering Board (PSB)Product Lifecycle ManagementSupport phase in / phase out of products or components into ProductionImplement product / process changes into Production; develop, document, maintain and improve processes, workflows, and tools for existing production lines in compliance with FDA, GMP and ISO requirementsInvestigate and resolve production problems/failures using root cause analysis techniques; Initiate Design Change Requests (DCRs); review/approve Design Change Orders (DCOs)Represent Operations in Product Steering Boards (PSBs) and Cross Functional Teams (CFTs)Continuous ImprovementIdentify continuous improvement opportunities; develop and implement solutionsFoster Lean culture and lead Lean/Kaizen Events in Production Lead and manage continuous improvement projectsTrain and mentor colleagues on Lean principles and toolsAct as Project Lead when larger scale Production improvements are needed.Act as proxy for the Production Quality Engineer.Performs other duties as needed and assigned.Your QualificationsEducationBachelor’s degree in Industrial Engineering, Manufacturing Engineering or related field; Master’s degree preferred.Experience5 – 8 years related experience in a manufacturing environment required.Prior SAP/ARAS usage in a Production environment desired.Continuous Improvement experience requiredProcess Verification and Validation experience required.Experience with FMEA, 5S and Poka-yoke preferred.Experience in Medical Device Industry preferred.Proficiency with Minitab or other statistical software preferred.MS Office proficiency required, MS Access & MS Project preferred.Proven track record with continuous improvement projects preferred.Demonstrated Organizational & Project Management Skills preferredLEAN and/or Six Sigma Black Belt Certification strongly preferred.Ability to effectively communicate and present information to management and peers; excellent interpersonal and administrative skills.Stay current with new and emerging technologies and trends; learn and utilize new knowledge quickly and effectively.Perform a variety of tasks, and work independently, without appreciable direction.The Dräger WorkplaceIn North America, Draeger employees over 1,400 employees working in our major sites in the United States and Canada (in the US: Andover, MA; Telford, PA; Houston / Coppell, TX, and in Canada: Mississauga, ON), including our Sales and Service workforce employees from coast to coast.The design, development and manufacturing of Draeger’s Patient Monitoring product line takes place in our Andover, Massachusetts location.Equal Opportunity Employer – Disability and VeteranWho we areDraeger is a leading international company in the fields of medical and safety technology. Whether in clinical applications, in industry, mining or emergency services: Draeger products protect, support and save lives. That's what our more than 15,000 employees have been striving for - every day for more than 130 years. Dräger - Technology for Life ®What we offerAdditional/Voluntary InsuranceEducation & TrainingHealth center and gymHealth InsuranceRetirement SavingsSpecial AssistanceTime AwayWorkplace WellnessAdditional/Voluntary Insurance; Education & Training; Health center and gym; Health Insurance; Retirement Savings; Special Assistance; Time Away; Workplace WellnessIf you have any questions, please contactGwendolyn ZappalaE-Mail: gwendolyn.zappala.contractor@draeger.com",bos,de
26,The Boston Beer Company,Manufacturing,4.5,"Data Engineer, BI","Boston, MA",$57K - $111K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_cc6bf836&cb=1619364030068&jobListingId=4043885075,"Our mission at The Boston Beer Company is to bring the highest-quality products to the U.S. beer drinker. To answer that mission, we are creating an inclusive culture that celebrates the differences in both our people and our brands. Our diversity makes us stronger, and when you bring your authentic self to work, we are a stronger, more innovative, and more sustainable company & community.As a fast-paced, growing company with a strong family of brands (Samuel Adams, Dogfish Head, Angry Orchard, Twisted Tea, and Truly Hard Seltzer), we seek constantly to challenge the status quo. We are always looking for hardworking, talented, and passionate people (that means you!) to join our team.We are The Boston Beer Company, and together we are heavy.We are currently hiring a Data Engineer, BI in Boston, MA.This is a great role on a team that is transforming Business Intelligence technology at Boston Beer. The Data Engineer is a technical role with SQL Server and Azure cloud data technology at its core and has ample opportunity for technical growth as we move from traditional data technologies to cloud data architecture. As Boston Beer takes on new challenges in areas like supply chain and digital, this role will be highly involved in ensuring our data platform is scalable, performant, and ready for the future.Working within the Boston-based Business Intelligence team, this role is responsible for various database activities all centered on delivering impactful Business Intelligence solutions and maintaining and improving our database systems. This is a multi-faceted role that includes technical analysis, design, development, testing and maintenance as well as user interaction including requirements gathering, training, etc. This role will work on our on-premise SQL data warehouse platform and helping to build out the data platform of the future in Azure.What You'll Do:Build out and migration to cloud data technologies, which may include (but not limited to) Azure Data Lake, Azure SQL Pools, Apache Spark, Synapse, Azure Data FactorySQL Server Database development work including tables, views, stored procedures and functions. SSIS development for Extract Transform Load (ETL) processes as wellPerformance tuning and testing of BI structures and processesParticipation in the design of data models to house and deliver essential reportingAutomation with Powershell ScriptingConsultation with other IT personnel to perform essential analysis on source dataCollaborate with BI Team members and key BI power users on specific data designs and intended useCollaborate on requirements definition, design and build out of key data warehousing and integration deliverables for Supply Chain, Brand Insights, Digital, Sales and other areasSQL scripting to perform essential data maintenance functions including reclassifications, some master data setup and otherThis role may also be involved in data preparation and modeling using the Power BI platform as well as Analysis Services-TabularMaintenance and extension of our SQL server jobs and Azure PowerShell runbooks for update of our SQL and Azure environmentsPartner with the BI team to promote and evolve design, development, and testing standardsAdhere to IT department policies and procedures when performing tasks to ensure controls are in place and departmental goals are met. Adhere to standards for testing, documentation, and change managementOccasional travel may be required (What We're Looking For:Bachelor’s degree in computer science or equivalent relevant experience requiredMicrosoft SQL Server, Azure data technologies, Power BI training and certification all a plus 3+ years in a data integration or data warehouse development role, preferably in a Microsoft environment3+ years hands-on development experience with SQL Server, SSIS1+ years working with Azure cloud data technologies including migration, integration, and designPowershell experience a mustMicrosoft Power BI platform, including DAX and Power Query expressions and Analysis Services tabular a big plusPython scripting a plusMuleSoft, SAP Hana data experience helpfulOther cloud platforms such as AWS a plusSome Perks:Our people are our most important “ingredient.” We not only have to hire the best, but we have to reward, develop, and retain them too. We also have a variety of benefits including a competitive compensation package, extensive training programs, excellent healthcare, a discounted stock purchase plan, and a 401K program with a generous company match. Not to mention, there’s the free beer too!Boston Beer Corporation is an equal opportunity employer and is committed to a diverse workforce. In order to help ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Veteran’s Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who wish to request accommodation in the job application process can contact jobs@bostonbeer.com for assistancePrimary Location: US-MA-BostonWork Locations: Boston Office One Design Center Place Suite 850 Boston 02210Job: Information TechnologyOrganization: CorporateSchedule: Full-timeEmployee Status: RegularJob Type: StandardJob Posting: Mar 26, 2021, 8:25:46 AM",bos,de
27,Liberty Mutual Insurance,Insurance,3.8,Software Engineer,"Boston, MA",$55K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1044074&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_85b1102a&cb=1619364030068&jobListingId=4042137226,"Do you have the skills—and drive—to join a tech team that’s working to digitally transform a trillion-dollar industry? From test-driving the latest technologies to creating intuitive consumer apps harnessing the power of AI and Machine Learning, Liberty Mutual is constantly innovating and creating industry-leading solutions that provide peace of mind for our customers, brokers and agents worldwide. As a data engineer at Liberty Mutual, you’ll apply your talents in an agile environment that has the creative energy of a start-up—and the full backing and comprehensive benefits of a Fortune 100 company.Liberty Mutual Global Risk Solutions Technology, Analytics Enablement and Emerging Technologies is actively searching for a Senior Software Engineer to work on our team in a cross functional partnership with GRS Advanced Analytics, The AA Hub, to support our data scientists with deployment and integration of AI and ML technologies across multiple product verticals.Job SummaryAs a full-stack developer in GRS A&ET, you will be working side by side with other engineers as well as data scientists to design, develop and implement coding solutions which enable our data scientists to push their advanced analytics models to market faster, more efficiently and securely. Our teams focus on updating aged N-tier technologies to cloud-native designs, leveraging the cloud to process Big Data at scale, and continuously finding ways to maintain an MVP mindset while incrementally delivering the most feature rich solutions to our internal and external customers. Use of AWS cloud-based tools is a priority, leveraging CICD pipelines and microservices to deliver performant data solutions. You will participate in the oversight for the technical integrity of these systems, while ensuring solutions address business needs and align with market and industry trends. This role requires solid interpersonal skills and an understanding of predictive modeling. The team consists of a healthy mix of skills and seniority and this role will play a vital role in driving the continuous learning for the team through mentoring and knowledge sharing.This is a range posting for Software Engineer or Senior Software Engineer. The actual internal level/grade for this role will depend on the candidate's overall experience and skill level.ResponsibilitiesResponsible for the analysis, development and execution of data science and data integration solutions, in order to manage the information lifecycle needs of an organization.Works from specifications to develop or significantly modify highly complex software, applications and programs. Develops and/or modifies effective, defect free source code that meets business requirements and team standards.Seen as a technical expert within the team, this role analyzes complex technical problems and provides solutions. May mentor junior team members.Participates in unit test case development and develops complex test scripts. Executes all levels of testing (System, Integration, and Regression).Actively participates in and often leads peer development and code reviews within each Agile sprint, with focus on test driven development and Continuous Integration and Continuous Development (CICD).Works closely with stakeholders to develop custom REACT/Node.js applications, with a focus on UX best practices, to deliver best in class advanced analytics AI/ML model outputs to our underwriters for use in decisioning.Designs and builds data provisioning workflows/pipelines, physical data schemas, extracts, data transformations, and data integrations and/or designs using ETL and API microservices to deliver payloads to and from AI/ML models and integrated systemsBuilds data architecture and applications that enable reporting, analytics, data science, and data management and improve accessibility, efficiency, governance, processing, and quality of data.This role analyzes complex technical problems and is expected to recommend process improvements that address complex technology gaps within a single business process and improve data reliability, quality, and efficiency. Contributes technical alternatives.Continuously learning to maintain strong knowledge of technology enablersProvides successful deployment and provisioning of data driven solutions to production or other required environments.Bachelor or Master`s degree in technical or business discipline or equivalent experience. Generally, 5+ years of professional software or data engineering experience.Highly proficient in data engineering languages and tools, and strong proficiency in general programming languages and frameworks; ability to develop on multiple platforms.Strong understanding of AWS technologiesStrong understanding of REACTStrong understanding of RESTful API development, Oauth authentication and endpointsExtensive understanding of agile data engineering concepts and processes, such as CICD, pipelines, and iterative development and deployments.Strong negotiation, facilitation and consensus building skills.Strong collaboration, prioritization, and adaptability skills requiredStrong oral and written communication skills; presentation skills.Extensive knowledge of the following: IT concepts, strategies, methodologies.Versed in diverse technologies and new technical architecture principles and concepts.Demonstrated knowledge in layered systems architectures solutions and designs and shared data engineering concepts.Business function(s) and I/T industry business issues; knowledge of business operations, strategies and objectives.Must be proactive and self-driven, demonstrated initiative and be a logical thinker.Proven consultative skills, including the ability to understand and apply customer requirements, including drawing out unforeseen implications and making recommendations for design, the ability to define design reasoning, understanding potential impacts of design requirements.Proven understanding of backlog tracking, burndown metrics, and incremental delivery.At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.16",bos,de
28,"Suffolk Construction Company, Inc.","Construction, Repair & Maintenance",4.2,Data Engineer,"Boston, MA",$68K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_895c4486&cb=1619364030068&jobListingId=4068355934,"Overview:Overview:As a national leader in the construction industry, Suffolk is redefining what it means to build. We challenge the status quo every day by gathering the people, innovations, and partnerships that can explore and go after new ways to do our jobs. Our focus on high-performing teams and technology translates to groundbreaking solutions for all industry sectors and phases of building. We provide value throughout the entire project lifecycle by leveraging our core construction management services alongside vertical service lines, an approach that is revolutionizing the industry and making a permanent mark on the world of business. Join us for a thrilling experience that will energize you, challenge you, and propel your career.About Suffolk:Suffolk is a national enterprise that invests, innovates, and builds. We provide value throughout the entire project lifecycle by leveraging our core construction management services with vertical service lines that include real estate capital investment, design, self-perform construction services, technology start-up investment and innovation research and development. We have $4.5 billion in annual revenue, 2,400 employees, and main offices in Boston (headquarters), New York, Miami, West Palm Beach, Tampa, Estero, Dallas, Los Angeles, San Francisco, and San Diego. We serve clients in every major industry sector, including health care, science and technology, education, gaming, transportation and aviation, and commercial. Suffolk is privately held and is led by founder, chairman and CEO John Fish. We’re ranked #23 on the Engineering News Record list of “Top 400 Contractors.” And we’re proud to be a certified 2020 “Great Place to Work.” For more information, visit www.suffolk.com and follow Suffolk on Facebook, Twitter, LinkedIn, YouTube, and Instagram.The Role:Suffolk Construction is seeking an experienced Data Engineer to support Suffolk’s enterprise data management program and systems. The Data Engineer, an emerging role in Suffolk’s data and analytics team, will be pivotal in operationalizing the most-urgent data and analytics initiatives for Suffolk’s digital business initiatives. This role will require both creative and collaborative work with IT and Suffolk’s wider business. It will involve evangelizing effective data management practices and promoting a better understanding of data and analytics.The Data Engineer will be responsible for creating and optimizing our data models and data pipeline architecture. The ideal candidate is an experienced data pipeline builder, data wrangler, and data modeler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our data analysts and data scientists to ensure optimal delivery of data throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of designing our company’s data architecture to support our next generation of products and data initiatives.Responsibilities:Analyze and organize raw data; prepare data for descriptive modeling.Combine raw data from different sources and explore ways to enhance data quality and reliability.Ability to prepare curated datasets for self-service consumption (data democratization)Develop and maintain a scalable data pipeline and build out new API integrations to support continuing increases in data volume and complexity.Understand and translate business needs into data models supporting long-term solutions.Work and collaborate with IT to understand the current data architecture, data pipes, data security, and IT data strategy.Prepare data for predictive and prescriptive modeling.Create logical and physical data models using best practices to ensure high data quality and reduced redundancy.Develop best practices for standard naming conventions and coding practices to ensure consistency of data models.Recommend opportunities for reuse of data models in new environments.Design, construct, install, test, and maintain data management systems.Collaborate with the data and analytics team and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization.Develop data models that can be used to make predictions and answer questions for the overall business.Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders.Work closely with all business units and engineering teams to develop a long-term data platform architecture strategy.Research new uses for existing data.Evaluate data models and physical databases for variances and discrepancies.Support the data visualization team and data science team with formatted data and provide data model QA/QC.Qualifications:A bachelor’s or master’s degree in computer science, statistics, applied mathematics, data management, information systems, or a related quantitative field [or equivalent work experience] is required.At least 4 years or more work experience in data management disciplines including data integration, data modeling, data management and data quality.At least 3 years of experience working in cross-functional team and collaborating with business stakeholders in support of departmental and/or multi-departmental data management and analytics initiatives.At least 3 years of experience with cloud data warehouses (i.e., Snowflake, AWS Redshift, Azure Synapse), with an aptitude to learn new tools.Strong SQL skills with a background for building data models.Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.Proven ability to perform data cleaning, wrangling, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.Proven ability to design, build, and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata and workload management.Strong experience with advanced analytics programming languages such a R, Python, C++, Scala, etc.Well versed in BI tools to include Microsoft PowerBI, Tableau, etc.Experienced in working with IT to build a data-driven infrastructure.Strong verbal and written communication skills.Construction experience preferred but not required.Necessary AttributesExcellent analytical and problem-solving skillsSound business acumenPositive attitude with a strong willingness to learnCurious and tenaciousStrong drive to insightWorking Conditions:While performing the duties of this job, the employee is regularly required to sit for long periods of time; talk or hear; perform fine motor, hand and finger skills in the use of a keyboard, telephone, or writing. The employee is frequently required to stands; walk; and reach with arms and/or hands. Specific vision abilities include close vision, distance vision, depth perception and the ability to adjust focus. The employee will spend their time in an office environment with a quiet to moderate noise level. Job site walking.EEO Statement:Suffolk provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, pregnancy or maternity, national origin, citizenship, genetic information, disability, protected veteran, gender identity, age or any other status protected by law. This policy applies to recruiting, hiring, transfers, promotions, terminations, compensation, benefits, and all other terms and conditions of employment. Suffolk will not tolerate any unlawful discrimination toward, or harassment of, applicants or employees by anyone at Suffolk, or anyone working on behalf of Suffolk",bos,de
29,Splunk,Information Technology,4.2,Data Engineer,"Boston, MA",$99K - $180K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=4128&s=58&guid=00000179099e24918b071123ee97220e&src=GD_JOB_AD&t=SR&vt=w&cs=1_355a85ba&cb=1619364030068&jobListingId=4069269042,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.

Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.

Requirements: I’ve already done that or have that!

5+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data ScientistSavviness with complex SQL queries and knowledge of database technologies including window and analytical functionsExperience with Python analytic libraries and Business Intelligence tools such as Tableau.An ability to provide technical guidance, direction and problem solving to data engineering team members.Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.A familiarity working with an AGILE/SCRUM process management.

Preferred knowledge and experience: These are a huge plus.

Knowledge of Splunk productsAgile certifications

Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.

A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.A stable, collaborative and supportive work environment.

We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",bos,de
0,DriveCentric,Information Technology,4.3,Data Engineer I/II,"Chicago, IL",$49K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044077&s=149&guid=0000017909a313d8ae9185f92801b427&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_e65f77ef&cb=1619364353537&jobListingId=4070007946,"Are you tired of not being challenged, not having a voice, or having to work with outdated technologies? Do you want to be a direct contributor in a company that is an innovation leader and has the awards to prove it? Do you want your fair share of the profits from a fast-growing company that’s doubling its customer base year-over-year?A Data Engineer I/II develops and performs data migration / ETL processes for store launches, investigates and fixes data issues, monitors and optimizes database performance, and assists in the administration of databases and data warehouses.Responsibilities:Write, execute, and validate DML, DDL, and DCL scripts to meet business and customer needs.Coordinate and perform data imports, data modifications, database maintenance, etc. outside of business hours, as needed.Assist Customer Support and Development by analyzing data to troubleshoot application issues.Manage SSIS packages for customer onboarding ETL processes.Onboard new customers by scrubbing data and importing from multiple data sources.Requirements:2+ years of experience writing DML and DDL, with 1+ years of hands-on experience with T-SQL.1+ years of hands-on Microsoft SQL Server 2012+ experience.Ability to balance business and technical objectives when making decisions.Ability to balance multiple assignments in a fast-paced environment.Exceptional communication, problem-solving, and analytical skills are a must.Have a positive, can-do attitude.Pluses:1+ year of scripting and managing ETL packages, with SSIS or other tools.Hands-on experience with Database Administration (SQL Server)Hands-on experience with PostgreSQL.Benefits:Competitive salaryHealth, Vision, and Dental Insurance (eligible on day 1)401K with matching up to 4%9 company holidays + 12 vacation days in first yearAmple professional growth opportunitiesJob Type: Full-timePay: $70,000.00 - $100,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insurancePaid time offVision insuranceSchedule:Monday to FridayWork Location:One locationVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:Open to applicants who do not have a college diplomaCompany's website:https://drivecentric.com/Company's Facebook page:https://www.facebook.com/DriveCentric/Work Remotely:Temporarily due to COVID-19",chi,de
1,Deloitte,Accounting & Legal,3.9,Data Engineer - Experience Management,"Chicago, IL",$103K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1008783&s=149&guid=0000017909a313d8ae9185f92801b427&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_d223b3ac&cb=1619364353538&jobListingId=4070112896,"Locations: New York, NY | Greensboro, NC | Chicago, IL | Raleigh, Durham, Chapel-Hill, Charlotte, NCDeloitte Digital offers services that enable client solutions using digital technologies, including the Web, Mobile, Social Networking, Digital Strategy, Digital Content and Digital ERP. The Digital Web team works with clients to advise, design, implement and deploy eCommerce and Portal solutions.Our eCommerce capabilities provide transactional solutions related to online marketing, sales and service; for both Direct-To-Consumer and Business-to-Business.Our Portal capabilities provide intranet and internet solutions focused on content presentment and transaction capabilities for both internal enterprise as well as customer facing purposes.Work you'll doAs a Data Engineer, you'll perform the technical implementation of customer data platforms (CDPs) and serve as a key player as it relates to data management.Your responsibilities will include:Interface with clients to gather requirements, map solutions, and make recommendationsLead customer project conference calls or interface with project managerCreate technical specifications to drive development of the solutionDeliver technical specifications documents for customer reviewDesign custom development solutions that meet customer requirementsProgress through full development lifecycle for custom solutionDeploy new solutions to production environmentsMaintain and support new and existing solutions and frameworksInnovate on new ideas to solve customer needs and assist to market internally new solutionsProvide project estimates and timelines to drive new businessPartnership and collaboration with sales and other internal teamsTeaming with engagement managers to communicate project status, risk and issues to clients as appropriateEngaging cloud solution engineers and other domain-specific SMEs (Adobe, Salesforce, Oracle, Google and similar) to support platform implementation as neededCoordinating Testing/SIT/UAT activities as required by project scope and team structureUnify disparate data sources in initial phase of engagementsVet, type check, transform data sources before consumption by data scientistsBuild automation between engagements to ease the above, in collaboration with our product engineersThe teamAdvertising, Marketing & CommerceOur Advertising, Marketing & Commerce team focuses on delivering marketing and growth objectives aligned with our clients' brand values for measurable business growth. We do this by creating content, communications, and experiences that engage and inspire their customers to act. We implement and operate the technology platforms that enable personalized content, commerce and marketing user-centric experiences. In doing so, we transform our clients' marketing and engagement operations into modern, data-driven, creatively focused organizations. Our team brings deep experience in creative and digital marketing capabilities, many from our Digital Studios.We serve our clients through the following types of work:Cross-channel customer engagement strategy, design and development (web, mobile, social, physical)eCommerce strategy, implementation and operationsMarketing Content and digital asset management solutionsMarketing Technology and Advertising Technology solutionsMarketing analytics implementation and operationsAdvertising campaign ideation, development and executionAcquisition and engagement campaign ideation, development and executionAgile based, design-thinking, user-centric, empirical projects that accelerate resultsQualificationsRequired:3+ years experience in ETL development using Big Data Technologies3+ years experience in building large-scale data processing projects using cloud technologies3+ years experience with data modeling and tuning of relational as well as NoSQL datastoresExperience with Programming and Scripting Languages (.NET, Python, Powershell, Java, Batch, Bash and similar)Industry experience as a data engineer or related specialty (software engineer, application developer)Experience building/operating highly scalable, fault tolerant, distributed systems for extraction, ingestion and processing of large data setsExperience with software engineering best-practices, including but not limited to version control, CICD, automated unit testingExperience using cloud-native tools and design patternsDegree in computer science, engineering, or relevant industry experienceExcellent interpersonal skills and the ability to articulate complex technology concepts with technical and non-technical individualsAbility to approach a technical solution to solve for challenges from a business perspectiveUnderstanding and experience working with customer centric data and how to define uses for this data to enable business goalsUnderstanding of the full SDLC processTravel up to 25% (while up to 25% of travel is a requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice)Limited immigration sponsorship may be availablePreferred:Experience and knowledge with marketing cloud solutionsExperience and knowledge with web analytics or digital marketingExperience working with public cloud offerings (AWS, Azure, Google Cloud Platform, and similar)GCP - (Cloud Functions, Composer, SQL, Storage, Dataproc, Datastore, Kubernetes, Big Query, Stackdriver, Pub/Sub)AWS - (Lambda, Glue, Data Pipeline, Redshift, Aurora, Athena/Spectrum, S3/Glacier, Fargate, Cloud Watch, Kinesis)Azure - (Functions, Batch, Blob Storage, Data Warehouse, Data Factory, Containers, Monitor, Service Bus)Experience and knowledge with data science, ML/AI, R, or JupyterExperience and knowledge with data science, ML/AI, R, or JupyterExperience and knowledge with customer data platforms or demand side platformsExperience as an enterprise technical or engineer consultantExperience using C#, Java or PythonExperience with Martech/Adtech tools and how to integrate technologies into the data management solution. (Adobe, Salesforce, Oracle, Google, and similar)",chi,de
2,True North Equities,N/A,4.3,Senior Building Maintenance Engineer - International Position,"Downers Grove, IL",$56K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044077&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_62f0128e&cb=1619364353538&jobListingId=3628190193,"True North Equities is looking for an International Building Maintenance Engineer. You must be willing to relocate (with or without family) to Middle East, North Africa, SE Asia (non-war Zone). must have working knowledge of facilities management, asset life cycles, asset management and preventative maintenance procedures. A strong working knowledge of CMMS offerings and building inspection processes is desired. Candidate must possess the ability and desire to manage a small team of dedicated professionals in CMMS sales opportunities, implementations and/or building inspections. A background in Telecommunications is a plus. Strong multinational communication and presentation skills are required.Requirements:1. B.S in Engineering discipline, Master level or 10 plus years industry experience - Maintenance,Telecommunications, Energy/Power preferred.2. Multi-lingual: English & Arabic.3. Willing to relocate (with family) to Middle East, North Africa, SE Asia (non-war Zone).4. Willing to travel.5. CMMS Experience a definite plusQualifications:1. Strong knowledge of predictive, preventive, corrective and routine maintenance of facilities andassociated industries.2. Knowledge of mechanical, electrical, plumbing, fire, HVAC, security, fire systems, and assetinteractions.3. Proficient in the sale implementation, demonstration, and use of CMMS software systems and howthey can improve the efficiency of asset management and building maintenance.4. Deep knowledge of asset tracking, work order scheduling, inventory control and energy management.5. Ability to manage, motivate and lead a small team of dedicated multinational professionals.6. Must possess business development and client management skills to include identify, acquiring and managing both SMB clients and key partners.7. Must have excellent writing skills and a background in responding to RFP/RFQ’s.8. Must be willing to be hands-on when necessary.9. Must be capable of working independently and multi-tasking.10. Experience in hotels, hospitals and data centers is desirable.Job Type: Full-timeExperience:Building Maintenance: 1 year (Preferred)Language:Arabic (Preferred)Work authorization:United States (Required)Required travel:50% (Preferred)",chi,de
3,Leidos,Aerospace & Defense,3.8,Technical Solution Sales Engineer,"Chicago, IL",$93K - $136K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_e3857380&cb=1619364353538&jobListingId=4067229193,"Technical Solution Sales Engineer – Electric Utility Spatial AnalyticsNo two career paths will ever look the same. At Leidos, we know the most talented and diverse IT and engineering professionals will always have a multitude of career choices; your time at Leidos will be a wise investment in your career and in yourself.Protect yourself and your family, with the benefits of working for a world-class employer. When you join Leidos, you join a Fortune 500 company and one of Ethisphere Institute’s “World's Most Ethical Companies”.Successful candidates can look forward to a fast paced, diverse work environment & flexible work hours/work arrangements as well as managers who will encourage career development and growth including:Opportunity to lead, grow, and inspire a dynamic teamLeadership trainingManagement opportunitiesIn this role, you can also expect to:Participate in strategic development of solutionsContribute to an expanding portfolio of businessPartner with leading utilities across the nationLeidos fuses technological excellence with decades of operational and management consulting expertise, providing utilities with solutions delivering tangible and meaningful business results. Our expertise in each facet of utility operations is strengthened not only by the skill and experience of our staff, but also by the breadth of our collective capabilities. This perspective drives our experts to frame technological solutions within the business context and incorporate and leverage advanced technologies to meet utilities' challenges and unlock opportunity.Leidos is currently seeking an experienced individual to provide geospatial solution development and sales support as part of our Utility Spatial Analytics team. Preferred locations include Orlando, New Orleans, Washington DC, Boston, Nashville and Denver.Location may be flexible depending on the individual candidates identified. Successful candidates will be part of a team that provides spatial analytic solutions to electric utilities throughout the U.S.A successful candidate will have experience in the electric utility industry and in the development, sale, and/or implementation of technology-forward geospatial solutions that lead to improved electric utility business operations. Extensive travel will be required once client travel restrictions are no longer in place. The successful candidate will be highly self-motivated, articulate, personable, and able to perform with limited direct supervision.Representative services and activities in which successful candidates may be engaged include:Engage existing and potential clients in review of technology-forward geospatial solutions and value propositions.Present Leidos technical capabilities and provide expert insights to support the sale of utility spatial analytics solutions.Translate critical customer needs to technology solutions.Develop next-generation geospatial solutions utilizing advanced sensing technologies combined with AI / ML enhancing environmental and asset awareness.Direct interaction with clients at a high management level, including interpersonal interaction and presentation of information and analyses.Work with Leidos technical staff to refine utility spatial analytics solutions, pricing and scope.Partner with Leidos Commercial Energy business development staff to create a utility spatial analytics sales pipeline and drive opportunities to closure of complex sales opportunities.Monitor ongoing utility spatial analytics programs for effectiveness and client satisfaction and provide input to technical teams.Develop key client plans for the continuation of program development and expansion.Required Qualifications:Bachelors degree and 12+ years of prior relevant experience or Masters and 10+ years of prior relevant experience. Relevant experience includes demonstrated experience in crafting and selling solutions that utilize data analytics, spatial analytics, artificial intelligence/machine learning.Over 5 years experience in, and understanding of, the use of spatial analytics in electric utility operations including: GIS, LIDAR, satellites, and other remote sensing technologies.Demonstrated success marketing and selling complex solutions over a long sales cycleHighly motivated individual with experience articulating value propositions of technically advanced solutions to current and potential clients.Understanding of industry issues and trends and demonstrated ability to explain and assess how those issues impact industry participants.Baccalaureate in engineering, computer science, finance, economics or a related field from an accredited university.Ability to work both independently and in a team atmosphere.Ability to manage multiple time-sensitive priorities without diminished effectiveness.Ability to effectively communicate verbally and in writing to varied audiences.Ability to travel extensively and work overtime hours as needed.Ability and desire to network extensively in marketplace and within organizations.Leidos is a trusted and technology-focused solutions provider. Utilities and mobile operators rely on our Power Delivery Services Team for reliable power and telecommunication expertise, as reflected through our work with more than 50 investor-owned utilities, more than 160 municipals/cooperatives, as well as a growing number of mobile operators, local utility providers and private developers. In addition to providing engineering and project management services, Leidos works with an established group of industry-leading construction partners delivering meaningful Energy Delivery Solutions. Our recognition as an industry leader is confirmed by the latest national rankings by Engineering News-Record (ENR) ranking Leidos within the Top 10 T&D Firms, and Top 10 Power Firms.PowerDeliveryPDSDLINEExternal Referral Bonus:IneligiblePotential for Telework:Yes, 50%Clearance Level Required:NoneTravel:Yes, 25% of the timeScheduled Weekly Hours:40Shift:DayRequisition Category:ProfessionalJob Family:Business DevelopmentPay Range:",chi,de
4,Uline,Manufacturing,3.6,Supply Chain Data Analyst (North of Chicago),"Chicago, IL",$44K - $81K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_a18850ab&cb=1619364353539&jobListingId=4044153232,"Supply Chain Data AnalystCorporate Headquarters12575 Uline Drive, Pleasant Prairie, WI 53158Driven by Speed, Passion and Operational Excellence, Uline’s Distribution Operations team supports our fulfillment operations across North America to be the leading distributor of shipping, packaging and industrial supplies!Better together than apart. This position is on-site, and we are looking for good people who share our passion.Uline is proud to operate as a drug-free workplace. All new hires must complete a pre-employment hair follicle drug screening.Position ResponsibilitiesAnalyze company operations, including performance and productivity data, error rates and their root causes.Independently interpret results using a variety of techniques, ranging from simple data analysis to complex data mining.Analyze reports to identify distribution operational issues.Conduct ad hoc analyses on various departments and branches.Design, develop, implement and maintain business solutions to improve performance.Minimum RequirementsBachelor's degree.2 years experience.Working knowledge of SQL, data extraction and analysis a must.Experience in a distribution, supply chain or warehouse environment a strong plus.Excellent proficiency in Microsoft Office, especially Excel.BenefitsComplete insurance coverage that includes medical, dental, vision and life insurance, Flexible Spending Accounts and wellness programs.401(k) with 5% employer match.Paid holidays and generous paid time off.Bonus programs that include annual performance, sales goals and profit sharing.Scholarship program for children of employees.Employee PerksOn-site café with executive chefs and seasonal dinner-to-go options.First-class fitness center with complimentary personal trainers.Over four miles of beautifully maintained walking trails.Numerous employee appreciation events throughout the year.Professional development classes and monthly in-house speakers.About UlineUline is North America's leading distributor of shipping, industrial and packaging materials. We're a family-owned company known for incredible service, our 800+ page catalog of over 38,500 quality products and same-day shipping of our huge in-stock inventory. With over 7,000 employees across 12 locations, it's time you joined Uline.Uline provides the essential supplies needed to keep organizations operational and productive. To protect the health and safety of our employees, we have modified our normal operating policies in response to COVID-19.Each resume submitted gets individually reviewed by our team and retained for 24 months in case a great opportunity opens for you to join our Uline family.EEO/AA Employer/Vet/Disabled#LI-SN1#CORP",chi,de
5,Duck Creek Technologies,Information Technology,4.2,Support Engineer II,"Rosemont, IL",$70K - $81K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_b2f1e391&cb=1619364353539&jobListingId=4070116773,"Challenging convention. Trying new things. Reshaping an industry.The team at Duck Creek helps insurance companies bring amazing ideas to life quickly and easily with software that thinks and works like they do. We're fueled by sharing ideas openly, challenging conventions, trying new things, and valuing ""Why not?"" over ""Why?"" Our certainty that there is always a better way to do things keeps carriers ahead of their competition and is helping to reshape an industry.If having a hand in transforming one of the world’s oldest and largest industries into a standard for innovation, open exchange, and peerless user experience sounds exciting, let us know. We may be looking for you.Support Engineer IIThe Support Engineer II is responsible for the client’s success in using the Duck Creek solution by driving the resolution of raised client issues, providing updated information on future releases, and clearly responding to base software related questions. The Support Engineer II is assigned to complex client accounts or directly assisting with the management of complex accounts and manages critical client escalations with little oversight.Responsibilities :Requires minimal direction and minimal oversight; moderately independentCommunicates directly with the customer(s) via web meetings and incident tracking workflowCommunicates directly with Customer Service Managers to provide status updates in a timely manner for high priority incidentsQualifies incidents submitted by third-party implementation teams or customers by identifying gaps in the details of incidents and gathering informationSets up environments within Azure test labs to replicate and triage incidents reported submitted by third-party implementation teams or customersWorks within DCOD environments to replicate and triage incidents reported submitted by third-party implementation teams or customersTriages moderate to high complexity incidents with minimal to no oversight from Sr. Support Engineer or aboveLeverages Duck Creek utilities such as Trace Monitor, ExampleUtil, data copy tools, etc to triage reported incidentsLeverages third-party utilities such as Visual Studio, HTTPWatch, Fiddler, SQL Management Studio, etc to triage reported incidentsCodes debug moderate to high complexity incidents with low to moderate oversight from Sr. Support Engineer or higherProvides work-a-rounds or solutions to third-party implementation teams or customers based on analysis during the triage processEscalates incidents deemed to be base code defects to the proper Engineering teamsApplies SQL or XML scripts in DCOD environments to align dataIdentify trends and patterns of reported data fix requestsIdentifies ways to automate processes regarding data fix requests or develop utilities to assist in the triaging processCreates training modules in areas of expertise to sharpen knowledge of Triage team membersOptionally act as a Skills Lead for Associate Support Engineer, Sr. Associate Support Engineer, and Support Engineer 1 team members to mentor and provide annual performance feedbackAttends sprint reviews and supports targeted trainingServes as on call Support Engineer for after-hours emergencies as needed to triage Severity Level 1 incidentsAnalyzes and assesses upgrade impact based on release notes and code changes for new release featuresLeverages Duck Creek upgrade tools to generate differential analysis and produce low impact upgrade path for Duck Creek CustomersDevelops Duck Creek product upgrade strategyDevelops customer upgrade approach and timelines and facilitates planning with customers/implementation partners and drives plan through completionBuilds tools and automates processes for flawless and efficient product upgrade for Duck Creek OnDemand CustomersDevelops DCOD test automation and execution strategyDevelops DCOD test best practices and contribute to developing test offering for customersRequires minimal direction and minimal oversight; moderately independentPerform other related duties and activities as required.Requirements :Education and Work Experience:Bachelor’s degree, or higher education level, or its foreign equivalent, in Computer Science, Computer Information Sciences, or a related engineering/computer field.Work Experience: Minimum 8 yearsSpecialized Knowledge, Skills, and/or Abilities:Demonstrates expertise in the following competencies:After hours call service expertise/triageAnalytical abilityApplicable DCU boot camp assessment scoreCreating training modules in area of focus for team membersDuck Creek triaging tools knowledgeInstallation troubleshooting knowledgeKnowledge-base contributorProduct Installation in supporting areaReplication/qualification of reported casesSalesforce workflowUpgrade strategyTest automation and executionTeamTrack Workflow and submission (if applicable)TFS Workflow and submission (if applicable)Azure Dev Ops Workflow and submission (if applicable)Visual Studio or similar IDEDemonstrates proficiency in the following competencies:.NET and C# (or similar language)Ability to operate independently with minimal guidance in focus areaCoding debug dllsCoding additional trace messagesCommunicate with support personnelExtensible Markup Language (XML)Full Suite installationInternet Information Services (IIS)Root cause analysisSalesforce case organization and managementStructured Query Language (SQL)Understanding new feature release detailsAzure Test Labs or equivalent VM knowledgeFrontend technologies like HTML, CSS, Skins, Javascript, Jquery.Continuous integration practices.Demonstrates awareness in the following competencies:Insurance domain knowledgePerformance and memory diagnosisOther Requirements:Travel: 15%Special Work Hours: After-hours On-Call Support Engineer for emergencies as needed to triage Severity Level 1 incidentsWork Authorization: Legally authorized to work in the country of the job location.Physical: Exerting up to 20 pounds of force occasionally, and/or up to 10 pounds of force frequently, and/or a negligible amount of force constantly to move objects. If the use of arm and/or leg controls requires exertion of forces greater than that for sedentary work and the worker sits most of the time, the job is rated for light work",chi,de
6,Wolverine Trading,Finance,4.3,C++ Software Engineer,"Chicago, IL",$79K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_76d4fea3&cb=1619364353540&jobListingId=4014194183,"C++ Software EngineerWolverine is seeking passionate C++ programmers who are not satisfied with solutions that are good enough and who have a drive to push the envelope of what is technically possible. Our ideal candidate excels at both collaborating with technical and business subject matter experts to identify and implement new trading strategies, while also debugging and fixing mission critical problems. This is a hands-on position spanning the entire development stack of our bleeding edge ultra-low latency trading systems from idea generation all the way to support. If you are excited about finance, have a passion for technology, and a drive to learn, then we want to talk to you!What You’ll DoPerform full life cycle development and deployment of C++ applications and libraries for exchange gateways, trading strategy execution, risk management and trade reportingDevelop systems to maintain, analyze and improve performance, integrity and reliability of existing applicationsInvestigate and fix problems with production systems in real-timeConstruct experiments and analyze data to identify ways to improve technical performance and new trading opportunities, ensuring that results are valid and reproducibleCollaborate with technical and business peers to develop new trading strategies and systemsCommunicate technical knowledge to both technical and non-technical audiencesSkills You’ll NeedTop-notch C/C++ coding skills, with a solid foundation in data structuresExcitement for developing and dedication to testingExcellent analytical and problem solving skillsPassion for writing clean high quality code and the ability to provide, and take, code review feedbackWillingness to collaborate and learn from other team membersAbility to take ownership over projects and be self-directed on what needs to happen nextStrong communication skills with both engineers and people without a technical backgroundExperience with SQL database, mutli-thread programming, STL & BoostBachelor’s degree in Computer Science or Computer Engineering, or equivalent.Sponsorship is not available for this position.Are you a returning applicant?Previous Applicants:Email:Password:If you do not remember your password click here.",chi,de
7,Trexin Consulting,Business Services,4,HealthCare Data Scientist / Data Engineer,"Chicago, IL",$72K - $114K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044077&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_cc68c0a4&cb=1619364353540&jobListingId=4065282864,"Founded on the principles of trust, experience, and innovation, Trexin Consulting specializes in strategy execution – the effective implementation of business strategy to achieve a specific business goal. Also referred to as applied strategy, strategy execution situations that Trexin frequently leads include: scaling capabilities for growth, optimizing operations for cost reduction, driving synergies for M&A, and recovering projects in distress. Trexin’s services are right-sized for our Clients’ needs, ranging from our “Diamond Team” service when our Clients want Trexin to own an outcome and share delivery risk, to Expert/Advisory services for senior-level guidance, to Strategic Staffing services for execution-oriented tasks and roles. Our expertise spans Healthcare, Life Sciences, Financial Services, and Products & Distribution, overlaid by multidisciplinary skills in the five capabilities essential to executing strategy: Aligned Enterprise, Program Execution, Technology, Innovation, and Analytics.Trexin Consulting is searching for a Consultant to work as a Sr Data Scientist / Sr Data Engineer with extensive experience with Artificial Intelligence and Machine Learning (ML) in the Healthcare industry for our Healthcare client located in Chicago IL. This consultant will work with Healthcare Equity programs to develop AI / ML data models.Key Areas of Responsibility: Design and implement a Healthcare Equity AI / ML and data models for identifying disparities in Healthcare.Ensure that Artificial Intelligent (AI) & Machine Learning (ML) deliverables can be productionized and integrated into existing systems and processes.Effectively interact with other Data Science personnel, IT & Technical staff, Product Owners, Data & Application Architects, and Business AnalystsWork on data analysis projects relating to Healthcare Equity models.Acquire and transform large datasets which will be used for analytics including AI and ML.Analyze and evaluate large quantities of data in relational databases and unstructured forms of data, effectively balancing quality, availability, timeliness.Leverage data engineering skills to acquire data in an effective and timely manner.Work with consultants, clients, or internal teams to prepare complex analytic data models analyses and models that address client issues and deliver significant measurable impact.Key Desired Skills, Experience and Knowledge: Understanding of how to create Healthcare Equity models10+ years of relevant hands-on big-data engineering experienceStrong background in the following:Big Data, Data Science, AI, Machine Learning and Predictive AnalyticsBusiness Intelligence (BI) Systems, Data Lakes, and Data WarehouseExperience in working with large datasets, relational databases (SQL), and distributed Data Lake systems (Databricks, Hadoop, Hive)First-hand experience with the acquisition and transformation of data from Data Warehouse(s) and Data Lake(s).Demonstrated experience with the lifecycle development process for AI and ML models.Able to serve as a liaison between other Data Scientists and technical teams to drive effective, timely solutions that fulfill both strategic and operational needs.Strong logical and analytical problem-solving skills; rigorous approach to project / program management to deliver enterprise-level projects.Experience with Python, Pandas, and scikit-learn.Cloud experience with AWS and Azure.Knowledge and familiarity with statistical techniques, data mining, and machine learning including but not limited to regression, decision trees, clustering, random forests, and generalized linear models.Experience with visualization tools/technology product or platform such as PowerBI or Tableau to analyze data and answer business questions is highly desirable.Knowledge of additional programming languages is a plus, specifically C++ or JavaIntellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes and recommend solutions.Strong interpersonal skills, team-orientation, and professional attitude.Bachelor’s degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics, or related field preferred.Experience in Healthcare with payor, claims and membership platform experience preferred.Big 4 or previous consulting experience is a plus.Trexin is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. Trexin is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Trexin are based on business needs, job requirements, and individual qualifications. Trexin strictly prohibits and does not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth, or related medical conditions), gender (including gender nonconformity and status as a transgender individual), sexual orientation, age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state, or local law.Trexin complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Trexin will reasonably accommodate qualified individuals with a disability if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. Trexin will also, where appropriate, provide reasonable accommodations for an employee's religious beliefs or practices. Trexin strictly prohibits discrimination against protected veterans, and Trexin utilizes affirmative action to recruit, hire, promote, and retain veterans.Trexin Consulting does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Trexin Consulting vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Trexin Consulting Recruiting Team and such candidate was submitted to the Trexin Consulting Recruiting Team via our Applicant Tracking System.Job Types: Full-time, ContractPay: $1.00 per yearWork Location:One location",chi,de
8,Uline,Manufacturing,3.6,Associate Database Administrator (North of Chicago),"Chicago, IL",$71K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_6dd6ee67&cb=1619364353541&jobListingId=4067906514,"Associate Database AdministratorCorporate Headquarters12575 Uline Drive, Pleasant Prairie, WI 53158Real work. Real training. Real growth. There's no limit to what you can accomplish through our unique LearnIT program, with 6 weeks of orientation to set you up for professional and technical success at Uline.Better together than apart. This position is on-site, and we are looking for good people who share our passion.Uline is proud to operate as a drug-free workplace. All new hires must complete a pre-employment hair follicle drug screening.Position ResponsibilitiesImplement database technologies and disciplines.Create and maintain replication strategies between various database environments.Ensure industry-wide security standards.Assist in developing test data for application testing.Collaborate with users and developers to assist with performance tuning.Install and configure database management systems.Identify user access levels.Minimum RequirementsBachelor's degree in computer science, information technology or related field.Educational experience in SQL programming.Experience in data integration / data movement preferred.BenefitsComplete insurance coverage that includes medical, dental, vision and life insurance, Flexible Spending Accounts and wellness programs.401(k) with 5% employer match.Paid holidays and generous paid time off.Bonus programs that include annual performance, sales goals and profit sharing.Scholarship program for children of employees.Employee PerksOn-site café with executive chefs and seasonal dinner-to-go options.First-class fitness center with complimentary personal trainers.Over four miles of beautifully maintained walking trails.Numerous employee appreciation events throughout the year.Professional development classes and monthly in-house speakers.About UlineUline is North America's leading distributor of shipping, industrial and packaging materials. We're a family-owned company known for incredible service, our 800+ page catalog of over 38,500 quality products and same-day shipping of our huge in-stock inventory. With over 7,000 employees across 12 locations, it's time you joined Uline.Uline provides the essential supplies needed to keep organizations operational and productive. To protect the health and safety of our employees, we have modified our normal operating policies in response to COVID-19.Each resume submitted gets individually reviewed by our team and retained for 24 months in case a great opportunity opens for you to join our Uline family.Applicants must be authorized to work lawfully in the US without sponsorship.EEO/AA Employer/Vet/Disabled#LI-POST#CORP",chi,de
9,Univar Solutions,Business Services,3.4,Senior Software Engineer - Test Automation,"Downers Grove, IL",$65K - $100K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_4e356326&cb=1619364353541&jobListingId=4066223927,"Want to work for a company that is reimagining distribution? Join Univar Solutions, the premier global distributor of chemicals and ingredients. Our goal is to function as a direct extension of our customers’ teams; to serve as an ally in their quest of business success.At Univar Solutions, we’re building on our more than 90 years of experience and drawing on deep resources – inventory and logistics experts, scientists, PhDs, procurement, customer service, sales and marketers-to deliver consultative services and an unmatched portfolio to solve customers’ formulation and operational challenges. When you work for Univar Solutions, you’ll play an important role in shaping how we deliver more than chemical and ingredients.Primary Purpose:At Univar Solutions, our vision is to redefine distribution and be the most valued chemical and ingredient distributor on the planet. As part of our digital transformation, we are seeking an Senior Software Engineer - Test Automation to join our team. This role designs, builds, tests, deploys, and supports products, platforms, and solutions with a focus on test automation. They work collaboratively with Software Developers, Architects, and Analysts to develop the physical design and build testing solutions that meet the defined functional, quality, performance, security, and architectural standards.Education/Experience/Training:Bachelor’s degree in Information Technology, Computer Science, another relevant field or demonstrated work experience equivalent3-5 years automated test development experienceMaster’s degree a plusSpecialized Knowledge/Skills:Selenium, Katalon, SOAP UI, and JUnit for test scripting and executionPerformance testing experienceLoad testing experienceExperience performing automated testing with AWS (using CodeBuild/CodePipeline) preferredJira for backlog, task, test, and defect managementZephyr for test executionGitHub, Bitbucket, etc. for source controlInformatica Cloud for batch integrationJenkins and Apache ANT for automated build and continuous integrationMuleSoft for real-time integrationServiceNow for service managementConfluence for process documentation and documentation reviewTest data management solutions as neededDemonstrated willingness and capability to learn new technologies and methodologies quicklyExperience assisting development teams using Test-Driven DevelopmentUnivar Solutions is an equal opportunity employer. All qualified applicants will receive consideration for employment and will not be discriminated against based on their race, gender, sexual orientation, gender identity, religion, national origin, age, disability, veteran status, or other protected classification.We offer comprehensive benefits to employees including medical, dental, STD, LTD and life insurance, 401k, generous PTO and much more.#LI-SR1",chi,de
10,Q-Centrix,Health Care,4.4,Data Engineer,"Chicago, IL",$52K - $73K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_19d9cc40&cb=1619364353542&jobListingId=4014493842,"Who are we?Q-Centrix is a leading healthcare information solutions provider with offices in Chicago and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.What’s the job?Q-Centrix is implementing a robust data infrastructure solution to provide further analysis capabilities for our partners in the areas of quality reporting, analysis and improvement. We’re searching for an ambitious and curious team member to report into the Data Architect, Engineering. The Data Engineer will embrace challenging work; while showcasing superior Nerf gun talents throughout the day. You’ll have a leg up if you don’t mind a few orange darts decorating your desktop, love memes and awful puns, and are open to wearing apparel prominently featuring the letter Q.Applicants for employment with Q-Centrix must be legally authorized to work in the United States now or in the future without sponsorship.As a Data Engineer, you will…Work closely with the Data Architect to create and maintain optimal data architecture.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.Support the Product Development, Operations and Finance Teams in creating and analyzing reports both for our partners and internally.Envision and create reports that are translated from internal ideas, client feedback and competitive analysis.Partner with other disciplines within Q-Centrix to ensure project requirements are comprehensive and thoroughly planned and documented.Work with internal and market-facing stakeholders to validate suggested features and enhancements to Q-Apps.Be a vital contributor on a product development team accountable for building the industry’s only Healthcare Quality Information System.You’re a great fit if you…Experience in building data pipeline within Cloud architecture using workflow management tools(Brownie points if you are experienced in Airflow + DBT).Experience with object-oriented/object function scripting languages: Python, Java, Scala etc.Ability to perform root cause analysis on External and Internal processes and data to identify opportunities for improvement.Have had exposure to data modeling for data warehousing - star, snowflake schema designsHave worked within the framework of common Project Management structures and practices including waterfall, agile, project planning, scope control, customer relationship managementKeen on learning and growing technical skillsetGreat if you have experience in healthcare or a related fieldBrownie points if you’re experienced with PostgreSQL and have healthcare industry experienceWho are we?At Q-Centrix, we hire people who love learning, value innovation and believe in our mission and values to improve outcomes in healthcare. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.We employ people based on the needs of the business and the job, and their individual professional qualifications. Here’s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.We celebrate and embrace these differences, and take pride in our commitment to being an equal opportunity team.",chi,de
11,ServiceNow,Information Technology,4.3,Sr Staff Product Security Engineer (SSDL),"Chicago, IL",$131K - $185K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_21f99ba7&cb=1619364353542&jobListingId=4068893399,"Company DescriptionServiceNow is making the world of work, work better for people. Our cloud‑based platform and solutions deliver digital workflows that create great experiences and unlock productivity for employees and the enterprise. We're growing fast, innovating faster, and making an impact on our customers' and employees' lives in significant and important ways. With over 6,900 customers, we serve approximately 80% of the Fortune 500, and we're on the 2020 list of FORTUNE World's Most Admired Companies.®We're looking for people who are ready to roll up their sleeves and help us build on our incredible momentum, our diverse, engaged workforce, and our purpose to make the world of work, work better.Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.Job DescriptionWhat you get to do in this role:Work on a wide range of technologiesIntegrate and aggregate data from different systems into consolidated dashboardsWork on architectural and technical challengesParticipate in threat modeling activitiesMentor and collaborate with development teams to adopt secure coding practicesWork on strategic and highly visible BSIMM activities across the organizationBe an advocate for security and participate in a security champions programCreate, measure, and refine metrics used to measure program successQualificationsTo be successful in this role you have:10+ years of overall product security experience is required4+ years of experience in threat modeling and threat modeling tools is requiredIn-depth knowledge of common web application vulnerabilities (OWASP Top Ten) is requiredProficiency in at least one language - Python, Java, or JavaScript is requiredKnowledge of static, dynamic, and component analysis security tools is requiredKnowledge of the Software Development Lifecycle (SDLC) is requiredKnowledge of OWASP ASVS, SCVS, and related verification standards is requiredKnowledge of BSIMM, OWASP SAMM, or similar maturity models is requiredAbility to communicate technical concepts to both non-technical business users as well as technical stakeholders is requiredA passion for security is requiredJV20Additional InformationServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at +1 (408) 501-8550, or [email protected] for assistance.For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.",chi,de
12,Fresenius Kabi,Manufacturing,3.6,QUALITY ENGINEER,"Melrose Park, IL",$59K - $74K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_5993f884&cb=1619364353542&jobListingId=4068204609,"Job SummaryResponsible for ensuring that the integrated fill line facilities, equipment and associated processes, as well as the quality processes that govern them, are effective, efficient, compliant and remain in a state of control. Responsible for evaluating for compliance and approval of Preventative Maintenance, Metrology, Validation and Qualification activities for the integrated fill line systems. Work in partnership with manufacturing operations, research and development, quality control and assurance, engineering, maintenance to solve problems and provide support on compliance issues and corporate quality policy requirements relating to the integrated fill line equipment.ResponsibilitiesOversees engineering change controls (ECR) for critical equipment and controlled areas related to integrated fill lines which include preapproval and post approval of change controls.Provides support to the plant during operational run times as well as during maintenance shutdown activities both of which include off shift coverage.Provides quality oversight for software validation, equipment qualification, and facility commissioning and validation. Drafts, executes and approves validation documentation for critical equipment.Troubleshoots problems related to equipment (Water, HVAC, Pest Control, Lyophilizers, Vial Washers, etc). Analyzes data and implements both corrective and preventative actions to enhance processes.Analyzes data, conducts root cause investigations, performs gap analyses and risk assessments, develops corrective or preventive actions, and implements procedural and physical changes to reduce defects, improve efficiencies, and ensure compliance with all regulatory requirements, e.g., cGMPs, FDA Guidelines, USP, ISPE, ISO etc.Proactively takes ownership of quality processes and implements solutions in support of continuous improvement.Addresses daily quality concerns and questions related to operating and environmental concerns. Implements and follows up on corrective actions.Provides additional support for batch record review and critical processing steps, in order to meet production and release scheduling.Assures standard operating procedures (SOPs) and batch records define the steps necessary to complete tasks. Writes, reviews, and updates documents as needed.Conducts internal audits of all critical processes and equipment, as well as the quality processes that oversee them, and identifies gaps in compliance and opportunities for improvement.Provides training to appropriate personnel related to facilities and equipment quality system.Interacts with regulatory officials to convey the compliance level of the quality system during regulatory inspections.Prioritizes and efficiently completes tasks with minimal supervision and consistently delivers on commitments by date requested.Responsible for any additional tasks as assigned by the Manager.Requirements:B.S. degree in a technical science is required. Engineering degree is highly preferred.3 years' experience in a highly regulated industry required.3 years' experience in the pharmaceutical industry highly preferred.3 years' experience in change control preferred.Working knowledge of aseptic processing is highly preferred.Working knowledge of cGMP practices to include 21 CFR Part 210, 211 and Part11, Electronic Records, USP, ISO 13485 and 14644, and ISPE trends and guidelines.CQE or CSSGB is a plus.Experience with Trackwise and Documentum preferredAdditional InformationWe offer an excellent salary and benefits package including medical, dental and vision coverage, as well as life insurance, disability, 401K with company match, and wellness program.Fresenius Kabi is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disabilities, or protected veteran status.",chi,de
13,CapTech Consulting,Information Technology,3.9,Data Engineer,"Chicago, IL",$100K - $101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_3975c33a&cb=1619364353543&jobListingId=4068354404,"Company DescriptionCapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.Job DescriptionCapTech Data Engineers enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Distributed Data Engineers are focused on delivering data engineering solutions using non-Cloud Specific Tools in a distributed computing tech stack. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients.Specific responsibilities for the Data Engineer – Distributed Systems position include:Developing data pipelines and other data products using on-premises Hadoop clusters, hybrid infrastructure, Snowflake, Databricks, or MPP systemsAdvising clients on specific technologies and methodologies for utilizing resources to efficiently ingest and process data quicklyUtilizing your skills in engineering best practices to solve complex data problemsCollaborating with end users, development staff, and business analysts to ensure that prospective data architecture plans maximize the value of client data across the organization.Articulating architectural differences between solution methods and the advantages/disadvantages of eachQualificationsPreferred QualificationsTypical experience for successful candidates includes:Experience delivering solutions on Hadoop or other distributed processing system (Snowflake, Databricks, or MPP)Ability to think strategically and relate architectural decisions/recommendations to business needs and client cultureExperience in the design and implementation of data architecture solutionsA wide range of production database experience, usually including substantial SQL expertise, database administration, and scripting data pipelinesAbility to assess and utilize traditional and modern architectural components required based on business needs.A demonstrable ability to deliver production data pipelines and other data products. This could be through hands on experience, degrees, certifications, bootcamps, or other learning.SkillsSuccessful candidates usually have demonstrable experience with technologies in some of these categories:Languages: SQL, Python, Java, R, C# / C++ / CDatabase: Hive, Snowflake, Teradata, Presto, Vertica, NetezzaDevOps: git, docker, subversion, Kubernetes, Jenkins, CA, Dollar UniverseAdditional Technologies: Hadoop, Databricks, Spark, KafkaPopular Certifications: Hadoop certification from Hortonworks / Cloudera, MapR, IBM; database certification from Snowflake or Teradata; Databricks certificationAdditional InformationWe provide challenging and impactful opportunities in our client work and internal teams, while keeping individual interests in mind. We want everyone at CapTech to be able to envision a lifelong career here, which is why we offer a variety of career paths based on your skills and passions. As a CapTecher, you will experience exciting, and rewarding roles that help you grow and make a difference, while having fun along the way.At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:Competitive salary with performance-based bonus opportunitiesSingle and Family Health Insurance plans, including Dental and Vision coverageShort-Term and Long-Term Disability InsuranceMatching 401(k)Competitive Paid Time OffPaid Maternity Leave and Family BondingTraining and Certification opportunities eligible for expense reimbursementTeam building and social activitiesMentor program to help you develop your careerCapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements).CapTech is a Drug-Free work place.Candidates must have the ability to work at CapTech’s client locations.All positions include the possibility of travel.CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.#LI-AB1",chi,de
14,Trexin Consulting,Business Services,4,HealthCare Data Scientist / Management Consultant,"Chicago, IL",$84K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1044077&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ccb22b71&cb=1619364353543&jobListingId=4065283545,"Founded on the principles of trust, experience, and innovation, Trexin Consulting specializes in strategy execution – the effective implementation of business strategy to achieve a specific business goal. Also referred to as applied strategy, strategy execution situations that Trexin frequently leads include: scaling capabilities for growth, optimizing operations for cost reduction, driving synergies for M&A, and recovering projects in distress. Trexin’s services are right-sized for our Clients’ needs, ranging from our “Diamond Team” service when our Clients want Trexin to own an outcome and share delivery risk, to Expert/Advisory services for senior-level guidance, to Strategic Staffing services for execution-oriented tasks and roles. Our expertise spans Healthcare, Life Sciences, Financial Services, and Products & Distribution, overlaid by multidisciplinary skills in the five capabilities essential to executing strategy: Aligned Enterprise, Program Execution, Technology, Innovation, and Analytics.Trexin Consulting is searching for a Consultant to work as a Sr Data Scientist / Management Consultant with extensive experience with Artificial Intelligence and Machine Learning (ML) in the Healthcare industry for our Healthcare client located in Chicago IL. This consultant will work with Healthcare Equity programs to develop AI / ML data models.Key Areas of Responsibility: Design and implement a Healthcare Equity AI / ML models for identifying disparities in Healthcare.Provide business and business process direction that Artificial Intelligent (AI) & Machine Learning (ML) deliverables can be productionized and integrated into existing systems and processes.Effectively interact with Product Owners, Management, Data Engineers, Data & Application Architects, and Business AnalystsWork on data analysis projects relating to Healthcare Equity models.Analyze and evaluate large quantities of data in relational databases and unstructured forms of data, effectively balancing quality, availability, timeliness.Leverage data analysis skills, create innovative approaches to answer clients’ most relevant questions.Work with consultants, clients, or internal teams to prepare complex data analyses and models that help solve client problems and deliver significant measurable impact.Key Desired Skills, Experience and Knowledge: Understanding of how to create Healthcare Equity models10+ years of relevant hands-on data analysis experienceStrong background in the following:Big Data, Data Science, AI, Machine Learning and Predictive AnalyticsBusiness Intelligence (BI) ModernizationOptionally hands on experience with Data Lakes, Data WarehousesDemonstrated experience with the lifecycle development process for AI and ML models.Able to serve in a management consulting capacity between the business and technical teams to drive effective, timely solutions that fulfill both strategic and operational needs. Ability to effectively work with management and business personnel to clarify business objectives, identify the appropriate AI / ML analytic approach to address the business objectives, and then communicate the approaches to data engineers and the technical teams.Strong logical and analytical problem-solving skills; rigorous approach to project/program management to deliver enterprise-level projects.Proficiency with Python, Pandas, and scikit-learn; Experience with SAS and R would also be of benefit.Experience with statistical techniques, data mining, and machine learning including but not limited to regression, decision trees, clustering, random forests, and generalized linear models.Experience with visualization tools/technology product or platform such as PowerBI or Tableau to analyze data and answer business questions is highly desirable.Intellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes and recommend solutions.Extensive experience in working with and presenting analytic outcomes to management personnel in business language devoid of analytic and technical vernacular.Strong interpersonal skills, team-orientation, and professional attitude.Bachelor’s degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics, or related field preferred.Experience in Healthcare with payor, claims and membership platform experience preferred.Big 4 or previous consulting experience is a plus.Trexin is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. Trexin is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Trexin are based on business needs, job requirements, and individual qualifications. Trexin strictly prohibits and does not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth, or related medical conditions), gender (including gender nonconformity and status as a transgender individual), sexual orientation, age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state, or local law.Trexin complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Trexin will reasonably accommodate qualified individuals with a disability if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. Trexin will also, where appropriate, provide reasonable accommodations for an employee's religious beliefs or practices. Trexin strictly prohibits discrimination against protected veterans, and Trexin utilizes affirmative action to recruit, hire, promote, and retain veterans.Trexin Consulting does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Trexin Consulting vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Trexin Consulting Recruiting Team and such candidate was submitted to the Trexin Consulting Recruiting Team via our Applicant Tracking System.Job Types: Full-time, ContractPay: $1.00 per yearWork Location:One location",chi,de
15,RML Specialty Hospital,Health Care,3.3,Performance Improvement Data Analyst,"Chicago, IL",$40K - $71K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_19059725&cb=1619364353544&jobListingId=4065642205,"Ready to make a career move? RML Specialty Hospital is seeking an experienced and dedicated individual to join our Quality & Patient Safety team as a Performance Improvement Data Analyst. As a Performance Improvement Data Analyst, you will strive to develop and foster strong working relationships with the health care and operations team. In addition, you will assist in helping implement an ongoing Performance Improvement Program which systematically evaluates patient safety, care, and satisfaction to identify opportunities for improvement.GENERAL SUMMARY:As a liaison between the Quality & Patient Safety Department and all levels of the hospital, the Performance Improvement Data Analyst establishes strong working relationships with interdisciplinary members of the health care team including the medical staff, clinicians, administration, support services, and other operational areas. The Performance Improvement Data Analyst reports to the Director of Quality and Patient Safety and assists the department and organization with data analytics, performance improvement training, and quality improvement initiatives. Leading by example, the Performance Improvement Data Analyst acts as a change agent liaison that spreads the mindset of continuous improvement and innovation that systematically drives enhancements and improvement throughout the organization.PRINCIPAL DUTIES & RESPONSIBILITIES:Supports the organizational efforts to have a comprehensive and effective program for evaluating and improving organizational performance.Demonstrates ability to develop, maintain and produce reports related to organizational performance.Performs accurate tracking, aggregating, trending, analysis and creating of reports.Assists in Quality Assurance (QA) Activities by monitoring timely submission of organizational QA reports as outlined in annual organization quality and patient safety plan, analyzing QA reports for opportunities to improve and effectively collaborate with leads, assisting in development of Quality Assurance sustainment plans and reports, and maintaining safety and quality database(s) and produces aggregate reports.Leads and/or assists with Quality Improvement activities. Applies basic quality improvement statistical analysis to support decision making. Collects and enters quality data for external reporting.Populates and submits mandatory reporting on events: Falls, Restraint-related deaths, expiration report.Oversees CARE Tool reporting and submission to LTRAX. Participates in all required training related to CARE Tools. Provides training to all appropriate staff regarding necessary documentation necessary for each section of the assessment tool. Establishes or maintains appropriate data collection and submission procedures to CMS. Collects data as needed or required. Identifies and corrects any problems in data collection. Updates and refreshes staff training as needed. Assures all RML patient data submitted to CMS is timely, accurate and best describes the condition of the patient.Demonstrates a basic knowledge and application of principles relevant to each section of the CARE tool assessment. To include but not be limited to:Demonstrates an understanding of definition statements (appropriate inclusion / exclusion criteria or answer options) as determined by CMS.Demonstrates an understanding of the various skip patterns throughout the CARE Tool.Assures all portions of each admission CARE tool assessment are completed using data from the first 48 hours of the patient’s hospitalization.Assures all portions of each discharge CARE tool assessment are completed within a 48-hour window prior to the patient’s discharge.Completes all data entry (web based) within required time frame for submission of assessments.Promotes a safe work environment for self and others. This includes but is not limited to identifying and responding to actual or potentially unsafe conditions and by using applicable safe work practices.Exemplifies the RML REACH (Service Excellence) culture by demonstrating respect, excellence, appreciation, concern, and honor in all interactions with patients, families, and co-workers, and as identified in departmental and hospital wide behavioral expectations.JOB REQUIREMENTS & CHARACTERISTICSMINIMUMPREFERREDSkills & Abilities1. Knowledge of performance improvement science and application strategies in health care.2. Demonstrative proficiency in Microsoft Word, Excel, PowerPoint, Project, and data base software3. Positive mindset and communication skills to interact positively with hospital staff, management, physicians, and outside agencies.4. Organizational skills to prioritize work and meet frequent deadlines.5. Analytic ability and problem-solving techniques.Meditech experience preferred.Experience in project management methods/applicationsKnowledge & ExperienceBachelor of Science in healthcare or related field2 years healthcare experienceHealth care and performance measurement or improvement experienceMaster’s degree in healthcare or related fieldLicense & CertificationsLean Six Sigma Green/Black BeltExcel CertificationCPPSCPHQWorking ConditionsWork is divided between reviewing open electronic and paper record, on and off the patient unit. Computer data entry and report writing, attendance at meetings and data analysis.#JVRML",chi,de
16,Wavicle Data Solutions,Information Technology,4.3,Data Engineer,"Chicago, IL",$60K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=14295&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_48cf0d3f&cb=1619364353544&jobListingId=4066109718,"About Us:

Wavicle designs and delivers data and analytics solutions to reduce time, cost, and risk of companies’ data projects, improving the quality of their analytics and decisions now and into the future. As a privately-held consulting service organization with popular, name brand clients across multiple industries, Wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions.

Our 250+ local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost-effective, right-fit solutions leveraging our team’s deep business acumen and knowledge of cutting-edge data and analytics technology and frameworks.

At Wavicle, you’ll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. Employees appreciate being part of something meaningful at Wavicle. Wavicle has been recognized by industry leaders as follows:

Chicago Tribune’s Top Workplaces

Inc 500 Fastest Growing Private Companies in the US

Crain’s Fast 50 fastest growing companies in the Chicago area

Talend Expert Partner recognition

Microsoft Gold Data Platform competency

About the Role:

We are looking for a Data Engineer with strong real-life experience in Python development, including PySpark in an AWS Cloud environment.

Responsibilities:

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of sources like Hadoop, Spark, AWS Lambda, etc.

Experience with AWS Cloud on Data Integration with Apache Spark, EMR, Glue, Kafka, Kinesis and Lambda in S3, Redshift, RDS, and MongoDB/DynamoDB ecosystems.

Strong real-life experience in Python development, especially in PySpark in AWS Cloud environment.

Design, develop, test, deploy, maintain and improve data integration pipeline.

Develop pipeline objects using Apache Spark / Pyspark / Python or Scala.

Design and develop data pipeline architectures using Hadoop, Spark and related AWS Services.

Load and performance test data pipelines built using the above-mentioned technologies.

Requirements

At least 5 years of experience with AWS and Python programming, experience with Python frameworks (e.g., Django, Flask, Bottle)

Expert level knowledge of using SQL to write complex, highly-optimized queries across large volumes of data.

Working experience on ETL pipeline implementation using AWS services such as Glue, Lambda, EMR, Athena, S3, SNS, Kinesis, Data-Pipelines, Pyspark, etc.

Hands-on experience using programming language Scala, Python, R, or Java.

Expert level knowledge of using SQL to write complex, highly-optimized queries across large volumes of data.

Knowledge or experience in architectural best practices in building data lakes.

Strong problem solving and troubleshooting skills with the ability to exercise mature judgement.

Equal Opportunity Employer

Wavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.",chi,de
17,PayPal,Information Technology,4.1,"MTS 1, Data Engineer","Chicago, IL",$71K - $135K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_95fe3041&cb=1619364353544&jobListingId=4013666292,"Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 375 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.Job Description Summary: A strong data engineer with prior hands-on knowledge of Payments industry with a passion to deliver quality deliverables in a fast-paced environment with an undivided customer focusJob Description:Job Responsibilities:Build scalable systems, lead technical discussions, deliver good quality results, participate in code reviews and guide the team in engineering best practicesProvide technical leadership and contribute to the definition, development, integration, test, documentation and support across multiple platforms (Python, Hadoop, SAP, Teradata, Machine Learning)Establish a consistent project management framework and develop processes to deliver high quality software, in rapid iterations, for business partners in multiple geographiesParticipate in a team that designs, develops, troubleshoots and debugs software programs for databases, applications, tools etc.Experienced in balancing production platform stability, feature delivery and reduction of technical debt across a broad landscape of technologiesEstablish a productive and collaborative team environment to ensure there is a strong customer focus in all activities of the function at all timesExperience required:Undergraduate degree in Engineering or equivalent from a leading university10+ years experience of Data Analytics platform implementationGood team player that can collaborate with both internal and external teamsGood understanding about data processing concepts and data warehousing knowledgeMaster SQL language on top of RDBMS (Oracle/MySql)/ HiveQL/ SparkSQL/ Big QueryUnderstanding of Apache Spark/Hadoop ecosystem and the Data Analytics ecosystemStrong conceptual and creative problem-solving skillsRelentlessly resourceful and scrappyA great communicator and strong project management skillsSkills & Abilities required:Must be results focused and highly energetic to drive defined team and organizational goalsAbility to work with considerable ambiguityAbility to learn new and complex concepts quicklyGiven the growth nature of this business, individual must be pragmatic and capable of working in a fast moving and entrepreneurial environmentAnalytical with superior problem-solving skills over near and long-term planning horizonsHighly detailed with a systematic approach, sense of responsibility and strong, positive customer focusFinancial literacy to manage P&L and efficiently communicate with stakeholdersCloud experience is a plusBehaviors:Deliver Stand out Results – Delivers outcomes that make a significant business impactExecute Well – Creates clear focus, plans and prioritiesInnovate – Identifies and owns significant business improvementsEvangelize Technology - Absorbs and propagates new technologyWe're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",chi,de
18,Beam Inc.,Business Services,4.2,Data Engineer,"Chicago, IL",$75K - $99K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_96d912f2&cb=1619364353544&jobListingId=3809689244,"Beam Suntory is Crafting the Spirits that Stir the World. Rooted in two centuries of family heritage, Beam Suntory has evolved into the world's third largest leading premium spirits company ... where each employee is treated like family and trusted with legacy. With our greatest assets - our premium spirits and our people - we're driving growth through impactful marketing, innovation and an entrepreneurial spirit. Beam Suntory is a place where you can come Unleash your Spirit by making an impact each and every day.Data EngineerThe following position is open in Illinois, United States.What makes this a great opportunity?Beam Suntory is a leader in the spirits industry with a track record of profitability and growthOpportunity to help shape the Digital Technologies & Analytics initiativesGrowth potential beyond this roleRole ResponsibilitiesThis position will support the company’s Digital Technologies & Analytics initiatives by taking a senior technical role in the development of advanced analytics capabilities and innovation.Drive the implementation of the defined innovation strategy through the design and architecture for analytics platform components/services utilizing Google Cloud Platform infrastructure and provide technical expertise to deliver advanced analyticsDesign, build & operate a secure, highly-scalable, reliable platform to consume, integrate and analyze complex data using a variety of best-in-class platforms and toolsCollaborate with various global IT teams to develop Big Data reference architecture patterns for data ingestion, data processing, analytics and data science solutionsDrive innovation through developing proof-of-concept’s and prototypes to help illustrate approaches to technology and business problemsProvide strong technical skills with ability to design, architect, and get into low-level implementation detailsBe a hands-on developer and build scalable, real time, Big Data systems whilst providing a deep business understanding of CPG functions & processesProven experience in working with globally distributing agile teamsDevelop and maintain modern development & data management methodologyQualifications & ExperienceA bachelor's degree in computer science, math, physics, engineering or a related field5+ years of progressive experience in data and analytics, with at least 3 years' experience in Google cloud platformOverall, 5+ years of progressive experience working in software engineering teams (mentoring junior engineers, setting technical direction, etc.).Experience with Google Cloud Platform technology stack for Data Analytics and Big data technologies (Big Query - DWH concepts, ANSI SQL, Big Table – HBase, DataProc – Spark/Hadoop, Dataflow – Apache Beam/Scala/Python) is requiredExperience in developing the data pipeline, ETL processes, data platform, data modelling, and data governance processes in delivering end-to-end solutionsSolid foundation in design, data structures and algorithms, and strong analytical and debugging skills with customer-facing products experienceGood understanding of private and public cloud design considerations and limitations in the areas of virtualization, global infrastructure, distributed systems, load balancing, networking, massive data storage, Hadoop, MapReduce, and security.Strong programming experience in Python and ScalaExperience of using development tools like Eclipse and IntelliJExperience of using Jenkins, GitHub flow and artifact repo.Experience developing real time data streaming pipelinesDrive innovation by assessing, piloting, building DevOps/Cloud tooling and services to improve overall developer experience and productivityExpertise & experience in building large scale, cloud based and open source projects.Hands-on solution driven attitude, with ability to turn around quick insights along with delivering strategic capabilitiesMulti-tasking ability to participate in multiple complex programs at the same time in an agile environmentStrong organization and prioritization skills along with outstanding written and verbal communication skillsKnowledge of agile software development methodologyAt Beam Suntory, people are our number one priority, and we believe our people grow together in diverse and inclusive environments where their unique insights, experiences and backgrounds are valued and respected. Beam Suntory is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, military veteran status and all other characteristics, attributes or choices protected by law. All recruitment and hiring decisions are based on an applicant’s skills and experience.",chi,de
19,ELEMENTS Global Services,Business Services,4.5,Data Engineer,"Chicago, IL",$81K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_34439d29&cb=1619364353545&jobListingId=4067215364,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client’s employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the “Glocal” team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.Key responsibilities:Key member of the product team building Business Intelligence and Analytics SaaS solutions.Collaborate with business stakeholders to gather and define data and reporting requirements.End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analyticsDevelop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.Drive Web Scraping alternate data implementation and automation.Build, test, and maintain scalable and robust data and analytics stack.What we value:You hold a bachelor’s in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etcWhat we Offer:Opportunity to work in a fast-growing organization with the ability to make a quick impact.Allow your inspirational ideas to come to life in a highly creative and executional environment.Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",chi,de
20,Inspire11,Business Services,4.9,Data Engineer,"Chicago, IL",$67K - $124K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=8095&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1b20d49d&cb=1619364353545&jobListingId=3645946662,"Turn it up to 11 as a Data Engineer!

Do you want to solve some of the biggest challenges facing companies today using data and analytics? Do you want the opportunity to work with a team of incredibly intelligent, fun-loving, and collaborative individuals? Are you looking to grow and develop your skills across a variety of technologies and tools?

If you answered yes to any of those questions, then Inspire11 could be a great fit for you! We are a full services local consulting firm that is building out customized solutions to help our clients stay relevant in an ever-changing technological environment. Our project work spans across a variety of specialties from data warehousing to data science and a variety of industries.

We partner with our clients to optimize their business, and ultimately blow their minds with the solutions we're able to implement. Our team is always tackling the most difficult problems that client teams face, and are never stuck in maintenance mode.

Our team is always learning from each other and pushing the boundaries of what's possible.

You're still not sold? There's More:

Growth opportunity: We are always learning new technologies and educating our clients on what's available in the data space. You also will have the opportunity to engage in growing the team and there are ample opportunities to take ownership
Work life balance: We are respectful of people's boundaries and have unlimited time off so that our team has time to recharge and do their best work
Flexible hours: We understand that our team members have different needs and do our best to work with their schedules while accommodating client needs
Inclusive environment: We are committed to building an inclusive environment where all teammates feel comfortable and supported 

Fun! We love to keep things fun, both within our client work and at company wide events

So what do I have to do to join?

Participate in the full life-cycle of development, through definition, design, implementation, and testing
Identify data sources, provide data flow diagrams and documents source to target mapping and process
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Work with the client and consulting team to help gather requirements; understand different processes as it relates to different parts of the business and where there is overlap
Assist with report development using tools such as: Tableau, PowerBI, Qlikview
Regularly contribute to ongoing improvements in engineering process and product development
Support business decisions with ad hoc analysis as needed

I can do that! Any other skills that I need?

5+ years of experience as a data/software engineer
Strong understanding of data modeling concepts and design
Strong understanding of data warehousing technologies, ETL processes and data flow architectures and tools
Experience in Software Development Lifecycle (SDLC) utilizing the Agile approach
Organized, detailed oriented, and can manage multiple projects at the same time
Excellent communication skills
Comfortable working in fast paced environments, are able to wear many hats, and have a general fear of being bored

We believe that everyone drives change, and everyone is an owner. Nothing excites us more than having the ability to collaborate with intelligent, highly-motivated and talented people on challenging problems as we work to change the face of the digital and analytics space.",chi,de
21,Siemens,Manufacturing,4.1,Data Engineer,"Chicago, IL",$77K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=37049&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_dd0ad76c&cb=1619364353545&jobListingId=4065537258,"Data Engineer Predictive Insights Team

At

Siemens we are always challenging ourselves to build a better future. We

need the most innovative and diverse Digital Minds to develop tomorrows

reality. Find out more about the Digital world of Siemens here: www.siemens.com/careers/digitalminds

Job Description:

Siemens Digital Industries Software is looking for an

enthusiastic Data Engineer with a focus on SaaS for the Predictive Insights

& Analytics team supporting the Global Customer Support and Success Support

organization. In this role you'll be responsible for developing,

maintaining, and optimizing the processes to collect, store, process, and

integrate GCSS data. You will help to differentiate the nuggets of data from

the noise. Partnering with the data engineer, architect, and

visualization team, you will unlock new insights and predictive models with

robust visualizations. Key characteristics of a successful Data Engineer: self-starter,

enthusiastic, detail oriented, analytical and strategic thinker. The Data

Engineer is a flexible problem solver.

The Data Engineer must be able to think strategically at

scale, integrate complex data sets, work with stakeholders, and be able to

collaborate with other PI&A team members, both as a mentor and as a service

provider.

The team is situated within Global Customer Support &

Success though team members collaborate with the greater analyst community

around the organization to pursue a coordinated, cross-functional approach to

identifying new and existing data sources and analytics to drive business

results.

Job Duties:

· 

Design,

build, test, document, optimize, and deploy, ETL (Extract, Transform, Load)

packages

· 

Work

with customers, report developers, management, and architects to build new,

standardized, and scalable data delivery and analytics solutions.

· 

Design,

model, document, and implement data storage and retrieval structures such as

databases structures and unstructured data.

· 

Provide

query, code, and troubleshooting assistance to visualization team.

· 

Work

cross-functionally on technology and infrastructure migrations.

· 

Identify

new opportunities for automation or embedding algorithms into existing business

processes

· 

Seek

out relevant data sources, including new internal and external data sources

· 

Manage

analytics projects iteratively to ensure adoption of information products

· 

Develop

automated processes to cleanse and integrate datasets from disparate sources

· 

Evaluate

and help implement new analytics platforms, services, and methodologies

· 

Assist,

train, and learn from other team members

· 

Provide

ad-hoc analysis for management and innovate new information products

deliverables

· 

Additional,

related duties as required

Required Knowledge/Skills, Education, and Experience:

· 

Bachelors

Degree or higher in Data Analytics, Data Management, Data Science, Statistics,

Math, Computer Science or related disciplines (MBA desirable) or equivalent experience


5+ years of

 Database, Programing or equivalent experience with at least 3 years in a

 hands-on role.

· 

Self-starter

who prioritizes multiple projects with competing deadlines and is motivated to

promote change

· 

Broad

understanding of data infrastructure, data processing, and data integration.

· 

Ability

to work collaboratively with others in team environment and maintain trusted

relationships with business customers and leadership.

· 

Ability

to deliver repeatable, operationalized, solutions.

· 

Demonstrated

communication and presentation skills.

· 

Superior

solutions framework design capability; holistic, cross-functional thinker.

· 

Ability

to successfully navigate ambiguous environments autonomously with minimal

direction.

· 

Advanced

knowledge of T-SQL, PL/SQL

· 

Demonstrated

passion for answering business questions and improving business processes

· 

Professional

and customer focused with developed project, organization and time management

skills

· 

Familiar

with dimensional data modeling and data normalization

· 

Understanding

of data sourcing

Preferred

Knowledge/Skills, Education, and Experience:

· 

Experience

with SaaS solutions a plus

· 

Advanced

knowledge of MySQL

· 

Understanding

of data sourcing technologies: (APIs, screen-scraping, internal data

warehouses), data formats (structured, text, image, etc.), data structures

(XML, JSON, relational databases, etc.), data types, variables, mapping,

logical operations, and data profiling

Qualified Applicants must be legally authorized for

employment in the United States. Qualified Applicants will not require employer

sponsored work authorization now or in the future for employment in the United

States.

#LI-PLM #LI-JB1
Organization: Digital Industries

Company: Siemens Industry Software Inc.

Experience Level: Experienced Professional

Job Type: Full-time

Equal Employment Opportunity Statement

Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law

Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision

Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice

California residents have the right to receive additional notices about their personal information. To learn more, click here.",chi,de
22,Balyasny Asset Management,Finance,4.2,Data Engineer – Data Acquisition,"Chicago, IL",$85K - $158K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=242900&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_9d01a70b&cb=1619364353545&jobListingId=4014237355,"The Job Details are as follows:

The Data Intelligence Group (DIG) is a key part of BAM’s continued growth. Year over year, the knowledge needed to leverage data plays an increasingly important role in the firm’s core business. The analysis, services, software, and operational expertise that DIG provides are part of BAM’s competitive advantage.

Role Overview

We are looking for creative and enthusiastic Data Engineers to join our team in building the best Data Platform on the street. We’re responsible for managing the flow of data into the firm, maintaining the data lake, creating analytics-ready datasets, and building the APIs that make everything accessible to our clients. Our singular goal is to help our investment teams use data to make better investment decisions.

Our analysts and systematic trading teams rely on us to provide analytics-ready datasets. For each dataset we must consider the implications of point in time storage, optimize for our users’ access patterns, and create useful aggregations/slices. Our ideal candidate will have experience with storing, transforming, and modeling big data. In this role, you will:

Develop cloud-first data ingestion processes using Python, SQL, and SparkEngineer data models and infrastructure for a wide variety of market and alternative datasetsDesign and build services and plugins to enhance our Data Acquisition PlatformMaintain alerting systems to ensure smooth day-to-day operations for hundreds of datasetsAuthor tests to validate data quality and the stability of the platformInvestigate and defuse time-sensitive data incidentsCommunicate with data providers to onboard new datasets and troubleshoot technical issuesEvangelize best practices to our partners throughout the firmWork directly with Analysts, Quants, and Portfolio Managers to understand requirements and provide end-to-end data solutions

WHAT YOU’LL BRING

Bachelors/Masters degree in Computer Science or a related fieldStrong analytical, data, and programming skills (Python/SQL/NoSQL)3+ years of experience with at least one of Spark/Hive/Hadoop2+ years of experience orchestrating pipelines with a technology like Airflow/Luigi/Oozie/Nifi1+ years of experience with cloud technologies ( AWS / Azure / Google Cloud )Solid understanding of time series data and temporal queriesExperience with large data sets and techniques to architect them for performanceAbility to understand and contribute to our existing data system softwareAptitude for designing infrastructure, data products, and tools for Data Scientists a plusFinancial industry experience is a plusStrong oral and written communication skills, most importantly, must be a team player
",chi,de
23,Northwestern Medicine,Health Care,4,Data Engineer,"Chicago, IL",$62K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_fe13cf78&cb=1619364353545&jobListingId=4067403676,"The Data Engineer reflects the mission, vision, and values of NM, adheres to the organization’s Code of Ethics and Corporate Compliance Program, and complies with all relevant policies, procedures, guidelines and all other regulatory and accreditation standards.Working in Analytics at Northwestern Medicine, we help our clinical and administrative leadership through the development of thoughtful, highly engaging analytics products that will impact the clinical and financial areas of our health system. We do this by engaging with our customers to understand opportunities for improvement and then applying the right analytic solution to drive that improvement. Our health system looks to us to be thought-leaders in Analytics, which requires us to be analytical problem solvers by nature. We also strive to develop a deep understanding and empathy for our internal customers and communicate the value and purpose to stakeholders. Through tenacity and resilience, we will strive through ambiguity, drive impactful projects, and overcome challenges.Northwestern Medicine is looking for a data driven, business-minded, results-oriented Data Engineer to join our team. The Data Engineer uncovers insights that drive strategy and optimal decision making for the executive team and leaders across the organization. In this role, you will be charged with understanding the ‘who, what, and whys’ of our business - working cross-functionally to realize the value of NM’s data assets.Responsibilities:The Data Engineer is responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data, building analytical solutions, and administering systems to deliver information to the health system.Serves as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions.Applies knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures.Collaborates with the Architecture team in the design and execution of solutions.Ensures that new and existing data models and databases are consistent with approved data architecture standards.Provide facilitation, analysis, design, and execution of architecture solutions and ensure solutions are leveraged. Create, document, and communicate the integration approach of all the components of the solution.Define key solutions and ensure they are managed for consumption by users and across teams. Research, analyze, determine capabilities and propose solution alternatives to address specific business needs and product/service strategies.Maintain knowledge of current trends and development in the field. Actively explores emerging technologies.Independently work with business users to gather and scope requirements and recommend analytical solutions to meet business needs.Assists with ETL design and development including data analysis, source-target mapping, quality profiling, change data capture, code performance.Evaluate data quality and interpret results in a clear, concise manner.Document all programming changes and design, system modifications and their associated maintenance.Own analytics projects and be accountable for collaborating with the business to gather requirements, execute to provide analytical solutions, which exceed customer expectations.Work collaboratively with and support multi-departments efforts and projects.Mentor staff by sharing skills, experience, knowledge, and expertise on analytic tools and solutions.Serve as subject matter expert within the department.Provide training and support through the organization on the use of analytics tools.Performs other duties and functions as assigned.QualificationsRequired:Bachelor’s degree or equivalent experience in relevant fieldFive or more years of experience in a role querying, analyzing data, and/or data modeling/architectureExperience working with a variety of data warehousing models and design fundamentals (e.g. Inmom Kimball)Experience with developing and maintaining ETL / data pipeline (e.g. Microsoft SSIS, Azure Data Factory)Experience with OLAP or Tabular cube softwareExperience using SQL for data extraction, manipulation, and reportingPrevious experience working in an Agile environmentStrong knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored proceduresExperience with report writing and data visualization tools such as: Microsoft Power BI, Tableau, Crystal Reports, SSRS, etc.Preferred:Experience developing, designing and supporting applications and relational databasesExperience using a software package for statistical analysis (R, Python, etc)Previous experience working with Epic Clarity dataPrevious healthcare experience, ideally with a health system",chi,de
24,ShopRunner,Information Technology,3.7,Data Engineer,"Chicago, IL",$87K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=8095&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_8c33c0bd&cb=1619364353545&jobListingId=4043001296,"ABOUT US

We build tools for 100+ brands and retailers in the ecommerce space that help them offer free two-day shipping, same-day delivery, and product expansion into new marketplaces -- keeping them several steps ahead of the curve in a rapidly changing industry.

We are a purpose and culture driven organization that prides ourselves on connectivity, equality, diversity and inclusion. We are committed to our people as a service-oriented company as our people are at the heart of everything we do.

We are Headquartered in Chicago, with offices in New York, Conshohocken, PA (Philly area), and Krakow, Poland and we operate as a subsidiary of FedEx Services.

ABOUT THE ROLE:

As a Data Engineer at Shoprunner, you'll help power many of our data-backed solutions and manage the large scale data we ingest from our merchant partners. Data Engineering will work in collaboration with our Enterprise, Consumer, and Data Science teams to bring data models to production, power solutions for our merchant partners, and create more personalized experiences for our customers in our never-ending quest to help our shoppers and retailers connect in new ways and new applications.

ABOUT WHAT YOU'LL DO

Own the key data pipelines which enable real-time event handling, smarter personalization, and more nimble applications.
Develop frameworks to productize our machine-learning models that give our members more product choices.
Help us define and manage our big data infrastructure including Kinesis/Kafka streams, Apache Spark and Snowflake data warehouse.
Help us evolve our service architecture, embracing architecture approaches such as 12 factor, microservices, and well-formed APIs to allow our architecture to scale both internally and externally.

ABOUT WHAT WE'RE LOOKING FOR

Experience working in an Agile environment and using a VCS like Git.
Experience writing production code in Python or JVM-based systems.
Experience with data stores and technologies such as Spark, Airflow, ElasticSearch, Kinesis, Kafka, Postgres, MySQL, and Snowflake and a strong understanding of SQL.
Experience with building REST APIs to serve and consume data
Experience with building batch/streaming ELT pipelines to move and transform data.
Experience with data transformation tools and techniques and workflow management
Experience optimizing larger applications to increase speed, scalability, and extensibility.
Proven self-starter with a strong desire to learn new technologies and work independently but knows to seek help when they are blocked.

We want you to bring your whole human self to work every day. We accept you for who you are and consider everybody on an equal opportunity basis without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.",chi,de
25,Dyson,Manufacturing,2.7,Data Engineer,"Chicago, IL",$70K - $137K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=4120&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_508ad883&cb=1619364353545&jobListingId=4043479696,"Summary


 Salary:

 Starting salary will be based on experience and credentials

 Team:

 Information Technology

 Location:

 Chicago, IL, USA

About us


Data and analytics excellence at Dyson are delivered by a diverse and collaborative global community spread across Dyson locations from Bristol to Chicago, Malmesbury to Singapore. Domain-specific experts form spoke analytics teams, enabled by a central team at the hub. All teams benefit from significant recent investments in cloud technologies and tools, combined with an expansive scope and no shortage of ambition and momentum; data and analytics are recognized throughout the organization, to the highest level, as critical to all of Dyson’s strategic objectives. With a ‘one-team’ approach, the global community are on a mission to…


…evolve existing solutions to stay ahead …embed emerging solutions to capitalize on potential benefits …deliver conceptualized & future solutions to introduce net-new capability


Our Data Team: As the ‘hub’ team delivering the data, technology and community provision enabling Dyson’s global data and analytics capabilities, Global Data Services (GDS) have end-to-end responsibility for data from foundations (DQ, MDM) to management (data platforms, integrations), to value realization (analytics enablement and delivery). GDS are a multi-disciplinary, global team providing round-the-clock development and operations – including product and project management, community enablement, governance, data architecture, data engineering, data science, and analytics expertise. Involved with every aspect of Dyson’s global business - from finance to product development, manufacturing to owner experience – GDS are enjoying record-breaking investment and mandate for 2021 and beyond, seeking to deliver solutions generating impressive and tangible business value.
About the role

 As a Data Engineer you will be responsible for developing, industrializing, and optimizing Dyson's big data platform running on GCP. You will ingest new data sources, write data pipelines as code, and transform, enrich and publish data using the most efficient methods.

Working with data from across Dyson’s global data estate, you will understand the best way to serve up data at scale to a global audience of analysts. You will work closely with data architects, data scientists and data product managers on the team to ensure that we are building an integrated, performant solutions.

Ideally you will have a Software Engineering mind-set, be able to leverage CI/CD and apply critical thinking to the work you undertake. The role would suit candidates looking to make the move from working with traditional big data stacks such as Spark and Hadoop to using cloud native technologies (DataFlow, Big Query, Docker/Kubernetes, Pub/Sub, Redshift, Cloud Functions). Candidates who also have strong software development skills and wishing to make the leap to working with Data at scale will also be considered.

Responsibilities include:

Designing and building end to end Data Engineering solutions on the Google Cloud PlatformBeing a proactive member of DevOps / Agile scrum driven team; always looking for ways to tune and optimize all aspects of work delivered on the platformAligning work to both core development standards and architectural principles

About you

 Essential:


Strong programming skills in languages such as Python/Java/Scala including building, testing and releasing code into productionStrong SQL skills and experience working with relational/columnar databases (e.g. SQLServer, Postgres, Oracle, Presto, Hive, BigQuery etc…)Knowledge of data modelling techniques and integration patternsPractical experience writing data analytic pipelinesExperience integrating/interfacing with REST APIs / Web ServicesExperience handling data securelyExperience with DevOps software delivery and CI/CD processesA willingness to learn and find solutions to complex problemsResilient and comfortable with high pace change.

Desirable:

Experience migrating from on-premise data stores to cloud solutionsExperience of designing and building real/near real time solutions using streaming technologies (e.g. Dataflow/Apache Beam, Fink, Spark Streaming etc) Hands-on experience with cloud environments (GCP & AWS preferred)Building API's and apps using Python/JavaScript or an alternative languagePractical experience with traditional Big Data stacks (e.g Spark, Flink, Hbase, Flume, Impala, Hive etc)Experience with non-relational database solutions (e.g. Big Query, Big Table, MongoDB, Dynamo, HBase, Elasticsearch)Experience with AWS data pipeline, Azure data factory or Google Cloud DataflowWorking with containerization technologies (Docker, Kubernetes etc…)Experience working with data warehouse solutions including extracting and processing data using a variety of programming languages, tools and techniques (e.g. SSIS, Azure Data Factory, T-SQL, PL-SQL, Talend, Matillion, Nifi, AWS Data Pipelines)

Benefits

 At Dyson, how we reward you is linked to our high-performance culture. But it’s about more than salary and bonus. Through a package of financial, lifestyle and health benefits, we support whatever stage of life you’re in and the moments that matter.

Financial benefits:

401K with up to a 4% matchCompany paid Life Insurance and AD&DFlexible Savings Account (FSA) and Health Savings Account (HSA)

Lifestyle benefits:

Competitive Paid Time Off Benefits including Separate Holiday, Sick, and Vacation TimePre-tax Commuter Benefits (applicable areas only)Generous Child Care Leave ProgramWellness ProgramEmployee Assistance ProgramGenerous Dyson Product Discounts

Health benefits:

Multi-Level Healthcare Coverage OptionsVision & Dental CoverageCompany paid Short-Term and Long-Term Disability


Dyson is committed to fostering an inclusive and accessible environment that reflects the diversity of the community in which we live. If requested, we will provide reasonable accommodation during the recruitment process for persons with disabilities. Contact us at americas.talentacquisition@dyson.com for more information. Dyson is an Equal Opportunity Employer.

#LI-DYSON

Interview guidanceWe are following the government guidelines regarding COVID19. At this time all interviews will be conducted via video or telephone. We’re taking these precautionary measures to protect both our employee and candidate wellbeing. Our Talent Acquisition team will work with you and provide further information as appropriate.
Posted: 08 February 2021

Apply
",chi,de
26,Elements,Retail,3.3,Data Engineer,"Chicago, IL",$84K - $117K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2e0671f2&cb=1619364353545&jobListingId=4067136552,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client's employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the ""Glocal"" team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.Key responsibilities:Key member of the product team building Business Intelligence and Analytics SaaS solutions.Collaborate with business stakeholders to gather and define data and reporting requirements.End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analyticsDevelop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.Drive Web Scraping alternate data implementation and automation.Build, test, and maintain scalable and robust data and analytics stack.What we value:You hold a bachelor's in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etcWhat we Offer:Opportunity to work in a fast-growing organization with the ability to make a quick impact.Allow your inspirational ideas to come to life in a highly creative and executional environment.Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",chi,de
27,Cognizant Technology Solutions,Business Services,3.7,Data Engineer,"Chicago, IL",$62K - $80K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_d77ee685&cb=1619364353546&jobListingId=4065617103,"Cognizant Technology Solutions is seeking for ""Data Engineer"", who could join in our team of IT professionals in a permanent role. If you meet our background requirment and skilss and looking for an opportunity to be rewarded for your skills and expertise, here is the ideal opportuinty for you!""Cognizant will not sponsor H1-B or other U.S. work authorization, or lawful permanent residence (otherwise known as a ""Green Card"") for this role""Purpose:Analyzing, designing, programming and testing Clients software programs and applications. Working closely with Product Design, Business Analysis, Systems Analysis, Quality Assurance and Customer Support to assess, enhance, maintain and support software solutions to business problems. Using strong logic, computer language skills, combined with healthcare industry and practical knowledge, deliver and maintain applications and software providing comprehensive business solutions to the healthcare industry.Experience:SQL skills including object creation and query tuning.Be able to tune queries to alter the query planUnderstand indexing and partitioningBasic understanding of OLTP and OLAP database structures.Basic understanding of ETL development including both Powershell and SSIS to move and transform dataDevelopment work to load WarehouseBasic understanding of role based permissions.Basic understanding of DBA type tasks like backing up, restoring, and creating databases.Used to maintain Dev/functional server for application teamsSQL job AgentSupport production jobs for SSIS, Powershell, and TSQLApplication level experience:Visual Studio and Team Foundation Server for source control/deploymentUse source control to deploy SQL to different environments.SSMS for interaction with the SQL servers.PowershellUsed often for data movementSSISBasic understanding. No new dev is being done in SSIS currentlyExperience: Minimum of five years' related experience. Healthcare industry experience is preferred.Employee Status : Full Time EmployeeShift : Day JobTravel : NoJob Posting : Apr 22 2021About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",chi,de
28,Jumpcloud,Information Technology,3,Data Engineer,"Chicago, IL",$63K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_b797a72c&cb=1619364353546&jobListingId=4065275971,"About JumpCloudDo you enjoy solving challenging problems using the latest technologies within a great team? Is knowing your work will be highly visible and mission critical a key component for the next step in your career? At JumpCloud, we’re looking for best-in-class talent to help define the future of modern identity and device management from the ground up.JumpCloud’s mission is to Make Work Happen®, providing simple, secure access to corporate technology resources from any device, or any location. The JumpCloud Directory Platform gives IT, security operations, and DevOps a single, cloud-based solution to control and manage employee identities, their devices, and apply conditional access controls based on Zero Trust principals. JumpCloud has a global user base of more than 100,000 organizations, with over 3,000 customers including Cars.com, Grab, ClassPass, Uplight, Beyond Finance and Foursquare. JumpCloud is backed by BlackRock, General Atlantic, OpenView, and Foundry Group.What you’ll be doing:We’re looking for data engineers with a passion for building reliable big data systems to be the next members of our awesome engineering team. JumpCloud is focused on delivering cloud-based directory services via a SaaS model and as a result are trying to solve some very difficult problems around identity, authentication, security, and cloud scaling.As a data engineer on our data engineering team you’ll assist in creating and maintaining data pipelines, data lakes using big data technologies. The systems you will help build will become the backbone of the JumpCloud Data Platform.We're solving complex problems in the cloud using the latest and greatest technologies like MongoDB, Postgres, Golang, Docker, ELK Stack, Redis, etc. But wait, you haven’t used those technologies? No worries: we’re open-minded and we believe that good engineering is not technology specific.We’re looking for…1-3 years of programming experience in Golang, Python, and/or NodeJS1-3 years of experience using cloud technologies such as AWS, Azure, or GCP3-5 years of professional experience building enterprise applicationsData operations experience using tools such as Terraform, CloudFormation and/or SaltAdvanced experience working with and building RESTful APIsWillingness to learn and embrace new technologies, languages, and frameworks (we will test your skills with a take home exercise)Solid Git experienceComfortable with Linux or OSX as a desktop development environment.Database experience is a plus, including relational and non-relational databases.Strong team player that wants to win together. We are both Agile and agile, and we’re a tight-knit team that’s constantly working togetherStrong communication skills.Bonus points if you haveExperience building data pipelines and lakes in AWSPassion for learningIn accordance with the Colorado Equal Pay for Equal Work Act, the approximate annual compensation range for this role is $105,000-$150,000, including base salary and any related bonuses or commissions. JumpCloud provides comprehensive benefits, including medical, dental and vision insurance, short and long term disability, life insurance and a 401k savings plan. We have an unlimited vacation policy.Where you’ll be workingAll our roles are remote in the U.S. unless otherwise specified. Our Headquarters is in the Denver/Boulder, CO area. Once we reopen our offices you will have the opportunity to remain fully remote (in the U.S.), work from one of our office locations (CO only currently) or flex your time.Why JumpCloud?If you thrive working in a fast, SaaS-based environment and you are passionate about solving challenging technical problems, we look forward to hearing from you! JumpCloud is an incredible place to share and grow your expertise! You’ll work with amazing talent across each department who are passionate about our mission. We’re out of the box thinkers, so your unique ideas and approaches for conceiving a product and/or feature will be welcome. You’ll have a voice in the organization as you work with a seasoned executive team, a supportive board and in a proven market that our customers are excited about.Please submit your résumé and brief explanation about yourself and why you would be a good fit for JumpCloud. Please note JumpCloud is not accepting third party resumes at this time.We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",chi,de
29,Numerator,Information Technology,4.1,"Data Engineer, Data Science","Chicago, IL",$104K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_ef606100&cb=1619364353546&jobListingId=4070399804,"Numerator is a data and tech company bringing speed and scale to market research. Headquartered in Chicago, IL, Numerator has more than 2,000 employees worldwide. The company blends proprietary data with advanced technology to create unique insights for the market research industry that has been slow to change. The majority of Fortune 100 companies are Numerator clients.Job DescriptionNumerator is looking for a Data Engineer, Data Science to help us drive decision-making, find bigger opportunities and work with our established and rapidly evolving platforms. In this position, you will be responsible for taking on new initiatives to automate, enhance, maintain, and scale services in a rapidly-scaling environment.As a Data Engineer, Data Science at Numerator, you will help our team deliver data products, analytics, and models quickly and independently. The role is cross-functional by nature and is responsible for developing resilient data pipelines and infrastructure for evaluating and deploying data science models.The ideal candidate should be experienced with processing large quantities of data, building algorithms alongside software engineers, data warehouse and/or service architecture and using declarative infrastructure and Kubernetes.You will have a broad impact and exposure across Numerator as you help build out and expand our technology platforms across several software products. This is a fast-paced role with high growth, visibility, impact, and where many of the decisions for new projects will be driven by you and your team from inception through production.What you get to do!Work cross-functionally with Product, Data Science, and Engineering teams to build and/or improve data productsDeliver complex, end-to-end projects involving heavy data and statistical modeling (e.g. sampling, segmentation, classification, predictive modeling, etc.)Lead the design and development of pipelines and services integrating Data Science models into customer-facing productsSkills & RequirementsWhat you bring3+ years designing data warehouses and building data pipelines. or, in a data intensive engineering roleProficiency in one major programming language (preferably Python) and SQLExperience with data modeling, ETL design and tooling (especially Airflow), and transforming data to meet business goalsFamiliarity with the process of Machine Learning or Statistical Model DevelopmentExperience designing (or architecting) and deploying production solutions to the cloud with AWS, Azure or GCPAutonomy, versatility, intellectual curiosity, and ability to thrive in a fast-paced organizationExtra, Nice to HavesExperience with developing, deploying and maintaining back-end services, including (but not limited to) applied ML frameworks and applications (e.g. SciKit Learn, TensorFlow, etc.)Experience building tools to manage machine learning/statistical model deployment and monitor their performanceExperience with declarative infrastructure (e.g. Terraform) and Kubernetes (EKS)Experience creating integrations, managing user permissions and optimizing queries in SnowflakeExperience working with marketing insights, shopping data or in the retail industryWhat we offer More data than you could imagine to play with!An inclusive and collaborative company culture- we work in an open environment while working together to get things done, and adapt to the changing needs as they comeMarket competitive total compensation packageVolunteer time off and charitable donation matchingRegular hackathons to build your own projects and work with people across the entire companyStrong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groupsGreat benefits package including health/vision/dental, exceptional maternity leave coverage, unlimited PTO, flexible schedule, 401K/RRSPs matching and much moreIf this sounds like something you would like to be part of, we’d love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience.We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.",chi,de
30,Request Technology,Business Services,2.2,C# Full Stack Software Engineer,"Chicago, IL",$44K - $81K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1044072&s=58&guid=0000017909a313d8bd758304cb33935e&src=GD_JOB_AD&t=SR&vt=w&cs=1_b1ffacea&cb=1619364353546&jobListingId=4064627589,"Overview***We are unable to sponsor for this permanent full-time role******Position is bonus eligible***Prestigious Financial Institution is currently seeking a C# Full Stack Software Engineer. Candidate will work on the development of a global proprietary trading platform with a specialized focus on back-end systems. Candidate will work on performing certifications with customers, troubleshoot production issues, improve monitoring, issue resolution, and manage start- and end- of day position, clearing and reporting processes.Qualifications:Bachelor’s Degree, or equivalent experience, in Computer Science, Engineering or related fieldAt least three years of experience in a Software Engineering role in, preferably in a real-time trading related position required, with recent and demonstrable experience writing high performant, well tested and elegant code with C# and the .NET FrameworkPrior experience developing highly distributed and fail-safe systemsStrong commitment to Agile development methodologies and best practicesPreferred Skills:Experience with real time trading systems, knowledge of order handling and protocols such as FIX and market data processing and distributionExperience in the listed options market is a plusExperience with regulatory reporting (e.g. OATS, CAT) and market surveillance is a plusTagged as: .net developer, ajax, asp.net, bootstrap, c++ developer, CSS, full stack developer, html, ind123, j2ee, jangular, Java, javascript, jquery, k2 developer, microsoft application developer, sharepoint developer, software engineer, spring, vb.net, web developer, web services",chi,de
62,DriveCentric,Information Technology,4.3,Data Engineer I/II,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1110586&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ab62c23f&cb=1619364480972&jobListingId=1007020433909&cpc=654405A9B1E0A9F5&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-75a43a0e753158e1&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLbmhKQ1hfSlh6TVFKSXJvTEpMN1daaFhvb05YaThVZXI4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlPdG9nQ3V3ZnNQWWMyUWxTMlF4bUZ5SlJZMkUyaktaT2xqeDhiVml3S0pVZ2t5TkV0VXhpQmh0Y3ZNUnpHTXh5S0ZVWjRhNnA4MWNJRkhUV3AtZ3p5SEZyVnBoZmZRTkJ0NFJZQXA2eXlOSzMwZVN0NVVaQ2hTLW1meGxxdzBjQ3k0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVmdzWGJvdzE4UUlXWFY2S1h3SGxxN1RHYzcybGc0YkcxZEZZQ2ZIUmZycEVLNkdZaVRiQ05DdEw4SGZUVGJWc2NOX01LaV80a2NFRVk4MkJPNllDcDNMLTZBQVVURTBkSDBydFlrQ2xZUjN5dFhtdENQZGpmWmxsRGZpYkJrUzF4QVRWTGxFSnlvbkkyYmNqN2pyaV9XcTYxa01PMVNrN0ZwWUZpNmlocTB3T29DSWtHeF9pRFhGbHFnYm5waEYtdE9yODVxcEl5dDVrTDg2SHVqYzB2cEdpY0JWMmJVTHI1bkdaYXlPQUVzcHVUMElMVFY0SGNRczNrR0pPR3Z0V0hKVnI0QkNNc1R6X2p6b05DSXhQZnFoS0c5ZC0zeW1GSnZPeFY5UlZ6aFN0c3J6MlBFNms2SHpiSm85SGxFMFhhSzJsVEFTaVlWOU5TblI3QllNRWk0d1lnTUNBVkNUZi0,"Are you tired of not being challenged, not having a voice, or having to work with outdated technologies? Do you want to be a direct contributor in a company that is an innovation leader and has the awards to prove it? Do you want your fair share of the profits from a fast-growing company that’s doubling its customer base year-over-year?A Data Engineer I/II develops and performs data migration / ETL processes for store launches, investigates and fixes data issues, monitors and optimizes database performance, and assists in the administration of databases and data warehouses.Responsibilities:Write, execute, and validate DML, DDL, and DCL scripts to meet business and customer needs.Coordinate and perform data imports, data modifications, database maintenance, etc. outside of business hours, as needed.Assist Customer Support and Development by analyzing data to troubleshoot application issues.Manage SSIS packages for customer onboarding ETL processes.Onboard new customers by scrubbing data and importing from multiple data sources.Requirements:2+ years of experience writing DML and DDL, with 1+ years of hands-on experience with T-SQL.1+ years of hands-on Microsoft SQL Server 2012+ experience.Ability to balance business and technical objectives when making decisions.Ability to balance multiple assignments in a fast-paced environment.Exceptional communication, problem-solving, and analytical skills are a must.Have a positive, can-do attitude.Pluses:1+ year of scripting and managing ETL packages, with SSIS or other tools.Hands-on experience with Database Administration (SQL Server)Hands-on experience with PostgreSQL.Benefits:Competitive salaryHealth, Vision, and Dental Insurance (eligible on day 1)401K with matching up to 4%9 company holidays + 12 vacation days in first yearAmple professional growth opportunitiesJob Type: Full-timePay: $70,000.00 - $100,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insurancePaid time offVision insuranceSchedule:Monday to FridayWork Location:One locationVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:Open to applicants who do not have a college diplomaCompany's website:https://drivecentric.com/Company's Facebook page:https://www.facebook.com/DriveCentric/Work Remotely:Temporarily due to COVID-19",chi,de
63,Trexin Consulting,Business Services,4,HealthCare Data Scientist / Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1110586&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_117186ec&cb=1619364480973&jobListingId=1007011601846&cpc=6FC5BA77C9A4CD78&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-df5f51c4d44557e8&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLOWhROVA1eHJOeE1OLU02czJSckdtMHFONnNpT2xFRGI4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX2RUYjl3eFpoRlhiVVdGSFBBN1U5SHdTaFJmd3NzdjZDMGwydkF1UEhCYmlVWEUyd1F1bGp6UUxEd1hlTC15OHNtODM3dkF6MkM5NlY4bTRtRGZfaGE1TThlLUQ4bHR3LThrTVMwb2luWUc3VDBpOEZtSFlmWERMWnVkMk15eTd4NFJZQXA2eXlOSzZKeGVRZzhqQjRKMldzSV9vWW40Q2E0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVkxWMEtBLTd5aDlqRDZPdFo0RmJfanFCbUZIZnFlZHlxRXpfbm92OG1heDc1ZTF6dGJjS003QWlvWG15LVVjclhxRDZxN2NRVEdXdVNfalVLMzdLYnAxbjJVMzNfVC1qT1Fad0JVYU1BNTJMNVBsMmxYSjV6VG4wM0FLbmFSM1MzQ0VRMTFHNzFMZDR3UEpsczBkVVdnckRhM05aZ21iMTZHV2NyRkxRYUhUd3JNUUJlSHoyZ0NkVVVaN3FQaWJVdklIUm1RRWtIbi1lZS1UQ0V5ekt2aHRwdUV4c2c2QUlzazhqc3ZVdGRpWHctOFo4eHFoWlZPMVdnMXZvUjJpOEZTQnBSeXZmc0tQaUV6clEtR2lBNWZxMHNUNmhya19IT2x6VWVKcS1Qdk5EeXNCTUl3VThGeXFKd2NyZUxQemZwQ0xMeWVNQ2twWFdXeVoycnNWZm5BX05rajk3b2QxU2Q,"Founded on the principles of trust, experience, and innovation, Trexin Consulting specializes in strategy execution – the effective implementation of business strategy to achieve a specific business goal. Also referred to as applied strategy, strategy execution situations that Trexin frequently leads include: scaling capabilities for growth, optimizing operations for cost reduction, driving synergies for M&A, and recovering projects in distress. Trexin’s services are right-sized for our Clients’ needs, ranging from our “Diamond Team” service when our Clients want Trexin to own an outcome and share delivery risk, to Expert/Advisory services for senior-level guidance, to Strategic Staffing services for execution-oriented tasks and roles. Our expertise spans Healthcare, Life Sciences, Financial Services, and Products & Distribution, overlaid by multidisciplinary skills in the five capabilities essential to executing strategy: Aligned Enterprise, Program Execution, Technology, Innovation, and Analytics.Trexin Consulting is searching for a Consultant to work as a Sr Data Scientist / Sr Data Engineer with extensive experience with Artificial Intelligence and Machine Learning (ML) in the Healthcare industry for our Healthcare client located in Chicago IL. This consultant will work with Healthcare Equity programs to develop AI / ML data models.Key Areas of Responsibility: Design and implement a Healthcare Equity AI / ML and data models for identifying disparities in Healthcare.Ensure that Artificial Intelligent (AI) & Machine Learning (ML) deliverables can be productionized and integrated into existing systems and processes.Effectively interact with other Data Science personnel, IT & Technical staff, Product Owners, Data & Application Architects, and Business AnalystsWork on data analysis projects relating to Healthcare Equity models.Acquire and transform large datasets which will be used for analytics including AI and ML.Analyze and evaluate large quantities of data in relational databases and unstructured forms of data, effectively balancing quality, availability, timeliness.Leverage data engineering skills to acquire data in an effective and timely manner.Work with consultants, clients, or internal teams to prepare complex analytic data models analyses and models that address client issues and deliver significant measurable impact.Key Desired Skills, Experience and Knowledge: Understanding of how to create Healthcare Equity models10+ years of relevant hands-on big-data engineering experienceStrong background in the following:Big Data, Data Science, AI, Machine Learning and Predictive AnalyticsBusiness Intelligence (BI) Systems, Data Lakes, and Data WarehouseExperience in working with large datasets, relational databases (SQL), and distributed Data Lake systems (Databricks, Hadoop, Hive)First-hand experience with the acquisition and transformation of data from Data Warehouse(s) and Data Lake(s).Demonstrated experience with the lifecycle development process for AI and ML models.Able to serve as a liaison between other Data Scientists and technical teams to drive effective, timely solutions that fulfill both strategic and operational needs.Strong logical and analytical problem-solving skills; rigorous approach to project / program management to deliver enterprise-level projects.Experience with Python, Pandas, and scikit-learn.Cloud experience with AWS and Azure.Knowledge and familiarity with statistical techniques, data mining, and machine learning including but not limited to regression, decision trees, clustering, random forests, and generalized linear models.Experience with visualization tools/technology product or platform such as PowerBI or Tableau to analyze data and answer business questions is highly desirable.Knowledge of additional programming languages is a plus, specifically C++ or JavaIntellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes and recommend solutions.Strong interpersonal skills, team-orientation, and professional attitude.Bachelor’s degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics, or related field preferred.Experience in Healthcare with payor, claims and membership platform experience preferred.Big 4 or previous consulting experience is a plus.Trexin is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. Trexin is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Trexin are based on business needs, job requirements, and individual qualifications. Trexin strictly prohibits and does not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth, or related medical conditions), gender (including gender nonconformity and status as a transgender individual), sexual orientation, age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state, or local law.Trexin complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Trexin will reasonably accommodate qualified individuals with a disability if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. Trexin will also, where appropriate, provide reasonable accommodations for an employee's religious beliefs or practices. Trexin strictly prohibits discrimination against protected veterans, and Trexin utilizes affirmative action to recruit, hire, promote, and retain veterans.Trexin Consulting does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Trexin Consulting vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Trexin Consulting Recruiting Team and such candidate was submitted to the Trexin Consulting Recruiting Team via our Applicant Tracking System.Job Types: Full-time, ContractPay: $1.00 per yearWork Location:One location",chi,de
64,New Relic,Information Technology,4.2,Senior Software Engineer - Data Platform (Remote),"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1110586&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_104b2059&cb=1619364480972&jobListingId=1007019776214&cpc=FB7E4A1762AE5BEC&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-a247a2e7c46e3723&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMeVlzUkE4dXhTaVRiQXFTVXY0QVlDLXZhd1ZZZWFSdUQ4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOG1JYUJ1cUVaajdrT3FKWmUwTnlFb1hYYjQ3YVJfTE1fY3VFWFI4MWJEbEFqY1JxX0RUVlV1c0ZnWmtGV1N4NGdTYlgwelNwUnZHR2NFbDR1ZTRnVFFsS0RBcU1jb3lDT2hTeW83bFZnUlhEX1JQNks1RzdDSDhBa0lTc0owZzV4YnR0ZzNlSFNURE45cVhyOWlwZ2ZIR3lBT2RRVk1vYTdTcmhHQXpYOGkweHdFWjFwemxiajlKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSSXpfQ2c2TnhHQmZsLVBVUlNZM2dTSUdhU3NjY1JyNTFjR0QzV3RBRFNpY3VZZ2xjdzFZYjZNbVZCenV5MGlwRVBILUVqdktLVGhJWmNYY05BbWdHT2ZHTGJzZ1VQWjJuaWM1dmMzRlFISG1QOUFobUV5Ylk3NlZZOGpKLWNGV2ZnLVBwUFNZbnhmeUkyb1VaenhWbzFPM3E2STVvVlM2bFQ0TDFabjFKcjQ5aHpVS2xjU2IydGJIa1NmOUw5UU9mU0M2Y2h2QUphSDFiQUlVdEpSZlBxNFlsaDBvY2NOSWU4ZzgyWExxM1F4WmlVcUM3Wk9zY2d0WHdsWEVnd3oweWh1UVRhcDMzYUdscW80MGlWSkZhdFVhZVQ3NkxZem5ySjN1eU5HbTNiQ1pwSkhSbzRuaFRiYzNrR0pPR3Z0V0hLOFVXc0FVZlQtdFNmeTExbWlDTUdR,"Please note that visa sponsorship is not available for this position
We are excited to consider a remote engineer for this role! Remote team members will be expected to work out of their home office.
Your Opportunity
The Data Platform group at New Relic builds the foundation for all of our products: data ingest, storage, and query. As an engineer on the Ingest Team, you’ll get a chance to work on some of the fastest and highest throughput microservices in the company. You will be developing automation for and operating horizontally-scalable systems at the core of New Relic's business.
We own our software from top to bottom and are directly responsible for its quality and reliability. Each member of the team shares our pager rotation and will occasionally be on-call to respond to system failures; so we prioritize work that keeps the lights on and the pager quiet, in addition to the work that powers all of our new products and streams of data. The opportunity to work from a remote office may be available depending on your location in the US.
As with most development teams, communication is of central importance to us. We mostly work independently, but we pair-program on occasion, and we do a lot of collaborative design. We value the ability to think creatively and work collaboratively to tackle hard problems in a resource-efficient manner.
What You’ll Do
Automate and operate our 10+ microservices for high-speed ingest and high availability.
Participate in the team’s on-call rotation for our services, ensuring that we’re meeting our SLAs.
Give and receive feedback on Pull Requests as well as writing and commenting on designs.
Your Qualifications
Must-have:
3+ years experience in software development.
An understanding of Computer Science.
Fluency in Java.
Ability to go deep on the command-line and fix things when they’re broken.
Nice-to-have:
5+ years of experience developing and operating within a 24x7 SaaS business.
Experience working in AWS.
Experience in high-throughput software development.
Our architecture is built around Apache Kafka, and every single one of our services interacts with Kafka in one way or another. Experience with Kafka or other data pipeline technologies is a plus, but not required.
Experience on distributed teams. An ability to work well asynchronously and share your thoughts in writing will be a big asset.
Please note that visa sponsorship is not available for this position
About Us
New Relic (NYSE: NEWR) is a cloud-based observability platform that gives developers, engineers, operations, and management a clear view of what’s happening in today’s complex software environments. So they can find and fix problems faster, and deliver delightful experiences for their customers. That's why the world’s best engineering teams rely on New Relic to visualize, analyze, and troubleshoot their software. It’s the simplest, most powerful cloud-based observability platform, built to create more perfect software. All from one place.
Founded in 2008, we’re a global company passionate about building a culture where all employees feel a deep sense of belonging, where every ‘Relic’ can bring their whole self to work and feel supported and empowered to thrive. We’re consistently recognized as a distinguished employer and are committed to building world-class products and an award-winning culture. For more information, visit newrelic.com.
Our Hiring Process
New Relic takes seriously our stewardship of the data of our thousands of customers worldwide. In compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification.
We will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance. https://sfgov.org/olse/sites/default/files/FCO%20poster2020.pdf
Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic.
New Relic is an equal opportunity employer. We eagerly seek a diverse applicant pool and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities (or disability), age, sexual orientation, veteran status, or any other characteristic protected by law.
Interested in the details of our privacy policy? Read more here: https://newrelic.com/termsandconditions/applicant-privacy-policy",chi,de
65,Northwestern Medicine,Health Care,4,Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_285fd956&cb=1619364480973&jobListingId=1007015966960&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-4cb83d31e6196a09,"The Data Engineer reflects the mission, vision, and values of NM, adheres to the organization’s Code of Ethics and Corporate Compliance Program, and complies with all relevant policies, procedures, guidelines and all other regulatory and accreditation standards.
Working in Analytics at Northwestern Medicine, we help our clinical and administrative leadership through the development of thoughtful, highly engaging analytics products that will impact the clinical and financial areas of our health system. We do this by engaging with our customers to understand opportunities for improvement and then applying the right analytic solution to drive that improvement. Our health system looks to us to be thought-leaders in Analytics, which requires us to be analytical problem solvers by nature. We also strive to develop a deep understanding and empathy for our internal customers and communicate the value and purpose to stakeholders. Through tenacity and resilience, we will strive through ambiguity, drive impactful projects, and overcome challenges.
Northwestern Medicine is looking for a data driven, business-minded, results-oriented Data Engineer to join our team. The Data Engineer uncovers insights that drive strategy and optimal decision making for the executive team and leaders across the organization. In this role, you will be charged with understanding the ‘who, what, and whys’ of our business - working cross-functionally to realize the value of NM’s data assets.
Responsibilities:
The Data Engineer is responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data, building analytical solutions, and administering systems to deliver information to the health system.
Serves as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions.
Applies knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures.
Collaborates with the Architecture team in the design and execution of solutions.
Ensures that new and existing data models and databases are consistent with approved data architecture standards.
Provide facilitation, analysis, design, and execution of architecture solutions and ensure solutions are leveraged. Create, document, and communicate the integration approach of all the components of the solution.
Define key solutions and ensure they are managed for consumption by users and across teams. Research, analyze, determine capabilities and propose solution alternatives to address specific business needs and product/service strategies.
Maintain knowledge of current trends and development in the field. Actively explores emerging technologies.
Independently work with business users to gather and scope requirements and recommend analytical solutions to meet business needs.
Assists with ETL design and development including data analysis, source-target mapping, quality profiling, change data capture, code performance.
Evaluate data quality and interpret results in a clear, concise manner.
Document all programming changes and design, system modifications and their associated maintenance.
Own analytics projects and be accountable for collaborating with the business to gather requirements, execute to provide analytical solutions, which exceed customer expectations.
Work collaboratively with and support multi-departments efforts and projects.
Mentor staff by sharing skills, experience, knowledge, and expertise on analytic tools and solutions.
Serve as subject matter expert within the department.
Provide training and support through the organization on the use of analytics tools.
Performs other duties and functions as assigned.

Qualifications
Required:
Bachelor’s degree or equivalent experience in relevant field
Five or more years of experience in a role querying, analyzing data, and/or data modeling/architecture
Experience working with a variety of data warehousing models and design fundamentals (e.g. Inmom Kimball)
Experience with developing and maintaining ETL / data pipeline (e.g. Microsoft SSIS, Azure Data Factory)
Experience with OLAP or Tabular cube software
Experience using SQL for data extraction, manipulation, and reporting
Previous experience working in an Agile environment
Strong knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures
Experience with report writing and data visualization tools such as: Microsoft Power BI, Tableau, Crystal Reports, SSRS, etc.
Preferred:
Experience developing, designing and supporting applications and relational databases
Experience using a software package for statistical analysis (R, Python, etc)
Previous experience working with Epic Clarity data
Previous healthcare experience, ideally with a health system",chi,de
66,Balyasny,Finance,4.2,Data Engineer – Webscraping,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_495a4aee&cb=1619364480973&jobListingId=1007020956965&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-80e20530120b7e82,"The Data Intelligence Group (DIG) is a key part of BAM’s continued growth. Year over year, the knowledge needed to leverage data plays an increasingly important role in the firm’s core business. The analysis, services, software, and operational expertise that DIG provides are part of BAM’s competitive advantage.
Role Overview
We are looking for a creative and meticulous developer to join our Webscraping team. The data we provide drives investment decisions across the firm and we work hard to make sure it’s timely and accurate. The optimal candidate will be strongly self-motivated with the ability to work and solve problems independently. In your role, you will:
Collaborate with analysts to understand and anticipate requirements
Design, implement, and maintain webscrapes for a wide variety of alternative datasets
Author tests to validate data availability and integrity
Maintain alerting systems to ensure smooth day-to-day operations
Investigate and defuse time-sensitive data incidents
Minimum Qualifications
Bachelors/Masters degree in Computer Science or a related field
1-3 years web development experience (Python/SQL/HTML/CSS/HTTP)
Linux experience (Windows experience a plus)
Excellent verbal and written communication skills
Preferred Qualifications
Aptitude for designing infrastructure, data products, and tools for Data Scientists
Familiarity with scraping and common scraping tools (Selenium, scrapy, Fiddler, Postman, xpath)
Experience containerizing workloads with Docker (Kubernetes a plus)
Experience with build automation (Jenkins, TeamCity)
Experience with AWS",chi,de
67,"JPMorgan Chase Bank, N.A.",Finance,3.8,Senior Cloud Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_5652cc63&cb=1619364480974&jobListingId=1007022416881&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-73c4c910f9b51db3,"As an experienced member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.
Graphite Strategic Payments team is seeking a Senior Data Engineer / Architect. You will be a part of our mission to modernize payment flows and environments to drive organizational growth. You will play a part in this modernization by working to implement cloud strategies, modernizing legacy systems, and coding for the future of distributed data processing. As you grow in technical expertise in one or more areas of specialization as well as leadership capabilities, your role within the team will provide opportunities to advance.
This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
Expertise in application, data, and infrastructure architecture disciplines
Advanced knowledge of architecture and design across all systems
Proficiency in multiple modern programming languages
Knowledge of industry-wide technology trends and best practices
Keen understanding of financial control and budget management
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Excellent knowledge of data pipeline development to dive innovation within data engineering using low latency, high frequency technologies
Extensive experience in developing complex relational (Oracle) as well as NoSQL (Cassandra) data stores, or distributed databases in a medium to large company
Hands-on experience in software engineering in Java web services and API development
Deep understanding of Java, Spring Core, Junit, Jmeter and DevOps
Prior experience in a technical role supporting and designing data layer on VSIs, preferably private or public cloud (AWS, GCP)
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
Equal Opportunity Employer/Disability/Veterans",chi,de
68,Numerator,Information Technology,4.1,"Data Engineer, Data Science","Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_3f3a3ffd&cb=1619364480974&jobListingId=1007021318605&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-03f5e758326b4fe7,"Numerator is looking for a Data Engineer, Data Science to help us drive decision-making, find bigger opportunities and work with our established and rapidly evolving platforms. In this position, you will be responsible for taking on new initiatives to automate, enhance, maintain, and scale services in a rapidly-scaling environment.

As a Data Engineer, Data Science at Numerator, you will help our team deliver data products, analytics, and models quickly and independently. The role is cross-functional by nature and is responsible for developing resilient data pipelines and infrastructure for evaluating and deploying data science models.

The ideal candidate should be experienced with processing large quantities of data, building algorithms alongside software engineers, data warehouse and/or service architecture and using declarative infrastructure and Kubernetes.

You will have a broad impact and exposure across Numerator as you help build out and expand our technology platforms across several software products. This is a fast-paced role with high growth, visibility, impact, and where many of the decisions for new projects will be driven by you and your team from inception through production.

What you get to do!

Work cross-functionally with Product, Data Science, and Engineering teams to build and/or improve data products
Deliver complex, end-to-end projects involving heavy data and statistical modeling (e.g. sampling, segmentation, classification, predictive modeling, etc.)
Lead the design and development of pipelines and services integrating Data Science models into customer-facing products

What you bring

3+ years designing data warehouses and building data pipelines. or, in a data intensive engineering role
Proficiency in one major programming language (preferably Python) and SQL
Experience with data modeling, ETL design and tooling (especially Airflow), and transforming data to meet business goals
Familiarity with the process of Machine Learning or Statistical Model Development
Experience designing (or architecting) and deploying production solutions to the cloud with AWS, Azure or GCP
Autonomy, versatility, intellectual curiosity, and ability to thrive in a fast-paced organization

Extra, Nice to Haves

Experience with developing, deploying and maintaining back-end services, including (but not limited to) applied ML frameworks and applications (e.g. SciKit Learn, TensorFlow, etc.)
Experience building tools to manage machine learning/statistical model deployment and monitor their performance
Experience with declarative infrastructure (e.g. Terraform) and Kubernetes (EKS)
Experience creating integrations, managing user permissions and optimizing queries in Snowflake
Experience working with marketing insights, shopping data or in the retail industry

What we offer

More data than you could imagine to play with!
An inclusive and collaborative company culture- we work in an open environment while working together to get things done, and adapt to the changing needs as they come
Market competitive total compensation package
Volunteer time off and charitable donation matching
Regular hackathons to build your own projects and work with people across the entire company
Strong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groups
Great benefits package including health/vision/dental, exceptional maternity leave coverage, unlimited PTO, flexible schedule, 401K/RRSPs matching and much more

If this sounds like something you would like to be part of, we’d love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience.

We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.",chi,de
69,Siemens,Manufacturing,4.1,Data Engineer 248200,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_c4238b64&cb=1619364480974&jobListingId=1007012525400&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-3e2663090c6a04b9,"Data Engineer – Predictive Insights Team
At Siemens we are always challenging ourselves to build a better future. We need the most innovative and diverse Digital Minds to develop tomorrow’s reality. Find out more about the Digital world of Siemens here: www.siemens.com/careers/digitalminds
Job Description:
Siemens Digital Industries Software is looking for an enthusiastic Data Engineer with a focus on SaaS for the Predictive Insights & Analytics team supporting the Global Customer Support and Success Support organization. In this role you'll be responsible for developing, maintaining, and optimizing the processes to collect, store, process, and integrate GCSS data. You will help to differentiate the nuggets of data from the noise. Partnering with the data engineer, architect, and visualization team, you will unlock new insights and predictive models with robust visualizations. Key characteristics of a successful Data Engineer: self-starter, enthusiastic, detail oriented, analytical and strategic thinker. The Data Engineer is a flexible problem solver.
The Data Engineer must be able to think strategically at scale, integrate complex data sets, work with stakeholders, and be able to collaborate with other PI&A team members, both as a mentor and as a service provider.
The team is situated within Global Customer Support & Success though team members collaborate with the greater analyst community around the organization to pursue a coordinated, cross-functional approach to identifying new and existing data sources and analytics to drive business results.
Job Duties:Design, build, test, document, optimize, and deploy, ETL (Extract, Transform, Load) packagesWork with customers, report developers, management, and architects to build new, standardized, and scalable data delivery and analytics solutions.Design, model, document, and implement data storage and retrieval structures such as databases structures and unstructured data.Provide query, code, and troubleshooting assistance to visualization team.Work cross-functionally on technology and infrastructure migrations.Identify new opportunities for automation or embedding algorithms into existing business processesSeek out relevant data sources, including new internal and external data sourcesManage analytics projects iteratively to ensure adoption of information productsDevelop automated processes to cleanse and integrate datasets from disparate sourcesEvaluate and help implement new analytics platforms, services, and methodologiesAssist, train, and learn from other team membersProvide ad-hoc analysis for management and innovate new “information products” deliverablesAdditional, related duties as required
Required Knowledge/Skills, Education, and Experience:Bachelor’s Degree or higher in Data Analytics, Data Management, Data Science, Statistics, Math, Computer Science or related disciplines (MBA desirable) or equivalent experience
5+ years of Database, Programing or equivalent experience with at least 3 years in a hands-on role.
Self-starter who prioritizes multiple projects with competing deadlines and is motivated to promote changeBroad understanding of data infrastructure, data processing, and data integration.Ability to work collaboratively with others in team environment and maintain trusted relationships with business customers and leadership.Ability to deliver repeatable, operationalized, solutions.Demonstrated communication and presentation skills.Superior solutions framework design capability; holistic, cross-functional thinker.Ability to successfully navigate ambiguous environments autonomously with minimal direction.Advanced knowledge of T-SQL, PL/SQLDemonstrated passion for answering business questions and improving business processesProfessional and customer focused with developed project, organization and time management skillsFamiliar with dimensional data modeling and data normalizationUnderstanding of data sourcing
Preferred Knowledge/Skills, Education, and Experience:Experience with SaaS solutions a plusAdvanced knowledge of MySQLUnderstanding of data sourcing technologies: (APIs, screen-scraping, internal data warehouses), data formats (structured, text, image, etc.), data structures (XML, JSON, relational databases, etc.), data types, variables, mapping, logical operations, and data profiling
Qualified Applicants must be legally authorized for employment in the United States. Qualified Applicants will not require employer sponsored work authorization now or in the future for employment in the United States.
#LI-PLM #LI-JB1
Organization: Digital Industries
Company: Siemens Industry Software Inc.
Experience Level: Experienced Professional
Job Type: Full-time
Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",chi,de
70,ELEMENTS Global Services,Business Services,4.5,Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_357d5ed2&cb=1619364480975&jobListingId=1007015752143&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-6af4fbef1d7f1e4b,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client’s employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the “Glocal” team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.


A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.
Key responsibilities:

Key member of the product team building Business Intelligence and Analytics SaaS solutions.
Collaborate with business stakeholders to gather and define data and reporting requirements.
End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analytics
Develop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.
Drive Web Scraping alternate data implementation and automation.
Build, test, and maintain scalable and robust data and analytics stack.


What we value:

You hold a bachelor’s in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.
You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.
You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.
You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).
You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.
You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etc


What we Offer:

Opportunity to work in a fast-growing organization with the ability to make a quick impact.
Allow your inspirational ideas to come to life in a highly creative and executional environment.
Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.
The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.

This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.


Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",chi,de
71,TeamBradley,Business Services,4.5,Data Integration Engineer,"Glendale Heights, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1110586&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_351000a3&cb=1619364480976&jobListingId=1007021049067&cpc=9908D8D4413DBB8A&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-e1d328db4858ccc1&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKMGRjYWdINGZIbFZMcTJvaV81ZGY4UUVwN3pYWVZaWFA4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX2RUYjl3eFpoRlhiVVdGSFBBN1U5SHdTaFJmd3NzdjZDMGwydkF1UEhCYmlVWEUyd1F1bGp6NzRiSGdkQVp5aUlzamEybjNwY2Y5V1JXVnRTWG5RS1BwclltcEx1cWtwa25aSEVPOTlJUFRRYXVMQkFqOXNzUHd2b3gwbmc1NzdGNFJZQXA2eXlOS19RMEpEWG9adFRQcDdYelBlVEFNVks0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVk5WVzgyLVBZMUszeWFTWXBBd2NRNmhycW1ReFBBQ2JhRXpfbm92OG1heDZtY21hT1pxR2Y0TDZuZXRxbERELWNxRDZxN2NRVEdXdVNfalVLMzdLYnAxbjJVMzNfVC1qT1Fad0JVYU1BNTJMNVBsMmxYSjV6VG4wM0FLbmFSM1MzQ0VRMTFHNzFMZDR3UEpsczBkVVdnckRhM05aZ21iMTZHV2NyRkxRYUhUd3JNUUJlSHoyZ0NkVVVaN3FQaWJVdnM2Z0VoS2g1NWlIN1FPMkVqbkhJUzN6WUVNTjNMbkFGTU5CSkpBVzdZbkJnRFlNNk44MmU4MnFqalNKVWtWcTFScDVQdm90ak9ldlFEUzhSMFY5STBNM2tHSk9HdnRXSDBZMmVFbEdJOHc0NGN0VkpVR0U0M2FKd2NyZUxQemZwQ0xMeWVNQ2twWFdXeVoycnNWZm5BX05rajk3b2QxU2Q,"LOCATION: Greater Chicagoland area near Glendale Heights, ILOVERVIEW OF THE POSITION: Our client, a leader in industrial distribution is growing and they are turning to TeamBradley to help them. They continue to grow and provide opportunities for development and advancement. They are currently looking for a Data Integration Engineer. This person will collaborate with others to understand the enterprise objectives and build capabilities in BI, Reporting and Analytics applications.RESPONSIBILITIES: · Perform Power BI solutions development activity· Develop and support backend data model and source data analysis· Support data integration· Develop and support EDI· Develop roadmaps for Analytics and Advance analytics· Stay up to date on all technology trendsSKILLS: · Bachelor’s degree with 5+ years of relevant experience and 2+ years of Integration / ETL· ETL techniques and concepts experience· Data modeling experience· 3+ years of Microsoft application experience· Relational databases, including SQL Server Database Management Systems experience· Experience working in a large organizationWHEN RESPONDING TO THIS OPPORTUNITY:  Resumes without the required technical skills and experience will not be considered. Although a strong desire for a certain type of position is a credit to your goal, experience is necessary. Our client is not considering sponsorship at this time and is not open to relocation expenses.ID#13386: Data Integration EngineerJob Type: Full-timeBenefits:Dental insuranceHealth insurancePaid time offSchedule:Monday to FridayEducation:Bachelor's (Preferred)Work Location:One locationCompany's website:teambradley.com",chi,de
72,Intone Networks,Information Technology,4.4,Data Center Storage Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_838f68ee&cb=1619364480975&jobListingId=1007011779401&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-5b6f67819f0ee8cd,"We are in need of two Data Center Storage Engineers to start immediately. Candidates should have strong VxRail experience. Start date: Immediate Job Description: 2.1.4 Data Center Storage Engineer 2.1.4.1 Principal accountabilities • • Engineer, design, implement, upgrade, harden, and manage customer SAN/NAS environments. • • Troubleshooting storage and networking issues as it concerns storage. • • Gathering requirements and providing technical planning and documentation to meet future storage needs on a project by project basis. • • Provide for data backup, restoration and redundancy in line with customer requirements. • • Perform work on Cisco SAN Fabrics, Brocade SAN Fabrics, and EMC SAN/NAS storage technologies. 2.1.4.2 Qualification and experience • • 5 years storage experience. • • Experience with EMC storage solutions. • • Experience documenting technical solutions utilizing Microsoft Vizio. • • Understanding of NFS, iSCSI, CIFS, S3, and FC storage protocols.",chi,de
73,AHEAD,Retail,2.7,Associate Data Center Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_7a2a3952&cb=1619364480975&jobListingId=1007011969874&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-5587e7bf8510f929,"AHEAD builds platforms for digital business. By weaving together advances in cloud infrastructure, automation and analytics, and software delivery, we help enterprises deliver on the promise of digital transformation.
AHEAD is looking to hire a cohort of Associate Data Center Engineers be a part of our LAUNCH Program – AHEAD’s two-year early career development program.

As a Data Center Engineer in LAUNCH, you will be put through a 3-month rotation within our Data Center practice. This rotation will focus on Networking, Virtualization and Storage providing you with basic technical knowledge, certifications, and shadowing opportunities. Upon completion of this rotation, you will be placed into either the Virtualization or Storage team where you’ll continue through the remainder of the Launch Program.

LAUNCH is built on a foundation of technical training, certifications, and shadowing, but you’ll also develop the key soft skills necessary to be successful at AHEAD. If you’re ready to begin an exciting career in IT Consulting, LAUNCH is where you should be!
Qualifications/Requirements
Bachelor’s Degree in a technical discipline
Prior intern, co-op, or research experience in IT, software, or relevant field a plus
Working knowledge of Data Center a plus
Willingness to travel to support client projects and shadowing opportunities (50+ % of the time)
Existing permanent U.S. work authorization is required
Desired Characteristics
Drive and determination
Passion for technology and innovation
Collaborative and inclusive
Critical thinking
Excellent communication skills
Why should you join AHEAD?
The culture and people here are amazing. Through our daily work and internal groups like Moving Women AHEAD and RISE AHEAD, we value and benefit from diversity of people, ideas, experience, and everything in between.
We’ve got an awesome technical playground. We fuel growth by stacking our office with top-notch technologies in a multi-million dollar lab and by sponsoring certifications and credentials for continued learning.
We understand that you have a life outside of work. That’s why we offer unlimited paid time off, paid company holidays, and the ability for you to manage your work schedule as needed.
Why Ahead?
Transparent management
Work alongside and collaborate with industry experts
Investment in training & development
Incentives for certifications
Ability to make an immediate impact
Unlimited PTO
Outstanding lab",chi,de
74,Northwestern Memorial Healthcare,Health Care,4,"Data Engineer - Enterprise Data Warehouse - Full-Time, Days","Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_5e2bb1ea&cb=1619364480975&jobListingId=1007014979168&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-974160d6a95f683a,"Company Description
At Northwestern Medicine, every patient interaction makes a difference in cultivating a positive workplace. This patient-first approach is what sets us apart as a leader in the healthcare industry. As an integral part of our team, you'll have the opportunity to join our quest for better healthcare, no matter where you work within the Northwestern Medicine system. At Northwestern Medicine, we pride ourselves on providing competitive benefits: from tuition reimbursement and loan forgiveness to 401(k) matching and lifecycle benefits, we take care of our employees. Ready to join our quest for better?

Job Description
The Data Engineer reflects the mission, vision, and values of NM, adheres to the organization’s Code of Ethics and Corporate Compliance Program, and complies with all relevant policies, procedures, guidelines and all other regulatory and accreditation standards.
Working in Analytics at Northwestern Medicine, we help our clinical and administrative leadership through the development of thoughtful, highly engaging analytics products that will impact the clinical and financial areas of our health system. We do this by engaging with our customers to understand opportunities for improvement and then applying the right analytic solution to drive that improvement. Our health system looks to us to be thought-leaders in Analytics, which requires us to be analytical problem solvers by nature. We also strive to develop a deep understanding and empathy for our internal customers and communicate the value and purpose to stakeholders. Through tenacity and resilience, we will strive through ambiguity, drive impactful projects, and overcome challenges.
Northwestern Medicine is looking for a data driven, business-minded, results-oriented Data Engineer to join our team. The Data Engineer uncovers insights that drive strategy and optimal decision making for the executive team and leaders across the organization. In this role, you will be charged with understanding the ‘who, what, and whys’ of our business - working cross-functionally to realize the value of NM’s data assets.
Responsibilities:
The Data Engineer is responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data, building analytical solutions, and administering systems to deliver information to the health system.
Serves as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions.
Applies knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures.
Collaborates with the Architecture team in the design and execution of solutions.
Ensures that new and existing data models and databases are consistent with approved data architecture standards.
Provide facilitation, analysis, design, and execution of architecture solutions and ensure solutions are leveraged. Create, document, and communicate the integration approach of all the components of the solution.
Define key solutions and ensure they are managed for consumption by users and across teams. Research, analyze, determine capabilities and propose solution alternatives to address specific business needs and product/service strategies.
Maintain knowledge of current trends and development in the field. Actively explores emerging technologies.
Independently work with business users to gather and scope requirements and recommend analytical solutions to meet business needs.
Assists with ETL design and development including data analysis, source-target mapping, quality profiling, change data capture, code performance.
Evaluate data quality and interpret results in a clear, concise manner.
Document all programming changes and design, system modifications and their associated maintenance.
Own analytics projects and be accountable for collaborating with the business to gather requirements, execute to provide analytical solutions, which exceed customer expectations.
Work collaboratively with and support multi-departments efforts and projects.
Mentor staff by sharing skills, experience, knowledge, and expertise on analytic tools and solutions.
Serve as subject matter expert within the department.
Provide training and support through the organization on the use of analytics tools.
Performs other duties and functions as assigned.

Qualifications
Required:
Bachelor’s degree or equivalent experience in relevant field
Five or more years of experience in a role querying, analyzing data, and/or data modeling/architecture
Experience working with a variety of data warehousing models and design fundamentals (e.g. Inmom Kimball)
Experience with developing and maintaining ETL / data pipeline (e.g. Microsoft SSIS, Azure Data Factory)
Experience with OLAP or Tabular cube software
Experience using SQL for data extraction, manipulation, and reporting
Previous experience working in an Agile environment
Strong knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures
Experience with report writing and data visualization tools such as: Microsoft Power BI, Tableau, Crystal Reports, SSRS, etc.
Preferred:
Experience developing, designing and supporting applications and relational databases
Experience using a software package for statistical analysis (R, Python, etc)
Previous experience working with Epic Clarity data
Previous healthcare experience, ideally with a health system
Additional Information
Northwestern Medicine is an affirmative action/equal opportunity employer and does not discriminate in hiring or employment on the basis of age, sex, race, color, religion, national origin, gender identity, veteran status, disability, sexual orientation or any other protected status.",chi,de
75,Deloitte,Accounting & Legal,3.9,Data Engineer - Experience Management,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_eda7de2c&cb=1619364480976&jobListingId=1007018023696&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-f3deea7cc8673059,"Locations: New York, NY | Greensboro, NC | Chicago, IL | Raleigh, Durham, Chapel-Hill, Charlotte, NC
Deloitte Digital offers services that enable client solutions using digital technologies, including the Web, Mobile, Social Networking, Digital Strategy, Digital Content and Digital ERP. The Digital Web team works with clients to advise, design, implement and deploy eCommerce and Portal solutions.
Our eCommerce capabilities provide transactional solutions related to online marketing, sales and service; for both Direct-To-Consumer and Business-to-Business.
Our Portal capabilities provide intranet and internet solutions focused on content presentment and transaction capabilities for both internal enterprise as well as customer facing purposes.
Work you'll do
As a Data Engineer, you'll perform the technical implementation of customer data platforms (CDPs) and serve as a key player as it relates to data management.
Your responsibilities will include:

Interface with clients to gather requirements, map solutions, and make recommendations
Lead customer project conference calls or interface with project manager
Create technical specifications to drive development of the solution
Deliver technical specifications documents for customer review
Design custom development solutions that meet customer requirements
Progress through full development lifecycle for custom solution
Deploy new solutions to production environments
Maintain and support new and existing solutions and frameworks
Innovate on new ideas to solve customer needs and assist to market internally new solutions
Provide project estimates and timelines to drive new business
Partnership and collaboration with sales and other internal teams
Teaming with engagement managers to communicate project status, risk and issues to clients as appropriate
Engaging cloud solution engineers and other domain-specific SMEs (Adobe, Salesforce, Oracle, Google and similar) to support platform implementation as needed
Coordinating Testing/SIT/UAT activities as required by project scope and team structure
Unify disparate data sources in initial phase of engagements
Vet, type check, transform data sources before consumption by data scientists
Build automation between engagements to ease the above, in collaboration with our product engineers


The team
Advertising, Marketing & Commerce
Our Advertising, Marketing & Commerce team focuses on delivering marketing and growth objectives aligned with our clients' brand values for measurable business growth. We do this by creating content, communications, and experiences that engage and inspire their customers to act. We implement and operate the technology platforms that enable personalized content, commerce and marketing user-centric experiences. In doing so, we transform our clients' marketing and engagement operations into modern, data-driven, creatively focused organizations. Our team brings deep experience in creative and digital marketing capabilities, many from our Digital Studios.
We serve our clients through the following types of work:

Cross-channel customer engagement strategy, design and development (web, mobile, social, physical)
eCommerce strategy, implementation and operations
Marketing Content and digital asset management solutions
Marketing Technology and Advertising Technology solutions
Marketing analytics implementation and operations
Advertising campaign ideation, development and execution
Acquisition and engagement campaign ideation, development and execution
Agile based, design-thinking, user-centric, empirical projects that accelerate results


Qualifications
Required:
3+ years experience in ETL development using Big Data Technologies
3+ years experience in building large-scale data processing projects using cloud technologies
3+ years experience with data modeling and tuning of relational as well as NoSQL datastores
Experience with Programming and Scripting Languages (.NET, Python, Powershell, Java, Batch, Bash and similar)
Industry experience as a data engineer or related specialty (software engineer, application developer)
Experience building/operating highly scalable, fault tolerant, distributed systems for extraction, ingestion and processing of large data sets
Experience with software engineering best-practices, including but not limited to version control, CICD, automated unit testing
Experience using cloud-native tools and design patterns
Degree in computer science, engineering, or relevant industry experience
Excellent interpersonal skills and the ability to articulate complex technology concepts with technical and non-technical individuals
Ability to approach a technical solution to solve for challenges from a business perspective
Understanding and experience working with customer centric data and how to define uses for this data to enable business goals
Understanding of the full SDLC process
Travel up to 25% (while up to 25% of travel is a requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice)
Limited immigration sponsorship may be available
Preferred:
Experience and knowledge with marketing cloud solutions
Experience and knowledge with web analytics or digital marketing
Experience working with public cloud offerings (AWS, Azure, Google Cloud Platform, and similar)
GCP - (Cloud Functions, Composer, SQL, Storage, Dataproc, Datastore, Kubernetes, Big Query, Stackdriver, Pub/Sub)
AWS - (Lambda, Glue, Data Pipeline, Redshift, Aurora, Athena/Spectrum, S3/Glacier, Fargate, Cloud Watch, Kinesis)
Azure - (Functions, Batch, Blob Storage, Data Warehouse, Data Factory, Containers, Monitor, Service Bus)Experience and knowledge with data science, ML/AI, R, or Jupyter
Experience and knowledge with data science, ML/AI, R, or Jupyter
Experience and knowledge with customer data platforms or demand side platforms
Experience as an enterprise technical or engineer consultant
Experience using C#, Java or Python
Experience with Martech/Adtech tools and how to integrate technologies into the data management solution. (Adobe, Salesforce, Oracle, Google, and similar)",chi,de
76,Chowbus,Information Technology,3.5,Senior Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_9cd3a999&cb=1619364480976&jobListingId=1007018560463&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-38819510013e831c,"Chowbus is a fast growing, well-funded food startup headquartered here in Chicago on a mission to help diners to discover new and exquisite dishes, and to give traditional mom and pop restaurants a fighting chance to succeed without compromising who they truly are. By building a super app, our goal is to be the one stop shop for everything related to food.

As we continue to grow, we are looking for a Senior Data Engineer to join our team and help build Chowbus' next generation data warehouse, data marts, real-time intelligence, and state-of-the-art data-driven logistics solutions.


Responsibilities include:

Design and model Chowbus' data warehouse and business/domain specific data marts
Design and build ETL pipelines and efficient ETL jobs, ingesting data from multiple sources, and transforming raw data into consumable data assets
Ensure high data quality through testing automation
Help design, build, maintain a robust data platform for batch and realtime integration
Manage and provide technical guidance/mentorship to team members
Analyze data to measure impacts of data schemas and use it to iterate on improvements


We are excited if you have...

Excellent knowledge of SQL, data warehouse modeling and data design patterns
5-8 years experience with Python or other general purpose programming languages
Hands-on experience with Spark and/or other big data tools for batch processing
Exposure within Amazon AWS, Snowflake, Databricks or other cloud / data platforms
Background in designing / building complex, interdependent ETL pipelines
A Bachelor's or Master's degree, preferably in a computer or data discipline

Even Better:

Experience with Real-time streaming technologies like Spark Streaming
Knowledge of event instrumentation / event hub technologies like Kinesis, Kafka
Exposure to Data Science and Machine Learning


Chowbus is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.",chi,de
77,Cognizant Technology Solutions,Business Services,3.7,Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_a2ce8a53&cb=1619364480977&jobListingId=1007012394960&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-aedb84e106749b46,"Cognizant Technology Solutions is seeking for ""Data Engineer"", who could join in our team of IT professionals in a permanent role. If you meet our background requirment and skilss and looking for an opportunity to be rewarded for your skills and expertise, here is the ideal opportuinty for you!

""Cognizant will not sponsor H1-B or other U.S. work authorization, or lawful permanent residence (otherwise known as a ""Green Card"") for this role""

Purpose:
Analyzing, designing, programming and testing Clients software programs and applications. Working closely with Product Design, Business Analysis, Systems Analysis, Quality Assurance and Customer Support to assess, enhance, maintain and support software solutions to business problems. Using strong logic, computer language skills, combined with healthcare industry and practical knowledge, deliver and maintain applications and software providing comprehensive business solutions to the healthcare industry.

Experience:
SQL skills including object creation and query tuning.

Be able to tune queries to alter the query plan

Understand indexing and partitioning

Basic understanding of OLTP and OLAP database structures.

Basic understanding of ETL development including both Powershell and SSIS to move and transform data

Development work to load Warehouse

Basic understanding of role based permissions.

Basic understanding of DBA type tasks like backing up, restoring, and creating databases.

Used to maintain Dev/functional server for application teams

SQL job Agent

Support production jobs for SSIS, Powershell, and TSQL

Application level experience:
Visual Studio and Team Foundation Server for source control/deployment

Use source control to deploy SQL to different environments.

SSMS for interaction with the SQL servers.

Powershell

Used often for data movement

SSIS

Basic understanding. No new dev is being done in SSIS currently

Experience: Minimum of five years' related experience. Healthcare industry experience is preferred.
Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Apr 22 2021

About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.
Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.
If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",chi,de
78,"JPMorgan Chase Bank, N.A.",Finance,3.8,Java/Scala Software Engineer - Data Engineering,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_ce330d22&cb=1619364480977&jobListingId=1007022121722&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-af61fdf8fe3b6adb,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.
You will join the Data Engineering team (part of the Engineering and Architecture organization in the Corporate and Investment Bank) and be responsible for delivering solutions to our clients in CIB technology, QR and Data Analytics. We are engineering cutting edge solutions in meta-data & data to model, track and deliver Data in Place and Data in Motion solutions. Our work facilitates data modelling, lineage & transporting data at scale on Cloud technologies, capturing Models & APIs in our Model Repository and building automation and tooling to control and evolve them. As part of Engineering & Architecture we are at the forefront of defining & driving adoption of the latest technology and best practice throughout the CIB.
Your role is to work with our users, developers and DevOps teams to gather requirements, design, implement & support our platform. Your knowledge of Java and/or Scala, OOP and/or functional programming, continuous delivery & testing will help our team meet our client's requirements. You will work on challenging projects ranging from delivering Cloud based micro-services, meta-programming, DSL & interpreter design to delivery of components to integrate with SQL / NoSQL DBs, Kafka & Spark. You will work as part of a global and diverse team, with clients across the globe.
This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
Advanced knowledge of application, data, and infrastructure architecture disciplines
Understanding of architecture and design across all systems
Working proficiency in developmental toolsets
Knowledge of industry-wide technology trends and best practices
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Proficiency in one or more modern programming languages
Understanding of software skills such as business analysis, development, maintenance, and software improvement
Experience in one or more general purpose programming languages and web technologies: Java, Spring Framework, REST API, cloud, microservice
Experience with development and build tools (or similar): Intellij/Eclipse, Maven, Gradle, Bitbucket/Git/Gitflow, Sprint Boot, MVC, Spring Cloud
Scala / functional programming experience preferred
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
Equal Opportunity Employer/Disability/Veterans",chi,de
79,Deloitte,Accounting & Legal,3.9,eDiscovery Complex Analytics Data Engineer - Senior Consultant,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_e27cb1b2&cb=1619364480977&jobListingId=1007018023620&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-e7767ab3d2f0dbb5,"e-Discovery Complex Analytics - Data Engineer

Deloitte Transactions and Business Analytics LLP advises clients on managing business controversy and conflict, executing deals, and maintaining regulatory compliance. We provide services to companies throughout their lifecycle from purchasing a company to investigating potential fraud.
Work You'll Do

Identify appropriate software, custom scripts, or in-house development to solve specific issues.
Evaluate, develop, and test custom scripts to address issues utilized as short term solutions.
Ability to retrieve data within or across multiple environments to identify anomalies or define the scope of an issue.
Escalate when challenges are encountered that alter the work plan.
Provide clear and concise updates & ad-hoc reports to Project Managers which may be delivered directly to a client.

The Team
In 2008, Deloitte Transactions and Business Analytics LLP (DTBA) opened a new facility in Nashville, TN for e-discovery and computer forensics work. DTBA's E-Discovery Solutions Center (""EDSC"") continues to increase the capacity, quality, and efficiency of DTBA' s e-file processing by utilizing state-of-the-art technology in a dedicated environment. We are looking for dedicated individuals to join DTBA's Analytic & Forensic Technology practice and help drive the success of the EDSC.
Qualifications:

Bachelor's degree
Education or experience analyzing business problems, transactional data, or unstructured data.
Strong (2+ years) SQL development (DML and DDL), Stored Procedure authorship, and SQL optimization are a must and mandatory for consideration for this position.
Helpful to have software engineering experience or 2+ years of application support, development, maintenance of relational database technologies.
Knowledge of common e-Discovery tools is a plus (i.e. Concordance, Relativity, Ringtail, IPRO, Recommind, or Clearwell)
Scripting experience with C#, Perl, Python, Batch file creation, Microsoft Access, Visual Basic is a plus.
Hands on experience with both traditional (boolean and key word search) as well as concept-based search tools and technologies is a plus.
Experience in handling multiple concurrent complex activities within a technical environment
Ability to identify project issues and escalate in a timely manner.
Excellent verbal and written communication skills with both internal staff and clients.
Strong analytical and problem solving skills
Limited immigration sponsorship may be available",chi,de
80,"JPMorgan Chase Bank, N.A.",Finance,3.8,Senior Python Software Engineer - Data Engineering,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_c8fd7a22&cb=1619364480977&jobListingId=1007022121832&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-9a107d56ee1fb9da,"As an experienced member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.
As a developer you will join the Data Engineering team (part of the Engineering and Architecture organization in the Corporate and Investment Bank). You will be responsible for delivering solutions to our clients in CIB technology, QR and Data Analytics. We are engineering cutting edge solutions in meta-data & data to model, track and deliver Data in Place and Data in Motion solutions. Our work facilitates data modelling, lineage & transporting data at scale on Cloud technologies, capturing Models & APIs in our Model Repository and building automation and tooling to control and evolve them. As part of Engineering & Architecture we are at the forefront of defining & driving adoption of the latest technology and best practice throughout the CIB.
Your role is to work with our users, developers and DevOps teams to gather requirements, design, implement & support our platform. Your deep knowledge of Python, continuous delivery & testing will help our team meet our client's requirements. You will work on challenging projects ranging from delivering Cloud based micro-services, meta-programming, DSL & interpreter design to delivery of components to integrate with SQL / NoSQL DBs, Kafka & Spark. You will work as part of a global and diverse team, with clients across the globe.
This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
10+ years hands on experience in design, coding, testing and debuggins kills in Python
Advanced knowledge of application, data, and infrastructure architecture disciplines
Understanding of architecture and design across all systems
Working proficiency in developmental toolsets
Knowledge of industry-wide technology trends and best practices
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Proficiency in one or more modern programming languages
Understanding of software skills such as business analysis, development, maintenance, and software improvement
Knowledge of computer science fundamentals such as data structures and algorithms
Hands-on experience of building distributed system with micro-services or server-less
Hands-on experience of SQL and NoSQL databases
Working with Agile, Lean and Continuous Delivery best practice
Good working knowledge of Spark, Hadoop and Kafka is preferred
Familiarity with Docker, Kubernetes, functional programming, and Scala is preferred
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
Equal Opportunity Employer/Disability/Veterans",chi,de
81,Sinai Health System,Health Care,2.9,DATA ENGINEER FEATURED,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_bcc173b9&cb=1619364480978&jobListingId=1007012029142&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-8040bf089b755f81,"Job Overview
We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Knowledge, Skills, Abilities, and other Characteristics:

Qualifications:
5+ years of experience in a Data Engineer role, who has attained a Master’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Industry-recognized certifications in data engineering, data architecture, informatics, machine learning, SQL
Experience with health care data, claim data, EMR systems (Meditech preferred), X.12 data formats, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with Microsoft and AWS cloud services: Azure, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with statistical programming languages: R, Stata, SAS, etc.
Experience with architectural concepts and schemas: TOGAF, MITA, Star schema, etc.
Skilled in problem-solving with strong attention to detail.
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.
Excellent follow-up skills paired with the ability to multi-task and determine root causes.
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.
Strong response time to phone calls, emails and customer requests.
Adhere to department policies and standards.
Ability to work independently under minimal supervision in stressful situations and meet deadlines.
Ability to prioritize, plan, and organize tasks based upon user requirements.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
MINIMUM WORK EXPERIENCE:
Bachelors Degree, 5 years of relevant experience including leading projects or 8 years of relevant experience including leading projects and developing teams .

REQUIRED LICENSES, CERTIFICATES, REGISTRATIONS:
MCSE or equivalent is strongly desired but not required",chi,de
82,KPMG,Business Services,3.9,"Manager, Snowflake Data Engineer","Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_d97e992d&cb=1619364480978&jobListingId=1007013524711&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-dae9f67d2b8f1491,"Historically, the travel requirement for this position has ranged from 80-100%. The safety and well-being of our people continues to be the top priority, and our decisions around travel are informed by government COVID-19 response directives, recommendations from leading health authorities, and guidance from a number of infectious disease experts. For now, all KPMG business travel, international and domestic, is currently restricted to client-essential sales/delivery activity only. At some point in the future and with the safety of people as the critical factor, the travel requirement will likely increase, possibly to previous levels, but KPMG is committed to balancing client requirements with new delivery capabilities.
The KPMG Advisory practice is currently our fastest growing practice. We are seeing tremendous client demand, and looking forward we don't anticipate that slowing down. In this ever-changing market environment, our professionals must be adaptable and thrive in a collaborative, team-driven culture. At KPMG, our people are our number one priority. With a wealth of learning and career development opportunities, a world-class training facility and leading market tools, we make sure our people continue to grow both professionally and personally. If you're looking for a firm with a strong team connection where you can be your whole self, have an impact, advance your skills, deepen your experiences, and have the flexibility and access to constantly find new areas of inspiration and expand your capabilities, then consider a career in Advisory.
KPMG is currently seeking a Manager in Digital Lighthouse for our Consulting practice.
Responsibilities:
Manage and lead technical design and development activities for implementation of large-scale data solutions in Snowflake to support multiple use cases (transformation, reporting and analytics, data monetization, etc.)
Lead design and development of technology and data architectures to support client solutions leveraging best practices for cloud data warehouse migrations
Capture and translate business and technical requirements, perform hypothesis-driven consulting and lead project management and client relationship development
Translate advanced business data, integration and analytics problems into technical approaches that yield actionable recommendations, across multiple, diverse domains; communicate results and educate others through design and build of insightful visualizations, reports and presentations
Exhibit strong knowledge of the Snowflake ecosystem and can clearly articulate the value proposition of cloud modernization/transformation to a wide range of stakeholders
Qualifications:
Minimum five years of recent experience as a cloud data lake/warehouse architect, designer or developer
Bachelor's degree in Engineering, Information Technology, Computer Science or a related field from an accredited college/university
Experience in leading projects relating to cloud modernization, data migration, data warehousing – experience with cloud-based data platforms (i.e., Snowflake)
Experience driving technical workshops with technical and business clients to derive value added services and implementations
Hands-on working knowledge of topics such as data security, messaging patterns, ELT, Data wrangling and cloud computing and proficiency in data integration/EAI and DB technologies, sophisticated analytics tools, programming languages or visualization platforms
Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future and travel as needed
KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.",chi,de
83,CapTech Consulting,Information Technology,3.9,Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_8072cef2&cb=1619364480978&jobListingId=1007017306742&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-a59f3fad13e23e8b,"Company Description
CapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.
As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.

Job Description
CapTech Data Engineers enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Distributed Data Engineers are focused on delivering data engineering solutions using non-Cloud Specific Tools in a distributed computing tech stack. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients.
Specific responsibilities for the Data Engineer – Distributed Systems position include:
Developing data pipelines and other data products using on-premises Hadoop clusters, hybrid infrastructure, Snowflake, Databricks, or MPP systems
Advising clients on specific technologies and methodologies for utilizing resources to efficiently ingest and process data quickly
Utilizing your skills in engineering best practices to solve complex data problems
Collaborating with end users, development staff, and business analysts to ensure that prospective data architecture plans maximize the value of client data across the organization.
Articulating architectural differences between solution methods and the advantages/disadvantages of each

Qualifications
Preferred Qualifications
Typical experience for successful candidates includes:
Experience delivering solutions on Hadoop or other distributed processing system (Snowflake, Databricks, or MPP)
Ability to think strategically and relate architectural decisions/recommendations to business needs and client culture
Experience in the design and implementation of data architecture solutions
A wide range of production database experience, usually including substantial SQL expertise, database administration, and scripting data pipelines
Ability to assess and utilize traditional and modern architectural components required based on business needs.
A demonstrable ability to deliver production data pipelines and other data products. This could be through hands on experience, degrees, certifications, bootcamps, or other learning.
Skills
Successful candidates usually have demonstrable experience with technologies in some of these categories:
Languages: SQL, Python, Java, R, C# / C++ / C
Database: Hive, Snowflake, Teradata, Presto, Vertica, Netezza
DevOps: git, docker, subversion, Kubernetes, Jenkins, CA, Dollar Universe
Additional Technologies: Hadoop, Databricks, Spark, Kafka
Popular Certifications: Hadoop certification from Hortonworks / Cloudera, MapR, IBM; database certification from Snowflake or Teradata; Databricks certification

Additional Information
We provide challenging and impactful opportunities in our client work and internal teams, while keeping individual interests in mind. We want everyone at CapTech to be able to envision a lifelong career here, which is why we offer a variety of career paths based on your skills and passions. As a CapTecher, you will experience exciting, and rewarding roles that help you grow and make a difference, while having fun along the way.
At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance-based bonus opportunities
Single and Family Health Insurance plans, including Dental and Vision coverage
Short-Term and Long-Term Disability Insurance
Matching 401(k)
Competitive Paid Time Off
Paid Maternity Leave and Family Bonding
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.
At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.
Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements).
CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.
#LI-AB1",chi,de
84,Elements,Retail,3.3,Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f5d6334d&cb=1619364480978&jobListingId=1007015504042&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-9e061e2cad61ea11,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client's employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the ""Glocal"" team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.


A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.
Key responsibilities:

Key member of the product team building Business Intelligence and Analytics SaaS solutions.
Collaborate with business stakeholders to gather and define data and reporting requirements.
End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analytics
Develop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.
Drive Web Scraping alternate data implementation and automation.
Build, test, and maintain scalable and robust data and analytics stack.


What we value:

You hold a bachelor's in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.
You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.
You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.
You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).
You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.
You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etc


What we Offer:

Opportunity to work in a fast-growing organization with the ability to make a quick impact.
Allow your inspirational ideas to come to life in a highly creative and executional environment.
Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.
The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.

This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.


Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",chi,de
85,CapTech Consulting,Information Technology,3.9,Data Engineer - Cloud,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_8181a03e&cb=1619364480978&jobListingId=1007012654605&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-61c81bb09eea3425,"Company Description
CapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.
As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.

Job Description
CapTech Data Engineering consultants enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Cloud Data Engineers leverage the client’s cloud infrastructure to deliver this value today and to scale for the future. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients.
Specific responsibilities for the Data Engineer – Cloud position include:
Developing data pipelines and other data products using Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP)
Advising clients on specific technologies and methodologies for utilizing cloud resources to efficiently ingest and process data quickly
Utilizing your skills in engineering best practices to solve complex data problems
Collaborating with end users, development staff, and business analysts to ensure that prospective data architecture plans maximize the value of client data across the organization.
Articulating architectural differences between solution methods and the advantages/disadvantages of each

Qualifications
Qualifications :
Typical experience for successful candidates includes:
Experience delivering solutions on a major cloud platform
Ability to think strategically and relate architectural decisions/recommendations to business needs and client culture
Experience in the design and implementation of data architecture solutions
A wide range of production database experience, usually including substantial SQL expertise, database administration, and scripting data pipelines
Ability to assess and utilize traditional and modern architectural components required based on business needs.
A demonstrable ability to deliver production data pipelines and other data products. This could be hands on experience, degree, certification, bootcamp, or other learning.
Skills:
Successful candidates usually have demonstrable experience with technologies in some of these categories:
Languages: SQL, Python, Java, R, C# / C++ / C
Database: SQL Server, PostgreSQL, Snowflake, Redshift, Aurora, Presto, BigQuery, Oracle
DevOps: git, docker, subversion, Kubernetes, Jenkins
Additional Technologies: Spark, Databricks, Kafka, Kinesis, Hadoop, Lambda, EMR
Popular Certifications: AWS Cloud Practitioner, Microsoft Azure Data Fundamentals, Google Associate Cloud Engineer

Additional Information
We provide challenging and impactful opportunities in our client work and internal teams, while keeping individual interests in mind. We want everyone at CapTech to be able to envision a lifelong career here, which is why we offer a variety of career paths based on your skills and passions. As a CapTecher, you will experience exciting, and rewarding roles that help you grow and make a difference, while having fun along the way.
At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance-based bonus opportunities
Single and Family Health Insurance plans, including Dental and Vision coverage
Short-Term and Long-Term Disability Insurance
Matching 401(k)
Competitive Paid Time Off
Paid Maternity Leave and Family Bonding
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.
At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.
Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements).
CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.
#LI-AB1",chi,de
86,Integral Ad Science,Information Technology,3.5,"Senior Software Engineer, Big Data","Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_c9145631&cb=1619364480978&jobListingId=1007021215888&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-37b39e80e59ac7f2,"Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for a Sr. Software Engineer to join our Core Data Engineering team. If you are excited by technology that has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day; and evaluate thousands of data-points in real-time all while responding in just a few milliseconds, then IAS is the place for you!

What you'll get to do:

Work on Big Data technologies such as Hadoop, MapReduce, Kafka, Spark and MPP columnar databases
Design, code and maintain components aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming, batch ETL and RESTful API's
Mentor junior team members

You should apply if you have most of this:

5+ years of recent hands-on Java experience
Regular use of collections, multi-threading, JVM memory model, etc.
Great understanding of designing for performance, scalability, and reliability
In-depth understanding of algorithms, scalability and various tradeoffs in a Big Data setting
Proficiency with object oriented programming concepts
Experience with Hadoop MapReduce, Spark, Pig
Interpersonal and communication skills

Bonus points:

Good knowledge of Linux command line tools
Solid understanding of database fundamentals, good knowledge of SQL
Exposure to messaging frameworks like Kafka or RabbitMQ
Experience with Spark streaming or Flink
Experience with AWS big data technologies (s3, emr, glue, etc)
If you are a solid backend Java developer looking to leap into and learn Big Data, we will consider you!

About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",chi,de
87,Exelon Corporation,"Oil, Gas, Energy & Utilities",4.1,Sr Engineer (Asset Data Quality Engineer),"Oakbrook Terrace, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_95ec213c&cb=1619364480978&jobListingId=1007017558534&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-7d9b540462b01360,"Description
At Exelon, we've got a place for you!


Join the nation's leading competitive energy provider, with one of the largest electricity generation portfolios and retail customer bases in the country. You will be part of a family of companies that strives for the highest standards of power generation, competitive energy sales, and energy delivery. Our team of outstanding professionals is focused on performance, thought leadership, innovation, and the power of ideas that come from a diverse and inclusive workforce.


Exelon will provide you the tools and resources you need to design, build and enhance a successful career. We are also dedicated to motivating the success of our employees through competitive base salary, incentives, and health and retirement benefits.


Join Exelon and share your passion at a forward-thinking Fortune 100 company. Establish yourself in a place where you can truly shine and create a brighter, more sustainable tomorrow. Energize your career at Exelon!


Role Overview

Develops and/or leads teams in studies, plans, criteria, specifications, calculations, evaluations, design documents, performance assessments, integrated systems analysis, cost estimates, budgets, associated with the planning, design, licensing, construction, commissioning, operation, and maintenance of Exelon’s electric generation, transmission, distribution, gas and telecommunication facilities/systems. Provides consultation and recommendations to the Company within and to other business units and/or customers as a result of studying company or customer-owned systems, processes, equipment, vehicles or facilities. Reviews financial data from budget and actual costs of projects. Provides technical expertise to strategic, legislative and operational decisions. Participates in creating, updating, and applying internal/industry standards and technology in a specialized area of expertise. Trains and mentors others.


Position may be required to work extended hours, including 24 x 7 coverage during storms or other energy delivery emergencies.


Key Areas of Responsibility
Leads and performs assignments in specialized areas requiring extensive engineering expertise. Requiring maintaining state of the art engineering credential in the specialized technical area.
Leads and performs engineering tasks and projects associated with a critical or analytical engineering project or a small number of complex projects that require specialized knowledge in many areas, may include field testing troubleshooting, and peer review.
Evaluates, develops, implements and leads projects that have significant financial and operational impact, may also develop initial commissioning plans. Plans, writes and performs tasks for documentation deliverables and projects
Participates in department planning, through field/site walkdowns, attend meetings/conference calls, provide budget recommendations and monitor performance for the accomplishment of committed results.
Performs assignments while acting independently, and may lead multi-discipline teams, may include providing direct oversight of contractors.
Serves as an expert in specialized area.
Acts as an expert witness or provide expert opinions as required.
Provides recommendations to management and implements action plans to improve performance and cost effectiveness.
Provides detailed technical training, mentorship, peer review, and/or guidance to others.
Participates in technical and industry societies and committees to enhance knowledge of new technologies or issues in areas of company interest, make recommendations for business decisions regarding strategy for new technologies and/or engineering techniques and tools.
Qualifications
Education and/or Experience Qualifications
Bachelor of Science degree in Engineering or Licensed Professional Engineer
Ability to analyze and interpret complex electrical and mechanical systems
Knowledge and ability to apply problem solving approaches and engineering theory
Knowledge of engineering designs, principles and practices
Eight or more years of professional engineering experience
Thorough knowledge and experience in unique areas of engineering expertise
Detailed knowledge of applicable standards, codes methods, and practices unique to areas of expertise
Ability to apply advanced engineering principles to identify and resolve complex issues
Minimum of three related career experiences (i.e., changes in technical job responsibilities, which may or may not include a change in department) OR
Lead Member of a recognized industry committee OR
Professional Engineer’s License, advanced technical degree, MBA or Project Management Certification

Preferred Qualifications
Graduate degree or Graduate level work in Engineering, Business Administration or Project Management Certification
Licensed Professional Engineer
Strong teamwork, interpersonal skills and the ability to communicate with all management levels
Strong written and oral communication skills
A working knowledge of analysis software packages such as CYMDIST, PSS\E, Python, PSCAD, MATLAB, etc.
Ability to analyze industry wide trends and implement enhancements
A working knowledge of GIS and Asset management software packages such as TED CEGIS, Asset Suite 8 etc.
Ability to collect, analyze and summarize large sets of asset data, understand industry wide trends and implement enhancements
Strong teamwork, interpersonal skills and the ability to communicate with all management and craft levels
Strong understanding and practice of a culture of electric utility safety
Strong written and oral communication skills
Background in electric utility Engineering, New Business, or applicable field roles
Legally licensed driver

Exelon is proud to be an equal opportunity employer and employees or applicants will receive consideration for employment without regard to: age, color, disability, gender, national origin, race, religion, sexual orientation, gender identity, protected veteran status, or any other classification protected by federal, state, or local law.

VEVRAA Federal Contractor

EEO is the Law Poster",chi,de
88,Zoro Tools,Retail,3.5,"Sr. Data Engineer, Zoro","Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_f33f92da&cb=1619364480978&jobListingId=1007016999849&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-07a116a8aa06b2d5,"Company Summary:
Zoro.com is an eCommerce company that sells business supplies, equipment, and tools—but we’re much more than just a website. We’re a team of people who win and lose together (we prefer winning!). Since 2011, Zoro has been working hard to make it easy for our customers to purchase everything they need to make their businesses go. Zoro currently offers over 6 million products, fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time, recently surpassing 400 team members and reaching annual revenue of over $500 million. Add to that our award-winning culture—we were named a Great Place to Work for 2020-21, among other accolades—and we think Zoro is a pretty amazing place to work and grow.

Primary Function:
Imagine what you could help us achieve as a Senior Data Engineer!
The Senior Data Engineer will collaborate within Data Engineering and with other IT groups, business partners and external service providers, to play a key role in building, maintaining and supporting our new analytics platform, the “Zoro Data Platform (ZDP)”. S/he will also provide direction to, and oversee various service providers and junior engineers’ activities.

Job Responsibilities Include:
Primary responsibility for Zoro Data Platform (ZDP):
Data model ongoing design & development
Conceptual, logical and physical design (database, ODS, aggregates, etc.)
Database administration
Capacity analysis & management
MDM Lead
Identify key domains that’d benefit from an MDM approach (e.g. Product, Customer), along with best data sources & necessary attributes, and integrate into the ZDP
Define governance strategy with associated roles & responsibilities (e.g. Data Steward, Quality Specialist)
Define & implement Policies & SOPs
Monitor operations, develop and report quality metrics to key stakeholders
Data Pipeline development:
Participate in Requirements Gathering: work with key business partner groups (e.g. Product Mgt) and other Data Engineering personnel to understand department-level data requirements for the ZDP
Design Data Pipelines: work with other Data Engineering personnel on an overall design for flowing data from various internal and external sources into the ZDP
Build Data Pipelines: leverage standard toolset and develop ETL/ELT code to move data from various internal and external sources into the ZDP
Support Data Quality Program: work with Data QA Engineer to identify automated QA checks and associated monitoring & alerting to ensure ZDP maintains consistently high quality data
Support Operations: triage alerts channeled to you and remediate as necessary
Technical Documentation: leverage templates provided and create clear, simple and comprehensive documentation for your development
Key contributor to defining, implementing and supporting:
Data Services
Data Dictionary
Tool Standards
Best Practices
Data Lineage
User Training
Define Best Practices and Guidelines for other Data Engineering team members
Lead the team in developing new technical skills necessary for cloud-native data engineering platform
Explores new tech
Shares and documents learnings
Productionalizes proof of concepts

Skills & Responsibilities:
Expert-level data modeler (back-end and semantic layer)
Expert-level ETL/ELT designer/developer
Strong database administration and operations experience & proficiency
Strong SQL
Structured & unstructured data expertise
Cloud environment development & operations experience (e.g. Google Cloud Platform/GCP experience a plus)
Excellent verbal and written communications
Strong team player
Working knowledge of eCommerce data a plus
Prior experience with Git, Terraform, GCP Deployment Manager, CICD, Docker, Kubernetes, Apache Airflow, Apache Beam, Apache Spark experience is a plus

Success Criteria:
Expert knowledge of data modeling concepts and data relationships
Advanced Analytical Thinking and Problem Solving skills
Solid experience in architecture, advanced reporting and dashboards
Strong SQL skills and experience with performance tuning are required
“Get it done” attitude with a high degree of autonomy, ownership and responsibility
Superior Communication and Business-Technical Interaction skills

To qualify, you must possess the following skills:
Bachelor’s degree in computer science, management information systems, or a related discipline
10+ years hands-on data warehouse-data modeling experience
10+ years hands-on database admin/ops experience
10+ years hands-on ETL/ELT design/development experience
Key resource on team(s) that have delivered successful enterprise-level analytics platforms

Final note:
We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective.

Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.",chi,de
89,Envision LLC,Business Services,4.5,Geospatial Software Engineer-Data Warehousing -Remote,United States,$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1110586&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_14436444&cb=1619364480979&jobListingId=1007016342650&cpc=3BA4CE39D5B5DEF5&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-f893b9bd4bdac3e6&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKb01yOGo3MFVmMXRObHZBTEJ1V1hoUl85YTBOSm1qajc4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOVpHdmcxR25WdHdWVWo4ck5wS2hpclFzYlJIUE5hdE8xM3RoR0hGYlhvZy0tdnVWZUdiRTFzamEyQ09QYWJlX1pvREJQTWdnV0tGYm1BSXVMNFpMWE5Bckc5bFktYmZ5SncyVHd4VGE3N2NwdnNLSExuTTg0anI1aFB6c0t3QW1SNFJZQXA2eXlOSzlWemNRNXA4UEd5T2ktMnJRQlpkUU80c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVkxWMEtBLTd5aDlnR0FrU1Joa0FzaVdGUVJCVTN3dWlFZjN3TXJtV1lNb21CcmxPR3FKUFBXUmV4NnFfczRNamk3bUJyMjgwVktIMEJHTFNXdklGVEkxbFRJd0hfaGVBcDB6US1jRlhRc1FPQ3hiYjZsbE9ZNTJVVUdNLS1HcDNNSXlnZWRfVk5DdjctU2VpQkNOVVNNa0djQVZHakFPZGlBUTZhZlloTVhoY2tSWkdVNzByR0VrSGIxYkcxMnJVYVRWbDZzMW1PR2RKYkFJVXRKUmZQcTRZbGgwb2NjTkllOGc4MlhMcTNReFppVXFDN1pPc2NndFh3bFhFZ3d6MHlodVFUYXAzM2FHbHFvNDBpVkpGYXRVYWVUNzZMWXpucjhUWVg3NGNqNEc0X1Z0aHBZbS1nMGhLRzlkLTN5bUZKNDNRek9nYWZUQktJMjB5ai03cGFndw,"Software Engineer- Geospatial Data Warehousing, Remote
No C2C, must be out W2 employee
Will consider sponsorship for exceptional candidates

Minimum Required Qualifications:
BSc degree in Computer Science or relevant job experience.
Minimum of 2-year experience with Python, Java, Go, or similar development languages.
Extensive knowledge in different programming or scripting languages like Go, Scala, Java, Javascript, SQL, Bash, Python, R.
Experience developing HTTP APIs that serve up data in a cloud environment.
Ability to build and maintain workflows and applications in modern cloud architecture, e.g. AWS, Google Cloud, etc.
Proven experience working with ETL concepts of data integration, consolidation, enrichment, and aggregation. Design, build and support stable, scalable data pipelines or ETL processes that cleanse, structure and integrate big data sets from multiple data sources and provision to integrated systems and Business Intelligence reporting.
Experience working with PostgreSQL/PostGIS.
Proven success utilizing Docker to build and deploy within a CI/CD Environment, e.g. Argo.
Experience with code versioning and dependency management systems such as GitHub, SVT, and Maven.
Proficient working in a Command Line Interface system e.g. Docker, K8s, AWS CLI, GCloud, Argo, psql, SSH

Desirable qualifications:
MSc in Computer Science or related field.
Demonstrated knowledge of open-source geospatial solutions like GeoServer, GeoTrellis, GeoMesa.
Proven experience (2 years) with distributed systems, e.g. Kubernetes, Spark, distributed databases, grid computing.
Experience with stream processing, e.g. Kafka.
Proven experience (2 years) with GoLang
Experience developing schema data models in a data warehouse environment.
Experience working with customers/other developers to deliver full-stack development solutions e.g collect software, data, and timeline requirements in an Agile environment.
Demonstrated knowledge of agriculture and/or agriculture-oriented businesses.
Experience implementing complex data projects with a focus on collecting, parsing, managing, and delivery of large sets of data to turn information into insights using multiple platforms.
Demonstrated experience adapting to new technologies.
Capable to decide on the needed hardware and software design needs and act according to the decisions. Ability to develop prototypes and proof of concepts for the selected solutions.
Experience with object-oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large-scale data infrastructures should be present.
Experience creating cloud computing solutions and web applications leveraging public and private API’s.",chi,de
90,"JPMorgan Chase Bank, N.A.",Finance,3.8,Java Engineer - NoSQL/Big Data/AWS,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_3e78b841&cb=1619364480979&jobListingId=1007022046446&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-82c94603baf68b20,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.
CIB Payments Technology is looking for an experienced software developer to help build out its big data platform. As a Big Data engineer you will work on delivering innovative solutions that help Payments platform to scale to millions of transactions processed per day and are responsible for managing data at Terabyte scale.
This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
5+ years of experience with full development lifecycle - requirements analysis, design, implementation, and testing (TDD)
Experience with AWS APIs and hands-on experience in working with AWS S3
Experience working on NoSQL Databases such as Cassandra, HBase, DynamoDB, and Elastic Search
Experience working with Kafka
Advanced hands-on experience in Java, Spring Framework, React Js, REST API
Advanced hands-on experience in testing tools - Junit, Selenium
Hands-on experience in DevOps and CI/CD practices
AWS Certification is a plus
Expertise in application, data, and infrastructure architecture disciplines
Advanced knowledge of architecture and design across all systems
Keen understanding of financial control and budget management
Working proficiency in developmental toolsets
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Proficiency in one or more modern programming languages
Understanding of software skills such as business analysis, development, maintenance, and software improvement
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
Equal Opportunity Employer/Disability/Veterans",chi,de
91,StoneX Group Inc. US,Finance,3.2,Senior Data Engineer,"Chicago, IL",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136043&s=58&guid=0000017909a5057c8c7e43987f38d469&src=GD_JOB_AD&t=SR&vt=w&cs=1_7d8a370f&cb=1619364480979&jobListingId=1007017628658&jrtk=1-1f44qa1d3u41k801-1f44qa1dlhilr800-ff7dcce5a050484a,"Position Purpose: The Senior Data Engineer is responsible for empowering the Data team to achieve its primary objectives: ingesting, mastering and exposing real-time, event-driven data streams pertaining to the essential relational data dimensions that are crucial to the evolution and continued success of StoneX Group Inc. This position will focus heavily on utilizing advanced techniques and cutting-edge technologies around data mastering specific dimensional data and exposing it rapidly to internal and external consumers. The ideal candidate will exhibit passion for continuous improvement and a dedicated focus on enabling our consumers to achieve their goals and make data driven decisions.
Primary Accountabilities/Responsibilities:
Prioritizes and executes rapid raw data collection from source systems, targets and implements efficient storage of, employs fast and reliable access patterns.
Master Data Management concepts and implementation.
Understands system protocols, how systems operate and data flows. Aware of current and emerging technology tools and their benefits. Expected to independently develop a full software stack. Understands the building blocks, interactions, dependencies, and tools required to complete software and automation work. Independent study of evolving technology is expected.
Strong focus on innovation and enablement, contributes to designs to implement new ideas which improve an existing and new system/process/service. Understands and can apply new industry perspectives to our existing business and data models. Reviews existing designs and processes to highlight more efficient ways to complete existing workload more effectively through industry perspectives.
Maintains knowledge of existing technology documents. Writes basic documentation on how technology works using collaboration tools like Confluence. Creates clear documentation for new code and systems used. Documenting systems designs, presentations, and business requirements for consumption and consideration at the manager level.
Collaborates with technical teams and utilizes system expertise to deliver technical solutions. Continuously learns and teaches others existing and new technologies. Contributes to the development of others through mentoring or in-house workshops and learning sessions.
Drives team practices and procedures to achieve repeatable success and defined expectation of services
Provides a significant collaborative role in long-term department planning, with focus on initiatives achieving data empowerment, operational efficiency and sustainability
Monitors and evaluates overall strategic data infrastructure; tracks system efficiency and reliability; identifies and recommends efficiency improvements and mitigates operational vulnerabilities.
Job Requirements:
Bachelor’s degree or relevant work experience in Computer Science, Mathematics, Electrical Engineering or related technical discipline.
8+ years of experience developing software in a professional environment (preferably financial services but not required)
5 years of hands on Data Driven Enterprise Application development, preferable in financial industry
Strong understanding of Enterprise architecture patterns, Object Oriented & Service Oriented principles, design patterns, industry best practices
Foundational knowledge of data structures, algorithms, and designing for performance.
Proficiency in programming in Java, C# or Python and willingness to learn and adopt new languages as necessary
Experience with ETL, Airflow, SSIS, .NET Core, C#, Python, SQL, Web APIs, Microsoft MDS are strongly preferred.
Exposure to containers, microservices, distributed systems architecture, orchestrators and cloud computing.
Comfortable with core programming concepts and techniques (e.g. concurrency, memory management)
Enjoys working with algorithms and data structures (e.g. trees, hash maps, queues)
Data Analytics and Data Science experience will be a plus.
Good sense of user interaction and usability design to provide an intuitive, seamless end user experience.
Excellent communications skills and the ability to work with subject matter expert to extract critical business concepts.
Ability to work and potentially lead in an Agile methodology environment.
Physical requirements/Working conditions:
Climate controlled office environment
Minimal physical requirements other than occasional light lifting of boxed materials
Dynamic, time-sensitive environment
StoneX (formerly known as INTL FCStone) is an institutional-grade financial services network that connects companies, organizations and investors to the global markets ecosystem through a unique blend of digital platforms, end-to-end clearing and execution services, high-touch service and deep expertise. We provide access to 36 derivatives exchanges, 175 foreign exchange markets, nearly every global securities marketplace and a number of bi-lateral liquidity venues. We deliver this access with support throughout the entire lifecycle of a trade – from consulting and “boots-on-the-ground” intelligence, to best execution, to post-trade clearing, custody and settlement. In these ways, StoneX enables clients to use the global markets ecosystem to achieve their business goals through one trusted partner. We currently serve more than 30,000 commercial, institutional and payments clients, and more than 125,000 retail clients across more than 130 countries. Our clients use our institutional-grade digital platforms, our high-touch service, and our market intelligence to pursue trading opportunities, make investments efficiently, manage their market risks, and improve their business performance. Our relentless focus on helping them accomplish these objectives has enabled us to build deeply valued, long-term relationships based on guidance, integrity, transparency and trust.

StoneX Group Inc. is an Equal Opportunity Employer . Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",chi,de
0,Comcast,Telecommunications,3.9,Data Engineer,"Englewood, CO",$89K - $144K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=0000017909a82c7bb522bb1cf7333fd9&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_d65ce9e3&cb=1619364687527&jobListingId=4042104741,"Job Summary The Data Experience Team (dx) has the responsibility of data engineering and data governance for Comcast data platforms, focused on gathering, organizing and making sense of Comcast data. Within the Big Data domain, this role is responsible for software development including planning, designing, developing, testing, implementation and management of big data applications focused on video usage and viewership, both on premise and in the cloud. Responsible for design to implementation, including new programs, enhancements, and modifications. Contribute to functional strategy development. The candidate should have experience operating in a DevSecOps team and will be expected to contribute to an internal DevSecOps culture encompassing end-to-end responsibility for development, deployment, production support, monitoring, data quality and automation of their applications.Job DescriptionCore ResponsibilitiesCollaborates with project stakeholders to identify product and technical requirements. Conducts analysis to determine integration needs.Designs new software and web applications, supports applications under development and customizes current applications. Assists with the software update process for existing applications and roll-outs of software releases.Participates in training representatives and operations staff on internally developed software applications.Researches, writes and edits documentation and technical requirements, including software designs, evaluation plans, test results, technical manuals and formal recommendations and reports.Monitors and evaluates competitive applications and products. Reviews literature, patents and current practices relevant to the solution of assigned projects.Provides technical leadership throughout the design process and guidance with regards to practices, procedures and techniques. Serves as a guide and mentor for junior-level Software Development Engineers.Works with Quality Assurance team to determine if applications fit specification and technical requirements.Displays in-depth knowledge of engineering methodologies, concepts, skills and their application in the area of specified engineering specialty.Displays in-depth knowledge of and ability to apply, process design and redesign skills. Presents and defends architectural, design and technical choices to internal audiences.Displays knowledge of and ability to apply, project management skills.Consistent exercise of independent judgment and discretion in matters of significance.Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) and overtime as necessary.Other duties and responsibilities as assigned.Employees at all levels are expected to:Understand our Operating Principles; make them the guidelines for how you do your job.Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.Win as a team - make big things happen by working together and being open to new ideas.Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.Drive results and growth.Respect and promote inclusion & diversity.Do what's right for each other, our customers, investors and our communities.Qualifications:Apache Spark; AWS Cloud Computing; Big Data Architecture; Big Data Solutions; Big Data Systems; Big Data Technologies; Databricks; DevOps; Java; PySpark; Python; ScalaDisclaimer:This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.Comcast is an EOE/Veterans/Disabled/LGBT employer.EducationBachelor's DegreeRelevant Work Experience5-7 YearsBase pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.",co,de
1,Strive Health,Health Care,5,Data Engineer,"Denver, CO",$83K - $100K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=0000017909a82c7bb522bb1cf7333fd9&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_4f1ede6c&cb=1619364687527&jobListingId=4044509916,"Overview:Strive HealthStrive Health is built for purpose- to transform a broken kidney care system. We are fundamentally changing the lives of kidney disease patients through early identification and engagement, comprehensive coordinated care, and home-first dialysis. Strive’s model is driven by a high-touch care team that integrates with local providers and spans the entire care journey from CKD through ESRD, leveraging comparative and predictive data and analytics to identify patients at risk. Strive Health’s interventions significantly reduce the rate of emergent dialysis crash, cut inpatient utilization, and significantly improve patient outcomes and experience. Come join our journey as we create THE destination for top talent in the Healthcare community and set a new standard for how care kidney should be done.Data EngineerWe are building commercial-grade technology to operate kidney care services at scale. Our data platform is EMR agnostic which would enable data integrations between different applications. We are in progress of building our first applications on the top of the data platform. The Data Engineer focuses on acquiring data from various sources that are found in a Health System’s ecosystem. Data Engineers become accustomed to both the technical and business details of the source systems and engage with multiple technologies on how to acquire the source data.Essential Functions:Oversee bringing new source systems into the Strive’s Data Platform using various cutting-edge technologies.Ability to dig into the data and understand business logic within the source system data and build and perform data validation tests to ensure quality via data pipeline.Balance tasks and priorities between multiple client projects and internal initiatives; ensure assigned tasks are executed efficiently and according to project requirements and timelines.Qualifications:Minimum QualificationsExpert in Structured Query Language (SQL)Experience working with EMR\EHR systems and an understanding of the healthcare clinical domainExposure to Extract, Transform and Load (ETL) concepts and processesWorking knowledge of database principles, processes, technologies and toolsWorking knowledge with structured and unstructured dataExperience with processing HL7 messages, CCD documents, and EDI X12 Claims files.Familiarity with development methodologies, including the AGILE development approachesAble to code and comprehend code around technologies that deal with acquiring dataExperience working with Hadoop and other Big Data TechnologiesExposure to programming languages such as Python, C#, or Java5+ years’ experience in healthcare/technology related fieldAnnual Salary: $83,554.00- $125,330.00Strive Health offers competitive compensation and benefits. An annual performance bonus, determined by company and individual performance, is available for many roles and aligned to Strive Health guidelines.Strive Health is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Please apply even if you feel you do not meet all qualifications. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to peopleops@strivehealth.comStrive provides clinical resources, technology, and capital to enable nephrologists to participate and succeed in value-based models. We serve as an extension of practice and empower nephrologists to enhance patient care and maximize revenue through new payment models.",co,de
2,"Cesare, Inc.","Construction, Repair & Maintenance",3.5,"Geotechnical Engineer, PE","Centennial, CO",$50K - $75K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044077&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_92432f28&cb=1619364687528&jobListingId=3625237946,"Seeking two geotechnical engineer's who have been licensed as Professional Engineer's for 5 + years for our Silverthorne and Frederick locations. Ideal applicants must have experience with a variety of commercial, industrial, and residential type projects.PREFERRED QUALIFICATIONSB.S. and preferably an M.S. degree in civil/geotechnical engineering.Possesses 5+ years’ experience as a P.E.State of Colorado Professional Engineering License or ability to become licensed in ColoradoPossesses effective oral and written communication skills.Willingness and ability to travel within the State of Colorado, occasionally outside of Colorado.Is a participating member at a local branch of one or more professional organizations related to materials testing, construction, and/or geotechnical/geological/civil engineering.Enthusiasm for engineering, construction, innovation, and building a winning team.Job Description:Scoping work and preparing proposals, and project management.Performing geotechnical studies, analysis, and design.Preparing/reviewing a variety of geotechnical reports, studies, and evaluations.Reviewing construction observation and testing data and preparing reports.Analysis and design of mechanically stabilized earth retaining structures.Slope stability analysis.Analysis and design of ground anchors and soil nails.Analysis and design of drilled shafts, helical piles, driven piles.Pavement design.General knowledge of concrete, asphalt, and aggregate materials testing.Experience with failure analysis/distress structures and pavement is a plus.PRIMARY DUTIESPerforms a variety of skilled professional engineering work in the office and/or field.Applies broad/basic knowledge of principles of civil and geotechnical engineering to observe construction work, observe and document existing conditions, scope work, prepare proposals, perform site studies, identify soil and bedrock, establish laboratory testing programs, evaluate and characterize site conditions, perform engineering analysis, provide foundation design recommendations, establish basic design criteria, and prepare reports. Requires application of standard engineering techniques and procedures, including professional judgment to execute work, develop solutions, and make design modifications.Assigns tasks to and directs staff level engineers/geologists, technicians, and administrative staff.Schedules, plans, and coordinates detailed aspects of the engineering work.Performs all or some project management duties.Responsible for technical performance on routine projects, and designated tasks on large or complex projects.Benefits Offered: Competitive Wage/Salary, Medical, Vision, Dental, Life, Retirement, Vacation, Holidays, and Educational Opportunities.Job Type: Full-timeSalary: competativeJob Type: Full-timeExperience:Geotechnical Engineering: 5 years (Required)Education:Bachelor's (Required)Work Location:One locationBenefits:Health insuranceDental insuranceVision insuranceThis Company Describes Its Culture as:Detail-oriented -- quality and precision-focusedOutcome-oriented -- results-focused with strong performance culturePeople-oriented -- supportive and fairness-focusedTeam-oriented -- cooperative and collaborative",co,de
3,Flexential,Information Technology,3.4,Senior Dev Ops Engineer,"Denver, CO",$77K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_9b740be8&cb=1619364687528&jobListingId=4069034519,"Job Description:Flexential stands for something not often found in the world of IT transformation: the human touch. The best infrastructure solutions aren’t about infrastructure, they’re about people. With a mission to accelerate customer success through people and technology, we build trusted relationships and deliver tailored, value-added and reliable solutions to demonstrate the power of people in a technical world.Utilizing our people, values and reliable performance, Flexential is deeply invested in the success of our 4,200+ customers, who trust us to deliver core data center solutions of colocation and connectivity, as well as cloud, managed solutions and professional services. Flexential’s robust suite of assets spans 21 domestic and international markets and comprises 41 highly redundant and connectivity-rich data centers.Key Responsibilities and Essential Job FunctionsAbility to support but not an expert in a microservice based app built with .Net, AWS, Kafka, EKS, EventStoreDB, PostgreSQL RDS, ELK, Terraform, Flux and Git to name a few core pieces.Working closely with internal teams to help guide the next steps on an internal application, suggesting improvements on both the core platform and integrating with teams for improvements with the applications.Troubleshoot, diagnose, and repair issues within production Linux OS, Windows server, and container environments.Perform system patching, software updates, and deployments consistent with change management processes in defined maintenance windows.Respond quickly to system outages and alerts.Coordinate communication with other teams and facilitate escalations of issues as appropriate.Apply and support automation using DevOps tools such as Ansible, Kubernetes, and TerraformDesign, configure, troubleshoot, and maintain cloud environments.Write and maintain as-built documentation and diagrams of environments.Consult with customers to solve technical and business challenges through gathering customer requirements, evaluating options, and selecting and implementing technologies.Perform security, performance, and availability assessments.Deploy, manage, and maintain secure, scalable network systems using technology from a variety of vendors.Learn (and share) new skills through independent research, formal training, and industry events.Required QualificationsA four-year degree, preferably in computer science or a related fieldTwo to five years of hands-on system administration or system engineering experienceInterest in learning new skills and keeping pace with changing technologiesAbility to problem solve and work with others to find the best solutionPrecision and attention to detailStrong interpersonal and written communication skillsCapability to work independently and self-motivateA commitment to providing our customers with 100% satisfactionA passion for DevOps tools and culturePreferred QualificationsSenior-level Linux skillsExperience with DevOps Methodology and ToolsExperience with Ansible and TerraformExperience with CI/CD MethodologyFamiliarity with DockerExperience with at least one programming language, Python preferredThe Linux Foundation Certified Kubernetes Administrator CertificationAWS certified associate level or higher (AWS Certified SysOps Administrator, AWS Certified Solutions Architect, AWS Certified Developer)Physical RequirementsModerate keyboard usageMay require extended periods of sitting or standingBase Pay Range : Annualized salary range offered for this position is estimated to be $75,000-$105,000 however, the actual pay range depends each candidate’s experience and qualifications.Variable Pay : Discretionary annual bonus, based on personal and company performance.Benefits of working at Flexential:Medical, Telehealth, Dental and Vision401(k)Health Savings Accounts (HAS) and Flexible Spending Accounts (FSA)Life and AD&DShort Term and Long Term disabilityUnlimited Paid Time Off (PTO)Leave of AbsenceEmployee Assistance ProgramWellness ProgramRewards and Recognition ProgramBenefits are subject to change at the Company’s discretion",co,de
4,Particle Measuring Systems,Manufacturing,3,Mechanical Engineer,"Boulder, CO",$45K - $109K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_fa326249&cb=1619364687529&jobListingId=4067592204,"Do you want to be part of a business that genuinely values entrepreneurialism , innovation and individual accountability? We focus on our customers and are proud of the difference our technology makes. We partner with some of the biggest manufacturing companies in the world and our technical innovations are used to enhance well-known brands across multiple industries.Mechanical Engineer – Boulder, CODo you want to be part of a business that genuinely values Entrepreneurialism , Innovation and Individual Accountability? We focus on our customers and are proud of the difference our technology makes. We partner with some of the biggest manufacturing companies in the world and our technical innovations are used to enhance well-known brands across multiple industries.Particle Measuring Systems (PMS) sets the standard for cleanroom contamination monitoring. With more than 60 patents, we create the technology that enables our customers to make fact-based decisions, improve process yields and comply with ever-changing regulatory requirements.The RoleAs the Mechanical Engineer you’ll be working on highly technical products as part of a team of dedicated engineers and scientists from multiple disciplines. You’ll be responsible for creating and implementing engineering solutions on product enhancement and new development projects. As a key member of the team, you will be the go-to person for mechanical engineering solutions for of air and liquid particle counting systemsSpecific Job Responsibilities:Supporting research, new product development, and sustaining engineering activities.Designing complex mechanical, opto-mechanical and electro-mechanical assembliesCreating solutions for gas and liquid handling systemsQualifications:Bachelor of Science (MS preferred) in Mechanical or Opto-Mechanical Engineering8+ years of hands-on mechanical engineering designExperience with injection molded plastics, machined, and sheet metal parts. Ability to specify the optimal alloys, plastics, carbon fiber, and other materials for a variety of environmentsExperience with electronics packaging design of sensitive instrumentation and IPX rated enclosures.Experience with fabrication and assembly methods to optimize Design for Manufacturing. Knowledge of product servicing needs to optimize Design for Serviceability.Knowledge of product BOM structuring and ERP systems.Knowledge of how to effectively use DFMEA and PFMEAs in the product development process.Experience in tolerance analysis per ASME Y14.5M,GD&T, thermal analysis, stress calculations, tooling and fixture design.Excellent technical problem solving skills.Experience working in a fast paced results driven environment.Preferred QualificationsOpto-Mechanical design experienceExperience in gas and liquid handling systemsMaster’s degree in EngineeringThe Nuts and BoltsLocation – This is an “in-office” position 50-100% of the time with Covid precautions being taken. The location of this position is in Boulder, CO. The remainder of the time you may work from home. Relocation may be offered for this role, but local candidates will receive first consideration.2021 Benefits At-a-GlanceOur benefit package is provided through our parent company, Spectris.MedicalHealth Advocate – This confidential service can help you; your spouse, dependent children, parents, and parents-in-law resolve health care and insurance-related issues, manage chronic conditions and improve your health and well-being.Dental – Delta Dental PPO; DeltaCare USAVision – VSP Vision Plan401(k)Flexible Spending AccountOnsite Wellness Clinic – Onsite physician for basic health and wellness consultations.Pay Range$95,000-125,000 depending upon experienceHow we determine what we pay (compensation philosophy)Particle Measuring Systems determines pay for positions using local, national, and industry-specific survey data, for the Boulder, Colorado area. We will evaluate external equity, which is the relative marketplace job worth of jobs directly comparable to jobs within our company.For new hires, we to make competitive offers between the minimum and around the midpoint of the range. This allows the new employee room for future merit increases during review cycles. There may be times when we will offer above the midpoint. The decision to do so will be based on the applicant’s level of experience, education, and specialized knowledge and skills. Additionally, we consider the external market rate, the amount we have budgeted internally, and the compensation rates of the employees within the company doing the same position.Note to external agencies: We are not accepting resumes, emails or calls from outside agencies regarding this position currently.Note to visa candidates: We are not able to sponsor H-1B’s, so we accept applications from US citizens and those with permanent U.S. residency status (green card).To apply: Please Click HereParticle Measuring Systems is proud to be an Equal Opportunity Employer",co,de
5,Jaxon Engineering and Maintenance,Aerospace & Defense,3.9,Senior Engineer,"Colorado Springs, CO",$68K - $79K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044077&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_50d38344&cb=1619364687529&jobListingId=4070313890,"Description: Jaxon Engineering is looking for an experienced Senior Engineer to join our team.Jaxon is fast-paced, results-oriented company that provides industry-leading High-Altitude Electromagnetic Pulse (HEMP)-hardening products and services to military, governmental and commercial clients. Our core competencies include design, engineering, testing, construction, refurbishment, and sustainment of HEMP-hardened equipment, facilities and systems located throughout the world. Headquartered in Colorado Springs, Colorado, Jaxon offers outstanding benefits packages, competitive pay, bonuses, and an unmatched corporate culture.Jaxon is seeking a motivated professional with a demonstrated ability to work with minimal supervision while meeting often tight schedule and budgetary constraints to achieve customer, corporate and personal goals and objectives. The successful candidate will have demonstrated knowledge, abilities, and relevant experience in multiple technical disciplines, strong program execution and management talents, and excellent written and oral communication skills. Applicable technical experience sought includes knowledge of facility and equipment HEMP-hardening methods, implementation and testing; strong hands-on time- and frequency-domain test and measurement expertise; knowledge of applied electromagnetics (EM wave propagation test and measurement); familiarity with AC and DC power systems; exposure to high-voltage pulsed-power testing equipment; and other related categories.The successful candidate will also be an effective team player; possess an ability to both lead and mentor other engineers and technicians of all experience levels; be able to interface and communicate effectively with staff, customers, program management and corporate leadership; and welcome the opportunity to learn, grow, and become a HEMP-hardening subject matter expert. In-country and international travel will be required for this position, at times up to 50%.Salary:  $100,000- $120,000 per year plus eligibility for bonus.Benefits:  Medical, dental, vision, life, STD, LTD, 401(k), PTO, paid holidays and annual bonus eligibility.Security Clearance:  Ability to obtain a Department of Defense Secret clearance or higher.Primary DutiesProvide technical execution, management and oversight of multiple projectsAct as Technical Subject Matter Expert for large programs, including direct client interfaceServe as a subject matter expert to customers and clientsLead HEMP test teams in both laboratory and field settingsGenerate and present a variety of technical documents (reports, presentations)Perform quality reviews of technical documents and deliverablesTrain, mentor and educate staff. Requirements: Job Qualifications (Preferred)Proficiency with all types of time- and frequency- domain test equipment (oscilloscopes, network / spectrum analyzers, instrument control and data acquisition)Technical project management experienceStrong problem solving and critical thinking skillsProficient with MS Office productsCurrent Secret DoD security clearance.Job Qualifications (Required))Minimum of a Bachelor of Science degree in Electrical Engineering or Physics plus 10+ years’ experienceExperience in one or more of the disciplines mentioned aboveAbility to obtain a DOD Secret and/or Top Secret security clearanceWillingness to be coached and to learn new skills in a rapidly-growing industryJob Type: Full-timePay: $100,000.00 - $120,000.00 per year",co,de
6,Verizon,Telecommunications,4,AI Chatbot Engineer,"Lone Tree, CO",$98K - $114K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_7e2934ae&cb=1619364687529&jobListingId=4066491328,"When you join VerizonVerizon is a leading provider of technology, communications, information and entertainment products, transforming the way we connect across the globe. We’re a diverse network of people driven by our ambition and united in our shared purpose to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward – and you can too. Dream it. Build it. Do it here.What you’ll be doing...We are honored that you are considering Visible as your next place of employment. Visible is the first all-digital wireless carrier in the U.S. Named by Fast Company as one of the most innovative companies in the world, Visible offers unlimited messages, minutes, and data, on Verizon’s Network. Visible is designed to fundamentally change the way millions of consumers sign up for and manage their phone service. Although headquartered in Denver, we have a permanent Work from Home Structure, and our team members work remotely.We are looking to hire an AI Chatbot Engineer to join the Visible Engineering Team.Lead and develop Chatbot conversational Flows in utilizing in-house and vendor products for solving customer’s problems and increasing customer satisfaction.Develop and lead customer facing applications that will be driven by chatbots across Agent automation /Mobile/Desktop.Participate in IT security process for application assessment and providing the fixes and remedy for the identified issues.Lead projects, Coordinate development activities, ensure timely delivery of modules to business with good quality and report project status to management.Coordinate application architecture and technology initiatives to ensure adoption of proper technology for application development.Manage application initiatives, schedule and align business projects working with CAM and business sponsors.Application management, handling customer escalations, production change controls and ongoing application maintenance.Coordinate activities to diagnose and resolve customer and other production issues by working with other IT teams and business partners.Ensure proper change control procedures are followed complying with IT change management.Business communications and relationships with other IT, Network, Marketing, Products and Revenue Assurance teams.Communicate effectively with business sponsors and other partner teams to maintain a healthy working relationship.Exchange and share information about product, pricing and promotions as needed to fulfill business needs and to keep IT applications up to date.Keep up to date with new technology to provide suggestions on technology directions to management.Help management in developing future strategies for IT Applications, development methodologies and technology solutions.What we’re looking for...You’ll need to have:Bachelor’s degree or four or more years of work experience.Six or more years of relevant work experience.Experience in programming with Java & J2EE Technologies.Experience on NLP/NLU.Experience with Artificial Intelligence / Machine learning methodologies.Experience on Google Dialog Flow.Experience on D-Tree implementation.Experience with Micro services architecture and Springboot development.Even better if you have:A Degree.Mobile/Desktop application development experience.Experience on implementation of Conversational Chatbots.Experience with chat platforms like Salesforce/Live Person.Experience with JWT and Oauth Framework.Experience with Social Media handles and integration with Google Dialog Flow.Experience with application performance tuning and monitoring.Experience in using messaging / JMS.Experience in GCPimplementations.Experience with in-memory data store and cache service.Experience in Unix/Linux operating systems.Knowledge of shell scripting.CompensationOur benefits are designed to help you move forward in your career, and in areas of your life outside of Verizon. From health and wellness benefits, short term incentives, 401 (k) Savings Plan, Stock Together, paid time off, parental leave, adoption assistance and tuition assistance, plus other incentives,we’ve got you covered with our award-winning total rewards package. For part-timers, your coverage will vary as you may be eligible for some of these benefits depending on your individual circumstances.If you are hired into a Colorado work location, the compensation range for this position is between $107,200 and $199,200 based on a full-time schedule. The salary will vary depending on your location and confirmed job-related skills and experience. This is an incentive based position with the potential to earn more. For part-time roles, your compensation will be adjusted to reflect your hours.Equal Employment OpportunityWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",co,de
7,CVS Health,Health Care,3.1,Staff Engineer - Productivity,"Denver, CO",$97K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ccb861ab&cb=1619364687530&jobListingId=4066650868,"CVS Health Enterprise Digital seeks to change the way individuals manage their healthcare by focusing on the features that matter to our customers, building software in a modern, lean way, and deploying continuously into the cloud. As part of an engineering organization building the Aetna Health experience, we help our members effectively find the care they need.What You'll DoThe Productivity team is responsible for supporting the engineering teams that build our Aetna Health client applications. They are the data-driven problem solvers who focus on helping improve the productivity of our engineers.In any given day you will:Help improve engineering efficiency by building and supporting a diverse range of services and toolsIdentify bottleneck areas and help optimize workflows in order to accelerate software releasesSeek opportunities to enhance the stability, performance, maintainability, and extensibility of our applicationThe typical salary range for this role is $112,200 to $167,200.This position is eligible for a CVS Health bonus plan or program.Benefit Overview:https://jobs.cvshealth.com/employee-benefits?prefilters=none&CloudSearchLocation=none&CloudSearchValue=noneRequired Qualifications5+ years of web development experiencePreferred QualificationsExperience working with CircleCIExperience with AWSProficient with CI/CD pipeline integrationExperience designing and building test/release infrastructureExperience in tools developmentExperience leading technical projectsEducationBachelor's degree or equivalent years of experienceBusiness OverviewAt CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",co,de
8,T-Mobile,Telecommunications,4.1,"Sales Engineer, Solutions Support","Englewood, CO",$85K - $219K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_20e5830c&cb=1619364687530&jobListingId=4066686877,"Associates are subject matter experts in specific solution verticals and support customers, sales, and solution engineers via pre-sales consultations, deployments, enablement, troubleshooting & debugging, and lifecycle. Associates leverage their technical expertise within their solution vertical to assist peers and collaborate across product verticals. Associates work with customers, vendors and peers to ensure the best possible customer experience by leveraging a high-level of technical acumen, a strong understanding of customer management and soft-skills, and the ability to create plans of action with clearly defined tasks and executables.At least 18 years of ageLegally authorized to work in the United StatesHigh School Diploma or GEDBachelor’s Degree: Technical DisciplineLess Than 2 Years: Experience Operating A Computer In A Windows Based EnvironmentLess Than 2 Years: Experience In A Customer-Facing EnvironmentLess Than 2 Years: Database Administration, System Administration, IT AdministrationMicrosoft Office: Ability To Utilize Advanced Office Suite Products Such As Word, Excel, PowerPoint, Teams, And SharePoint.Able To Effectively Express, Transmit, Understand, And Interpret Complex Information And Ideas Verbally And In Writing.Able To Make Rational Decisions Based On Facts Presented Regardless Of Specific Situation, Leveraging Both Knowledge And Available Resources.Able and Willing to Learn New, Highly Technical Things and Be Passionate About Technology.#LI-CS2Inbound Customer Queue Management –Will be responsible for receiving inbound calls, chats, emails, and tickets directly from sales, solution engineers, and customers. Is responsible for managing and resolving these issues in a professional manner as defined by process and expectations. Is expected to leverage their knowledge and skills to resolve complex customer issues with minimal outside engagement, internal or external to the team.Documentation – Will be expected to document all work completed in the approved databases, forms, and customer communications as defined by process. Documentation will need to be kept up to date and information entered in real-time for all issues and projects the individual is working on. Will take ownership of the quality and accuracy of documentation they produce and data they enter. Is responsible for reporting and submitting repair/improvement requests to management regarding current documentation, processes, and tools.Troubleshooting & Debugging – Will be responsible for troubleshooting highly complex issues that may or may not have defined resolution steps, working to resolve customer issues in a timely manner. Is expected to escalate issues per defined technical tiers and process. Will be required to communicate updates, resolution steps and information to customers, leadership, and additional stakeholders in a clear, concise, and professional manner.Pre-Sales Consultations, Deployment, Enablement & Lifecycle – Will be responsible for working directly with both internal and external customers in a Pre-Sales consultancy capacity, managing complex product deployments, supporting ongoing customer product enablement and managing overall customer lifecycle. Is expected to follow designated process when completing these tasks and is expected to engage additional internal and external resources promptly to ensure the best possible customer experience and drive customer and company success.Network Assessments – Is expected to produce internal and external documents as outlined by process and templated via PowerPoint and Excel. Must be able to analyze data and make accurate assessments of expected user experience on the T-Mobile network. Must be able to balance production requirements while still meeting other job responsibilities. Must be open to receiving direct feedback and management regarding execution of Assessments as it relates to quality and production metrics. May be responsible for providing Quality Assurance checks per process and providing design and development input to leadership regarding network assessments.Project/Program Management - Is expected to participate in and lead projects as assigned by management and complete their required tasks on-time and with minimal direction. Will be tasked with multiple projects both technical and non-technical in nature and are expected to execute these projects while staying current on all other job responsibilities. Will need to collaborate with others in a professional and productive manner that supports project outcomes. Will be responsible for providing accurate project/program updates to leadership.Training & Certification – Is expected to complete all assigned trainings and achieve certifications as assigned by management per the defined Training & Certification path for Associates. Will be expected to complete trainings per schedule outlined by management while maintaining productivity amongst their other primary job responsibilities. Will be responsible for helping to identify and define training paths for the department.Also responsible for other Duties/Projects as assigned by business management as needed.Equal Employment OpportunityWe take equal opportunity seriously—by choice.T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.",co,de
9,Jaxon Engineering and Maintenance,Aerospace & Defense,3.9,Engineer 2,"Colorado Springs, CO",$46K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_da6f8b2e&cb=1619364687531&jobListingId=4070324548,"Description:Jaxon Engineering is looking for an experienced Engineer 2 to join our team.Jaxon is fast-paced, results-oriented company that provides industry-leading High-Altitude Electromagnetic Pulse (HEMP)-hardening products and services to military, governmental and commercial clients. Our core competencies include design, engineering, testing, construction, refurbishment, and sustainment of HEMP-hardened equipment, facilities and systems located throughout the world. Headquartered in Colorado Springs, Colorado, Jaxon offers outstanding benefits packages, competitive pay, bonuses, and an unmatched corporate culture.Jaxon is seeking a motivated professional with a demonstrated ability to work with minimal supervision while meeting often tight schedule and budgetary constraints to achieve customer, corporate and personal goals and objectives. The successful candidate will have demonstrated knowledge, abilities, and relevant experience in multiple technical disciplines, strong program execution and management talents, and excellent written and oral communication skills. Applicable technical experience sought includes knowledge in some of the following areas: facility and equipment HEMP-hardening methods, implementation and testing; strong hands-on time- and frequency-domain test and measurement expertise; knowledge of applied electromagnetics (EM wave propagation test and measurement); familiarity with AC and DC power systems; exposure to high-voltage pulsed-power testing equipment; and other related categories.The successful candidate will also be an effective team player; possess an ability to lead other engineers and technicians of all experience levels; be able to interface and communicate effectively with staff, customers, program management and corporate leadership; and welcome the opportunity to learn, grow, and become a HEMP-hardening subject matter expert. In-country and international travel will be required for this position, at times up to 50%.Salary: $90,000-100,000 per year plus eligibility for bonus.Benefits: Medical, dental, vision, life, STD, LTD, 401(k), PTO, paid holidays and annual bonus eligibility.Security Clearance: Ability to obtain a Department of Defense Secret clearance or higher.Primary DutiesProvide technical execution and oversight of multiple projectsServe as a subject matter expert to customers and clientsLead HEMP test teams in both laboratory and field settingsGenerate and present a variety of technical documents (reports, presentations)Perform quality reviews of technical documents and deliverablesTrain, mentor and educate staff. Requirements: Job Qualifications (Required)Minimum of a Bachelor of Science degree in Electrical Engineering or Physics plus 4+ years’ experienceExperience in one or more of the disciplines mentioned aboveAbility to obtain a DOD Secret and/or Top-Secret security clearanceWillingness to be coachedJob Qualifications (Preferred)Proficiency with all types of time- and frequency- domain test equipment (oscilloscopes, network / spectrum analyzers, instrument control and data acquisition)Technical project management experienceStrong problem solving and critical thinking skillsProficient with MS Office productsCurrent Secret DoD security clearance.",co,de
10,Stolle Machinery,Manufacturing,3.7,Controls Engineer II - Colorado,"Centennial, CO",$48K - $74K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044077&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_740ef0fb&cb=1619364687531&jobListingId=4069300631,"JOB SUMMARYA Controls Engineer II designs, develops, and improves new and existing electrical control systems for Stolle Machinery’s current and future offerings under the direct supervision of senior level engineers, managers, or directors. The position requires the individual to be able to work independently with some guidance. A Controls Engineer II may be tasked to lead the development initiative on specific projects, based on complexity and engineer experience. A certain degree of creativity and latitude is required.SUPERVISOR RESPONSIBILITIES: None.PRINCIPLE ACCOUNTABILITIES include the following:· Designs new electrical controls systems and improves existing electrical controls systems.· Capable of creating electrical schematics and panel drawings while maintaining a focus on industry standards & compliances related to IEC, ISO, QSR, GMP.· Offers creative, unique, and effective design solutions when presented with complex engineering challenges.· Capable of following verbal and written instructions from management and senior level engineers.· Supports Offsite tests and trials as required both domestically and internationally.· Documents workflow and individual design history and is capable of presenting to management with short notice.· Willing to review work performed by junior level engineers and provide constructive feedback.· Capable of writing and facilitating test plans and interpreting data to make sound conclusions.· Communicates with customers as directed in a professional and efficient manner.KNOWLEDGE/EXPERIENCE/SKILLS:  Minimal requirements for education, knowledge and experience:· Demonstrated experience troubleshooting, process controls, electrical equipment, PLC programs, HMI applications, sensors, valves, motors, drives, VFD motion control.· Familiarity with IEC 61131-3 programming languages (ladder, structured text, function block diagram).· Understanding of Six Sigma principles.· Experience with PLC manufacturers: Allen Bradley, Siemens, GE, Omron preferred.· Experience programming and troubleshooting motion control systems using equipment from manufacturers like Allen-Bradley, Kollmorgen, and Marathon preferred 2-5 years preferred.· Ability to setup/configure communication networks (EtherNet/IP, EtherCAT, IO-Link, ControlNet, DeviceNet, etc).· Proficient with AutoCAD for electrical design work with 2-3 years minimum experience required combined with PDM know-how.· ePlan electrical design software experience helpful.· Lightly skilled in SolidWorks helpful but not required.· Proficiency with Microsoft Office Suite, MSProject desired.· Able to obtain a passport and travel both domestically and internationally.· Ability to setup/configure communication networks (EtherNet/IP, EtherCAT, IO-Link, ControlNet, DeviceNet, etc.).· Proficiency in electrical troubleshooting using standard electrical test equipment -- multimeters, oscilloscopes, data acquisition sensors (temperature, strain, position, current, etc.).· Basic mechanical understanding/aptitude, comfortable using simple hand tools.· Must be able to obtain a Passport and travel internationally when required.· Excellent technical writing skills with experience developing manuals.· Excellent organizational skills and attention to detail.· Excellent time management skills with a proven ability to meet deadlines.· Strong analytical and problem-solving skills.· Ability to function well in a fast-paced and dynamic environment.· Advanced data analysis skills in Excel or Minitab.EDUCATION AND EXPERIENCE: · BS in Electrical Engineering or related engineering field (Controls Engineering, Software Engineering, automation, controls).· Minimum of 2-4 years of experience designing and implementing automation solutions in a manufacturing environment.· Experience in product development environment.· Proven track record of sound engineering design.PHYSICAL/MENTAL DEMANDS AND WORKING CONDITIONS:  This position requires the ability to perform the essential duties and responsibilities in the following environment:· Prolonged periods of sitting at a desk and working on a computer.· Must be able to lift up to 15 pounds at times. (office environment).· Must be able to lift up to 50 pounds at times (plant floor environment).This position description has been prepared to assist in defining job responsibilities, physical demands, working conditions and skills needed. It is not intended as a complete list of job duties, responsibilities and/or essential functions. Stolle Machinery Co, LLC retains and reserves any or all rights to change, modify, amend, add to or delete from any section of this document as it deems, in its judgment, to be proper.Additionally, Stolle Machinery Co, LLC is an equal opportunity employer and does not discriminate on the basis of race, color, religion, age sex, national origin, disability, or veteran status.Job Type: Full-timePay: From $75,000.00 per yearBenefits:401(k)Dental insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceLife insurancePaid time offTuition reimbursementVision insuranceSchedule:Monday to FridayEducation:Bachelor's (Preferred)Willingness To Travel:25% (Preferred)Work Location:One locationCompany's website:https://www.stollemachinery.com/Benefit Conditions:Waiting period may applyOnly full-time employees eligibleWork Remotely:No",co,de
11,Jaxon Engineering and Maintenance,Aerospace & Defense,3.9,Engineer 3,"Colorado Springs, CO",$55K - $126K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_d75fc625&cb=1619364687531&jobListingId=4070324544,"Description:Jaxon Engineering is looking for an experienced Engineer 3 to join our team.Jaxon is fast-paced, results-oriented company that provides industry-leading High-Altitude Electromagnetic Pulse (HEMP)-hardening products and services to military, governmental and commercial clients. Our core competencies include design, engineering, testing, construction, refurbishment, and sustainment of HEMP-hardened equipment, facilities and systems located throughout the world. Headquartered in Colorado Springs, Colorado, Jaxon offers outstanding benefits packages, competitive pay, bonuses, and an unmatched corporate culture.Jaxon is seeking a motivated professional with a demonstrated ability to work with minimal supervision while meeting often tight schedule and budgetary constraints to achieve customer, corporate and personal goals and objectives. The successful candidate will have demonstrated knowledge, abilities, and relevant experience in multiple technical disciplines, strong program execution and management talents, and excellent written and oral communication skills. Applicable technical experience sought includes knowledge in some of the following areas: facility and equipment HEMP-hardening methods, implementation and testing; strong hands-on time- and frequency-domain test and measurement expertise; knowledge of applied electromagnetics (EM wave propagation test and measurement); familiarity with AC and DC power systems; exposure to high-voltage pulsed-power testing equipment; and other related categories.The successful candidate will also be an effective team player; possess an ability to lead other engineers and technicians of all experience levels; be able to interface and communicate effectively with staff, customers, program management and corporate leadership; and welcome the opportunity to learn, grow, and become a HEMP-hardening subject matter expert. In-country and international travel will be required for this position, at times up to 50%.Salary: $100,000-120,000 per year plus eligibility for bonus.Benefits: Medical, dental, vision, life, STD, LTD, 401(k), PTO, paid holidays and annual bonus eligibility.Security Clearance: Ability to obtain a Department of Defense Secret clearance or higher.Primary DutiesProvide technical execution and oversight of multiple projectsAct as Technical Subject Matter Expert for certain programs, including direct client interfaceServe as a subject matter expert to customers and clientsLead HEMP test teams in both laboratory and field settingsGenerate and present a variety of technical documents (reports, presentations)Perform quality reviews of technical documents and deliverablesTrain, mentor and educate staff. Requirements: Job Qualifications (Required)Minimum of a Bachelor of Science degree in Electrical Engineering or Physics plus 7+ years’ experienceExperience in one or more of the disciplines mentioned aboveAbility to obtain a DOD Secret and/or Top-Secret security clearanceWillingness to be coached and to learn new skills in a rapidly-growing industry Job Qualifications (Preferred)Proficiency with all types of time- and frequency- domain test equipment (oscilloscopes, network / spectrum analyzers, instrument control and data acquisition)Technical project management experienceStrong problem solving and critical thinking skillsProficient with MS Office productsCurrent Secret DoD security clearance",co,de
12,Xero,Information Technology,4.3,Infrastructure Systems Engineer,"Denver, CO",$85K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_8ca13397&cb=1619364687532&jobListingId=4066506026,"Xero is a beautiful, easy-to-use platform that helps small businesses and their accounting and bookkeeping advisors grow and thrive.At Xero, our purpose is to make life better for people in small business, their advisors, and communities around the world. This purpose sits at the centre of everything we do. We support our people to do the best work of their lives so that they can help small businesses succeed through better tools, information and connections. Because when they succeed they make a difference, and when millions of small businesses are making a difference, the world is a more beautiful place.You’ll work in collaboration with your team and other Xeros to help create and deliver beautiful software to our customers, faster. You'll regard engineering teams as your customers, and test, measure and learn how best to provide them value.You’ll maintain the standard for engineering excellence at Xero and support your team members in building products together. You’ll contribute to our cross functional environment by working towards the same objectives, using modern principles and practices.You'll help build and manage software that solves engineering problems at scale. You will be enabled to seek clarity with technical complexities and be able to demonstrate smart ways to simplify. You’ll be able to make data-driven decisions that will release value early to solve Xero customers' problems more effectively.What you’ll bring with youHands-on experience automating infrastructure in a cloud environment, preferably AWSA customer focused mindset and the ability to directly engage with our PaaSPractical experience with infrastructure-as-code (e.g. Terraform, Cloudformation, Ansible or Chef, etc.)Exceptional troubleshooting and analytical abilitiesExperience with a programming language (e.g. Python, C# or Java, etc.)Experience administering Windows/Linux servers in a highly available environmentAn understanding of relational database management experience with a preferred emphasis on SQL ServerFamiliarity with agile software development methodology and tooling, including continuous integration and deliveryAn understanding of network services and/or building and maintaining a Kubernetes clusterA strong desire to automate processes, build software tools, and create infrastructure-as-code solutions in a DevOps environmentWhat you’ll doBe customer-focused; Obsess over customers and directly engage with them; identify customer pain points and solve real customer problems based on observing their struggles and analysing customer data.Be kind; embrace our culture where we encourage diversity in a psychologically safe workplace. Voice your own opinion while considering the opinions of others.Be engaged; actively contribute to your team activities, initiatives and technological challenges, while working towards your product roadmaps. Maintain processes and monitoring to drive incremental improvement.Be collaborative; work with the team and others to achieve a good outcome using a working style that suits the problem at hand. Take operational responsibility for services, which may include 24x7 on call rotation.Be coached; proactively work with your manager on your personal and career development, highlighting any training/development needs and following through with actions agreed.Success looks likeContributing to product discovery activities and aligning with the agreed roadmapTaking ownership of personal/career developmentCommunicating effectively and respectfully giving and receiving feedbackDisplaying empathy and inclusion in interactions with othersMeeting agreed Service Level Objectives for operational performanceEnsuring continued improvement in ways of working for efficient deliveryProviding support and guidance to teams that use our platform servicesPlaying an active role within the Communities of Practice in XeroCritical competenciesLiving the vision & values.Keeps Xero’s vision and values at the forefront of decision-making, actions, communication and behaviors.Delivery.Has track record of innovating and delivering technology in a team and solving customer’s problems through software.Growth mind-set.Understands that competency is not fixed but is enhanced through dedication and hard work.Self-awareness.Has an awareness of EQ and is capable of recognizing one's own emotions and of those around you.Balance.Maintains a healthy personal/work-life harmony. Considers the wide range of learning and social opportunities at Xero against the needs of the team.Great communication skills.Speaks and writes clearly, succinctly and articulately without relying on jargon.Relationship building. Successfully builds trust and credibility with their team, customers and stakeholders.ExperienceExperience in delivering code to production in a commercial environment.Ability to work with others and navigate areas of conflict in an open, positive and proactive way.Experience of modern product and engineering principles and practices.Xero is an equal opportunity employerXero celebrates diversity. We are committed to creating an inclusive environment where our employees can do the best work of their lives. We are committed to transparency and to equal pay for equal work. Total compensation for this role includes a base salary of $85,000 to $105,000, commensurate with experience, plus an annual grant of Xero shares, calculated as a percentage of base salary.Xero offers access to low-cost, high-quality health care options through Cigna and Kaiser (in CA & CO only)Xero will match 100% on the first 3% of 401k contributions plus 50% match on next 2% of contributionsEmployees enjoy 21 days of paid time off per yearEmployees have 10 days of wellbeing leave to care for their minds, bodies, and familiesUS employees enjoy 11 paid holidays per yearXero offers an industry-leading 26 weeks of parental leave at 100% payXero offers a number of employee wellness programs, to include yoga, mindfulness and nutrition workshops, EAP, free flu shots, team meals, and a monthly wellbeing allowanceWhy Xero?Diversity of people brings diversity of thought, and we like that. A collaborative and inclusive environment is important to us. Working at Xero will provide you with a diverse and inclusive environment alongside people who will respect, challenge and support you to have fun while you do the best work of your life. We are a place where personal development, flexible working, innovation, and well-being are not just inspired but celebrated. We value our people and offer a wide range of compelling benefits and perks, including Xero shares.Xero’s collaborative culture is underscored by our values - #Ownership, #Challenge, #Beautiful, #Human and #Team - which empower us to understand and serve customers, attract top talent and continuously innovate. From the moment you step through our doors, you’ll feel welcome and supported to do the best work of your life.",co,de
13,ClientSolv Technologies,Information Technology,3.3,Big Data Engineer,"Englewood, CO",$75K - $104K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1044076&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_88033211&cb=1619364687532&jobListingId=4013345736,"ClientSolv Technologies is an IT solution firm with over a decade of experience serving Fortune 1000 companies, public sector and small to medium sized companies. ClientSolv Technologies is a woman-owned and operated company that is certified as a WMBE, 8a firm by the Federal government's Small Business Administration.Job Summary: Big Data Developer/EngineerDuration: 6+ months Contract to hireCity, State & Zip Code: Englewood, COWe are looking for an exceptional Big Data Developer with expertise either with Spark or Map Reduce development to work with our cross-functional team and join our world-class community of talented experts.Top skills (Technical):Core Big Data development hands on experience using Spark or Map ReduceJava, Scala ,PythonData EngineeringAWS knowledge is a nice to have skill setJob Duties and ResponsibilitiesPrimary responsibilities fall into the following categories:Evangelist for data engineering function leveraging Bigdata frameworkOptimizing our data and data pipeline architectureSupport our software engineers and data scientistsContribute to our cloud strategy based on prior experienceUnderstand the latest technologies in a rapidly innovative marketplaceIndependently work with all stakeholders across the organization to deliver enhanced functionalitySkills - Experience and RequirementsMust be from Data warehouse/Bigdata background.Experience in advanced java programming with sound knowledge in shell scripting. Specifically, this experience must be in writing Bigdata data engineering jobs.Advanced SQL experience using Hive/Impala framework including SQL performance tuningExperience in physical table design in Bigdata environmentKnowledge of using, setting up and tuning resource management framework such as Yarn or MesosExperience in SparkExperience in MapReduce framework, Oozie workflows and scoop Jobs and external schedulers such as Autosys.Experience in writing streaming jobs (producers/consumers) using Apache Kafka or AWS KinesisExperience working in Key/Value data store such as Hbase.Experience in AWS services such as EMR, Glue, S3, Athena, DynamoDB, IAM, Lambda, Cloud watch.Please note this is an onsite role based out of Englewood, CO, with No telecommuting.Job Types: Full-time, ContractSchedule:Monday to FridayEducation:Bachelor's (Preferred)Experience:Big data: 5 years (Preferred)Data Warehouse: 3 years (Preferred)Spark: 3 years (Preferred)Map Reduce: 3 years (Preferred)Java, Scala ,Python: 1 year (Preferred)Data Engineering: 1 year (Preferred)Hive: 1 year (Preferred)AWS: 1 year (Preferred)SQL performance tuning: 1 year (Preferred)Contract Renewal:LikelyFull Time Opportunity:YesWork Location:One locationWork Remotely:No",co,de
14,Frontdoor,Business Services,2.9,Data Engineer,"Denver, CO",$60K - $116K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_b490a677&cb=1619364687532&jobListingId=4010461878,"Frontdoor is looking for a very strong data engineer who will bring a mindset of automation and innovation to the table. In addition to sharp technical skills, this person must be a strong communicator and collaborator who can partner up with business stakeholders to understand their needs and solve their data problems. As a data engineer at Frontdoor, you will be working in a fast-paced environment and using cutting-edge cloud technologies to develop a scalable data platform that will support years of company growth.Responsibilities:Build and maintain scalable data pipelines for both batch and stream processing in a cloud-computing environment.Apply dimensional modeling to design tables and views that map business processes into an enterprise data model.Optimize database architecture by trading off storage and computation to achieve low cost and high performance.Build and support complex ETL infrastructure to deliver clean and reliable data to the organization.Support the development of new products and services via ingestion, processing, and formatting data for reporting and analytics.Interact face-to-face with business stakeholders, develop cooperative relationships, and acquire domain knowledge of the business.Proactively automate manual processes throughout the business for higher efficiency, robustness, and speed.Enforce production standards and governance best practices in the management of enterprise-level data, metrics, and reports.Qualifications:Bachelor’s in Computer Science, Engineering, Data Science, or related field (Masters or PhD preferred)Excellent communication and inter-personal skills.Versatile and quick learner with ability to pick up any new skills necessary to get the job done.Demonstrated strength in data modeling, ETL development, data warehousing, data pipeline and data lake creation.Extensive experience with cloud infrastructure and tools for AWS and GCP.Demonstrable proficiency in Python development and advanced SQL querying.Strong grasp of business elements and ability to convert requirements into database models and full-data pipeline systems.Experience with visualization and reporting tools, such as Looker and Tableau.3-4 years of experience in data engineering or similar work.Desired skills:Snowflake experience (highly desirable).Full stack experience, including microservice and web app development.Knowledge of big data platforms, such as Hadoop and Spark.Frontdoor is a company that’s obsessed with taking the hassle out of owning a home. With services powered by people and enabled by technology, it is the parent company of four home service plan brands: American Home Shield, HSA, Landmark and OneGuard, as well as AHS Proconnect , an on-demand membership service for home repairs and maintenance, and Streem, a technology company that enables businesses to serve customers through an enhanced augmented reality, computer vision and machine learning platform. Frontdoor serves more than two million customers across the U.S. through a network of more than 16,000 pre-qualified contractor firms that employ over 45,000 technicians. The company’s customizable home service plans help customers protect and maintain their homes from costly and unexpected breakdowns of essential home systems and appliances. With nearly 50 years of experience, the company responds to over four million service requests annually (or one request every eight seconds).For more details, visit frontdoorhome.com.Job Category: EngineeringID: R0015252",co,de
15,Leidos,Aerospace & Defense,3.8,System Engineer with TS/SCI and Poly,"Aurora, CO",$91K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_186ef0e5&cb=1619364687532&jobListingId=4070658344,"The National Solutions Group at Leidos currently has an opening for a System Engineer to support a client’s requirements in a challenging, dynamic setting located in Aurora, CO. The position requires an active TS/SCI with Polygraph security clearance.The System Engineer will work in a collaborative environment with teammates, to include the Government customer, to ensure quality system engineering and project management with a focus on continuous improvement across the program. The successful candidate will support the Program Manager in the coordination/execution of all activities related to the task scope. The successful candidate will provide system engineering leadership to focus on the appropriate standards, processes, procedures, and tools to be utilized throughout the program/service life cycle and institutionalize a common process methodology for project, product, and service delivery and operations.Primary Responsibilities:Work with the Governments’ Managed Service Provider on HelpNow system issues, enhancements, functionality, reporting, onboarding and metric trackingDefine and specify the implementation of standards, methods, and procedures for inspecting and evaluating the accuracy and reliability of procedures and activities which can include standard proceduresAssist program teams in gathering and analyzing data to ensure performance to requirements, identify trends and anomalies, define solutions to addressApply knowledge of information technology, system engineering, project management, service delivery, six sigma/continuous service improvement to provide proactive engagement and effective solutionsProvide technical engineering inputs and expertise for program projectsParticipate in ongoing risk, issue and opportunity identificationManages program projects to ensure successful completion on time and within budgetSupport the Service Operations Manager to ensure that project and process controls, CDRL products, services and projects are compliant with requirements, standards, corporate direction, objectives and/or contract.Basic Qualifications:To be considered for this position, you must minimally meet the knowledge, skills, and abilities listed below:Bachelor's degree with 8+ years of relevant experience or Masters with 6-10 years of prior experienceTS/SCI with Polygraph is requiredDemonstrated System Engineering and Project Management experienceExperience with Service Level Management, ITIL, Process Framework, ITSM, Six Sigma and continuous service improvement initiativesProficient in designing, authoring, reviewing and maintaining schedules, process and project documents including requirements documents, knowledge articles, operating instructions, processes, procedures and workflowsStrong interpersonal skillsAbility to work in a fast-paced, collaborative team environmentProficiency in Microsoft Office applications (PowerPoint, Excel, Word, Project)Excellent communication and interpersonal skills; ability to effectively communicate both technical and non-technical topics to stakeholders at all levelsPreferred Qualifications:Candidates with these desired skills will be given preferential consideration:Demonstrated knowledge of HelpNowExperience within the ICProficient in agile concepts and principlesExperience with Scaled Agile Framework (SAFe) methodologyExternal Referral Bonus:EligiblePotential for Telework:NoClearance Level Required:Top Secret/SCI with PolygraphTravel:Yes, 10% of the timeScheduled Weekly Hours:40Shift:DayRequisition Category:ProfessionalJob Family:Systems EngineeringPay Range:Pay Range $91,000.00 - $140,000.00 - $189,000.00",co,de
16,Blue Margin,Information Technology,5,Data Visualization Engineer,"Fort Collins, CO",$44K - $77K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_abb99c27&cb=1619364687533&jobListingId=4070508598,"Blue Margin, Inc. helps companies improve their business performance using Microsoft’s Business Intelligence stack (including Power BI and SQL Server) and Cloud Computing software and services (Azure and Office 365). We believe in working hard, volunteering in our community, and enjoying life along the way.Why are we looking?We are expanding our Microsoft Power BI team, and are looking for people who are flexible and capable of putting themselves in the shoes of the client. We are looking for a clever, creative, data-savvy person to produce reports to support our executive and leadership teams and satisfy our clients’ requirements. Our growth means we are looking for people with great attitudes who are fun to work with. It also means we provide an excellent opportunity for someone who is serious about learning and advancing their career.We are seeking a candidate to work as a full-time employee in our local office in Fort Collins.Please note that we are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.For the initial step of the hiring process, all qualified candidates will be asked to complete a Power BI sample report and brief video introduction.Salary and Benefits:The starting salary for this position is between $60,000-$75,000 and is commensurate with experience and qualifications. This full-time position comes with a comprehensive benefits package consisting of medical and dental coverage, paid sick leave, vacation, and a retirement plan.Responsibilities:Develop accurate reports in Power BI that are not only visually engaging, but also make customers’ data accessible and actionable.Regularly interact with clients for project updates and inquiriesCreate, enhance, and troubleshoot data models in Power BI and Visual StudioAuthor documentation of customer reporting requirements and finished reportsCraft and use T-SQL queries for data validationCandidates MUST possess the following qualifications:1-3 years of experience in Power BI Desktop creating tables, graphs, drill downs, drillthroughs, bookmarks, and KPIsWorking knowledge of Power BI Service and how to configure itAbility to create intermediate to advanced DAX calculations using functions such as Calculate, Summarize and FilterExperience creating T-SQL queries in SSMSComprehensive grasp of data visualization methodsFamiliarity with data modelingBroad business experience with a proficient ability to talk to executives in business termsProfessional demeanorIdeal candidates would possess these additional qualifications:Experience using Visual Studio 2017/2019, DAX Studio, Tabular Editor, ALM ToolkitFamiliarity with tabular data modelsComfortable with manipulating data in Power Query EditorOur Culture:Company Core Values: Commit to Quality, Embrace Transparency, Choose to Be Positive, Be Efficient/Systematize, Pursue Learning, Be GenerousWeekly personal and professional development programs for allTeamwork—we maintain company-wide interaction and communicationEntrepreneurism – we want everyone on our team to be eager to adapt and evolve with our advancing business. We are looking for someone who is comfortable wearing more than one hat.Work Environment and Physical Requirements:This position requires standing or sitting for long durations and may require minimal physical effort including lifting materials and equipment of less than 10 pounds. This position requires viewing a computer screen more than 80 percent of the time. This position requires viewing a computer screen more than 80 percent of the time and takes place in a normal office environment with controlled temperature and lighting conditions. The position may require some travel and occasional participation in off-site functions.Note: for the initial step of the hiring process, all qualified candidates will be asked to complete a Power BI sample report and brief video introduction.",co,de
17,Crocs,Retail,3.6,Data Engineer,"Broomfield, CO",$82K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=8095&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_e25f6ce1&cb=1619364687533&jobListingId=4043910653,"Crocs is seeking a Data Engineer to develop, test, and maintain data pipelines and related architectures within the Azure platform. This position will help to enable the Crocs enterprise to make bigger, bolder decisions faster. The Junior Data Engineer will work independently and with the team to help facilitate the usage of more sophisticated analytics/data science throughout the organization

JOB DUTIES

Data Modeling -Execute a framework to be used within our Enterprise Data Warehouse (EDW) by providing consistent predictable techniques and methodologies for data

ELT/ETL -Develop ETL/ELT processes and patterns to efficiently move data using batch processing

Engineering Best Practices- Adhere to engineering standard methodologies, including test-driven development, agile management, and continuous integration pipelines

Documentation -Create and maintain accurate and complete documentation of the pipelines developed

Aptitude for Learning - Stay ahead of on what is happening within the BI and analytics space and demonstrate interest and desire in the area of data science and machine learning

JOB REQUIREMENTS

Minimum Education


Bachelor's degree in computer science, information technology, engineering, mathematics, or equivalent technical degree

Minimum Experience


2+ years in a similar role

Knowledge, Skills & Abilities


Strong proficiency in ANSI-SQL
Proficiency in Python, Pandas, and/or PySpark
Experience with Databricks or similar products
Experience with a business intelligence tool, such as Power BI
Experience in SAP ERP or other similar ERP systems is a plus
Experience in Snowflake Database or other similar columnar database
Prior experience working in a cloud platform
Experience working in Azure or a Microsoft-specific environment is a plus
Experience working with modern ETL/ELT tools, such as Data Factory, Databricks, or similar

Crocs is an Equal Opportunity Employer committed to a diverse and inclusive work environment.

Title: Data Engineer

Job level: Professional Individual Contributor

Career Level: CL 4

Salary Range: $71,500-107,300

This position is eligible to participate in a company incentive program.

This position is eligible for company benefits including but not limited to medical, dental, and vision coverage, life and AD&D, short and long term disability coverage, paid time off, employee assistance, participation in a 401k program that includes company match, and many other additional voluntary benefits.",co,de
18,Splunk,Information Technology,4.2,Data Engineer,"Denver, CO",$108K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_22e975a0&cb=1619364687533&jobListingId=4069672874,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.As the Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.What you'll do: Yeah, I want to and can do that.Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.Requirements: I’ve already done that or have that!5+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data ScientistSavviness with complex SQL queries and knowledge of database technologies including window and analytical functionsExperience with Python analytic libraries and Business Intelligence tools such as Tableau.An ability to provide technical guidance, direction and problem solving to data engineering team members.Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.A familiarity working with an AGILE/SCRUM process management.Preferred knowledge and experience: These are a huge plus.Knowledge of Splunk productsAgile certificationsEducation: Got it!Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.What We Offer You: Wow, I want that.A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.A stable, collaborative and supportive work environment.We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environmentThis isn’t a job – it’s a life changer – are you ready?Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",co,de
19,Charter School Growth Fund,Education,-1,Data Engineer,"Denver, CO",$88K - $125K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=8095&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_66d26d47&cb=1619364687533&jobListingId=4065152621,"THE ORGANIZATIONThe Charter School Growth Fund (CSGF) is a leading nonprofit venture philanthropy fund that identifies the nation's best public charter schools, funds their expansion, and helps to increase their impact. The portfolio includes 150 charter school networks that operate over 1,000 schools and serve more than 500,000 students in 31 states. We are committed to expanding the impact of schools that are closing achievement and opportunity gaps. Our investment strategy is like that of a nonprofit venture capital firm for public charter schools. The diverse ""portfolio"" of schools and leaders that we support include single-site charter schools as well as established networks that operate schools in several states. Ultimately, we believe the portfolio networks can serve more than one million students nationwide and in doing so, show how public schools can help students achieve excellent outcomes at scale.

This is an exciting time to join the Charter School Growth Fund. We are launching our next philanthropic fund in 2021, building on our 15-year track record of success. CSGF's new five-year ""Fund IV"" will be larger in size and scope than previous funds, with a goal to continue to fuel charter sector growth, accelerate innovation, and strengthen long-term outcomes for students, particularly students of color and those from low-income backgrounds. Our new fund will continue to prioritize investments in leaders of color as our current portfolio is led by more than 50% leaders of color and more than 50% female leaders. We believe it is vital for the networks we support to be proximate to the lived experiences of the students and communities they serve.THE OPPORTUNITYRole: The Data Engineer will play a critical role in overseeing the key systems that house data used by the entire organization. This role builds and maintains the infrastructure of our data warehouse that enables CSGF's internal teams to drive their work and to support our portfolio members. This is an ideal position for an experienced systems and database expert who is looking for an opportunity to play a meaningful role in the movement to expand great schools that put low-income students on a path to college and career success. The role reports to the VP of Analytics.

Team: CSGF's Analytics team is a trusted partner in providing support to the Investment Management Team, Investor Relations Team, Impact Team, portfolio members, external partners, and the charter sector. The Analytics Team provides readily accessible, strategic, and actionable insights that drive organizational decision-making and performance. It also serves as an expert resource to internal and external stakeholders to ensure that CSGF provides a broader impact on the education sector. Analytics team members are highly collaborative, seek to continuously improve their practices, and leverage each other's strengths to benefit the team and organization.KEY RESPONSIBILITIESThe responsibilities of the Data Engineer include:


Create and manage data architectures that integrate information from multiple sources using APIs, ETL processes, and other methods
Prepare and deploy schema updates, data migration, and ETL scripts
Design and develop database objects, stored procedures, views, functions, tables, and triggers; ensure their stability, reliability, and performance
Perform regular database monitoring duties to ensure databases and servers remain stable, accessible, and secure
Independently analyze and solve for database or server related issues in real time, collaborate with relevant parties to provide resolutions as necessary
Own and develop knowledge of current technology stack and analyze and implement new features, fine-tuning, and changes or improvements
Support the development of organizational dashboards, reporting tools, and tools for data access
Support the team that delivers on the annual cycle of data work: data collection process, internal & external reporting, new applicant process, and internal academic analyses
Assist in the completion of ad hoc projects by developing new queries to meet relevant reporting and visualization needs
Work with VP of Analytics to manage Azure subscriptions, usage, and drive technology investments and requirements to ensure that hardware & software needs for the organization are maintained and improved over time
Develop and maintains technical documentation for areas of responsibility

REQUIRED QUALIFICATIONS

Deep commitment to CSGF's mission
At least three years' experience managing a data warehouse (back-end architecture, front-end interface, tables, views, stored procedures, triggers, et al)
Experience with full-stack development, including front-end development, UX/UI, and cloud technologies
Technical proficiency with SQL/T-SQL, SQL Server, Azure Virtual Machines, and Visual Studio/SQL Server Data Tools (SSIS, SSAS, and SSRS), and at least one other language to wrangle and clean data (e.g. R, Python)
Strong quantitative skills with experience and demonstrated proficiency in managing large and/or challenging data sets; preferred experience wrangling varied, often highly variable, public datasets
Knowledge of and experience working with K-12 educational data
Customer-service orientation; understand end-user needs

WORKING AT CSGFWe are focused on hiring and developing great people and believe that building diverse perspectives across our team make us more effective in expanding our impact. (This is reflected in Our Commitment to Diversity Statement.) Our core values are:


Results. We work relentlessly to create efficient, measurable, and sustainable results. We strive for excellence and pursue our mission tenaciously. Ideally, you thrive working in a self-directed manner in a fluid environment where flexibility and tenacity are required.
Entrepreneurship. We embrace calculated risks and new approaches. We have an entrepreneurial spirit that welcomes innovation, diversity of ideas, and risk. We rely on you to question conventional wisdom and think independently.
Integrity. We are truthful, fair, and trustworthy in all aspects of our work. We hold ourselves and our partners to the highest ethical standards. We trust you will too.
Respect. We appreciate the challenges faced by education entrepreneurs and recognize the limits of our own knowledge. We understand that our ultimate success depends on that of our partners. Your humility will be key to building trusted and authentic relationships.
Teamwork. We value each of our team members as individuals but believe that we achieve the best results by working together. We willingly sacrifice individual interests and recognition for greater collective impact. We hope having fun at work is important to you and that you are a team player.

COMPENSATION

Compensation is commensurate with experience and education. The target salary range for this role is $110,000+ annually. CSGF offers a very competitive package of benefits, including: health, life, disability and dental insurance coverage; vacation/holidays and parental leave; and participation in CSGF's 403(b) plan. Candidates must have permanent authorization to work in the US.

START DATE

CSGF seeks candidates who can start as soon as possible.",co,de
20,GHX,Information Technology,3.6,Data Engineer I,"Louisville, CO",$69K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_fdc1cbb5&cb=1619364687533&jobListingId=4069577394,"The Data Engineer I works towards understanding the key business processes and the applications that support them. Under the supervision of Senior Data Engineers, the Data Engineer I will be responsible for the development efforts toward the creation, implementation, and support of existing and next-generation software solutions. This role will also analyze, design, program, debug, and modify software enhancements and/or new products used in local, networked, or Internet-related computer programs. The Data Engineer I will interact with users to define system requirements and/or necessary modifications in an Agile/Scrum environment.Essential Duties:Receives and understands completed technical design. Assists with stories while working with and/or shadowing other individuals on the team.Maintains code, bug fixes, and writes code under the team’s supervision.Codes web applications following specifications and using the appropriate tools. Follows best practices.May identify and raise issues to manager’s attention.Interacts directly and works closely with team members. Participates in all team meetings and ceremonies.Applies AGILE concepts and works collaboratively and closely with QA in an Agile/Scrum environment.Other Duties & Responsibilities:Development in Python, PySpark, SQL, and Node.JS.Technical writing in relevant areas including wikis, reports, and presentations.Competencies:May possess some theoretical knowledge or have little practical experience with technologies and/or automated test frameworks.Displays an ability to learn rapidly and adapt quickly to changing situations.Team player, contributes to team objectives, displays trust and mutual understanding, accepts constructive feedback, and handles confrontation constructively.Required Qualifications and Skills:BS Degree in Computer Science.1 year prior development experience and/or internship preferred.Possesses a strong academic record.Preferred Qualifications and Skills:PythonSQLAPI DevelopmentSnowflakeAWSEstimated Salary range for this position: $75,000 - $85,000The base salary range represents the anticipated low and high end of the GHX’s salary range for this position. Actual salaries will vary and will be based on various factors, such as candidate’s qualifications, skills, competencies and proficiency for the role. The base salary is one component of GHX’s total compensation package for employees. Other rewards and benefits include: health, vision, and dental insurance, accident and life insurance, 401k matching, paid-time off, and education reimbursement, to name a few. To view more details of our benefits, visit us here: https://www.ghx.com/about/careers/GHX: It’s the way you do business in healthcareGlobal Healthcare Exchange (GHX) enables better patient care and billions in savings for the healthcare community by maximizing automation, efficiency and accuracy of business processes.GHX is a healthcare business and data automation company, empowering healthcare organizations to enable better patient care and maximize industry savings using our world class cloud-based supply chain technology exchange platform, solutions, analytics and services. We bring together healthcare providers and manufacturers and distributors in North America and Europe — who rely on smart, secure healthcare-focused technology and comprehensive data to automate their business processes and make more informed decisions.It is our passion and vision for a more operationally efficient healthcare supply chain, helping organizations reduce – not shift – the cost of doing business, paving the way to delivering patient care more effectively. Together we take more than a billion dollars out of the cost of delivering healthcare every year. GHX is privately owned, operates in the United States, Canada and Europe, and employs more than 800 people worldwide. Our corporate headquarters is in Europe, Louisville, Colorado, just outside of Denver, with additional offices in Europe, Atlanta, Georgia, Chicago, Illinois, and Omaha, Nebraska.GHX provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. GHX complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.GHX expressly prohibits any form of unlawful employee harassment based on race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status. Improper interference with the ability of GHX’s employees to perform their expected job duties is absolutely not tolerated.",co,de
21,Ibotta,Information Technology,3.6,Data Engineer,"Denver, CO",$105K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=8095&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c8691cab&cb=1619364687534&jobListingId=4066473318,"Ibotta is looking for a Data Engineer to build something great with us. As part of the Data Services team, you will work with both Engineering and Analytics to develop and own stable, scalable, and forward-thinking data-driven processes. We're looking for a self-motivated engineer who has a passion for working with an event-based architecture heavily leveraging AWS cloud tools. The data engineering team is core to driving and delivering the current and future data, analytics, and decisioning platforms across Ibotta.

This position is located in Denver, Colorado or with the option of full-time remote. Candidates must live in the United States.

What you will be doing:

Embrace and uphold Ibotta's Core Values: Integrity, Boldness, Ownership, Teamwork, Transparency & Advocate for Savers
Work with engineering, analytics, and product management to implement and support event-driven processes
Be a key contributor in the engineering of distributed systems, frameworks, and design patterns of BI and Data Science/Machine Learning
Use Scala, Java, or Python to utilize Hadoop/Spark to collect and analyze large-scale datasets
Design, implement and maintain distributed messaging systems
Build, monitor, and maintain data ETL pipelines
Help manage Data Governance and Security
Administer and maintain our data infrastructure
Mentor junior data engineers in principles and best practices
Share relevant knowledge and evangelize Data Engineering with Platform and Analytics teams

What we are looking for:

Bachelor's degree in Computer Science, Engineering or a related field or equivalent work experience
2+ years of experience in software development, preferably with Scala, Java, or Python
1-2+ years of experience working in the Hadoop ecosystem, using tools such as Hive, Spark, or Pig
Proven expertise in taking data projects from ideation to implementation
Some experience with event-driven architecture design patterns and practices
Experience in database design and architecture principles, and strong SQL abilities
Experience with the following a strong plus:

AWS Cloud Services, like EC2, EMR, RDS, or Redshift
Experience with Python, Hadoop, Hive, and Spark (either PySpark or Scala)
Message Brokers such as Kafka or Kinesis
ETL tools and processes (Airflow or other similar tools)

Agile (Kanban or Scrum) development experience

About Us:

Built in Denver, CO, Ibotta (""I bought a..."") is a free mobile shopping app that gives users cash back on groceries and more. Through our partnerships with brands and retailers like Procter & Gamble, Kraft Heinz, Kellogg, Amazon, Walmart, Target and Uber, we've delivered over $800 million in cumulative cash rewards to our Savers. Guided by our values and our mission to make every purchase rewarding, we come to work energized by the business problems we get to solve, the technology we get to build, and the people we get to innovate (and have fun) with. Ibotta made Inc.'s 2020 list of the 5000 fastest-growing private companies in the U.S. for the third consecutive year. In 2019, we became the first mobile consumer technology company in Colorado to achieve $1B in valuation.

To learn more about what our Tech teams are doing day to day, visit Building Ibotta on Medium.com

Additional Details:

This position is located in Denver, CO and includes competitive pay, flexible time off, benefits package (including medical, dental, vision), Lifestyle Spending Account, 401k match, profit sharing and equity.
Base compensation range: $90,000 - $120,000
Ibotta is an Equal Opportunity Employer. Ibotta's employment decisions are made without regard with race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other legally protected status
Applicants must be currently authorized to work in the United States on a full-time basis.
For the security of our employees and the business, all employees are responsible for the secure handling of data in accordance with our security policies, identifying and reporting phishing attempts, as well as reporting security incidents to the proper channels.
",co,de
22,Perspecta,Aerospace & Defense,3.6,Senior Systems Engineer / MBSE engineer,"Colorado Springs, CO",$79K - $139K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_ca15c802&cb=1619364687534&jobListingId=4039470219,"Business Group HighlightsDefenseThe Defense group supports the Department of Defense (DoD) mission to keep our homeland and its citizens safe. We provide solutions to improve the Nation's defense by providing software, systems engineering, IT, training and logistics and fleet management solutions.ResponsibilitiesProvides the technical leadership and direction in implementing enterprise information/data management practices. Responsible for leading and engaging in information/data management projects including the Enterprise Information Architecture, information models and flows, data dictionaries, data standards, and data quality standards and processes. Responsible for developing and maintaining the logical Enterprise Information Architecture that enables seamless information interoperability of systems from transaction systems, document management systems and information delivery systems. Proven experience in developing information architectures aligned information lifecycle management. Proven experience performing conceptual, logical and physical data modeling with data modeling tools and database design in complex, large-scale data environments. Proven experience in transactional data modeling, dimensional modeling and object oriented modeling. Proven experience in developing scalable design of entities using advanced data structures (e.g., tall tables) is a plus. Experience in developing data models that support, inter alia, time dependency, historical tracings, taxonomies (simple and complex), and multilingual data. Knowledge of application modeling languages/techniques (e.g., UML, OML, entity relationship modeling, DFDs) including the ability to create and read the associated diagrams. Proven experience creating enterprise models incorporating master and reference data. Experience in creation of data dictionaries, defining metadata management approaches and governance processes. Experience in developing and implementing IT architecture plans, Enterprise Information Architecture standard and guidelines, software development methodologies and strategic plans. Experience in developing data sharing standards and architecting scalable service oriented solutions. Solid understanding of transaction and information systems, data warehouses, data marts, ODS, MDM methodologies and life cycle as well as ETL and MDM technologies.QualificationsRequires 12 to 15 years with BS/BA or 10 to 13 years with MS/MA or 7 to 9 years with Ph.D.Requires Unclassifed up to Top Secret ClearanceThe Colorado Equal Pay for Equal Work Act requires employers in the state of Colorado to disclose the following information. If the position applied to is not located in Colorado, the following information may not apply. Salary Minimum: $100,484.80 Salary Maximum:$214,822.40 The base salary range above represents the low and high end of the Perspecta salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and paid time off (PTO).About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
23,Colorado Community Managed Care Network,N/A,3.6,Data Engineer,"Denver, CO",$88K - $125K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_28a2b9a8&cb=1619364687534&jobListingId=4066158878,"The Data Operations department provides data management, integration, and reporting services for multiple external and internal consumers. The Data Engineer will be responsible for all aspects of data management that support CCMCN’s production services. Candidate must have experience in Microsoft SQL database development, data integration, ETL (extract, transform and load) tools and methods, analytics, reporting, and documentation.Essential Functions: 1. Provide development and maintenance support for data integrations between systems. 2. Provide development and maintenance support for the EDW and supporting databases. 3. Provide automated solutions whenever possible and proactively suggest alternative solutions. 4. Assist in the development of new databases and associated processes as necessary. 5. Provide data analytics report development for specific projects as needed. 6. Develop data validation reports and analysis where applicable. 7. Develop technical documentation of data integrations and processes. 8. Communicate and collaborate with other team members and clients to develop innovative data solutions. 9. Utilize up-to-date knowledge of database and data quality best practices to produce effective solutions. 10. Remain knowledgeable in healthcare data standards, measures and code sets as well as applicable data privacy practices and legal requirements.Required Skills and Experience:Experience working in a SQL environment, especially with data transformation, stored procedures, and query development.Experience working with a variety of ETL toolsExperience in Python, JavaScript, and/or C#, and familiarity with REST API connectionsKnowledge of data warehousing best practices, concepts and processes.Strong analytical and problem-solving skills, with demonstrated change management experience.Demonstrated ability to set and meet project timelines and deliverables.Effective interpersonal and communications skills with the ability to interact with various levels of personnel.Must be flexible, organized, self-directed, able to prioritize multiple tasks, and able to manage a full workload.Experienced in Microsoft Office and Microsoft Operating Systems.Fluency in written and spoken English.Additional Preferred Skills:Strong business and technical writing abilities.Experience working in Snowflake Cloud DatabaseKnowledge of healthcare data standards such as HL7, FHIR, CCD, CCR and claims data.Knowledge of standard healthcare code sets like LOINC, ICD9/10, CPT4 and SNOMED.Knowledge of IHI triple aim, clinical quality improvement, and primary care operations/workflow.Ability to stay current on healthcare reporting requirements such as UDS, PQRI, NQF, Meaningful Use and Patient Centered Medical Home.Ability to attend conferences and workshops for further education to expand and improve management skills.Base pay range: $70-85K/yearBenefits: CCMCN provides a generous, comprehensive benefits package that includes:Health, dental, and vision insurance plans.FSA, DCA, and employer sponsored HRA.Life, AD&D, and long-term disability insurance plans.401K retirement plan with employer match.Employee Assistance Program (EAP).Paid leave including vacation, sick, and holiday, including one floating holidayColorado Community Managed Care Network (CCMCN) is an equal opportunity employer and is committed to a diverse and inclusive work environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.At CCMCN, our mission is to provide services that enable its members and their community partners to succeed as efficient, effective, and accountable systems of care.CCMCN’s vision is that all Coloradans have access to high quality, integrated, accountable health care. Areas of focus include population health, accountable care, shared services, health information technology and clinical quality improvement programming. CCMCN is governed by a Board of Directors comprised of organizational representatives from each of its health center members as well as representation from Colorado Community Health Network (CCHN) and clinician representatives. Through working with health centers and community partners, CCMCN provides technological and analytical tools that help create a more comprehensive and collaborative network of care for Coloradans.TO APPLY:Please submit a resume and cover letter by email to jobs@ccmcn.com.PLEASE INCLUDE THE JOB TITLE IN THE SUBJECT OF THE EMAIL.No phone calls please.",co,de
24,CapTech Consulting,Information Technology,3.9,Data Engineer,"Denver, CO",$85K - $103K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_d6e16426&cb=1619364687534&jobListingId=4069671869,"Company DescriptionCapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.Job DescriptionCapTech Data Engineers enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Distributed Data Engineers are focused on delivering data engineering solutions using non-Cloud Specific Tools in a distributed computing tech stack. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients.Specific responsibilities for the Data Engineer – Distributed Systems position include:Developing data pipelines and other data products using on-premises Hadoop clusters, hybrid infrastructure, Snowflake, Databricks, or MPP systemsAdvising clients on specific technologies and methodologies for utilizing resources to efficiently ingest and process data quicklyUtilizing your skills in engineering best practices to solve complex data problemsCollaborating with end users, development staff, and business analysts to ensure that prospective data architecture plans maximize the value of client data across the organization.Articulating architectural differences between solution methods and the advantages/disadvantages of eachQualificationsPreferred QualificationsTypical experience for successful candidates includes:Experience delivering solutions on Hadoop or other distributed processing system (Snowflake, Databricks, or MPP)Ability to think strategically and relate architectural decisions/recommendations to business needs and client cultureExperience in the design and implementation of data architecture solutionsA wide range of production database experience, usually including substantial SQL expertise, database administration, and scripting data pipelinesAbility to assess and utilize traditional and modern architectural components required based on business needs.A demonstrable ability to deliver production data pipelines and other data products. This could be through hands on experience, degrees, certifications, bootcamps, or other learning.SkillsSuccessful candidates usually have demonstrable experience with technologies in some of these categories:Languages: SQL, Python, Java, R, C# / C++ / CDatabase: Hive, Snowflake, Teradata, Presto, Vertica, NetezzaDevOps: git, docker, subversion, Kubernetes, Jenkins, CA, Dollar UniverseAdditional Technologies: Hadoop, Databricks, Spark, KafkaPopular Certifications: Hadoop certification from Hortonworks / Cloudera, MapR, IBM; database certification from Snowflake or Teradata; Databricks certificationAdditional InformationWe provide challenging and impactful opportunities in our client work and internal teams, while keeping individual interests in mind. We want everyone at CapTech to be able to envision a lifelong career here, which is why we offer a variety of career paths based on your skills and passions. As a CapTecher, you will experience exciting, and rewarding roles that help you grow and make a difference, while having fun along the way.At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:Competitive salary with performance-based bonus opportunitiesSingle and Family Health Insurance plans, including Dental and Vision coverageShort-Term and Long-Term Disability InsuranceMatching 401(k)Competitive Paid Time OffPaid Maternity Leave and Family BondingTraining and Certification opportunities eligible for expense reimbursementTeam building and social activitiesMentor program to help you develop your careerCapTech supports Equal Pay for all. In addition, in the State of Colorado, we are committed to Equal Pay for ALL in accordance with the Colorado Equal Pay for Equal Work Act. The base pay range for this role is: $75,000 - $160,000.CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements).CapTech is a Drug-Free work place.Candidates must have the ability to work at CapTech’s client locations.All positions include the possibility of travel.CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.#LI-AB1",co,de
25,RTRP,N/A,-1,Sr Data Eng (Big data) – Start-up,"Denver, CO",$107K - $141K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1044077&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_6df29654&cb=1619364687537&jobListingId=4043904886,"Sr. Data Engineer5+ years of experience in high level programming languages such as Java, Python.Proficiency with databases and SQL is required.Bachelor's and/or Master's degree, preferably in CS, or equivalent experienceDemonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutionsExperience designing and deploying high performance systems with reliable monitoring and logging practicesProficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig.Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm.Experience with large scale data warehousing, mining or analytic systems.Ability to work with analysts to gather requirements and translate them into data engineering tasksAptitude to independently learn new technologies.Responsibilities:Develop and automate large scale, high-performance data processing systems (batch and/or streaming) to drive business growth and improve product experience.Build scalable Spark data pipelines leveraging scheduler/executor frameworkDesign our data models for optimal storage and retrieval and to meet critical product and business requirements.Understand and influence logging to support our data flow, architecting logging best practices where neededContribute to shared Data Engineering tooling & standards to improve the productivity and quality of output for Data Engineers across HeydayImprove data quality by using & improving internal tools to automatically detect issuesJob Type: Full-timePay: $140,000.00 - $160,000.00 per yearSchedule:8 hour shiftEducation:Bachelor's (Required)Experience:Python: 1 year (Required)Data Warehouse: 1 year (Preferred)Work Location:Fully RemoteCOVID-19 Precaution(s):Remote interview processVirtual meetings",co,de
26,Peraton,Information Technology,4,Principal Cyber Systems Engineer - TS/SCI required,"Schriever AFB, CO",$64K - $129K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_7b9fc611&cb=1619364687534&jobListingId=4068154944,"Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator, we are a trusted provider of highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies, including the Intelligence Community, Department of Defense, Department of Health and Human Services, and NASA. Every day, our 10,000 employees do the can’t be done, solving the most daunting challenges facing our customers.This Cyber Systems Engineer will support Peraton's five year Cyber Defense Engineering and Training II (CDET II) contract with the newly formed U.S. Space Force (USSF). The purpose of the CDET II contract is to provide cyber defense expertise to assigned Space Mission Systems with the goal of improving cyber defense capabilities.Roles and Responsibilities may include:Design, develop, and execute preventative measures to secure and fortify satellite command and control networks.Provide analysis and support for cybersecurity engineering and architecture considerations affecting DoD IT assets used to enable Space Force missions.Provide recommendations for cybersecurity and network hardening (Microsoft Windows and Linux networks) improvements.Provide analysis focused on cyber defense data flows/usage and transactions.Perform technical planning, system integration, verification and validation, and risk analysis.Work performed throughout systems development life cycle to include concept, design, test, installation, operation, maintenance and disposal.Responsible for analyzing, evaluating, and making recommendation to employ current and emerging technologies, Commercial Off The Shelf (COTS), or Government Off The Shelf (GOTS) software for integration into existing 614th AOC networks.Translate customer requirements into technical solutions.Recommends plans to re-architect assigned Government IT systems to improve cyber resilience.Provide technical solutions to a wide range of complex difficult problems. Solutions must be consistent with organization objectives.Independently determines and develops technical solutions. Frequent customer interaction.Basic Qualifications:Bachelor’s degree and a minimum five (5) years of experience. May consider an additional 4 years of experience in lieu of degree.Minimum 3 years of SIEM, IDS, or IPS maintenance/implementation experience.Must possess an active IAT III certification from the following: CASP+ CE, CCNP Security, CISA, CISSP (or Associate), GCED, GCIHDemonstrated complete understanding and wide application of technical principle, theories, and concepts in the field of cyber security. General knowledge of other related disciplines.Must possess an active TS/SCI security clearance. US citizenship required.Colorado Equal Pay for Equal Work Act:The yearly compensation range for this role is: Minimum- $ 101,200 to Maximum- $ 151,800.The successful candidate will be offered a yearly compensation that aligns with their individual skills and experience as it directly relates to the position requirements.In addition to the yearly salary, Peraton provides a variety of benefits to include: health insurance coverage, life and disability insurance, savings plan, company paid holidays and paid time off (PTO).We are an Equal Opportunity/Affirmative Action Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state, or local law.",co,de
27,Comcast,Telecommunications,3.9,Sr Data Engineer,"Englewood, CO",$91K - $158K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1044074&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_c0296f0b&cb=1619364687534&jobListingId=4044273770,"Job Summary Responsible for planning and designing new software and web applications. Analyzes, tests and assists with the integration of new applications. Oversees the documentation of all development activity. Trains non-technical personnel. Assists with tracking performance metrics. Integrates knowledge of business and functional priorities. Acts as a key contributor in a complex and crucial environment. May lead teams or projects and shares expertise.Job DescriptionComcast brings together the best in media and technology. We drive innovation to create the world’s best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.Do you have a real passion for building tools and products to improve the Customer Experience (CX), User Experience (UX), and Quality? Are you an “outside of the box thinker”? If yes, then join our team of highly skilled software development engineers who collaborate closely to solve complex problems which may impact our customers and develop user focused tools and applications to make it easier to identify, triage and resolve issues which impact our customers’ experience. If you share in our passion for teamwork, our vision to revolutionize CX, and our goal to lead the future in user-centric design, we want you to fast-forward your career at Comcast.Job Summary:Design and build scalable, high-volume Java web applications focused on Platform as a Service.Optimize the performance of the system for higher performance.Participate in design and code reviews.Analyzes, tests, and assists with the integration of new applications.Experience in Agile framework and its various implementations like Scrum, Kanban etc.Develop systems that are highly scalable, but easy to maintainCollaborate with colleagues on design and architectureBuild high-throughput and low latency micro services.Assists with tracking performance metrics.Provide solutions to complex problems and formally operationalize a product to resolve the problem.May lead teams or projects and shares expertise.Trains non-technical personnel.Solid understanding of Devops and has the tact to build tools for supporting application in production.Integrates knowledge of business and functional priorities.Acts as a key contributor in a complex and crucial environment.Excellent oral and written communications skills required.Oversees the documentation of all development activity.Employees at all levels are expected to:Understand our Operating Principles; make them the guidelines for how you do your job.Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communities.Core Responsibilities:Collaborates with project stakeholders to identify product and technical requirements.Conducts analysis to determine integration needs.Designs new software and web applications, supports applications under development, and customizes current applications. Develops software update process for existing applications. Assists in the roll-out of software releases.Trains junior Software Development Engineers on internally developed software applications.Oversees the researching, writing, and editing of documentation and technical requirements, including evaluation plans, test results, technical manuals, and formal recommendations and reports.Keeps current with technological developments within the industry. Monitors and evaluates competitive applications and products. Reviews literature, patents, and current practices relevant to the solution of assigned projects.Provides technical leadership throughout the design process and guidance with regards to practices, procedures, and techniques. Serves as a guide and mentor for junior and mid-level level Software Development Engineers.Assists in tracking and evaluating performance metrics. Ensures team delivers software on time, to specification, and within budget.Works with Quality Assurance team to determine if applications fit specification and technical requirements.Displays expertise in knowledge of engineering methodologies, concepts, and skills and their application in the area of specified engineering specialty.Displays expertise in process design and redesign skills. Presents and defends architectural, design, and technical choices to internal audiences.Consistent exercise of independent judgment and discretion in matters of significance.Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.Other duties and responsibilities as assigned.Job Specification:Java developer with 7-11 years of experience designing and implementing distributed systems in a UNIX/Linux environment.Development expertise should be in development from scratch, maintenance, and troubleshooting.Hands-on experience working through the entire micro services, both REST/SOAP and message-driven in java.Hands-on experience in Unix/Linux shell scripting and high-volume data processing environments.Experienced in deploying to cloud infrastructure especially in Pivotal Cloud foundry.Expert level skills with Spring framework and working knowledge of Spring boot.Experience in implementing SQL and NO-SQL database concepts. Mongo and Oracle experience is required.Experience in managed and distributed messaging queues, Kafka and/or RabbitMQ and/or Kinesis, experience is required.Experience in Spark streaming & databricks is highly preferredExperience working with AWS services like EC2, S3, Dynamo DB etc. preferred.Experience working with Hadoop system preferred.Experience building complex software systems that have been successfully delivered to customers.CI/CD background with architectural knowledge around how the services are constructed.Experience in analyzing system performance and propose solutions to build a highly scalable and available system.Ability to Present to Technical and Non-Technical AudiencesExperience in lead rolesBachelor’s Degree or Equivalent in Engineering, Computer Science etc.EducationBachelor's DegreeRelevant Work Experience7-10 YearsBase pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.",co,de
28,DISH,Telecommunications,3.2,Data Analytics Engineer,"Englewood, CO",$59K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=132977&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_385033e8&cb=1619364687535&jobListingId=4040207640,"At DISH Wireless, we reimagine connectivity through new platforms, new business models and new ways of thinking.Today, we are building America’s first cloud-native 5G network to transform the way we live, work and play with unlimited potential. Our teams operate at the intersection of wireless, data analytics, AI and the cloud to create something state-of-the-art, radically original, and truly unlike what anyone else can.High-level job responsibilities: The Data Analytics Engineer is responsible for building the DISH Wireless Commercial data integrations and implementing the fully-automated analytics modules catering to DISH business team needs and the analytics product offerings in the marketplace for Commercial customers. The engineer will focus on building the data pipelines, insights, KPIs and metrics using the DISH Wireless data from BSS, OSS, NSS or external sources to business/partners/customers. This individual will play an active role in delivery and ensure alignment to the end-state architecture.Day-to-day job responsibilities:Provide technical expertise in Wireless AnalyticsUnderstand business needs and analytics product offerings to design and build data and analytics solutionsAnalyze business and technical requirementsQuickly build prototypes to test out proof-of-conceptsAddress technical concerns, ideas and suggestionsAssist in solving technical problems when they ariseMonitor systems to ensure they meet the partner, user and business goalsDeliver solutions, features using agile delivery methodologies#LI- AY1Specific qualifications:3+ years as a Data Analytics engineer in the wireless and/or telecom space esp., in Sales, Marketing, Retention, Product, Revenue and Partner Management etc5+ years of hands-on experience with development and delivery of secure, reliable and scalable big data solutions using agile methodologiesExperience in building highly performant SQL based solutions delivered using file feeds, Data-as-a-Service APIs, streaming data analytics or BI tools like TableauExperience in data management and engineering capabilitiesExperience in cloud technologies (like AWS) and data analytics platformsExperience in delivering of self-service analytics, insights, KPIs and metricsExperience working with cross-functional teams in a dynamic environment across different geographies and vendorsExperience building and maintaining data catalog with dictionaryExperience with scheduling tools like Control-M or AirflowEnsure compliance on all deliverables by performing data audits and analysisCompensation: $99,360.00/Yr. - $138,230.00/Yr.From versatile health perks to new career opportunities, check out our benefits on our careers website.Employment is contingent on Successful completion of a pre-employment screen, which may include a drug test.",co,de
29,Jobot,Business Services,4.8,Senior Data Engineer,"Denver, CO",$102K - $118K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=798489&s=58&guid=0000017909a82c7bb17ec2cf994dbfdb&src=GD_JOB_AD&t=SR&vt=w&cs=1_9abb3e8f&cb=1619364687535&jobListingId=4065691653,"100% Remote opening for a Senior Data Analytics Engineer - Microsoft Azure, ETL/ELT, .NET, C#, PowerShell! Base pay up to $160,000This Jobot Job is hosted by: Patrick MurrayAre you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.Salary: $140,000 - $160,000 per yearA bit about us:Based out of Colorado and established in 2008, we are a well-established Cloud and end-to-end Software solutions company specializing in helping our customers achieve the best results possible with the latest and greatest of modern technologies. We are currently looking for a new Data Software Engineer to join our advanced engineering team. This position is fine to work from home!This role includes a mix of project delivery and pre-sales activities including discovery, scoping, and estimating.Why join us? Competitive base salary - $140,000 to $160,000 Work Remotely Flexible Paid Time Off (YOU take the time you need) 8 Day Holiday Pay Paid Volunteer Day Employer Contributed 3 Tier Medical Plan Options Employer Contributed Dental Plan 100% Employer-Paid Vision Plan 100% Employer-Paid Short-Term Disability Plan 100% Employer-Paid $50,000 Life Insurance Plan including AD&D Voluntary Long-Term Disability Plan  Voluntary Benefits including; Accident, Critical Illness, and Medical Bridge Options Additional Supplemental Life Insurance Plan including Spouse and Children 3% Employer Match 401k Retirement Plan Life Assistance and Wellness Programs Green Initiatives  Training and Development Programs  Employee Events  100% Employer Paid Gym MembershipJob DetailsResponsibilities: Lead discussions with client leadership explaining architecture options and recommendations Designing and delivering Data Analytics solutions Work with developers to build ""Smart Applications"" that incorporate data analytics to drive decision making within the application? Requirements Analysis and Solution Architecture Design Data modelling and data architecture design ETL/ELT, data integration and data migration design Master data management system and process design and implementation Advise clients on database management, integration and BI tools Perform architectural assessments of the client's Enterprise Data Warehouse (EDW) and data analytics systems Work with the sales and delivery teams to create and deliver client proposals and demonstrationsRequirements: 5+ years full-time professional experience in a project-based, consultative role for data platform, data warehouse, and business intelligence solution development Extensive experience in ETL/ELT, data integration, and data migration design Extensive background building and delivering business intelligence, data warehouse, or data analytics solutions using Microsoft technologies such as Azure Data Factory, Databricks, SQL Data Warehouse (now Synapse Analytics), and Power BI Experience managing client expectations, leading data/analytics solution delivery teams Experience using technologies such as Azure Data Lake, Azure SQL DW (now Synapse), Azure Data Factory, or Azure SQL DB and Azure Data Lake Desire to learn and leverage Microsoft Azure platform data technologies Development background using C#, Python, or PowerShell Desire to move into a consulting roleInterested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",co,de
0,Intuit,Information Technology,4.4,"Software Engineer 2, Big Data","Los Angeles, CA",$107K - $196K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=0000017909c73503b2642eaae8da874e&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_81478b62&cb=1619366721440&jobListingId=3811135994,"OverviewOur formula for innovation begins with agile, cross-functional teams that welcome diverse perspectives and embrace collaboration. Inspirational working environments help spark fresh ideas, with state-of-the-art technology and creative workspaces that allow our team to decide how they want to work. And our shared commitment to make a meaningful impact for our customers helps us push the boundaries of technology to uncover new possibilities. If you have a commitment to excellence and a passion for innovation, come join our team.",la,de
1,Ursus,Information Technology,4.4,Data Engineer,"Santa Monica, CA",$123K - $188K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=0000017909c73503b2642eaae8da874e&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_8510d0d9&cb=1619366721441&jobListingId=4066624996,"Job Title: Data EngineerLocation: Remote (West Coast Preferred)Duration: 6+ month contractSummary:As a data engineer, you bring software engineering best practices to production and maintenance of analytics code and bring an engineering mindset to discussions on how data is modeled from its source to its use in the data warehouse as business data & reporting data. You will be responsible for designing and implementing new AWS-based data solutions new data processing, datasets, and systems to support various advanced analytics needs.Responsibilities:Capture business requirements for analytics and translate complex ones into technical requirements. Collaborate with teams to design & implement end-to-end solutions.Design and build well-engineered data systems and services to support data analytics using AWS cloud services and Snowflake DWH.Implement data pipelines and modern ways of automating ELT data pipelines using orchestration tools.Own data model and test the data produced in order to ensure it is of high quality.Be part of discussions with product managers and analysts in order to guide them in their understanding of the data in the data lake, shape the product solutions and to better grasp the context of requirements coming your way.Use SQL queries to transform data in our data lake in order to move it from raw nuggets into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations on our platform. Investigate discrepancies in data.Assure accuracy of data processing and outputs through consistently high software development skills, adherence to best practice, thorough testing, and peer reviews.Provide production support for Data Warehouse issues such as data load problems, transformation translation discrepancies.Lead some refactoring of our data warehouse where needed, in order to make data more consistent, better documented and the pipelines more resource-efficient.Documents analytics datasets and any business logic.Qualifications:5+ years, demonstrable, hands-on professional software development skills using Java or Python.Demonstrable professional experience designing, building, and maintaining data systems and processes using cloud-based platforms such as GCP, AWS, including working knowledge in Unix/Linux OS, shell scripting, and tools.A solid experience and understanding of architecting, designing, and operationalization of large-scale data and analytics solutions on Cloud Data Warehouse such as Snowflake, Google BigQuery, or AWS Redshift is a must.Expertise in using AWS cloud-based systems and services to acquire and deliver data.Excellent SQL knowledge and hands-on experience with the ability to create efficient data models (applied to data warehousing in particular).Experienced with ELT processes to transform data, set up and schedule jobs with DBT, Python, Airflow, and cron.Experienced with building web services with Rest, GraphQL or GRPC.Experienced in CI/CD practices including unit testing, automation testing, data migration, code quality, performance, and integration/systems testing.IND123",la,de
2,Spokeo,Information Technology,3.9,"Data Engineer, Web Personalization","Pasadena, CA",$58K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_acedb4e9&cb=1619366721442&jobListingId=4065440063,"Spokeo is a people search engine that both enlightens and empowers our customers. With over 12 billion records and 14 million visitors per month, we reconnect friends, reunite families, prevent fraud, and more.We’re looking to hire a Data Engineer, Web Personalization, for our team based out of our Pasadena, California. You will join a cross-functional scrum team that values continuous product improvements. You will use Ruby on Rails, React, HTML, CSS, Javascript, and SQL to enhance our full-stack web personalization infrastructure. At Spokeo, expect your code and architecture to be constructively challenged, along with your basketball, badminton, tennis, pool, ping pong, and/or board game skills!Responsibilities:You'll design and develop robust full-stack analytics solutionsYou'll work in cross-functional scrum team to achieve regular sprint goalsYou'll use Spokeo’s customer data platform to build analytics-driven product featuresYou'll embrace software development best practices such as TDD, documentation, design patterns, secure coding, and algorithmic optimizationRequirements:Bachelor’s degree in computer science, a related field, or work experience equivalentAt least 5+ years of web application development experienceAt least 2+ years using SQL and NoSQL technologiesStrong scripting, programming preferably using Python, Ruby, and SQL.Strong foundation in object-oriented programming, algorithms, and data structuresExperience implementing and troubleshooting high-usage, high-throughput systemsExperience optimizing web site performance on both the client and server-sideExperience developing with cloud services such as AWS a plusExperience with services, microservices, and serverless environments a plusExperience with productizing personalization ML models in AWS is a plusKnowledge of agile methodology and Scrum framework a plusPrivacy Notice for Candidates: https://www.spokeo.com/recruiting-policySpokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products, and be relevant in a rapidly changing world.Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file and 2) being assigned to the open position (as a search) via our applicant tracking solution.This is a remote position.",la,de
3,Bastion Technologies,Consumer Services,4.2,"BT-1902 SME EEE, Parts Engineer (Photonics)","Pasadena, CA",$60K - $137K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5aa6daa4&cb=1619366721443&jobListingId=3735629241,"Job Description:ResponsibilitiesSupport to JPL's Electronic Parts Reliability Engineering Group, responsible for reviewing all Electrical, Electronic and Electromechanical Parts (EEE) parts for reliability related performance and advises the projects on optical component & part selection, conducts scientific experiments or theoretical analysis to determine the physical behavior of photonic parts in a space-like radiation environment, oversees photonic parts procurement to ensure compliance with engineering requirements and maintains part inventories.As a Photonics Component Engineer, responsible for:Evaluate, select and approve optical and photonic components and photonic ICs (PICs) from design, construction, quality and reliability perspectives for use in space missions.Advise project management on highly complex electronic part selections that maximize reliability while considering schedule and cost constraintsDevelop part engineering specifications andInterface with Mission Assurance Managers, Cognizant Engineers, and part suppliersWork with manufacturers on new component development and lead resolution of technical issues in order to support project flightSupport technical surveys and audits of photonic part suppliers.Perform statistical data analysis and risk assessmentDisposition test and inspection failures, including those during screening, destructive physical analysis (DPA), lot qualification, and receiving inspection.Develop screening methods that effectively reduce risk in space and during manufacturing of magnetics components.Understand potential failure mechanisms affecting photonic components and participate in failure investigations and reliability assessment.Utilize the Part Acquisition and Review System (PARS) to review project parts lists and assess part compliance to project requirements.Serve as an essential team member within the Group, ensuring part reviews, screening, and testing, and procurement meet project schedule.Required Skills:Bachelor of Science degree with equivalent course work in Electrical or Electronic Engineering, Physics, or an equivalent field.20+ years of related experienceMust be a US citizenMust be able to pass a national agency checkMust be able to pass a pre-employment drug screeningExtensive understanding and experience in the selection, procurement, manufacture, use and testing/screening of high reliability optical and photonic components for space-flight applications.Strong working knowledge of photonic part properties, including photon generation, detection, and manipulation through emission, transmission, modulation, signal processing, switching, amplification, and sensing elements.Ability to multi-task with an established track record of meeting schedule milestones.Excellent written and oral communication.Ability to work well with cross-functional teams with design engineers, line management, and project management.Deep understanding and substantial use of common computer tools.Other Desired Skills:Relevant experience in photonic technology including manufacturing or design.Knowledge of NASA parts requirements including EEE-INST-002Contract Technical Management.Demonstrated leadership skills.Bastion participates in the e-Verify and EEO.",la,de
4,Johns Hopkins Applied Physics Laboratory (APL),Aerospace & Defense,4.7,"Network and Cyber Security Systems Engineer (El Segundo, CA)","El Segundo, CA",$101K - $153K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_fcaa8f6f&cb=1619366721443&jobListingId=3810547774,"Do you have a passion for developing cyber systems and software architectures?If so, we are looking for someone like you to join our team at JHU Applied Physics Laboratory.As a Network and Cyber Security Systems Engineer, your role will be to work closely with Government sponsors to define cyber and software architectures for sponsor solutions, identify test approaches and environments to evaluate the impacts of cyber operations on all aspects of space systems, develop system CONOPS, work with stake holders to define system requirements, and assist sponsors to ensure user needs are met and contractors are meeting requirements and deliverables. Act as Technical Advisor Agent to sponsors in architecture, program development, system test, and in contractor program reviews, both internal and external.In addition, you will...Apply systems engineering processes to define and translate concepts, identify architecture technical requirements, identify test needs, and determine test and evaluation approaches. Participate in system design, development, prototyping, demonstration and testing efforts. Work as part of a Government team to architect space systems from a cyber operations perspective, validate and verify design specifications, document and analyze requirements, review and critique system verification plans / procedures, and analyze system performance vs. requirements and user needs.Interact closely with multiple stakeholders, system and software engineers to arrive at a consensus on the design, development and test phases of the program. Present analysis, propose technical solutions, model and measure performance, and validate results.Review cyber and software architectures and designs of applications within distributed computing networks, data networks, network simulation, and tactical networks. Perform vulnerability assessment of space segments, computer networks, and satellite ground segments.Identify and coordinate technical work performed for sponsor at APL Laurel location.Participate as a member of the team to evaluate program risks and develop mitigations. Brief approach, implementation and progress to APL management and sponsors.You meet our minimum requirements if you have....A BS in Aerospace Engineering, Electrical Engineering or Computer Science related disciplines.10+ years of strong software systems engineering and software development experience with emphasis on cyber security, software security requirements and definition, and software interaction with space systems. Demonstrated understanding of software development, software intrusion techniques, understanding of communication networks, and overall system vulnerability.Demonstrate strong analytical and problem solving skills with understanding of communication networks.Demonstrate experience in software and network system engineering methodologies, principles, and concepts to solve systems related challenges.Demonstrate the ability to work in a dynamic environment that includes working with changing needs and requirements.Demonstrated excellent interpersonal skills, be able to work independently, work as a team player and work closely with sponsors.Demonstrated outstanding written and oral communication skills and good organizational skills.The ability to travel occasionally.A Current Top Secret clearanceYou will go above and beyond our qualifications if you have:A MS in Aerospace Engineering, Electrical Engineering, or Computer Science related disciplines and 15+ years of frontend system engineering and software system engineering experience with understanding of cyber security.Experience with current Air Force satellite ground networks, DoDAF, DoD 5000, and model based systems engineering (MBSE) .Demonstrated ability in Cyber and Computer Network security and protection.Experience in Cyber intrusion techniquesNote: Position will be located in Los Angeles, CA, on-site at customer/sponsor facility.Why work at APL?The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation's most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates.At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL's campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers.",la,de
5,CM Solutions,"Construction, Repair & Maintenance",4.8,Cost Engineer / Financial Analyst - Project Controls,"Los Angeles, CA",$40K - $75K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044077&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ea129293&cb=1619366721444&jobListingId=3625677353,"CMS has a passion and focus on project controls for construction projects in Transportation, Energy, Water/Wastewater, and Infrastructure. We hire exceptional people to fill highly-desirable staff augmentation and consulting assignments including cost engineering, CPM scheduling, change management, estimating and claims consulting. CMS provides a competitive salary, as well as a comprehensive benefits package, including full “Gold” level health, dental and vision coverage, 401(k) retirement with matching funds, tuition/training assistance, as well as generous paid time off/vacation time. We truly believe that CMS employees are our most valuable assets and work hard to create an enjoyable and productive work environment that respects and appreciates the professional caliber of our employees.NO RELOCATION PROVIDEDPosition SummaryThe successful candidate will have proven cost engineering experience with complex, multi-phase, multi-million dollar construction and/or renovation projects. The general job duties include: Prepares detailed computer generated cost reports, charts and diagrams; Provides analysis and review of cost/budget expenditure and maintains cost control reports; Promptly reports anticipated cost overages or other unsatisfactory cost elements; Maintains liaison with Data Processing in developing support for network calculations, printouts and cost reports, and other cost related services.Essential Job DutiesMonitor project budgets for the multi-billion dollar Capital Improvement Programs at Los Angeles World Airports and Gas and Electric Utilities around Southern CaliforniaReview and analyze sub-contractor invoices. Prepares job costing reports to allocate these expenditures against the appropriate WBS numbers. Ensure that both commitments and expenditures follow the same allocation methodology.Perform cost-to-complete analysis for all cost elements within a project taking into consideration staffing plans, contract commitments, and expenditures to date, change orders and trends.Attend project meetings to provide Project Management with current financial information and trend log regarding potential impacts to project budget or forecast.Provide progress reporting documents and briefing materials as required. Develop creative reporting tools to communicate complex project sequencing and/or progress assessments.Review task orders for contractors and sub-consultants to ensure necessary budget and/or contract capacity exists.Analyze bid award values against current budget and prepare reconciliations to include in the current forecast at completion.Analyze change order values against current budget and prepare reconciliations to include in the current forecast at completion.Prepare data to support documentation required journal vouchers for budget transfersHardware/Software KnowledgeThorough familiarity with MS office suite software - Word, Excel, PowerPoint, and Outlook, (highly proficient in Excel..advanced functions such as VLOOKUP’s, pivot tables, filtering/sorting, charts and graphing).Experience in SAS or SAS VA (Visual Analytics).Experience performing SQL queries.Experience programming with Visual Basic is a plus.Other software that may be beneficial; Business Objects, Crystal Reports, JIRA, NetSuite, Power BI, PowerPoint, Python/Orange, R Studio, Report Builder, Enterprise/VA, SharePoint, SSRS, Tableau, VisioFamiliarity with Primavera, (P6), familiarityProfessional Experience Level/Other Qualifications5- to 10-years cost engineering experience with 3- to 5-years in direct support of an active construction projects.Demonstrated experience managing and reporting the cost components of large-scale, complex projects; including developing and managing a progress reporting methodology for a complicated design effort.Experience with Design-Build and Construction Management at Risk delivery methods is desirable.Demonstrated ability to understand technical and complicated construction program and the ability to communicate progress to both technical- and management-level personnel.Ability to work with others, a self-starter with results-driven focus.Flexible to a potentially varying shift time or overtime schedule.To Apply: Please provide relevant project history.Job Type: Full-timeExperience:construction cost engineering: 5 years (Required)Work authorization:United States (Required)Application Question:Are you located in Southern California?",la,de
6,"E2 CONSULTING ENGINEERS, INC.",Business Services,3.6,Cost Engineer,"Los Angeles, CA",$45K - $88K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044077&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_bcbecdf6&cb=1619366721444&jobListingId=4043048906,"E2 Consulting Engineers, Inc. (E2) is a professional services firm established in 1988 specializing in a full spectrum of engineering services including, project engineering and design, federal base operations and infrastructure support services, gas pipeline construction and inspection services, environmental consulting and remediation, and information technology services. At E2, we value safety, innovation and collaboration, and we are dedicated to excellence.A mid-level Cost Engineer position able to work and to provide analytical support on any project. The Project Cost Engineer will have excellent computer skills and knowledge of the various tools and software of Project Services.ResponsibilitiesCost Plan Development and AnalysisUse the cost and schedule plan to determine if project objectives are achievable.Create, maintain, and update monthly forecast budgets.Forecast costs to complete on projects and maintain reports with accuracy.Assess and report on project performance using established industry standards.Ensure that responses to project budget reflect accurate and current project cost information and stakeholders are in concurrence.Communicate project risks related to costs to key stakeholders.Assist Project Managers in preparing funding requests to gain project authorization.Assist Project Managers in gaining funding changes to projects through the Unifier change control system.Input data into various programs and prepare various cost and forecasting reports.Analyze and trend cost variances by comparing the current cost plan against the actual cost to date.Analyze and validate unauthorized costs to projects and report to Project Managers and Supervision.Verify that project cost and schedule milestones were/were not attained and provide input to identify future process or business improvements and work with responsible parties to implement.Manage project funding orders and ensure all required documentation is entered and/or correct in tracking documentation systems.Maintain scope change, contingency release, change order, and journal entry logs.Maintain written and electronic project documentation and records for required aspects of the project: Maintain project files in accordance with established guidelines and requirements.Assist in the closeout process of a project with other departments. Work closely with Project Management to determine required deliverables and expected dates to achieve closeout.May provide special reports for supervisor or manager upon request.RequirementsQualificationsBachelor's Degree in Engineering or relevant degree in Construction Management, Project Management, etc.4-7 years as a Cost Engineer or relevant Project Controls experience.DesiredExperience with Cost Engineering software tools:Cost experience associated with construction operations experienceAccounting/budgeting knowledgeMathematical skillsPlease no solicitation of any kind from agencies, staffing, or recruiting firms.E2 Consulting Engineers, Inc. offers an excellent benefits package including health, dental, vision, and life insurance, 401(k) with employer match, paid time off.Preferred method of application is through our online job system.E2 Consulting Engineers, Inc. is an Equal Opportunity Employer.Job Type: Full-timeBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offProfessional development assistanceReferral programRelocation assistanceTuition reimbursementVision insuranceSchedule:8 hour shiftEducation:Bachelor's (Preferred)Work Location:One locationThis Job Is Ideal for Someone Who Is:Dependable -- more reliable than spontaneousPeople-oriented -- enjoys interacting with people and working on group projectsAdaptable/flexible -- enjoys doing work that requires frequent shifts in directionDetail-oriented -- would rather focus on the details of work than the bigger pictureAchievement-oriented -- enjoys taking on challenges, even if they might failAutonomous/Independent -- enjoys working with little directionInnovative -- prefers working in unconventional ways or on tasks that require creativityHigh stress tolerance -- thrives in a high-pressure environmentThis Job Is:A job for which military experienced candidates are encouraged to applyOpen to applicants who do not have a high school diploma/GEDA good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or moreA job for which all ages, including older job seekers, are encouraged to applyOpen to applicants who do not have a college diplomaA job for which people with disabilities are encouraged to applyCompany's website:www.e2.comBenefit Conditions:Waiting period may applyWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredPlastic shield at work stationsTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",la,de
7,Army National Guard,Government,4.1,12Y Geospatial Engineer,"Long Beach, CA",$49K - $50K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_49f799d7&cb=1619366721445&jobListingId=4067004152,"Job DescriptionYou can play an important part in disaster relief missions as a Geospatial Engineer for the Army National Guard. In this role, you will extract and supply geographic data that supports military operations of all kinds and help commanders visualize the battlefield during combat.As a Geospatial Engineer, your primary responsibility will be to collect and process military geographic information from decentralized sources (remote sensed imagery, digital data, intelligence data, existing topographic products, and other collateral data sources), present this information to leaders, and return decisions to the field.You may also:Supervise topographic surveying, cartography, and photolithography activitiesAssist in topographic planning and control activitiesAssist in determining requirements and providing technical supervision of geographic intelligence programsJob DutiesCreate geographic data and compile them into mapsCreate and maintain multiple geospatial databasesPrepare military-style briefs covering all aspects of the terrainSome of the Skills You’ll LearnBasic knowledge of Geographic Information SystemsImagery interpretation and exploitationHelpful SkillsInterest in geography, maps, and chartsAbility to demonstrate basic computer skills and work with drafting equipmentConceptualize ideas into computer-generated 2-D/3-D geospatial productsPreference for a technical career fieldThrough your training, you will develop the skills and experience to enjoy a civilian career with construction, engineering, and architectural firms, as well as with government agencies as a surveyor, mapmaker, cartographer, cartographic technician, or photogrammetrist.Earn While You LearnInstead of paying to learn these skills, get paid to train. In the Army National Guard, you will learn these valuable job skills while earning a regular paycheck and qualifying for tuition assistance.Job training for a Geospatial Engineer requires 10 weeks of Basic Training, where you'll learn basic Soldiering skills, and 20 weeks of Advanced Individual Training (AIT) and on-the-job instruction, including practical application of geographic information systems. Part of this time is spent in the classroom and part in the field.Benefits/RequirementsBenefitsPaid trainingA monthly paycheckMontgomery GI BillFederal and State tuition assistanceRetirement benefits for part-time serviceLow-cost life insurance (up to $400,000 in coverage)401(k)-type savings planStudent Loan Repayment Program (up to $50,000, for existing loans)Health care benefits availableVA home loansBonuses, if applicableMost non-prior service candidates will earn between $200 and $250 per drill weekend, subject to changeRequirementsMilitary enlistment in the Army National GuardMust be at least a junior in high school, or have a high school diploma or a GED certificateMust be between the ages of 17 and 35Must be able to pass a physical exam and meet legal and moral standardsMust meet citizenship requirements (see NATIONALGUARD.com for details)Requires military enlistment. Programs and benefits are subject to change. Ask your Army National Guard recruiter for the most up-to-date information. Actual MOS assignment may depend on MOS availability.Other Job InformationJob ID: 1370152ZIP Code: 908221006Job Category: EngineerAge Requirements: Must be between the ages of 17 and 35 administrator map reader aide",la,de
8,Collins Aerospace,Aerospace & Defense,3.8,"Principal Engineer, Software Technical Lead","Los Angeles, CA",$80K - $104K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_daf6a0cd&cb=1619366721445&jobListingId=4043225097,"Date Posted:2021-02-24-08:00Country:United States of AmericaLocation:HCA39: Los Angeles, CA (IMS INC) 5140 West Goldleaf Circle Suite 300, Los Angeles, CA, 90056 USAThe Principal Software Engineer is a technical leader in the Rail projects software division responsible for providing technical oversight, software architectural support across multiple projects.Primary Responsibilities:Provide direction of project software engineering activities in accordance with organizational goalsMonitor project performance, providing EAC analysis, and conducting course corrective action as neededProvide leadership and direction in the implementation, adherence, and continuous improvement of the software engineering processes and proceduresSupport new proposal and change order pricing estimation and technical solutionsProvide technical leadership, guidance and direction for team members in identifying, understanding, and resolving technical issues encountered on projectsCollaborate with peers and other engineering managers within the Surface Transportation and Critical Infrastructure engineering organization to establish best practices for knowledge management, information sharing, and ensuring consistency of engineering processes and solutions across the divisionParticipate in bid and proposal activities, including evaluation of customer requirements, identification and development of technical solutions and development of engineering estimatesQualifications:Engineering experience in software development, including all phases of the development life-cycleExpertise in C/C++ and JavaExperience with RDBMS, primarily Oracle or Microsoft SQL ServerExperience working within a formal engineering process-driven environmentKnowledge of software engineering processesPreferred Qualifications:Advanced degree in a Science, Technology, Engineering or Math (STEM) disciplineExpertise in software architecturesExperience in integration and production systemsPrior experience working within the rail systems industryStrong organizational skillsStrong analytical and problem solving skillsStrong verbal and written communication skillsAbility to work independently and in a cross-functional team environmentBasic Qualifications:This position requires a Bachelor's degree in the appropriate discipline and 10 years of relevant experience or an Advanced degree in the appropriate discipline and 7 years of relevant experience. In the absence of a degree, 14 years of relevant experience is required.Collins Aerospace, a Raytheon Technologies company, is a leader in technologically advanced and intelligent solutions for the global aerospace and defense industry. Collins Aerospace has the capabilities, comprehensive portfolio and expertise to solve customers' toughest challenges and to meet the demands of a rapidly evolving global market.Our Avionics team advances aviation electronics and information management solutions for commercial and military customers across the world. That means we're helping passengers reach their destination safely. We're connecting aircraft operators, airports, rail and critical infrastructure with intelligent data service solutions that keep passengers, flight crews and militaries connected and informed. And we're providing industry-leading fire protection and safety systems that our customers can count on when it matters most. Are you ready to learn from the most knowledgeable experts in the industry, develop the technologies of tomorrow and reach new heights in your career? Join our Avionics team today.Diversity drives innovation; inclusion drives success. We believe a multitude of approaches and ideas enable us to deliver the best results for our workforce, workplace, and customers. We are committed to fostering a culture where all employees can share their passions and ideas so we can tackle the toughest challenges in our industry and pave new paths to limitless possibility.WE ARE REDEFINING AEROSPACE.Some of our competitive benefits package includes:Medical, dental, and vision insuranceThree weeks of vacation for newly hired employeesGenerous 401(k) plan that includes employer matching funds and separate employer retirement contribution, including a Lifetime Income Strategy optionTuition reimbursementLife insurance and disability coverageOptional coverages you can buy: Pet Insurance, Home and Auto, additional life insurance, accident insurance, critical illness insurance, group legalOvia Health, fertility and family planningEmployee Assistance Plan, including up to 5 free counseling sessionsRedbrick - Incentives for a Healthy YouAutism BenefitDoctor on Demand, virtual doctor visitsAdoption AssistanceBest Doctors, second opinion programAnd more!Nothing matters more to Collins Aerospace than our strong ethical and safety commitments. As such, all U.S. positions require a background check, which may include a drug screen.Note:Background check and drug screen required (every external new hire in the U.S.)Drug Screen only performed on re-hires who have been gone for more than 1 yearAt Collins, the paths we pave together lead to limitless possibility. And the bonds we form - with our customers and with each other - propel us all higher, again and again.Apply now and be part of the team that's redefining aerospace, every day.Raytheon Technologies is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.Privacy Policy and Terms:Click on this link to read the Policy and Terms",la,de
9,Firefighters First Credit Union,Finance,3.3,"Senior Application Engineer (Los Angeles, CA)","Los Angeles, CA",$105K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_450cef93&cb=1619366721445&jobListingId=3705898887,"The Senior Application Engineer at Firefighters First Credit Union (FFCU) is responsible for maintaining and supporting the Credit Union’s core applications by ensuring system integrity and maximize functionality of the system. The Senior Application Engineer (SAE) maintains, supports, develops, troubleshoots, tests, trains, and implements software applications to meet business goals. This includes automation of business processes, creation of tools to provide efficiency, and development of key functionality of our core system and third party products. The SAE is the technical Subject Matter Expert (SME) on supported applications with a proficient understanding of business functionalities and end-user experience. The SAE works closely with the IT team and other employees providing consultative technical direction and systems enhancements in line with business goals and technology best practice solutions. The SAE serves as the primary liaison with third party vendors to ensure systems availability, uptime, optimization, upgrade, enhancements, and security.Typical responsibilities: Ensures communication and prioritization of software issues, including escalation of non-resolved issues, are reported to appropriate management in a timely manner. Ensures integrity between core applications and their ancillary systems to minimize risk and business impacts. Maintains knowledge of the Credit Union’s technology applications and the service impact of component failures. Recognizes trends in service disruptions due to application issues and makes appropriate recommendations to IT Leadership. Troubleshoots issues and works with IT and third party vendors to identify remediation and permanent solutions. Serves as a technical resource, installing and supporting vendor and proprietary applications and databases for the Credit Union’s business units (retail and business banking & lending, residential mortgage, accounting, and investment services). Provides preventative maintenance to application databases and logs. Ensures systems uptime and maintenance of databases, including upgrade, performance tuning, archive and purge functions. Ensures technology is used to its fullest capacity and achieves the optimal ROI by developing customized solutions that increase service levels, efficiency, and accuracy. Responsible for developing software solutions using multiple software development languages, databases, tools, and coding techniques widely accepted in the industry and considered mainstream. Sets the standard in IT’s efforts to provide excellent member service, ensuring software solutions are relevant, supportable, documented, and implemented successfully. Collaborates with business stakeholders and leadership to ensure solutions meet or exceed business needs by proactively communicating with the appropriate parties throughout the software development lifecycle. Responsible for active risk mitigation planning to cover possible threats, including information theft, by either preventing or having a reaction plan in place if it occurs, thereby restricting the loss. Perform system upgrades through testing and validation of expected results, ensuring data integrity and system readiness prior to moving upgrades into production environment. Maintain a working knowledge of all associated rules, regulations, and policies, ensuring system compliance with a variety of regulatory requirements.Basic Qualifications: Bachelor’s degree in Computer Science, Data Science, Software Engineering, or a related field/experience. 5 years of experience in application development and implementation role (Software Developer/Programmer Analyst/Application Engineer) is required. Experience in developing applications using .NET 4.5/4.0/3.5, MS Visual Studio, MVC, Razor View Engine, C# .Net, ASP.Net, .Net, LINQ, AJAX, XML, JavaScript, JQuery, JSON, HTML and CSS, SQL 2008/2005. Experience with Web Service and ASP.NET Web API. Experience in object oriented programming and open source technology. Experience in server-side and client-side application development. Demonstrated ability to write functional and technical design documentations. Demonstrates the ability to consult by gathering and evaluating stakeholder needs, providing advice and recommendations, and partnering to achieve objectives. Demonstrates analytical thinking, problem solving, decision making, and judgment by gathering and applying relevant data to research and resolve issues. Demonstrates the ability to prioritize and organize work, handle multiple tasks, and meet deadlines in a fast paced, high-volume environment. Proficient in speaking and writing the English language using correct structure, vocabulary, and organization. Demonstrates experience and behavior consistent with FFCU’s core values of competence, integrity, excellence, curiosity, positivity, and humility. Demonstrates experience performing basic office functions such as answering phones, copying papers, assembling reports, and sending and receiving correspondence. Demonstrates the ability to use office software to create written documents (e.g., MS Word and PowerPoint) and prepare spreadsheets (e.g., MS Excel), as well as use office database applications to enter, maintain, and report data.Preferred Qualifications: Master’s degree in Computer Science, Data Science, Software Engineering, or a related field. Demonstrates the ability to interpret and apply financial information (e.g., credit scores, debt, assets, balances, payments, interest rates, etc.) and perform statistical and math functions (e.g., addition, subtraction, multiplication, division, percentages, ratios, etc.). Demonstrates the ability to prepare and present training materials on technical information for technical and non-technical audiences.Firefighters First Federal Credit Union is an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, color, religion, age, gender, marital status, physical or mental disability, medical condition, pregnancy, sexual orientation, gender identity or expression, national origin, veteran status, genetic information, or any other status protected under federal, state, or local law. Firefighters First Credit Union is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, contact Human Resources at careers@firefirstcu.org or 323-550-2214.",la,de
10,Spokeo,Information Technology,3.9,"Data Warehouse Manager, ETL","Pasadena, CA",$71K - $123K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1b5c8391&cb=1619366721446&jobListingId=4065439885,"Spokeo is a people search engine that both enlightens and empowers our customers. With over 14 billion records and 15 million visitors per month, we reconnect friends, reunite families, prevent fraud, and more.As the Data Warehouse Manager, ETL, you will lead and mentor the ETL team responsible for processing the public record data powering Spokeo’s people-search products. This is an exciting opportunity to help transform the quality of the data we process, partnering with business stakeholders, data scientists, and big data developers.To be successful in this role you will need to be comfortable operating in a world of billions of records and petabytes of data and have experience with cloud-based data systems. The ideal candidate will have an understanding of the challenges associated with big data aggregation, experience with ETL tools, and scripting languages with a focus on quality.Responsibilities:Collaborating with stakeholders to design and develop our data warehouse, data marts, and presentation databases.Utilizing insights from data profiling reports and business use cases to help define processing decisions, source-to-target mappings, and integration workflows.Helping manage the team backlog.Developing scalable, modular, and robust ETL routines, using ETL tools and external programming/scripting languages.Developing and mentoring the ETL development team, ensuring that best practices are implemented for data governance, data quality, data cleansing, and other ETL-related activities.Creating and maintaining technical documentation for source-to-target mapping.Assisting in production support by resolving source data issues and refining transformation rules when needed.Requirements:B.S. preferred in Computer Science, Information Systems, or related fields.5+ years of development experience with ETL tools such as Talend, DataStage, Pentaho, or Informatica3+ years of experience with scripting languages, PySpark, SQL3+ years of experience managing, motivating and mentoring a team.Experience with data warehousing, data modeling, and database architecture.Experience in agile environments using Scrum and/or Kanban and software development life cycle.Ability to communicate effectively with all stakeholders.Preference for open source big data experience with tools such as Spark, etc.Privacy Notice for Candidates: https://www.spokeo.com/recruiting-policySpokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products and be relevant in a rapidly changing world.Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file and 2) being assigned to the open position (as a search) via our applicant tracking solution.This is a remote position.",la,de
11,Tencent,Media,4.3,Data Engineer,"Los Angeles, CA",$69K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=8095&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_5fee7995&cb=1619366721446&jobListingId=4039001544,"Data Engineer Tencent Games is looking for Data Engineer (DE) with 2+ years' experience:

Responsibility:

Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.
Communicate, at scale, through multiple mediums: Presentations, dashboards, company-wide datasets, bots and more.
Educate your partners: Use your data and analytics experience to 'see what's missing', identifying and addressing gaps in their existing logging and processes.
Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.
Build data expertise and own data quality for your areas.

Requirements:

2+ years of Python development experience.
2+ years of SQL experience.
2+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
2+ years' experience in custom ETL design, implementation and maintenance.
Experience querying massive datasets using Spark, Hadoop, Presto, Hive, Impala, etc.
",la,de
12,Virgin Hyperloop,Transportation & Logistics,4.2,Data Engineer,"Los Angeles, CA",$123K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_d4eb744d&cb=1619366721446&jobListingId=3761468306,"To connect the world, we must reflect the world. At Virgin Hyperloop, we're bringing together unique perspectives, empowering our community to celebrate all voices, and creating equal opportunities to build, grow, and thrive.WHY WE NEED YOUThe Data Engineer will be part of the Machine Intelligence & Analytics Group, within the Software Engineering department. This team works closely with all other teams to develop, deliver and maintain data driven products and backend analytics platforms for the discovery, interpretation, communication, and exploitation of meaningful patterns in data. In addition, this team will develop and maintain an analytics pipeline for acquisition, storage, and processing data types of interest to feed real-time artificial intelligent system behaviors. The Analytics team will architect data systems supporting machine learning applications, develop custom toolchains for analysis and exploration, and work with DevOps and IT to host and scale intelligent applications.Ultimately, we will design reliable, scalable, real-time (or near-real time) applications that make Virgin Hyperloop One a reality. We are seeking candidates with various levels of experience to join our team of qualified, diverse individuals at our Los Angeles facility.WHAT YOU'LL DOArchitect and implement data pipelines (ingestion, batch simulation infrastructure, real-time insights).Perform ETL operations on large datasets from many complex, heterogeneous data sources.Develop or implement tools to support analyst-driven machine learning analyses.Work closely with Algorithms team to prototype AI/ML proof of concepts.Participate in design/code reviews to ensure compatibility with architecture.Deploy monitoring solutions to detect and resolve problems in real-time.Build reporting functionality on results of pipeline analysis and monitoring.Maintain quality and accessibility of data products.Champion processes and procedures across the organization.Develop or modify existing machine learning tools and libraries as needed.Develop visualizations of key parameters and relationships to provide insight into data.Enhance, scale, and deploy real-time analytics capabilities, models, and visualizations within production environment on production compute architecture.Collaborate in a fast-changing environment and communicate clearly and effectively with colleagues who range from data scientists, developers, DevOps, hardware engineers, and product managers.WHAT YOU'VE DONEBachelor's degree in Computer Science or a highly quantitative discipline.Minimum 1-3 years experience working as a Data Engineer.Strong knowledge in software engineering principles.Hands on experience and expertise with cloud computing services (AWS, Azure, etc.)Working knowledge of distributed computing architectures and databases.Working knowledge in manipulating large datasets.Strong programming ability with Python, Go and web technologies.Agile, fast prototyping skills, including feature integration during all cycles of development.Working proficiency and excellent communication skills in verbal and written English.NICE TO HAVEMS Degree in Computer Science or equivalent field.Ability with the following programming languages: Scala, RExperience with the following software packages: Tableau, TensorFlow, SQLAlchemy, Flask, PostgreSQL, NoSQL, Apache products (Airflow, Spark, Hadoop, Hive, etc.)Familiarity with DevOps and CI pipelines.Experience with visualization tools: Seaborn, Bokeh, D3.jsExperience working with front-end frameworks (Angular, React, etc.).Domain expertise and knowledge of transportation, logistics, and autonomous systems.Successfully delivered and maintained a major cloud service with a large numbers of end users.WHY VIRGIN HYPERLOOPOur Benefits: medical (including infertility & mental health), dental, vision, life, FSA, HSA, 401k, and moreYour Wellbeing: flexible work schedules, unlimited PTO, and 16 weeks of paid parental leaveFor full information on how your personal information will be stored and processed, please click here.",la,de
13,East West Bank,Finance,3.7,Data Engineer,"Pasadena, CA",$67K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_ceaae8aa&cb=1619366721447&jobListingId=4015668158,"Introduction:For more than 45 years, East West Bank has served as a pathway to success. With over 120 locations across the U.S. and Greater China, we are the premier financial bridge between the East and West. Our teams of experienced, multi-cultural professionals help guide businesses and community members on both sides of the Pacific looking to explore new markets and create new opportunities, and our sustained growth and expertise in industries like real estate, entertainment and media, private equity and venture capital, and high-tech help build sustainable businesses and expand our associates’ potential for career advancement.Headquartered in California, East West Bank (Nasdaq: EWBC) is a top performing commercial bank with an exclusive focus on the U.S. and Greater China markets. With total assets over $52.2 billion, we’re ranked among the top 25 largest banks by asset size in the United States. And since 2010, we have been recognized by Forbes magazine as one of “America’s Best Banks.” With a strong foundation, and enterprising spirit and a commitment to absolute integrity, East West Bank gives people the confidence to reach further.Overview:East West Bank is seeking a Data Engineer. The Data Engineer works with banking data and business units to propose, design, and deliver business solutions. The data engineer will collect and analyze data wherever it resides, including in spreadsheets, files, databases, and APIs. The data engineer will create reports, dashboards, and other visualizations and they will develop applications that collect data from users to enrich enterprise data sets to improve their completeness and accuracy.Responsibilities:Collaborate with team members and business units to Deliver Data-Oriented solutions to the enterprise.Design, implement, deploy and maintain Data solutions. These solutions are written in T-SQL, Python, C#, Java and R.Build reports in SSRS, Power BI, Tableau, Excel and other visualization tools.Build high-performance algorithms, predictive models, and prototypes.Translate, cleanse and normalize large datasets.Collect and document business requirements. Maintain functional and technical artifacts including design documents, data mappings, architecture, data models, and dictionaries.Qualifications:Bachelor’s degree required in Computer Science, Information Technology, Management Information Systems or Business Management.Master’s degree in Mathematics, Statistics, Computer Science, Data Science or relevant.Strong computing skills with at least one of the following: C#, Java, Python, R, T-SQL with a strong interest to learn.Quantitative, analytical, process oriented and troubleshooting skillsProficiency with Excel.Analytical and problem solving skills including troubleshooting.Able to work under pressure while managing competing demands and tight deadlines.Well organized with meticulous attention to detail.Can-do attitude, self-motivated and strong work ethic.Self-driven to identify areas of improvement.Must be team-oriented with experience working on interdepartmental team projects.Extract and collect large data sets from various sources and formatsInterpret and analyze results from data extractions to identifying patterns and trendsEvaluate internal controls and identify deficiencies through the testing of data source, systems, and processesDefine new data collection and analysis processesCreate reports, processes and tools to monitor key risk indicators for business units across the organization.Test and validate that key assumptions, data sources, and procedures utilized in measuring and monitoring risk and internal controls can be relied upon on an ongoing basis; and, in the case of transaction testing, to assess that controls are working as intended.Test adherence with Bank’s policies and controls, as well as regulatory requirementsMaintain an understanding of business operations, operational risks and regulatory requirementsAnticipate changes in the internal and external environment and adapt the testing program accordinglyAssuring the integrity of data, including data extraction, storage, manipulation, processing and analysisProvides recommendations to streamline tasks and create a more efficient working environmentReport results back to management and relevant team membersProduct knowledge inLoansDepositsBanking operations",la,de
14,Omaze,Business Services,4.3,Data Engineer,"Los Angeles, CA",$97K - $175K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=8095&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f5209eab&cb=1619366721447&jobListingId=3808126154,"


Who We Are: Omaze raises funds and awareness for charities by offering the chance to win once-in-a-lifetime experiences and dream-come-true prizes. We've offered everything from a double date with John Krasinski and Emily Blunt, to a walk-on role in Star Wars, to a brand new customized Mercedes Benz sprinter van. We've given over $130M to charities around the world, from donors in 180 countries. Our vision is to be the first for-profit company to give $1B to charity in a single year, and we're building our team of dedicated and passionate people to help us get there. That's where you come in!Who We're Seeking:The Data Engineering team at Omaze is responsible for creating information pipelines and data governance. As a Data Engineer - Security and Compliance, you have a broad knowledge of information system architectures. You have deep knowledge and experience with system integration, communication protocols and security controls. You have a working knowledge of cyber security best practices and compliance standards such as CCPA, GDPR, SOX and PCI-DSS. Your past experience communicating and collaborating with teams such as Legal, IT, Tech and Operations will be instrumental in the development of a comprehensive data security strategy and data protection framework. You have demonstrated the ability to secure databases, information pipelines, endpoints and applications. You are hands on and can write scripts to solve challenges, identify risk and research anomalies.

You are able to collaborate with both technical and non technical audiences. You believe everyone has something to contribute, value diversity and inclusion, and enjoy mentoring others to help them grow. You believe the quality of service we render has a direct impact on ourselves, surroundings and the world.What You'll Do

Establish standards and practices to achieve and maintain compliance with regulations and standards such as ISO27000, GDPR, CCPA, SOX and PCI-DSS.
Work with Legal, IT and Tech to establish ""Information Security Policy and Standards"" documentation.
Work with the SRE team and IT to ensure data standards are up to date, tracked and adhered to by associates and external partners.
Identify threats and risk associated to system integrations.
Work with the organization to ensure data is protected, secure.
Ensure audit trails are established for access and usage.
Identify and minimize risk to customer Personally Identifiable Information (PII).
Working with engineers and data users to maintain and implement best practices for protecting PII data in transit and at rest.
Ensure security of enterprise applications meet our Information Security Policy and Standards.
Investigate potential security events and fraud escalations.
Work with engineers to establish methods to detect, investigate, qualify and quantify threats with data.
Develop algorithms and reports to detect anomalies and provide threat assessments
Write scripts and programs to mine data.
Develop and document standards and best practices.
Work with the data team to deliver quality data solutions to business users and stakeholders.

Our Ideal Candidate:



5+ years data engineering experience
Experience in creating guidelines and policies in conjunction with legal and business stakeholders
Programming and scripting


SQL - Advanced
Snowflake Cloud Data Warehouse
Data Build Tool (DBT)
Experience with 1 or more of the following languages


Python
R
Go
Java


Data Modeling


Data Encryption


In Transit - SSL/TLS
AWS - SSE-S3, SSE-KMS, SSE-C
Public Key Encryption


Ability to learn new languages and tools quickly
Familiar with event-driven and streaming architectures, using tools like Kafka, Kinesis, or SNS.
Experience with Amazon Web Services (AWS)


RDS
Logging and Monitoring
IAM
S3


Comfortable operating in environments subject to regulatory, compliance, and risk-based security requirements.
Familiar with NoSQL solutions, such as Redis, ElasticSearch, or DynamoDB.
Experienced at applying strict regulatory, compliance, and security requirements to software systems.
Ability to work effectively in teams of technical and non-technical individuals (product, marketing, subject matter experts, etc).
Engage engineers across our organization to support a culture of collaboration and inclusion through mentorship, respectful code review, and dedication to quality.
You are excited to share and learn from your teammates about crafting amazing user experiences.
You are passionate about voicing your opinions and are able to be humble in receiving feedback.
You have a track record of trying and learning new things and are not afraid to learn through failures.




",la,de
15,"Association For Energy Affordability, Inc.",Transportation & Logistics,2.8,Energy Analyst/Energy Engineer,"Los Angeles, CA",$40K - $40K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044077&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b17603de&cb=1619366721447&jobListingId=4040373647,"Overview:  Association for Energy Affordability (AEA) is a rapidly growing non-profit energy services and training organization dedicated to building decarbonization, energy efficiency, and electrification in order to foster and maintain affordable and healthy housing and communities. Energy consulting services are completed through AEA’s participation in a variety of federal, state, and local building energy initiatives. AEA is a national organization with over 25 years of industry experience, and has been operating a West Coast office since 2010. For more information about AEA, see www.aea.us.org.Position Summary:  AEA West is seeking Energy Analysts/Energy Engineers to join our tight-knit, talented team of building energy geeks. The candidate will perform energy audits and modeling, as well as assist property owners through complex energy retrofit projects. If you are passionate about electrification, energy conservation, and renewable energy; you love buildings; and you’re seeking to learn from an experienced team in a hands-on environment, then this is the place for you.The Energy Analyst will assist senior analysts in conducting energy audits of multifamily and commercial buildings, providing analysis at both the project and program levels, designing and managing retrofit projects, performing green building assessments, and conducting a variety of technology and market assessments. The Energy Analyst engages in data collection, building diagnostics, research, data analysis, job costing and construction feasibility, energy modeling, and report production as needed to complete a range of project types. They are expected to be a self-starter, an independent problem solver, and a strong team-player.Responsibilities: The Energy Analyst may be responsible for:Conducting energy audits and in-field energy assessments, on-site diagnostics, field data collection and analysis, and renewable energy feasibility assessmentsPerforming energy modeling and building simulationsPreparing energy and green building assessment reports based on analytic findings which include detailed equipment specifications and cost & emissions reduction analysisJob costing, construction feasibility, and contractor bid walksWorking with building owners, architects, and other decision makers to successfully incorporate energy efficiency, electrification, and renewable upgrades in their projectsConstruction site visits to inspect in progress and completed workPerforming LEED, Green Point Rated and HERS consulting servicesPerforming commissioning and retro-commissioning studiesConducting training both internally and publicly on energy efficiency technologies, energy auditing principles, and decarbonized building operationsWorking on national projects to help develop industry standards and guidelinesThese job responsibilities may be revised over time to ensure the functional responsiveness of the Energy Analyst to AEA and Federal and California State program requirements.Minimum Qualifications: AEA staff have diverse educational backgrounds from architecture to linguistics, music to mechanical engineering. What unifies our team is a common passion to make the built environment more sustainable, especially in underserved and low-income communitiesBachelor’s Degree with a demonstrated interest in energy conservation and building science preferred or an Associate Degree with either on-the-job or trades experience in energy conservation, renewable energy, and energy auditsExcellent communication, organization, presentation and analytical skillsPrimary work location is in Emeryville, CA; must have the ability to travel to Northern and Southern CaliforniaAdditional Desirable Qualifications: Sound technical writing skills and experienceProficiency in Microsoft software, including Excel but also Word, Outlook, and PowerPoint.Knowledge of building systems including lighting technologies, building envelope, and mechanical systemsBasic knowledge and understanding of Title 24 and other building codesFamiliarity with local, state and federal incentive and rebate programsAbility to perform cost savings analyses and fuel data analysesHome Energy Rating Systems (HERS and HERS II) rater certification preferred.Building Performance Institute (BPI) certification preferredExperience with the use of energy modeling software i.e., EnergyPro, CBECC-Com & -Res, EnergyPlus, and CSE programsTO APPLY: Interested applicants must submit a cover letter and resume to be considered for this position. In your cover letter, please share examples of AEA’s past or current work that is most exciting to you and why.EEO Non-Discrimination and ADA Reasonable Accommodation Statement: EEO Non-Discrimination and ADA Reasonable Accommodation Statement: Applicants are considered for all positions without regard to race, color, creed, religion, age, national origin, alienage or citizenship status, gender, sexual orientation, gender identity, marital or partnership status, disability, military status, veteran status, or predisposing genetic characteristics. AEA does not discriminate on the basis of physical or mental disability where the essential functions of the job can be reasonably accommodated. Determinations on requests for reasonable accommodation will be made on a case-by-case basis. For more information on the physical requirements of this position and/or if you need reasonable accommodation for any part of the application and hiring process, please notify the agency at 212-279-6733 Ext-8265.~ Minorities and women are encouraged to apply ~*Job Type: Full-timeWork Location:One locationBenefit Conditions:Waiting period may applyWork Remotely:Temporarily due to COVID-19",la,de
16,mPulse Mobile,Health Care,3.5,Data Engineer,"Los Angeles, CA",$73K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_009a663e&cb=1619366721448&jobListingId=4043149810,"Purpose of the Role:The mission of the Data Science and Analytics (DSA) team at mPulse is to uncover insights from data in order to help drive better patient engagement and health outcomes. We are looking at everything from tactical optimizations to broad level strategic direction that is grounded in data evidence and heavy analytical rigor.&This requires a multidisciplinary blend of data science, behavioral science, and business strategy, all applied in tandem to discover key insights that lie hidden in our data sets. The Data Engineer will help build a research-based and data-driven approach to optimize mobile customer engagement. &This role will focus on deep diving into a broad variety of exploratory initiatives to improve segmentation, tailoring and personalization of mobile engagement.This will be a remote position with options to work in the CA or MN office.Behavioral Competencies:Customer FocusedAttention to DetailIndependent Self-StarterHighly OrganizedCritical ThinkerProblem SolverExcellent CommunicatorAbility to PrioritizeTeam Work & CollaborationMulti-Tasker with Strong Sense of UrgencyBenefitsMedical insuranceDental insuranceVision insurancePrescription drug coverage401K401K with company matchLife InsuranceHealth Spending Account (HSA)Flex Spending Account (FSA)Flexible work schedulePaid holidaysPhone/Internet StipendPaid time offEmployee Referral ProgramCommunity service programsCultureEnjoy Flexible PTO and flexible work hoursFull Vision, Dental and Healthcare - all individual premiums paid by mPulse!401K Program with a 4% match3 Weeks Paid Maternity/Paternity LeaveWeekly team lunches to celebrate victoriesPaid Parking as well as Car Pooling incentivesLaptop fitness stationsPing pong conference table and FoosballResponsibilitiesDuties and Responsibilities:Working with the data science and data analytics team to refine and develop data science and analytics (DSA) product roadmapSupport Redshift cluster management including monitoring, performance tuning, and optimizationCreate ELT data transformations and monitor nightly loadsResponsible for data loads and data extracts via Airflow DAG and python codeUnderstanding and applying data mining techniques, including NLP, clustering algorithms and regression analysis to generate deep insight and discover effective solutions to challenging problems Skills, Abilities, and Experience:2-5 years of experience in a corporate, start-up, or research environment2-5 years of experience mentoring data analysts (corporate) &2-5 years of experience in Airflow DAG creation, debugging and maintenance2-5 years of experience in PostgreSQL and Elasticsearch2-5 years of experience in Redshift administration and managementStrong background and solid skills in interactive data visualization (Tableau, Django, Shiny, D3.js)Experience in research methods, exploratory data analysis, and machine learning &Intense intellectual curiosity strong desire to always be learningAnalytical, creative, and innovative approach to solving difficult problems Minimum Qualifications:US Citizenship4 year BS/ BA Degree in Computer Science, Computer Engineering or other related field5 years of direct experience as a data engineer or working directing in data engineering / data science. &2-5 years of experience with Python (Pandas, NumPy, sciKit-learn), SQL and R &RequirementsUS Citizen5 years of direct experience as a data engineer or working directing in data engineering / data science.2-5 years of experience with Python (Pandas, NumPy, sciKit-learn), SQL and R2-5 years of experience in Airflow DAG creation, debugging and maintenance2-5 years of experience in PostgreSQL and Elasticsearch2-5 years of experience in Redshift administration and managementStrong background and solid skills in interactive data visualization (Tableau, Django, Shiny, D3.js)Experience in research methods, exploratory data analysis, and machine learning4 year BS/ BA Degree in Computer Science, Computer Engineering or other related fieldKnowledge in: Airflow DAGKnowledge in: PostgresSQLKnowledge in: TableauKnowledge in: DjangoKnowledge in: ShinyKnowledge in: RedhiftEqual Opportunity EmployerEqual Opportunity Employer: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or national origin.Requisition #ckjn5i40h02o40is6jwncgnjb",la,de
17,Jobot,Business Services,4.8,Data Engineer,"Los Angeles, CA",$104K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=798489&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_e7a5487c&cb=1619366721448&jobListingId=4066140626,"Prominent Credit Union is seeking an experienced Data Engineer!This Jobot Job is hosted by: Geo DaguerAre you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.Salary: $140,000 - $170,000 per yearA bit about us:Fantastic IT opportunity in the Banking & Finance industry!!Our client is a well-established and absolutely booming full-service Credit Union. They have a large tech team and need your help!Apply if interested and qualified.Why join us?Competitive Base Salary!Excellent Bonus Structure401K matching + medical/dental/vision insurance!Flexible PTO + 2 weeks off at the end of the year!40 hour work weeks (or less) are the rule, not the exception.High level autonomy in the positionJob DetailsRequirements:	5+ years of experience in software quality assurance automation BA/BS degree in Computer Science, Math or related field preferred with a strong academic record.	Hands-on experience with both white box and black box testing.	Hands-on experience with automated testing tools.	Experience troubleshooting data pipeline issues and providing root cause solutions.	Able to converse in both technical (data systems) and business (data management/governance) language.	Experience with analytics of subscription-based products is desirable but not required.	Experience with scripting languages like Windows PowerShell, Python, etc., is a plus.	Experienced with batch-oriented, API, and/or streaming processes. 	Strong hands-on experience with Oracle experience with MS SQL and/or Postgres, etc., are highly desirable.	Ability to Create complex SQL queries to analyze data characteristics and quality and create meaningful reports of findings.Interested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",la,de
18,Splunk,Information Technology,4.2,Data Engineer,"Los Angeles, CA",$121K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=4128&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_68b5ea9d&cb=1619366721448&jobListingId=4069269068,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.

Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.

Requirements: I’ve already done that or have that!

5+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data ScientistSavviness with complex SQL queries and knowledge of database technologies including window and analytical functionsExperience with Python analytic libraries and Business Intelligence tools such as Tableau.An ability to provide technical guidance, direction and problem solving to data engineering team members.Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.A familiarity working with an AGILE/SCRUM process management.

Preferred knowledge and experience: These are a huge plus.

Knowledge of Splunk productsAgile certifications

Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.

A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.A stable, collaborative and supportive work environment.

We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",la,de
19,Evolvinc,Information Technology,4.7,Data Engineer,"Burbank, CA",$77K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=4341&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_695abee2&cb=1619366721448&jobListingId=3020137604,"Our entertainment company is seeking an innovative Senior Data Engineer to join our fast-paced team! We utilize and develop cutting-edge technology to deliver high-end and creative content on a global scale. We work across multiple platforms to transform how we see media.

The ideal candidate will possess all of the required skills listed below and more! They will demonstrate excellent interpersonal and communication skills and adhere to the standards of quality and excellence at our company's core.

Please, only apply if you are able to work directly for a U.S. company for the next three years. We are not currently able to work with C2C, H1, or OPT for this position.

Duties & Responsibilities:

Build data pipelines orchestration.
Create the design and architecture for data-lake, data-marts, data-models, and data-warehouse.
Ensure efficiency of data science workflows and advanced machine learning algorithms.
Build and optimize performance of Hadoop and Spark batch jobs (Spark, Kafka, Cassandra, etc.).
Construct and improve ElasticSearch performance.
Contribute to open source solutions and communities.
Stay current on emerging tools and technologies.
Collaborate cross-functionally with other software engineers and their teams.
Establish and demonstrate technologies, solutions, and leading practices.
Balance resources, requirements, and complexity.

Qualifications:

5+ years of experience in full software development lifecycle.
5+ years of experience developing bis data apps.
Bachelors or Masters degree in Computer Science, Engineering, Mathematics or Physical Sciences.
Minimum 3 years experience with Apache Spark and Spark Streaming.
Minimum 3 years experience with Hadoop batch processing framework and map reduce design patterns.
Minimum 3 years experience with Java/Scala/Python in support of data applications.
Expertise in Java 1.8+, Scala 2.11, and Linux.
Demonstrated proficiency in programming and analysis (design patterns, hardware, software requirements, systems requirements, deployment protocols, etc.).
Previous experience in an Agile environment using Scrum.
Previous experience with open source technologies, widely used RDBMS and SQL, and at least one columnar NoSQL solution.

Preferred Qualifications:

Prior experience developing and maintaining large scale, consumer facing web apps.
Prior experience working for a large data enterprise organization, creating robust and reliable data pipelines, and using multiple NoSQL solutions (HBase, MongoDB, Neo4j).
Previous operational experience with large software systems.
Previous Schema or Cube design experience.
Familiarity with statistics, machine learning, and natural language processing apps.
Knowledge of security and PII and PCI compliance issues.

Previous experience with the following preferred:

Apache Airflow
Amazon AWS
AWS EMR
docker and Kubernetes
Restful APIs
Apache Kafka
Apache HBase
Apache Hive and/or Apache Crunch
Apache Avro

Powered by JazzHR",la,de
20,UpKeep Maintenance Management,Information Technology,4.1,Data Engineer,"Los Angeles, CA",$73K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=148364&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_8d3cccba&cb=1619366721448&jobListingId=4040421969,"UpKeep is the leading software solution developed to help businesses manage facilities and equipment. We empower our customers by providing a mobile-first SaaS application, cutting edge IoT technology, powerful data analytics tools, top-notch professional services, and advanced enterprise integrations.We're a California-based tech startup with over 100 team members in the US and thousands of customers around the world! We've been named a ""Best Place to Work"" several years in a row by fostering an inclusive and mission-driven culture where everyone has the opportunity make a meaningful impact. We've raised $50 million in venture capital following a recent Series B funding round led by Emergence Capital, Insight Partners, and Y Combinator.In addition to great benefits and stock options, most roles come with the flexibility work remote.Data Engineer role:Architect, implement, and maintain a comprehensive data environment including data warehousing, ETL pipelines, and BI toolsOptimize data ingestion, storage, and processing architecture to meet product, business, and performance needsIdentify opportunities to automate and improve existing data processes with long-term scalability in mind Translate business requirements into data models that are easy to understand and used by different disciplines across the companyDesign and develop tools to enable teams to consume and understand data faster Examine and troubleshoot data stored in SQL in collaboration with UpKeep's Postgres DBA Uphold and own UpKeep's data quality, privacy, and security in partnership with UpKeep's Engineering, TechOps, Legal, and IT teamsDocument and promote data engineering best practices Data Engineer qualifications:3+ years of data engineering experienceHave architected distributed systems with infrastructure automation, monitoring, and alerting Experience implementing and administering BI toolsExperience working with API’s to collect or ingest data in batch or real-timeExperience using variety of Amazon Web Services (EC2, ELB, RDS)Proficiency in SQL Databases; including advanced analytical query (Postgres preferred)BS in Computer Science, Mathematics, or equivalent is preferred Employee Benefits:Full-time team members at UpKeep receive stock options, paid holidays, unlimited vacation/sick time, 401(k), 12-week paid parental leave, affordable health insurance options, FSA, and the flexibility to work from home. We value work-life harmony and believe that family and mental health should always come first. The Company:UpKeep was founded by our CEO, Ryan Chan, based on an idea he had while using outdated desktop software as a process engineer in a manufacturing plant. He believed a mobile-first solution could significantly improve the workflow and productivity of the technicians he was working with. He was determined to build on this vision— so he quit his job, learned to write code, and created the first version of UpKeep in 2014, while living in his parents garage.Today, our cloud-based software-as-a-service (SaaS) and cutting edge IoT technology is modernizing the way thousands of businesses around the world maintain their facilities and equipment. Customers love UpKeep's mobile-first application because it gives them the ability to manage projects, teams, and work orders on-the-go. We're replacing tedious paperwork and cumbersome spreadsheets so technicians can focus on the work that matters most. We also provide advanced reporting tools and powerful integrations which enable managers to make data-driven decisions that improve efficiency and decrease costs.UpKeep is a Computerized Maintenance Management System (CMMS) and Enterprise Asset Management (EAM) software geared for deskless technicians in industries like manufacturing, energy, healthcare, transportation, fitness, education, government, construction, building, and property management. With over 1,500 positive customer reviews, we're the market leader on Gartner, G2, GetApp, and Capterra,Following our Series B in 2020, we've raised $50 million in VC funding led by Insight Partners, Emergence Capital, Mucker, and Y Combinator (YC W17). These investors recognized that only 1% of venture capital has been invested in technology for the deskless workers who make up over 80% of the global workforce! We're giving back to those underserved workers by making it easier for them to do their jobs and celebrating the meaningful work they do. Company culture, employee appreciation, career development planning, and DEI are very important to us— which is why UpKeep has been named a ""Best Place to Work"" several years in a row.Interested in learning more?Product Overview: www.onupkeep.com/overview Customer Stories: https://www.onupkeep.com/customersDemo Video: https://www.youtube.com/watch?v=oX7Lak7o0qI$36M Series B Announcement:https://www.onupkeep.com/blog/upkeep-series-b-funding-announcement/UpKeep Technologies Inc. is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to, and will not be discriminated against based on age, race, gender, color, religion, creed, marital status, pregnancy, disability, national origin, sexual orientation, gender identity, veteran status, or any other protected category. Please let us know if you need any accommodation due to disability. We celebrate our inclusive work environment and will always strive to create a diverse and equitable workplace by hiring people from all racial, ethnic, and socioeconomic backgrounds.",la,de
21,Twitter,Information Technology,4.2,Cloud Data Engineer,"Los Angeles, CA",$116K - $213K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_12199816&cb=1619366721448&jobListingId=4067085960,"Company DescriptionAs data engineers in Revenue Science, our mission is to build real-time and offline solutions to make data accessible and reliable while leveraging the largest-scale data processing technologies in the world - and then apply them to the Revenue’s most critical and fundamental data problems.Learn more about some of the challenges we tackle on this team:Building a Petabyte-scale Data Warehouse (Google Cloud Next '18) https://youtu.be/APBF9Z3uBCcHow Twitter Migrated its On-Prem Analytics to Google Cloud (Google Cloud Next '18) https://youtu.be/sitnQxyejUgJob DescriptionYou are passionate about data and driven to take the data organization challenges at the scope of entire Twitter’s Revenue.As a member of the Data Engineering team, you will build and own mission-critical data pipelines that are ‘source of truth’ for Twitter’s fundamental revenue data, as well as modern data warehouse solutions, while collaborating closely with Ads Data Science team.You will be a part of an early stage team and have a significant stake in defining its future with a considerable potential to impact all of Twitter’s revenue and hundreds of millions of users.You will be among the earliest adopters of bleeding-edge data technologies, working directly with Revenue Science and Revenue Platforms teams to integrate your services at scale.Your efforts will reveal invaluable business and user insights, leveraging vast amounts of Twitter revenue data to fuel numerous Revenue teams including Ads Analytics, Ads Experience, Ads Data Science, Marketplace, Targeting, Prediction, and many others.QualificationsStrong programming and algorithmic skillsExperience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce etc).Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica)Nice to have:Experience writing Big Data pipelines, as well as custom or structured ETL, implementation and maintenanceExperience with large-scale data warehousing architecture and data modelingProficiency with Java, Scala, or PythonExperience with GCP (BigQuery, BigTable, DataFlow)Experience with Druid or Apache FlinkExperience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming)Ability in managing and communicating data warehouse project plans to internal clientsAdditional InformationAll your information will be kept confidential according to EEO guidelines.",la,de
22,REX,Real Estate,4,Data Engineer,"Woodland Hills, CA",$103K - $192K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=4341&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a9d12480&cb=1619366721449&jobListingId=3808704504,"At REX, we are growing fast and hiring passionate, intelligent people to join us on our mission of becoming the BEST company in the world! We are changing the way people buy and sell homes by using technology to make the process more convenient and transparent. Come work with a company that is passionate about putting the consumer first as well as your career growth.

About REX

REX is a well-funded, game-changing real estate technology startup with offices in Austin, Los Angeles, and the Bay Area. With the goal of improving the lives of homebuyers and sellers, REX created a digital platform and real estate service that eliminates traditional agent commissions and shifts control away from agents over to those who matter most: consumers! REX saves homesellers thousands of dollars in fees by going around the MLS to target home-buyers directly with sophisticated marketing that has never been used in real estate. Since its launch in Southern California, REX has expanded to 17 states and over 250 employees. Throughout the years, REX has represented homes cumulatively valued at over $1 billion and in the process, saved customers over $20 million in fees they otherwise would have paid traditional brokers.

About the Position

As a DevOps Engineer, youll work on solving scalability, performance, and automation problems, and helping us to grow our business. Youll be responsible for both customer-facing and internal systems. Youll also be responsible for working with, helping, or teaching other engineers about how to run systems that are reliable, performant, scalable, and automated. Youll be flexible and open-minded about using a wide variety of tools and will focus on getting the job done right, not on processes and rules. Youll add, create or enforce formal processes only when it helps us to move faster.

As a Data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.

As a data Engineer, you will build from scratch highly available and highly scalable data processing systems using AWS technologies, Kafka, Map-Reduce, Hive and other big data technologies. You will build a system that is envisioned to handle terabytes of data at scale limits per day and petabyte scale warehouse. You will also be responsible for fine tuning and performance.

Experience & Qualifications

Our ideal candidate brings the following:

Significant experience with multiple data platforms, including SQL and NoSQL systems.Experience with ETL pipelinesComfortable coding in backend languages such as Java, Python, and GoAWS experienceExperience with distributed batch data-processing techniques and tools

Bonus Points:

Experience with web-scale architecturesKafkaSparkMap-Reduce, Hive or any big data technologyDRUIDJava proficiencyPython proficiency

Social Mission:

REX sets aside a portion of all income from selling homes to fund homes for families in dire need. It is our mission to contribute one home for every 50 homes we sell. We started in Sihanoukville, Cambodia, where we partnered with World Housing and the Cambodian Children's Fund to help homeless families get back on their feet.

Perks and Benefits

At REX, we appreciate diverse perspectives and want each person to feel valued and impactful in their work. We believe in nurturing your career growth at a fast pace and giving recognition where it's due!

Listed below are just some of the awesome perks available when joining REX:

Competitive base & bonus packages plus stock optionsOpen and flexible PTO planBenefits, including medical, dental & vision insurance, as well as 401(k)Career growth opportunities Cell phone & Internet reimbursement for some rolesParental leave Employer discounts on select home servicesSome perks do not apply to contract workers or interns

Additional Information

As a pioneer in our industry, REX is setting new standards in the marketplace for quality, innovation, integrity, professionalism, drive, consumer happiness, and social good. Our culture, together with our business vision and goals, serve as an orientation for leadership and a guide for how we conduct ourselves in day-to-day business. They also form the foundation for hiring, encouraging and rewarding great people. In addition, REX has been committed to doing good things for real estate consumers and to providing homes for those in the greatest need, wherever they may be. For every 50 homes we sell, we provide a home for a family in need. We started by funding the construction of a home for a family in Cambodia at the end of 2015. In addition to funding homes, the REX team regularly provides hands-on support to local nonprofits that provide shelter to families.

Powered by JazzHR",la,de
23,Intuit,Information Technology,4.3,"Senior Software Engineer, Big Data","Los Angeles, CA",$125K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1044074&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_b6d0eed9&cb=1619366721449&jobListingId=3811136024,"OverviewOur formula for innovation begins with agile, cross-functional teams that welcome diverse perspectives and embrace collaboration. Inspirational working environments help spark fresh ideas, with state-of-the-art technology and creative workspaces that allow our team to decide how they want to work. And our shared commitment to make a meaningful impact for our customers helps us push the boundaries of technology to uncover new possibilities. If you have a commitment to excellence and a passion for innovation, come join our team.",la,de
24,GoodRx,Biotech & Pharmaceuticals,4.7,Senior Data Engineer,"Santa Monica, CA",$144K - $194K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=148364&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_d3d536c6&cb=1619366721449&jobListingId=4013174108,"At GoodRx, we believe that all Americans should have access to convenient and affordable healthcare. As a nation, we spend about $3.5 trillion annually on our healthcare, but too many Americans struggle to get the care they need, and prices just keep rising. Our marketplaces for prescription medicines and telehealth have helped Americans save $25 billion since 2011. GoodRx is a public company; we're based in Santa Monica with additional offices around the country. We're a low-key and tight-knit group that likes to find new ways to fix big problems. If you share our belief that you can do well by doing good, let's talk.We’re committed to growing and empowering a more inclusive community within our company and industry. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunities to excel.With that said, research shows that women and other underrepresented groups apply only if they meet 100% of the criteria. GoodRx is committed to leveling the playing field, and we encourage women, people of color, and those in the LGBTQ+ communities to apply for positions even if they don’t necessarily check every box outlined in the job description. Please still get in touch – we’d love to connect and see if you could be good for the role!About the Role:GoodRx is looking for extremely smart and curious data engineers, who are deft at working with a wide variety of languages, such as Python and SQL, a variety of raw data formats, such as parquet and CSV, in a fast-paced and friendly environment. You will collaborate and work with teams across GoodRx to build outstanding data pipelines and processes that stitch together complex sets of data stores in order to guide marketing decisions. Responsibilities:Collaborate with product managers, data scientists, data analysts and engineers to define requirements and data specifications.Develop, deploy and maintain data processing pipelines using cloud technology such as AWS, Kubernetes, Airflow, Redshift, EMR.Develop, deploy and maintain serverless data pipelines using Event Bridge, Kinesis, AWS Lambda, S3 and Glue.Define and manage overall schedule and availability for a variety of data sets.Work closely with other engineers to enhance infrastructure, improve reliability and efficiency.Make smart engineering and product decisions based on data analysis and collaboration.Act as in house data expert and make recommendations regarding standards for code quality and timeliness.Architect cloud-based data infrastructure solutions to meet stakeholder needs.Skills & Qualifications:Bachelor’s degree in analytics, statistics, engineering, math, economics, science or related discipline.5+ years professional experience in the big data space.5+ years' experience in engineering data pipelines using big data technologies (Spark, Flink etc...) on large scale data sets.Expert knowledge in writing complex SQL and ETL development with experience processing extremely large datasets.Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions.Deep familiarity with AWS Services (S3, Event Bridge, Glue, EMR, Redshift, Lambda)Ability to quickly learn complex domains and new technologiesInnately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findingsThrives in fast-paced startup environmentGood To HaveExperience with customer data platform tools such as Segment. Experience using Jira, GitHub, Docker, CodeFresh, Terraform.Experience contributing to full lifecycle deployments with a focus on testing and quality.Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement.GoodRx is America's healthcare marketplace. The company offers the most comprehensive and accurate resource for affordable prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast, as well as a telehealth marketplace for online doctor visits and lab tests. Since 2011, Americans with and without health insurance have saved $25 billion using GoodRx and 15 million consumers visit goodrx.com each month to find discounts and information related to their healthcare. GoodRx is the #1 most downloaded medical app on the iOS and Android app stores. For more information, visit www.goodrx.com.",la,de
25,Netflix,Information Technology,4.2,Senior Data Engineer,"Los Angeles, CA",$148K - $264K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_0e3141f8&cb=1619366721449&jobListingId=4044425962,"Los Angeles, CaliforniaData Science and EngineeringNetflix Original shows and films are produced all over the world and watched by more than 200 million accounts globally. We aim to give content creators the opportunity to bring their most visionary ideas to life and create joy for our members around the world through innovative storytelling.The Studio Finance Data Science & Engineering team at Netflix is a group of Analytics Engineers, Data Engineers, and Data Scientists. We help scale our rapidly growing Studio by focusing on data sets for production finance, budgeting, and our global workforce of vendors and production talent. These data sets represent tens of billions of dollars - a large portion of Netflix’s revenue - reinvested into entertaining the world with new, original shows. We develop new data sets and pipelines, conduct analyses, develop analytic tools, and build predictive models and algorithms using machine learning, all with the goal of producing the best content we can in the best way we can. Check out this blog post to learn more about the area and some of the problems we're working on.We are looking for a Senior Data Engineer to help us architect, source, and build these foundational data sets into a rich, detailed playground for both our own team members and the hundreds of Studio colleagues we partner with. We’ve only just started down this path. This is an opportunity to shape a high-impact data space at Netflix from its early stages.In this role, you will:Architect, strengthen, and expand the core data models that our Studio uses to answer business questions and evaluate its financial decisions. You’ll get to envision how all the data elements from multiple sources should fit together as a whole, and then execute on that planPartner with Analytics Engineers, Data Scientists, Software Engineers, and Studio business teams to create data sets that will serve analysis and reporting needs intuitivelyHelp our Analytics Engineers craft the backend data layer of prototype applications or microservices used for reporting and analytic workflowsSource data from new Studio systems or rich unstructured records that are waiting to be structured!Develop best practices for governance of data sets with sensitive informationAbout you:Hands-on experience building production data pipelines, ideally using one or more frameworks such as Spark, Hive/Hadoop, or FlinkExpertise in data modeling and establishing data architecture across multiple systemsProficiency in Python, or willingness to grow into Python from your other scripting languages (i.e., Java, Scala)Comfort working in a variety of tech stacksExperience ingesting and managing data sets that may be messy or incomplete at sourceStrong communication; able to own and deepen direct relationships with our Engineering, Product Management, and Studio partnersEnthusiasm about innovating and learning in a fast paced environmentComfort with ambiguity; able to thrive with minimal oversight and processCultureYou will have the opportunity to impact the business in a meaningful way. You will have the freedom to innovate, solve interesting problems and influence in a fast paced, exciting environment. You will work with stunning colleagues who love to solve hard problems, and who not only expect but also foster high performance. You can learn more about the Netflix culture at jobs.netflix.com/culture.We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.APPLY NOWShare this listing:LINK COPIED",la,de
26,Acuant Inc,Business Services,3.9,Senior Data Engineer,"Los Angeles, CA",$95K - $167K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_90aac3b0&cb=1619366721449&jobListingId=4071002087,"WHO WE AREAcuant is a leading B2B provider of identity verification technology. We are revolutionizing the way consumers transact by allowing businesses to quickly and seamlessly identify who they are doing business on any platform while protecting both parties. Join a global team that works with leaders in all industries to delivers best in class technology.Acuant's Trusted Identity Platform provides complete identity verification based on your level of risk so you can build your business with valid customers. Powered by AI for the highest speed and accuracy, omnichannel products enable seamless customer experiences to increase conversions in the digital economy. Scalable, secure and compliant (KYC, AML & GDPR), Acuant allows businesses to establish trusted identities from any location in seconds. www.acuant.comWHAT WE LOOK FORWe are adding a new position to the team. The ideal candidate will possess 4 years of experience building big data systems. It is imperative that he/she have expert level understanding of bulidnig robust and scalable data infrastructure. A huge plus is domain knowledge in computer vision, fraud detection, and anti-money laundering (AML)!Tools: Python, Pandas, AWS (S3, Athena, SQS, Lambda), SQL, open source NoSQL systems (Cassandra, Presto, Spark)WHAT YOU BE RESPONSIBLE FORDevelop data pipelines to enable a variety of big data workloads, including machine learning, tracking product KPIs, general business intelligence, and data visualizationsModel data and select the appropriate storage and retrieval technologiesBuild system to orchestrate ETL jobsMaintain data infrastructure and monitor performance and errorsHOW WE VALUE OUR EMPLOYEESYou will always be heard, decisions are collaborativeCompetitive compensationChallenging and rewarding workGenerous benefits packageWork with an incredible team of smart and mission-driven people",la,de
27,MobileProgramming,Information Technology,3.7,Data Engineer (Only US Citizens),"Los Angeles, CA",$81K - $109K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_7b4eed02&cb=1619366721449&jobListingId=4010353320,"Candidate Skill: Apache, Hadoop and Data AnalyticsExperience: 7+ YrsCity: Los Angeles, CA (Remote Till Covid)Country: USAJob Description: • Provide expertise on all data concepts for the broader advanced analytics group, and inspire the adoption of advanced analytics, data engineering and data science across the organization. • This will include Installing continuous pipelines of large pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses.",la,de
28,Glassdoor,Information Technology,3.8,Senior Data Engineer (Remote),"Los Angeles, CA",$122K - $152K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=132937&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_673486ce&cb=1619366721449&jobListingId=3806594372,"We are looking for a talented Senior Engineer to join our growing Data Engineering team. The ideal candidate has significant experience in building scalable data platforms that enable analytics, data science and data products. You must have strong, hands-on technical expertise in a variety of technologies and the proven ability to fashion robust, scalable solutions. You should have a passion for continuous quality improvement.

We embrace a wide variety of technologies and work very closely with data scientists and business stakeholders to deliver end to end solutions. Although this is an individual contributor role, we are a tightly knit team who widely collaborate with one another. If you are interested in a fast paced environment, the latest technologies, and fun data problems, come join us!

Our mission is to help people everywhere find a job and company they love. We're transforming an entire industry through the power of transparency. As the worldwide leader in employer branding and insights, our vision is for a world where transparency holds companies accountable to strive to become better employers.

Please note this role is open to remote hiring. Our main office locations are in San Francisco, CA, Chicago, IL and Uniontown, OH.

Responsibilities

Design and develop big data applications using a variety of different technologies.
Develop logical and physical data models for big data platforms.
Automate workflows using Apache Airflow.
Write data pipelines using Apache Hive, Apache Spark.
Create solutions on AWS using services such as Lambda, API Gateway, Kinesis etc.
Participate in rotational on-call support.
Provide ongoing maintenance and enhancements to existing systems.
Learn our business domain and technology infrastructure quickly.
Document, share your knowledge freely and proactively with others in the team.

Key Qualifications

5+ years of hands-on experience with developing data warehouse solutions and data products.
2+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive, Spark, Airflow, Kafka, etc.
2-3 years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.
2+ years of experience using Python as a programming language.
Experience with scripting languages: Perl, Shell, etc.
Practice working with, processing, and managing large data sets (multi TB/PB scale).
Exposure to test driven development and automated testing frameworks.
Background in Scrum/Agile development methodologies.
Capable of delivering on multiple competing priorities with little supervision.
Excellent verbal and written communication skills.
Bachelor's Degree in computer science or equivalent experience.

Nice To Have

Experience building customer facing products, machine learning pipelines or data products.
Experience working with Tableau, Looker or other data visualization software.
Familiarity with AWS or GCS technologies.
Ability to program in multiple programming/scripting languages: Python, Java, JS, Scala, etc
Be passionate about or have contributed to open sourced engineering projects in the past.

Why Glassdoor?

Work with purpose join us in creating transparency for job seekers everywhere
100% company paid medical/dental/vision/life coverage, with 80% dependent coverage
Long Term Incentive Plan
401(k) Plan with a Company Match to prepare for your future
Generous paid holidays and open paid time off

Glassdoor is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. Glassdoor is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.",la,de
29,Logic20/20,Business Services,3.8,Senior Data Engineer,"Los Angeles, CA",$93K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136006&s=58&guid=0000017909c73503b331e9e418d98831&src=GD_JOB_AD&t=SR&vt=w&cs=1_42c78501&cb=1619366721450&jobListingId=4068348426,"Senior Data EngineerAbout the Role. . .Our Advanced Analytics team is looking for a seasoned Data Engineer with Cloud Solutions background to add to our team. This engineer is responsible for building a large-scale data pipeline in cloud platform. This may involve in automation of manual processes to cloud environment. This engineer would direct the initiatives for creation of data sets and delivering client value while ensuring high client satisfaction.At the same time, you’ll be joining a five-time Best Company to Work For, where super-smart, talented people come together to do outstanding work—and have a heck of a lot of fun while they’re at it. Because we’re a full-service consulting firm with a diverse clientele, you can count on a steady stream of opportunities to work with cutting-edge technologies on projects that make a real difference. Logic20/20's Global Delivery Model creates a connected experience for Logicians across geographies. You'll have access to projects in different locations, the technology to support Connected Teams, and in-person and online culture in our Connected Hub cities.Core responsibilities for this position include, but are not limited to the following. . .Extracts data from various databases; perform exploratory data analysis, cleanses, massages, and aggregates dataEmploys scaling & automation to data preparation techniques - Introduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveriesResearches relevant emerging empirical methods and quantitative toolsPossesses in-depth business knowledge in order to initiate and drive discussions with business partners to identify business issues needing analytic solutionsLeads innovative packaging and presentation of insights to business and broader analytics communityDevelops processes to automate and scale insights operationalizationDevelops and drives multiple cross-departmental projectsEstablishes brand and team as subject matter experts in advanced analytics across departments.Mentors data scientists in pioneering techniques and business acumen Qualifications . . .Cloud solution implementation experience with Azure Data Lake and Spark preferredMinimum 5 years hands-on experience with SQLAt least one year of experience in scripting languages such as PythonDemonstrated experience in a cloud-based -computing environment such as AWS, Azure, or Google Cloud PlatformBig data processing techniques, preferredCan work independently in ambiguous environmentAbout Logic20/20 . . .The Logic20/20 Advanced Analytics team is where rock stars in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Director, Advanced Analytics",la,de
0,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,Data Engineer,"San Francisco, CA",$61K - $118K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=0000017909f07fcc85940711e447453b&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_823a01ec&cb=1619369427634&jobListingId=4042138837,"Thermo Fisher Scientific Inc. is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them.How will you make an impact?You will be a part of the fast-growing field of Clinical Diagnostics developing algorithms for molecular diagnostics based on real-time PCR technologies. Your interaction and collaboration with a talented team of assay, reagents, software, hardware designers and manufacturing will revolutionize healthcare through high throughput diagnostic systems. Thermo Fisher Scientific Inc. has played a pivotal role in the COVID-19 pandemic with the TaqPath COVID-19 Combo Kit for testing SARS-CoV-2. We continue to innovate and provide new solutions for the pandemic and we need your talent to help save lives.What will you do?Architect and develop data pipeline for clinical qPCR data for scientists to derive analytics to assess the performance of clinical testOwn the data flow, data manipulation, transformation, storage, and integration of analytical toolsClean, aggregate, transform, and organize data from disparate sources and transfer it to data lakeManage data and meta-data in the data lakePrepare data for prescriptive and predictive modelingWork closely with scientists and algorithm developers to build data systems and pipelines and auto generation of reportsCollaborate with data scientists to explore ways to enhance data quality and reliabilityCollaborate and communicate with various teams and business unitsHow will you get here?EducationBachelor’s degree in Molecular Biology, Biology, Chemistry, Applied Mathematics, Physics, Electrical Engineering, Computational Biology, Biostatistics, Bioinformatics, Computer Science or related discipline; postgraduate degree (Master’s, PhD) is highly preferredExperience5+ years as a data engineer or in a similar role3+ years of product development experience (biotechnology industry preferred)Strong understanding of data modeling, algorithms, and data transformation techniques.Hands-on experience with ETL (data extraction, transformation, and loading), storages, and analytical tools.Strong software architecture backgroundFamiliarity with big data technologies such as Hadoop and KafkaExperience with AWS data lake and ML framework is preferredKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.Excellent programming skills in Python, Java, C++Knowledge, Skills, AbilitiesUnderstanding of qPCR and amplification curve data is strongly preferredKnowledge in Molecular Biology and Clinical DiagnosticsAbility to present and communicate data analysis results to non-expertsAbility to work independently and in a team environmentPrior experience with US-FDA 510k product development/submission, 21 CFR Part 11, and ISO 13485 is highly preferredUnderstanding of clinical trial design and evaluation is preferredOur global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.Apply today! http://jobs.thermofisher.comEVRD2020 *GTSDouble",sf,de
1,Ursus,Information Technology,4.4,Senior Data Engineer,"San Francisco, CA",$177K - $208K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=0000017909f07fcc85940711e447453b&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_f116d284&cb=1619369427634&jobListingId=4070692698,"Job Title: Senior Data EngineerLocation: Remote (within the US)Duration: PermanentSummary:This role is with a fast growing company in the mobile ticketing spaceResponsibilities:Design and implement scalable data pipelines and data storage on AWS using Kinesis, Redshift, S3, and a Spark based streaming architectureCreate scalable and low latency code for data products using MongoDB, Redis, Elasticsearch or similarScale and maintain our Analytics Databases to power our dashboardsCollaborate with our data scientists to productionize their modelsImplement Comprehensive Testing and Continuous Integration frameworks for schema, data, and functional processes/pipelinesQualifications:At least 5 years experience using Redshift or a similar Data WarehouseAt least 5 years experience programming, preferably with Python or GoHands-on experience with SQL, ETL, Data Warehousing and Data OrchestrationFamiliarity with scheduling frameworks, preferably AirflowFamiliarity with real-time/batch distributed systems like Kinesis, Kafka, Spark, professional experience with Redis and Elastic searchFamiliarity with business intelligence/analytics tools like Tableau or Periscope DataIND123",sf,de
2,Aechelon Technology Inc.,Information Technology,2.8,Pipeline Software Engineer,"San Francisco, CA",$127K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_592a8278&cb=1619369427634&jobListingId=3731121952,"Aechelon Technology, Inc. is a leading producer of 3D simulator content, including Geospecific visual/sensor databases and realistic 3D models. We seek people who share our passion for real-time computer graphics and commitment to our mission of helping make our Nation’s pilots safer. We will give you a chance to work with some of the most talented people in the graphics industry.Our Software Team is looking for Pipeline Engineers. The Pipeline Engineer’s primary role is to support our art team by designing tools and automating processes for the content creation pipeline.Due to the COVID-19 pandemic and related CA state-wide and San Francisco County restrictions, the Company is not currently supporting general operations in its San Francisco office. Until such restrictions are lifted and/or the pandemic conditions permit, the Company’s employees are primarily required to work from home offices. After resolution of the pandemic and the Company’s normal operations resume, your primary workplace will be the Company’s San Francisco, CA office.United States citizenship required due to restrictions on access to certain data.Primary Tasks:Assist in the design, development, testing and maintaining of new tools or updates to existing toolsWrite Python scripts to automate areas of the pipelineHelp ensure our user interface and processes have consistency across different tools and software platformsDevelop Maya and Photoshop plugins and scripts to enhance and streamline our production pipelineMinimum Qualifications:3+ years of experience in content creation software design, development and integration for CGI or game developmentIn depth experience in developing content creation tools and plug-ins with scripting languages such as Python, including integration of C/C++ libraries into Python programsDevelopment experience creating plug-ins and pipeline automation within Maya and Photoshop.Strong analytical and problem-solving skills, and ability to bridge the creative and technical aspects of graphicsEligibility to work with export-controlled technologyPreferred Qualifications:Experience with user interface development and design using Qt and pyQt / pySideExperience in C and C++ programming for 3D graphicsExperience with performance optimizations in realtime simulations/gamesExperience with Google Earth, GIS tools such as ArcInfo or remote sensing tools such as Erdas or Envi.BS in Engineering, Computer Science or similar technical fieldWe offer a very attractive compensation package including competitive base salary, company performance-based profit sharing, 401k, 100% employer paid health benefits (medical, dental, vision, life, std, ltd, and life insurance plans).No relocation reimbursement provided.For more information about our company, please visit www.aechelon.comAechelon Technology is an equal opportunity employer. We are committed to providing access and opportunities to individuals with disabilities. If you are an applicant who is unable to fully utilize/access our application process because of a disability, Aechelon Technology will provide a reasonable accommodation. Please send an email to hr_team@aechelon.com to request that accommodation, and please be sure to include a detailed description of your requested accommodation, your name and preferred method of contact.",sf,de
3,Bio-Rad Laboratories,Biotech & Pharmaceuticals,3.5,Data Quality Engineer,"Hercules, CA",$45K - $80K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_c3de9771&cb=1619369427635&jobListingId=4068148598,"Data Quality EngineerBio-Rad LaboratoriesData Quality and Analytics team is seeking a proficient Data Quality Engineer with experience using proven techniques and tools to measure, control, monitor, and improve the quality of data needed for key business processes. In this role, the candidate will help set a new bar for data quality by establishing new and build upon existing data quality processes and practices to deliver high quality data assets to internal stakeholders and customers. Candidate will focus on building data pipelines and infrastructure that power Quality data systems, tools, software and applications. Candidate should have experience working with large data sets, finding best ways to engineer the data to help develop critical KPI metrics, building innovative visualizations and dashboards all the while keeping in mind what improvements can be driven in underlying data systems.ResponsibilitiesHelp to develop the evolving Data Quality improvement strategy that not only satisfies current needs but can be easily adapted to future needs as new sources of data input and requirements for data output are identified.Develop a data quality testing frameworks (code, jobs, libraries etc.) to validate data flow through different transformations.Design, test, deploy, and document data quality procedures and their outputs.Work closely with data stewards, ETL developers, and business analysts demonstrating the ability to partner and maintain confidence as it relates to coordinating disparate information while being able to translate for downstream consumption.Document at a functional level how the procedures work within the data quality applications.Develop process improvements to ensure and if necessary improve overall data quality.Develop Data quality monitoring and reporting, including dashboards and scorecards.Guide team members by offering support, advice and best practices recommendations throughout the project implementation.Help BA team to deliver quality validated products on time.Interact with Business Data Governance Stewards to agree on KPI validation standards and implement them on behalf of the business.Guide team to adhere to and promote quality standards.QualificationsBachelor's degree in a technical field such as mathematics, computer science, or engineering.Minimum of five years experience building formal test automation scripts related to data quality, preferably in the context of an agile/scrum style environment.Understanding of Data Governance principles and how Data Governance relates to Data Quality Management.A mastery of how data quality is measured, including understanding of completeness, uniqueness, validity, accuracy, integrity, timeliness, etc.Experience designing and implementing data quality processes and frameworks.Strong troubleshooting skills for reaching to root cause of customer reported issues.Experience with cloud based data warehouses (e.g Snowflake, Amazon Aurora, SAP Hana, MicrosoftSQL, Oracle, MongoDB, Hadoop, Spark).Experience working with complex data domains with complex relationships between different data domains.Experience with both automated and manual data validation, with the focus on increasing automation.Proficient in scripting with Python and SQL queries related to test automation (e.g. Cucumber, Girkin etc.).Comfortable with version control systems such as Jira, Git/GitHub, Bitbucket.Knowledge of various data communication protocols (e.g. REST API, Kafka, gRPC).Prefer experience with products incorporating machine learning technology.Excellent verbal and written communications skills, and able to communicate very technical subject matter to non-technical users.Ability to work well both independently and collaboratively, in a fast-paced and demanding agile environment.About Bio-Rad:Bio-Rad is a global leader providing a broad array of clinical diagnostics and life science research products. With a team of more than 8,000 employees and a global network of operations serving our customers, we help people live longer, healthier lives.Bio-Rad was founded over six decades ago and has continued to provide the healthcare industry with innovative and useful products that help life science researchers accelerate the discovery process and medical diagnostic labs obtain faster, better results.EEO/AA Employer/Veterans/Disabled/Race/Ethnicity/Gender/AgeAgency Non-Solicitation:Bio-Rad does not accept agency resumes, unless the agency has been authorized by a Bio-Rad Recruiting Representative. Please do not submit resumes unless authorized to do so. Bio-Rad will not pay for any fees related to unsolicited resumes.To apply, please visit: https://careers.bio-rad.com/jobs/data-quality-engineer-hercules-california-united-statesjeid-074ac49041712a47955eb78c6fd9f95f",sf,de
4,Verizon,Telecommunications,4,AI Chatbot Engineer,"Walnut Creek, CA",$89K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_4b807be7&cb=1619369427635&jobListingId=4066604884,"When you join VerizonVerizon is a leading provider of technology, communications, information and entertainment products, transforming the way we connect across the globe. We’re a diverse network of people driven by our ambition and united in our shared purpose to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward – and you can too. Dream it. Build it. Do it here.What you’ll be doing...We are honored that you are considering Visible as your next place of employment. Visible is the first all-digital wireless carrier in the U.S. Named by Fast Company as one of the most innovative companies in the world, Visible offers unlimited messages, minutes, and data, on Verizon’s Network. Visible is designed to fundamentally change the way millions of consumers sign up for and manage their phone service. Although headquartered in Denver, we have a permanent Work from Home Structure, and our team members work remotely.We are looking to hire an AI Chatbot Engineer to join the Visible Engineering Team.Lead and develop Chatbot conversational Flows in utilizing in-house and vendor products for solving customer’s problems and increasing customer satisfaction.Develop and lead customer facing applications that will be driven by chatbots across Agent automation /Mobile/Desktop.Participate in IT security process for application assessment and providing the fixes and remedy for the identified issues.Lead projects, Coordinate development activities, ensure timely delivery of modules to business with good quality and report project status to management.Coordinate application architecture and technology initiatives to ensure adoption of proper technology for application development.Manage application initiatives, schedule and align business projects working with CAM and business sponsors.Application management, handling customer escalations, production change controls and ongoing application maintenance.Coordinate activities to diagnose and resolve customer and other production issues by working with other IT teams and business partners.Ensure proper change control procedures are followed complying with IT change management.Business communications and relationships with other IT, Network, Marketing, Products and Revenue Assurance teams.Communicate effectively with business sponsors and other partner teams to maintain a healthy working relationship.Exchange and share information about product, pricing and promotions as needed to fulfill business needs and to keep IT applications up to date.Keep up to date with new technology to provide suggestions on technology directions to management.Help management in developing future strategies for IT Applications, development methodologies and technology solutions.What we’re looking for...You’ll need to have:Bachelor’s degree or four or more years of work experience.Six or more years of relevant work experience.Experience in programming with Java & J2EE Technologies.Experience on NLP/NLU.Experience with Artificial Intelligence / Machine learning methodologies.Experience on Google Dialog Flow.Experience on D-Tree implementation.Experience with Micro services architecture and Springboot development.Even better if you have:A Degree.Mobile/Desktop application development experience.Experience on implementation of Conversational Chatbots.Experience with chat platforms like Salesforce/Live Person.Experience with JWT and Oauth Framework.Experience with Social Media handles and integration with Google Dialog Flow.Experience with application performance tuning and monitoring.Experience in using messaging / JMS.Experience in GCPimplementations.Experience with in-memory data store and cache service.Experience in Unix/Linux operating systems.Knowledge of shell scripting.Equal Employment OpportunityWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",sf,de
5,Netskope,Information Technology,4,Principal Software Engineer - Data,"San Francisco, CA",$145K - $181K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=985336&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_93e6353d&cb=1619369427636&jobListingId=3431062487,"About NetskopeToday, there are more data and users outside the enterprise than inside, causing the network perimeter as we know it to dissolve. We realized a new perimeter was needed, one that is built in the cloud and follows and protects data wherever it goes, so we started Netskope to redefine Cloud, Network and Data Security.
Since 2012, we have built the market-leading cloud security company and an award-winning culture powered by hundreds of employees spread across offices in Santa Clara, San Francisco, Seattle, Bangalore, London, Melbourne, and Tokyo. Our core values are openness, honesty, and transparency, and we purposely developed our open desk layouts and large meeting spaces to support and promote partnerships, collaboration, and teamwork. From catered lunches and office celebrations to employee recognition events (pre and hopefully post-Covid) and social professional groups such as the Awesome Women of Netskope (AWON), we strive to keep work fun, supportive and interactive.Visit us at Netskope Careers and follow us on Twitter @Netskope and Facebook.

Principal Software Engineer - Data

With a mission to evolve security for the way people work, Netskope, a cloud security company, was founded by early architects and distinguished engineers from security and networking leaders like Palo Alto Networks Juniper Networks, Cisco, and VMware.

Principal Engineer - Data

We are looking for skilled engineers with eyes for building and optimizing distributed systems. From data ingestion, processing, storage optimization, we work closely with engineers and the product team to build highly scalable systems that tackle real world data problems. Our customers depend on us to provide accurate, real-time, and fault tolerant solutions to their ever growing data needs. The senior level engineer position is a highly technical position with responsibility to lead the development, validation, publishing, and maintenance of logical and physical data models which support various OLTP and analytics environments.

Role and Responsibilities:

Designs and implements planet scale distributed data platform, services and frameworks including solutions to address high-volume and complex data collections, processing, transformations and analytical reporting
Work with the application development team to implement data strategies, build data flows and develop conceptual data models
Understand and translate business requirements into data models supporting long-term solutions
Develop best practices for standard naming conventions and coding practices to ensure consistency of data models
Analyze data system integration challenges and propose optimized solutions
Research to identify effective data designs, new tools and methodologies for data analysis
Provide guidance and expertise to development community in effective implementation of data models and building high throughput data access services
Work through all stages of a data solution life cycle: analyze/profile data, create conceptual, logical & physical data model designs, derive reporting and analytics solutions
Evaluate existing data and physical databases for variances and discrepancies
Participate in data strategy and road map exercises including data architecture, business intelligence / data lake tool selection, technical design and implementation
Provide technical leadership in all phases of a project from discovery and planning through implementation and delivery

Qualifications:

At least 8 years of hands-on experience in architecture, design or development of enterprise data solutions, applications, and integrations
Ability to conceptualize and articulate ideas clearly and concisely
Demonstrable experience in developing, validating, publishing, maintaining logical and physical data models
Excellent communication, presentation and interpersonal skills
Hands-on experience with modern enterprise data architectures and data toolsets (e.g.: data warehouse, data marts, data lake, 3NF and dimensional models, modeling tools, profiling tools)
Bachelor or Master degree in STEM majors
Strong algorithms, data structures, and coding background with either Java, Python or Scala programming experience
Exceptional proficiency in SQL
Experience building products using 1 of the each following distributed technologies:  Relational Stores (i.e. Postgres, MySQL or Oracle)  
Columnar or NoSQL Stores (i.e. Big Query, Clickhouse, or Redis)  
Distributed Processing Engines (i.e. Apache Spark, Apache Flink, or Celery)  
Distributed Queues (i.e. Apache Kafka, AWS Kinesis or GCP PusSub)
Experience with software engineering standard methodologies (e.g. unit testing, code reviews, design document)
Experience working with GCP, Azure, AWS or similar cloud platform technologies a plus
Ability to drive change through persuasion and consensus

#LI-SC1

#LI-REMOTE",sf,de
6,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,"Sr. Staff Engineer, Software Engineering","San Francisco, CA",$103K - $197K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_34b847cd&cb=1619369427636&jobListingId=4042138963,"Thermo Fisher Scientific Inc. is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them.Location/Division Specific Information:South San Francisco, CAGenetic Sciences DivisionHow will you make an impact?A successful candidate will have a thorough understanding of software and process development. This person will have a proven ability to work across cross functional teams and move technology projects forward while addressing and overcoming challenges.What will you do?Comprehensive knowledge in building software products and associated architectureBuild rapid prototypes, take them to production quality code and create new disruptive productsDocument and deliver assigned projects on-time from inception through completion.Identify and manage project risks.Work cross-functionally to create shared solutions.Participate in and/or drive departmental or interdepartmental projects.How will you get here?Education/Experience:Bachelor’s degree in computer science, engineering or life science related field or equivalent experience; advanced degree preferred.5+ years of experience leading or managing large scale software projects.10+ years of industry experience as a technical lead or software architect role.5+ years of direct work experience in medical device instrument is a plusExperience building/releasing web applications and microservices with Java 8+, Angular, Vue, SQL, NoSQL, Machine Learning, REST APIs, GraphQL, Python 3, Spring Framework, Guice, and Big data technologies like Hadoop, Spark.Strong experience and understanding of AWSExperience across the software development life cycle using methodologies such as Agile, Scrum or similar.Experience in Quality System Regulations (QSR) 21 CFR 820; Design Control: ISO 13485:2003, FDA regulations is a plus.Knowledge, Skills, Abilities:Proven interpersonal communication (written and verbal), and organizational skills.Ability to motivate a team to work in a fast-paced and changing environment.Experience developing clinical systems or production systems in the life science spaceExperience with lab processes, automation, and software (LIMS) is a plus.Our global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.*EVRD2020 *GTSDouble",sf,de
7,HealthCrowd,Health Care,3.2,Data Engineer,"San Mateo, CA",$101K - $116K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_3e9f1c06&cb=1619369427637&jobListingId=4013831669,"We're looking for a brilliant and versatile entry-level Data Engineer to help us build and scale HealthCrowd. Though we prefer candidates with internship or graduate research experience, those who without are welcome to apply as well.YOU, our Data Engineer is a key member of our Engineering and Customer Success teams. Just like your Software Engineer counterpart at HealthCrowd, you have software engineering and technical skills; however, you are also good at:getting our customers off the ground and running,measuring their successes/shortfalls,turning data into insights and helping them meet their ROI objectives.If you'd like a technical position with some customer-facing responsibilities and a skew on data analytics, this could be just the right opportunity.YOU get:To truly participate in building a company and its productsThe opportunity to learn from and be mentored by senior team membersAn environment where your success is our success — we'll invest in your growthSalary + stock options + 401(k)Are you the right person to help us capture the opportunity ahead?YOU:Have a graduate degree in STEM from a top school, with demonstrable academic brillianceHave 1-2 yrs of professional/academic experience in software engineering or data analysisHave familiarity with (some of) the following: non-relational database, data analysis and visualization, statistical model, ML/NLP framework, OOPAre willing, able and excited to tackle problems outside your comfort zoneAre located in the San Francisco Bay Area (or will find a way to get here!)We don't want to waste your time or ours. If you think you could be a fit, please:Respond with your resume to jobs@healthcrowd.com with “Data Engineer” in the subject line,send any supporting material that you think will help us get to know you better,and answer the questions below (there are no correct answers)What is the single most important quality/attribute you possess that will ensure your success at this position and why?What single project have you done (whether school or professional project) that demonstrates your critical thinking and problem solving skills?",sf,de
8,Amobee,Business Services,3.8,"Scientist/Machine Learning Engineer, Applied Science","Redwood City, CA",$124K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1021349&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_184a41e2&cb=1619369427637&jobListingId=3537354093,"The Scientist/Senior Scientist/Lead Scientist - (Machine Learning Engineers) will work with the rest of the team to research, invent, and implement the next generation prediction, optimization, and analytics technology. You are a brilliant, motivated self-starter and an extremely fast learner with top notch problem solving, and analytical skills. You have a deep sense of curiosity and innate desire to dig deep into terabytes of data and love to play with the innards of complex algorithms, mathematical constructs and code.Responsibilities Research, design and/or implement solutions to challenging problems in real-time bidding domain, such as all kinds of optimization problems, audience understanding, etc.Research and improve features and machine learning models for production pipeline.Provide insights and suggestions on customer campaign optimization problems and product/platform optimization problems through statistical data analysis when needed.Drive innovation by identifying and formulating new problems, publishing papers, filing patents, etc.Required QualificationsPhD degree in a closely related field (e.g.: computer science/engineering, optimization) with publications in the area is strongly preferredOr Masters with significant experience in advertising and Machine LearningExperience in one or more of the following areas: machine learning, data mining, statistical modeling, optimization, algorithms, big-data, game theoryProficiency with one or more programming languages - ability to write/debug production code.Excellent communication skills – ability to present and communicate complex ideas in simple termsStrong statistical/math/analytical abilities; Exceptional problem solving skillsDesired QualificationsPrevious experience in the advertising industryStrong programming experience with Java, C/C++, Python and/or ScalaExcellent knowledge in algorithms and data structures#LI-KR1About Amobee The world’s leading independent advertising platform, Amobee unifies all advertising channels—including TV, programmatic and social—across all formats and devices. We provide marketers with streamlined, advanced media planning capabilities powered by in-depth analytics and proprietary audience data. Our platform and technology, provides the most advanced advertising solutions for the convergence of digital and advanced TV— including linear TV, over the top, connected TV, and premium digital video. Enabling advertisers to plan and activate across more than 150 integrated partners, including Facebook, Instagram, Pinterest, Snapchat and Twitter. Amobee has been named to Fortune’s Top 10 Best Workplaces in Advertising and Marketing. Amobee’s platforms have been widely recognized amongst our industry winning numerous awards in technology innovation, see all Amobee Awards. We are a wholly owned subsidiary of Singtel, one of the largest telco companies in the world, reaching over 700 million mobile subscribers in 21 countries. Amobee operates across North America, Europe, Middle East, Asia and Australia. For more information, visit amobee.com or follow @amobeeIn addition to our great environment, we offer a competitive base salary, employee development programs and other comprehensive benefits. Please send a cover letter along with your resume when applying to the position of interest located at Amobee.com. We are an Equal Opportunity Employer. No phone calls and no recruiting agencies, please.",sf,de
9,Rakuten Americas,Information Technology,3.6,Big Data Engineer,"San Mateo, CA",$70K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_76e46d00&cb=1619369427638&jobListingId=4043153761,"SUMMARY: The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!KEY RESPONSIBILITIES1. Participate in design & development of Product Catalog & Search2. Work on implementing storage integration3. Work on developing code and unit testing search index integration4. Implement large data processing (stream & batch) solutions5. Work on enhancing APIs or implementing new APIs6. Implement analytics jobs to process large amount of dataMINIMUM REQUIREMENTS (Knowledge, Skills, AbilitiesTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.Strong knowledge of JavaStrong knowledge of design patterns, OOPS principles and data structuresStrong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, KafkaExperience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software developmentExperience with Relational databases, queries and RDBMS best practicesStrong troubleshooting and performance tuning skillsAbility to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.Able to effectively communicate across teams and roles.QUALIFICATION REQUIREMENTS BS/MS in Computer Science or a related field1-5 years of solid Java back-end experienceRAKUTEN SHUGI PRINCIPLESOur worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.Always improve, always advance. Only be satisfied with complete success - Kaizen.Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.#LI-DB1",sf,de
10,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,"Staff Engineer, Systems Engineering","San Francisco, CA",$61K - $124K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_0ea9efd7&cb=1619369427638&jobListingId=4042138843,"Job DescriptionJoin the forefront of innovation in genetic analysis for research & clinical applications. Our teams develop platforms, consumables, and reagents that help bring criminals to justice, ensure reproductive health, accelerate disease research, advance methods for syndromic testing of infectious diseases and viruses, and keep the world’s food supply safe. As the leading provider of genetic analysis solutions and leveraging the resources of a $24B enterprise, our technologies have great impact worldwide. And as a member of our team, you can play a critical role in helping us fulfill our global mission of making the world healthier, cleaner, and safer.How will you make an impact?Staff Engineers are key to defining and developing instrument and consumable products in the Genetic Sciences Division. This individual leads system definition & system integration aspects of product development in collaboration with highly technical and specialized engineering professionals and scientists to develop instruments and applications for our world class qPCR, Capillary Electrophoresis, Rapid DNA, and Microarray platforms in both RUO and IVD marketsThe Staff Engineer will have responsibility for providing direction and focus to drive Division objectives as follows:Exercise judgement and experience in qPCR to understand customer needs and goals to deliver on optimal product requirements on performancePartner with technical leads in chemistry, assay design, and system hardware to design products and conduct/facilitate performance trades between the different technical disciples to deliver optimized product performanceWork with a team to develop new highly multiplexed IVD qPCR assays including data analysis, troubleshooting and optimization.Technical lead for troubleshooting interface between system and application challengesContribute to data-driven decision making by designing multifactorial experiments, analyzing, and presenting resultsPartner with our Product Management teams to define system architecture and integration design, development, feasibility testing.Understand clinical customers and effectively translate their needs to product requirementsWork with cross-functional subsystem owners to design and develop integrated systems from beginning to end of the clinical sample workflow(s) including leading stage gate design reviews, d/pFMEA processes, and design documentation.Key experiences should include:Experience in the entire product development life cycle through customer care for qPCR based assays. (experience with QuantStudio product line and/or digital PCR is a plus)Experience in developing and analyzing multiplexed PCR and qPCR assays, with IVD (CE or FDA) experience as a plusExperience with nucleic acid sample extraction, purification, preparation and characterization from a variety of biological sources.Excellent organizational skills, including the ability to efficiently evaluate, prioritize and handle multiple programs/projects and priorities.Experience with robotic liquid handling systems (e.g. Tecan/Hamilton) would be a plusFluidics or optics experience a plus.Key people attributes:Fosters collaborative relationships and builds credibility across functions/teamsClear communication to product management and customer support teamsHow will you get here?Education:MS/Ph.D. degree in bioengineering or molecular biology or BS with equivalent experience.Experience:8+ years experience in a life science instrumentation, consumables, and assays in R&D setting, preferably in genomics3+ years experience serving regulated markets in a commercial environmentTrack record of delivering successful RUO and IVD products with a thorough understanding of quality systemsDemonstrated success working in a global matrixed-environment & willingness to travel up to 25%, domestic or internationallyDemonstrated ability to effectively build and manage internal and external relationships at senior levelsEVRD2020 *GTSDouble",sf,de
11,Collective Health,Information Technology,3.7,Data Engineer,"San Francisco, CA",$94K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=8095&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_063c1116&cb=1619369427639&jobListingId=4065224679,"We all depend on healthcare throughout our lifetimes, for ourselves, and our families and friends, but it is notoriously difficult to navigate and understand. As an industry that comprises 20% of the US economy we think healthcare should work better for all of us. At Collective Health we believe it's time for a new day in healthcare where as members we are informed and empowered to make the right care choices when the decisions are urgent and critical.
We deliver a connected healthcare experience for over a quarter million members and 60+ companies across the nation who want the best for their employees. We've got a ton of interesting problems to solve around data pipeline design and implementation, data architecture and modeling, distributed systems, and more. If you're passionate about tackling hard problems while making a real difference in the world, we'd love to talk!What you'll do: 

Data Pipelines - Create new pipelines and improve/maintain existing pipelines using Spark (Scala, Pyspark, Spark SQL)
Data Modeling - Partner with analytic consumers to design logical and physical schemas, improve existing data models and build new ones
Cross-functional Collaboration - Interface with Product, Engineering, Data Science, Analytics/BI, and Operations to understand their data needs, providing both consultative and data engineering solutions for consumers
Build data expertise and own data quality across various business domains including healthcare claims and member experience

Your skills and qualifications include:



BS degree in Computer Science or related technical field, or equivalent practical experience
2+ years proven work experience as a data engineer, working with at least one programming language (e.g. Scala, Python/PySpark) plus SQL expertise
2+ years experience with schema design, dimensional data modeling, and large-scale data warehousing architecture
Expertise in building data pipelines through efficient ETL design, implementation and maintenance
Background working with distributed data systems such as Spark, Presto, Hive, and Redshift. Experience with schedulers/workflow management tools (e.g. Airflow) a plus
Excellent communication skills to collaborate with stakeholders in Engineering, Product, Data Science, Analytics/BI, and Operations

Collective Health is a technology company simplifying employer healthcare to make health insurance work for everyone. With more than a quarter million members and over 60 enterprise clients—including Pinterest, Red Bull, Restoration Hardware, Box, Activision Blizzard, and more—our technical and customer experience teams are reinventing the healthcare experience for forward-thinking employers and their people across the U.S.

Collective Health is headquartered in San Francisco, CA, with additional offices in Chicago, IL, and Lehi, UT. Founded in 2013, Collective Health is backed by the SoftBank Vision Fund, DFJ Growth, PSP Investments, NEA, GV, G Squared, Founders Fund, Maverick Ventures, Mubadala Ventures, Sun Life, and other leading investors. For more information, visit us at https://www.collectivehealth.com.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Collective Health is committed to providing support to candidates who require reasonable accommodation during the interview process. If you need assistance, please reach out to recruitingaccommodations@collectivehealth.com.

Collective Health",sf,de
12,Taulia,Information Technology,4.7,Data Engineer,"San Francisco, CA",$83K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ab08fb36&cb=1619369427639&jobListingId=4070878748,"About Taulia:Taulia is a fintech provider of working capital management solutions headquartered in San Francisco, California. Taulia helps companies access value tied up in their payables, receivables and inventory. A network of more than 2 million businesses use Taulia’s platform to determine when they want to pay and be paid. Taulia processes more than $500 billion each year and is trusted by the world’s largest companies including Airbus, AstraZeneca, Nissan and Vodafone. For more information, please visit www.taulia.com.About the Job:Taulia is looking for an experienced Data Engineer who has a passion for building data products and systems. Our ideal candidate is bright, responsible, self-motivated, confident, and gets stuff done. We look for problem solvers who have the skill and experience to take large datasets and build the tools, processes, and systems to translate that data into actionable business decisions. Must be willing to do whatever it takes to get the job done while ensuring that we’re building a scalable system for the future of Taulia and our customers. We’re looking for someone who prides themselves on anticipating problems, looking beyond immediate issues and taking the initiative to improve both our software and our development infrastructure.In return you’ll get the reward of working inside a passionate, hungry, and FUN team. You’ll get the joy of bringing a new product to life from concept to delivery, and the technical and business learnings of working with data and users at scale.Essential Duties and Responsibilities:Help build and maintain a streaming infrastructure (AWS Kinesis & Lambda) to translate data from transactional product systems into a scalable DataMart architected for efficient reporting (Aurora). This system must keep up with over 1M messages per day.Help build and maintain processes to automatically supplement each streamed data piece with third party data from numerous APIs and sources (Salesforce, CapIQ, Social123, etc). Making sure our DataMart is always up to date and a true company data hub.Automate processes to transform datasets into efficient structure for reporting, and ensure that data is up to date in reporting tools (Salesforce, Analytics tools, etc).Maintain all components of data pipeline, from coding to deployments to monitoring.Design, build and support pipelines of data transformation, conversion, and validation.Design and support effective storage and retrieval of large datasets (180 million Invoices, Purchase Orders, etc.).Design and implement best practices for cloud based cluster deployments.Requirements:4+ years experience in a Data Engineering oriented role.Experience with AWS - Kinesis, RDS, Redshift, EC2, VPCs, S3, EBS Volumes, etc.Experience with Python, Node.js.Experience with MySQL.BA/BS in Computer Science or related field.Nice to have:Experience with Kinesis/Lambda - Streaming messages, building consuming lambda functions.Experience with Redshift/Aurora - maintaining clusters, designing table structures, interacting with S3 and moving data.Experience integrating with APIs, particularly Salesforce, Box, AWS, etc.GCP:- Looker, Big Query and Google Kubernetes Engine (GKE).Taulia is an Equal Opportunity Employer -Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.If you don't think you meet all of the criteria above but still are interested in the job, please apply. Nobody checks every box, and we're looking for someone excited to join the team.",sf,de
13,Grabango,Information Technology,3.7,Data Engineer,"Berkeley, CA",$76K - $140K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_18b7a6a8&cb=1619369427640&jobListingId=4015637572,"Who we are:Grabango is the leading provider of checkout-free shopper technology for existing stores. Founded by Will Glaser (former founder & CTO of Pandora Media), the Grabango team has developed the only enterprise class solution for large store chains in the market today. Grabango's system accommodates thousands of store locations, hundreds of thousands of SKUs and millions of square feet across a given retail enterprise.We're a growing group of curious, self-directed people working towards a common goal. We delight in taking risks and testing hypotheses in a collaborative environment. Our ability to celebrate both our successes and failures as milestones of progress opens the door to tremendous breakthroughs.Computer vision and machine learning are at the core of our patent pending technology. Our accomplished team is a powerful combination of technology and commerce professionals that are working to ""Eliminate lines and save people time!""Overview:Grabango is looking for a Data Engineer to join our growing team of analytics experts. This Data Engineer will be responsible for expanding and optimizing our data pipeline architecture and managing our data warehouse, as well as optimizing data accessibility for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts, and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.This full-time role reports to the Data Science Manager and is based in Berkeley.What you'll be doing:Create and maintain ETL pipelines that can robustly ingest, transform, and store both external customer data and internally generated dataBuild out our data warehouse and own the data flow between production databases and our data warehouseCollaborate with computer vision and machine learning teams to create data pipelines for iteration of cutting edge computer vision modelsImplement best practices to ensure data quality and integrity in our pipelinesWhat you should have:4-7 years of experience as a data engineerExcellent SQL and Python skillsExperience with both SQL and NoSQL databases, such as Cassandra and MongoDBExperience with data pipelining tools such as dbt, airflow, luigi or DagsterComfort working within systems running Kubernetes, Docker, Linux, GitStrong communication skills to collaborate with cross-functional stakeholdersYou can rapidly become familiar with and apply new tools and technologiesEducations & Certifications:BS in Computer Science, Engineering, or related fieldGrabango Values:Integrity: Do the right thing, particularly when you don't have to.Bold Innovation: Think recklessly, but temper your actions with pragmatism.People Matter: Hire the best, and treasure them.Don't Live with Broken: Have the courage to admit mistakes, and the urgency to correct them.Customer Focus: Deliver beyond expectations, both internally and externally.Inclusion: Foster an environment that welcomes all.Simplify: Everything should be made as simple as possible, but not simpler.Grabango is proud to be an equal opportunity employer and is committed to developing a workplace where diversity and inclusion are an essential part of who we are. We strive to hire and support a workforce as diverse as our shopper base, so we can develop products and services that best suit our customers. We do not make employment decisions based on race, color, religion, ethnic or national origin, nationality, sex, gender, gender-identity, sexual orientation, disability, age, military or veteran status and we comply with all local, state and federal employment laws.Grabango participates in the E-Verify Program, an internet-based system operated by the Department of Homeland Security and the Social Security Administration. It allows employers to confirm an individual's employment eligibility to work in the United States.",sf,de
14,Slack,Information Technology,4.7,Sr. Data Engineer - Data,"San Francisco, CA",$133K - $223K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_8b77e662&cb=1619369427640&jobListingId=4012530242,"Slack is looking for data engineers to join our Data Engineering team. In this role, you will partner cross-functionally with business domain experts, analytics, and engineering teams to design and implement our Data Warehouse model. You will design, implement and scale data pipelines that transform billions of records into actionable data that enable insights.You will work on initiatives and provide hands-on technical support to create impact across Slack by building and scaling our core data model and key company metrics.You have strong technical skills, you are comfortable contributing to a nascent data ecosystem, and you can build a strong data foundation for the company. You are a self-starter, detail and quality oriented, and passionate about having a huge impact at Slack.What you will be doingYou will translate business requirements into data models that are easy to understand and used by different disciplines across the companyYou will design, implement and build pipelines that deliver data with measurable quality under the SLAYou will partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-serviceYou will be a champion of the overall strategy for data across multiple teams and different use casesYou will increase access to foundational company metrics through process and technical foundationsYou will identify, document and promote data engineering best practices throughout SlackWhat you should haveYou have 4+ years of experience working in data architecture, data modeling, master data management, metadata managementYou have recent accomplishments working with relational as well as NoSQL data stores, methods and approaches (logging, columnar, star and snowflake, dimensional modeling)You have a proven track record in scaling and optimizing schemas, performance tuning SQL and ETL pipelines in OLAP and Data Warehouse environmentsYou have demonstrated skills with either Python or Java programming languageYou are familiar with data governance frameworks, SDLC, and Agile methodologyYou have excellent written and verbal communication and interpersonal skills, and ability to effectively collaborate with technical and business partnersYou have hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark), which is a huge plusYou have a Bachelor's degree in Computer Science, Engineering or a related field, or equivalent training, fellowship, or work experienceSlack has a positive, diverse, and supportive culture—we look for people who are curious, inventive, and work to be a little better every single day. In our work together we aim to be smart, humble, hardworking and, above all, collaborative. If this sounds like a good fit for you, why not say hello?Slack is registered as an employer in many, but not all, states. If you are not located in or able to work from a state where Slack is registered, you will not be eligible for employment.Visa sponsorship may not be available in certain remote locations.Visa sponsorship is not available for candidates living outside the country of this position.Slack is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. Slack will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.Slack has transformed business communication. It’s the leading channel-based messaging platform, used by millions to align their teams, unify their systems, and drive their businesses forward. Only Slack offers a secure, enterprise-grade environment that can scale with the largest companies in the world. It is a new layer of the business technology stack where people can work together more effectively, connect all their other software tools and services, and find the information they need to do their best work. Slack is where work happens.Ensuring a diverse and inclusive workplace where we learn from each other is core to Slack’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a pleasant and supportive place to work.Come do the best work of your life here at Slack.",sf,de
15,Procyon technostructure,Accounting & Legal,4,Data Engineer,"San Francisco, CA",$71K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_02933db5&cb=1619369427641&jobListingId=4069904540,"Primary Skills: Data engineering, Python, SQL, Shell, Jenkins, Tableau, HadoopDuration: 6+ Months (Possible extension) Contract Type: W2 OnlyJob Description:As a Data Operations Engineer you will ensure client’s Data Lake within Google Cloud Platform is accurate, consistent and available for our partner teams. You will build and ensure the Data Pipelines are functional and robust enough to enable the decision-makers across the organisation. In every decision that you influence, you will see the product safety improve and be more valuable.In this role you will:Build & maintain Data Platform, Data Pipelines, Data Storage & various Data Tools.Collaborate with Data Engineers, Analysts & Data Scientists to Client the best solutions.Diagnose and solve issues in our existing data pipelines and envision and build their successors.Handle various Data Operations tasks like environment building, data migration, GDPR related tasks etc.Qualifications:Strong experience in SQL, Python & Shell scripting.Strong understanding of Airflow, Luigi or Jenkins.Experience in working on Data Platforms in cloud.Experience in managing BI tools like Tableau.Broad knowledge of the data infrastructure ecosystemExperience with Hadoop or other MapReduce-based architecturesExperience working with large data volumesExperience in building Data Warehouses and data modeling.Understanding of Data Governance, networking & security in cloud.Job Type: Full-timePay: $60.00 - $70.00 per hourSchedule:8 hour shiftDay shiftMonday to FridayExperience:SQL: 2 years (Preferred)Data Engineering: 2 years (Preferred)Google Cloud Platform: 1 year (Preferred)Tableau: 1 year (Preferred)Work Location:One locationWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview process",sf,de
16,Acumen LLC,Government,3.5,Data Engineer I,"Burlingame, CA",$60K - $111K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=4011&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_bad9d2b9&cb=1619369427641&jobListingId=3784052350,"Are you someone who enjoys working with data? Are you a self-motivated thinker who wants to make an impact in the fast-growing healthcare data industry?

We are looking for an entry-level Data Engineer who highly values research, wants to work with multifaceted datasets, and craves new challenges in programming. As a Data Engineer, you will have the opportunity to gain first-hand experience integrating and structuring the healthcare data that shapes policy on many key topics, such as the Affordable Care Act, Medicare, and Medicaid. You will also have the chance to work closely with seasoned programmers, developing the skills to work with data management tools and various programming languages. In addition, you will work alongside smart, vibrant people with a passion for the exciting future of healthcare research.

The Data Engineer will:


Extract, transform, and load (ETL) big data.
Develop complex data processing algorithms that combine multiple data sources, while optimizing run-time efficiency.
Develop data structures, databases, and querying programs which facilitate efficient data access.
Develop data structures from claims and enrollment data which support research and analytic activities of in-house analysts as well as congressional and federal agencies.
Ensure data inventory is complete and accurate through application design, including fault analysis and detection, quality control, and the development of tracking systems.
Collaborate with other Data Engineers and in-house researchers to maintain systems, produce documentation, and educate internal and external users about company resources.
Perform validation checks across multiple sources to verify data integrity as needed.
Perform other duties and responsibilities as assigned.

Qualifications Required

A Bachelor’s in Computer Science, Statistics, Mathematics, Operations Research, Economics, Public Health, or related field with quantitative emphasis
Strong organizational, planning, and problem solving skills
Team player with strong interpersonal skills
Excellent written and oral communication skills
Familiarity with one or more computer programming languages

Qualifications Desired

Master’s in Information Management Systems, Statistics, Mathematics, Operations Research, Economics, Public Health, a related field with quantitative emphasis, or 2+ years of work experience in a field with quantitative emphasis
Interest in big data
Interest in making an impact in the field of healthcare policy research
Previous experience in a Data Analyst/Data Engineer position
1+ years of experience working with programming languages such as SAS, SQL, Python, or R
1+ years of experience working with databases or data pipelining tools

Please submit a cover letter and resume to be considered for this position.

Due to the sensitive nature of much of our work, all Acumen employees must undergo a background check. Your employment will be contingent upon your completing, and Acumen reviewing to its satisfaction, a mandatory background check. Employees who work with particularly sensitive information may be asked to undergo an additional background check after starting work. Please note this additional background check requires a minimum of three years' residency within the United States.Required Skills

Required Experience

Job Location

Burlingame, US-CA
",sf,de
17,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,Systems Engineer - Software/IT,"San Francisco, CA",$109K - $161K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_1f452726&cb=1619369427641&jobListingId=4042138736,"Thermo Fisher Scientific Inc. is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them.Location/Division Specific InformationJoin the forefront of innovation in genetic analysis for research & clinical applications. Our teams develop platforms, consumables, and reagents that help bring criminals to justice, ensure reproductive health, accelerate disease research, advance methods for syndromic testing of infectious diseases and viruses, and keep the world’s food supply safe. As the leading provider of genetic analysis solutions and leveraging the resources of a $24B enterprise, our technologies have great impact worldwide. And as a member of our team, you can play a critical role in helping us fulfill our global mission of making the world healthier, cleaner, and safer.How will you make an impact?You will be key to defining and developing instrument and consumable products in the Genetic Sciences Division. Working alongside a senior systems engineer, you will assist with system definition & system integration aspects of product development in collaboration with highly technical and specialized engineering professionals and scientists to develop instruments and applications for our world class qPCR, Capillary Electrophoresis, Rapid DNA, and Microarray platforms in both RUO and IVD markets.What will you do?Partner with our Product Management teams to define system architecture and integration design, development, feasibility testingUnderstand clinical customers and effectively translate their needs to product requirements, experience in usability engineering is a plusWork with cross-functional subsystem owners to design and develop integrated systems from beginning to end of the clinical sample workflow(s) including leading stage gate design reviews, d/pFMEA processes, and design documentationPlan, develop, and analyze system integration in order to maintain requirement traceability through various subsystems and verification activities in collaboration with subsystem requirements ownersContribute to data-driven decision making by designing experiments, analyzing, and presenting resultsWork hand-in-hand with the Operations team to transfer your products into manufacturingHow will you get here?EducationBachelor’s degree in Bioengineering or related discipline; Master’s degree is preferredExperience3+ years experience in a life science instrumentation, consumables, and assays in R&D setting, preferably in genomics2+ years of relevant industry/academic wet lab experience using a variety of laboratory techniquesFamiliarity with networking protocols (TCP/IP, HTTP) and standard network architecturesWorking knowledge of C, Java, and scripting languages such as Python, Perl, etc.Experience with software architecture and development processHighly data-driven/detail oriented and ability to understand individual's results effect on a systems levelExperience in systems engineering processes, from requirements gathering and risk analysis to statistical power in validation is a plusPrevious experience in developing moderate complexity integrated life sciences or clinical instrumentation, consumables, and software in RUO and IVD environment is highly preferredKnowledge, Skills, AbilitiesStrong understanding of genetic analysis tools, workflows, and chemistry in at least one of these areas: CE Sanger sequencing, qPCR, microarray, or sample preparationExcellent organizational skills, including the ability to efficiently evaluate, prioritize and handle multiple and changing programs/projects and prioritiesFoster collaborative relationships and builds credibility across functions/teamsMaintain a high level of professional expertise through familiarity with current engineering/scientific literature, competing technologies, and/or products as well as attendance of seminars and meetingsThis position has not been approved for relocation assistance.Our global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.Apply today! http://jobs.thermofisher.com*EVRD2020 *GTSDouble",sf,de
18,Deep-Labs,Information Technology,3.7,Data Engineer,"San Francisco, CA",$151K - $182K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=148364&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_f8216c1c&cb=1619369427641&jobListingId=4065799184,"Position Overview: Deep Labs is looking for an experienced Data Engineer to join ourgrowing team as we enter our next phase of growth. We are looking for a professionalwho has experience working in a fast-growing technology startup environment.We are looking for someone who enjoys the experience of turning the chaos of messydata into beautiful adaptable structures – you probably have a color-coordinated sockdrawer. You live in the clouds both in terms of delivery and creative thinking. Youprobably find the data scientists you work with frustrating because they just don’t quiteget the concepts of scalability and reproducibility no matter how many times you’ve triedto explain it to them. You hate being micromanaged and prefer to take ownership of thetasks and are opinionated on design. You understand that documentation is the heart ofeverything and are always the one to point out that more time should be spent on it.This role reports to the Director of Data Science. Our Mission: At Deep Labs, we believe Persona-Based Intelligence is the nextgeneration of true context-aware computing. Our mission is to be the world leader in thedelivery of persona-based decisions through innovation and technology, helping ourclients make faster and better decisions while improving customer experience.  Our People: We are a global group of unique, accomplished professionals who valuethe sharing of ideas, respect our diverse differences and values, are trusted advisors,yearn to create meaningful change, and explore opportunities to improve. We supporteach other and know that each win is a win for us all. Our people are our most valuableasset. Guided by our Core Values, we foster an environment that attracts and engagesour people to achieve their full potential, individually and as a team.Responsibilities:Own our data pipeline, responsible for the entirety of the data lifecycleDevelop containerized microservices and implement best practices in the reusability of data Collaborate in a small squad, as part of a larger team, architecting, extending, maintaining, and tuning our big data capabilitiesAccountable for the technical design (with support from the lead architect) and implementation of the application, end to endYou will be responsible for the code quality, CI/CD, and software development lifecycle (SDLC) of the applicationMonitor system performance and implement tuningYou will work with both product and engineering teams to ensure that our systems are fit for purposeAccurately estimate and implement feature work to a high standard, meeting both functional and non-functional requirements, on timeManage technical debt, making the right calls between balancing pragmatic delivery and compromising implementation patterns.Contribute to technical project meetings, technical reviews and delivery activities.Experience: You have a proven track record of:5+ yrs. operating in the big data stack (Spark; must, Scala, Kafka, Delta Lake; preferred) -- data-intensive applications running on distributed infrastructureDesigning and managing the successful delivery of cloud-native data pipeline applications at scaleExperience in the SDLC for a major projectDiscerning the nuances of the business context that should impact on system design and applying the right solution to the problemCreating a shared service used by multiple consumersDesigning interfaces with particular awareness of whether functionality should be inside or outside a service's boundarySpecific Skills:You are:Proficient in PythonProficient in SQL (MySQL and PostgreSQL databases)Proficient in Spark and Spark SQLExperienced across GCP (DataProc, Big Query), AWS (EMR)Experienced with containers and orchestration (Docker, Kubernetes)Experienced in the ELT paradigm and have worked with a range of tools, experience with Data Bricks is a plusHighly detail-orientedFocused on deliveryYou know:Modern big data architectureMicroservice architecture patternsAPI implementation patterns and interfacesBig data file formats (AVRO, ORC, PARQUET) and their different featuresResponsibilities: Own our data pipeline, responsible for the entirety of the data lifecycleDevelop containerized microservices and implement best practices in the reusability of data Collaborate in a small squad, as part of a larger team, architecting, extending, maintaining, and tuning our big data capabilitiesAccountable for the technical design (with support from the lead architect) and implementation of the application, end to endYou will be responsible for the code quality, CI/CD, and software development lifecycle (SDLC) of the applicationMonitor system performance and implement tuningYou will work with both product and engineering teams to ensure that our systems are fit for purposeAccurately estimate and implement feature work to a high standard, meeting both functional and non-functional requirements, on timeManage technical debt, making the right calls between balancing pragmatic delivery and compromising implementation patterns.Contribute to technical project meetings, technical reviews and delivery activities.Experience 5+ yrs. operating in the big data stack (Spark; must, Scala, Kafka, Delta Lake; preferred) -- data-intensive applications running on distributed infrastructureDesigning and managing the successful delivery of cloud-native data pipeline applications at scaleExperience in the SDLC for a major projectDiscerning the nuances of the business context that should impact on system design and applying the right solution to the problemCreating a shared service used by multiple consumersDesigning interfaces with particular awareness of whether functionality should be inside or outside a service's boundarySpecific Skills: Proficient in PythonProficient in SQL (MySQL and PostgreSQL databases)Proficient in Spark and Spark SQLExperienced across GCP (DataProc, Big Query), AWS (EMR)Experienced with containers and orchestration (Docker, Kubernetes)Experienced in the ELT paradigm and have worked with a range of tools, experience with Data Bricks is a plusHighly detail-orientedFocused on deliveryYou know: Modern big data architecture microservices architecture pattern API implementation patterns and interfacesBig data file formats (AVRO, ORC, PARQUET) and their different featuresWhy Deep Labs?At Deep Labs, there is tremendous potential to learn and grow, while also contributing to policies, decisions, and the direction of the company. We offer competitive compensation and benefits and provide a highly open, honest, and fun work environment. Our company is committed to equal employment opportunity. We will not discriminate against employees or applicants for employment on any legally-recognized basis [”protected characteristics’] including, but not limited to: race, religious creed (including religious dress and grooming practices), color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy), gender, gender identity, gender expression, age for individuals over forty years of age, sexual orientation, military and veteran status of any person, or any other consideration made unlawful by federal, state or local laws.",sf,de
19,DoorDash,Information Technology,4,"Software Engineer, Data Infrastructure","San Francisco, CA",$121K - $133K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=8095&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ddea5026&cb=1619369427641&jobListingId=3411775400,"Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash's three-sided marketplace of consumers, merchants, and dashers.

The Data Infrastructure team manages DoorDash's massive database and makes data accessible for teams driving decision making, machine learning, and experimentation. The team is relatively small, so there's an opportunity for impact where you can help grow the team and shape the roadmap for data infrastructure at DoorDash.

What You'll Do

Work on our data pipeline, ETL systems, and real-time dataCome up with solutions for scaling data infrastructureHelp all departments of the company have access to our dataCollaborate in a dynamic startup environmentImprove logistics by taking on cutting-edge, technical problems

What We're Looking For

B.S., M.S., or PhD. in Computer Science or equivalent5+ years of experience with CS fundamental concepts and OOP languages like Java and PythonExperience working with databases (e.g. SQL) and data infrastructureExperience in big data technology like Presto, Snowflake, Hadoop, Airflow, KafkaA passion for analyzing data to inform decisionsExperience improving efficiency, scalability, and stability of system resources

Why You'll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It's something everyone at DoorDash embraces and embodies.We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day. We are learners - We're not afraid to dig in and uncover the truth, even if it's scary or inconvenient. Everyone here is continually learning on the job, no matter if we've been in a role for one year or one minute.We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights. We offer great compensation packages and comprehensive health benefits.

About DoorDash

DoorDash is a technology company that connects customers with their favorite local and national businesses in all 50 US states, Canada, and Australia. Founded in 2013, DoorDash empowers merchants to grow their businesses by offering on-demand delivery, data-driven insights, and better in-store efficiency, providing delightful experiences from door to door. By building the last-mile delivery infrastructure for local cities, DoorDash is bringing communities closer, one doorstep at a time. Read more on the DoorDash Engineering blog or www.doordash.com.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.",sf,de
20,Splunk,Information Technology,4.2,Data Engineer,"San Francisco, CA",$117K - $210K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_c975002a&cb=1619369427641&jobListingId=4069920632,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.As the Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.What you'll do: Yeah, I want to and can do that.Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.Requirements: I’ve already done that or have that!5+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data ScientistSavviness with complex SQL queries and knowledge of database technologies including window and analytical functionsExperience with Python analytic libraries and Business Intelligence tools such as Tableau.An ability to provide technical guidance, direction and problem solving to data engineering team members.Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.A familiarity working with an AGILE/SCRUM process management.Preferred knowledge and experience: These are a huge plus.Knowledge of Splunk productsAgile certificationsEducation: Got it!Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.What We Offer You: Wow, I want that.A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.A stable, collaborative and supportive work environment.We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environmentThis isn’t a job – it’s a life changer – are you ready?Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",sf,de
21,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,Software Systems Engineer,"San Francisco, CA",$120K - $147K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_c65b60b1&cb=1619369427642&jobListingId=4042138940,"Job Title: Software Systems EngineerRequisition ID: 127224BRThermo Fisher Scientific Inc. is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them.How will you make an impact?You will be a part of the fast-growing field of Clinical Diagnostics developing systems for molecular diagnostics based on real-time PCR technologies. Your interaction and collaboration with a talented team of assay, reagents, software, hardware designers and manufacturing will revolutionize healthcare through high throughput diagnostic systems. Thermo Fisher Scientific Inc. has played a pivotal role in the COVID-19 pandemic with the TaqPath COVID-19 Combo Kit for testing SARS-CoV-2. We continue to innovate and provide new solutions for the pandemic and we need your talent to help save lives.We are developing an automated workflow for COVID-19 testing using liquid handlers, nucleic acid purification systems and real-time PCR instrumentation. The software experience is essential in providing users an easy to operate solution that minimizes hazards and the software system must be evaluated for use by trained personnel conducting clinical molecular tests.What will you do?Work with cross-functional team to design and develop integrated software systems including defining requirements and specifications of input/output processes, defining hardware or software compatibility and leading stage gate design reviews and design documentationParticipate and provide input into hazard analysis, d/pFMEA, and usability risks as the lead representative to software integrationDefine application interfaces between components, drive standards for data transferDevelop, write and perform integrated software system testingDevelop technical documentations and present for internal and external useTrain users on how to install and configure the system into their environmentsHow will you get here?EducationBachelor’s in Molecular Biology, Biology, Chemistry, Computer Science, Engineering or related disciplineExperience2+ years software systems integration, software architecture and design experience2+ years of product development experience2+ years of lab experience conducting diagnostic testing specifically with qPCRPrior hands on experience with data structures, algorithms, operating systems, and distributed systems fundamentalsKnowledge, Skills, AbilitiesKnowledge of fundamental networking conceptsRequires a good understanding of software development, software applications, system administration and integration and ability to multi-task and manage multiple prioritiesAbility to work independently, be a problem solver and strong desire to learn in a fast-paced environmentOur global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.Apply today! http://jobs.thermofisher.com*EVRD2020 *GTSDoubleThermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.",sf,de
22,Glu Mobile,Information Technology,4,Data Engineer,"San Francisco, CA",$150K - $170K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=148364&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_46093a4f&cb=1619369427642&jobListingId=3431288406,"Team OverviewThe Data Engineering team at Glu builds core data infrastructure and applications in support of all areas of our business, including our studio teams, user acquisition, monetization and finance. Glu is passionate about maximizing the value that data and analytics can provide to the business and is aggressively investing in new capabilities. Our team covers a lot of ground from data ingestion through to machine learning applications. Role OverviewWe leverage a cutting-edge tech stack to build both batch systems (YARN+Spark/Hive) and stream processing applications (Kinesis/Flink/Spark Streaming/Druid) that operate efficiently at high scale. The ideal candidate has a strong engineering background and has built robust data platforms and pipelines and takes complete ownership of their area of expertise. This is a fantastic opportunity to use your engineering skills to make a material impact on a highly valued analytics platform.You'll most often be:Taking ownership of and developing critical new features for our next-generation analytics platform, supporting Glu's worldwide studios and central functions such as marketing and finance Building scalable, accurate and extensible stream processing applications using cutting-edge technology such as Spark Streaming and Apache FlinkImplementing complex and highly scalable end-to-end data pipelines, using Elastic Beanstalk, Kinesis, EMR, Spark, Hive, Druid, CassandraBuilding data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications And your skills and experience include:Bachelor's degree in computer science/mathematics/engineering, or other fields with proven engineering experience More than 3 years of software engineering experience, especially working on back-end data infrastructure Proficiency with at least one of the following languages: Java, Python, Scala Experience with distributed stream processing technologies such as Flink, Spark Streaming and/or Kafka Streams Experience with AWS Ecosystem, especially Kinesis, EMR, Lambda, and GlueKnowledge of NoSQL application data stores i.e. Druid, HBase, Cassandra, DynamoDB, RedisBonus points:Experience with high-scale machine learning, i.e. Spark M/L, SageMaker, etcExperience with SQL and SQL-like languages, especially HiveExperience with CI/CD process, testing framework, and containerization technologyExperience building data-rich web applications, especially with technologies like Angular, Node.js, and Elastic BeanstalkAll qualified applicants will receive consideration for employment. Glu is an equal opportunity employer committed to diversity in the workplace. We welcome people of different backgrounds and experiences to ensure a diverse and inclusive workplace.”",sf,de
23,Pine Park Health,N/A,4,Data Engineer,"San Francisco, CA",$76K - $140K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_a1a1a433&cb=1619369427642&jobListingId=4069485811,"Pine Park Health: Our mission is to keep senior living residents healthy—by keeping them away from hospitals where exposure to health risks is high. Through our new clinical care delivery model, we bring doctors and clinical staff right into senior living communities, providing safer, more convenient urgent and primary care. Pine Park leases a dedicated space within each senior living community and staffs each location with a team of physicians, physician assistants, and nurses. This allows us to provide comprehensive healthcare on-site, see patients more regularly, and better support their overall health.We are a well-funded startup backed by First Round Capital, Google’s AI fund, and Y Combinator—and we’re growing fast. We’ve identified a rare opportunity to improve the way healthcare is delivered to millions of older adults and succeed with an economic model focused on care outcomes. We’re also developing proprietary technology to facilitate care coordination, back-end operations, and the consolidation of patient data so our physicians can track patient health efficiently.We’re looking to expand our small, motivated, multi-disciplinary team of engineers, operators, and clinicians. If you share our passion for this mission-driven business, love collaborating with others to realize a dream and scalable vision, join us! We’re building a company to improve the way healthcare is delivered to older adults now and for decades to come.What You'll Do:Partner with our Product, Clinical, and Operations teams to design data-driven care delivery workflows that consistently deliver remarkably personalized patient care. To this end, you will occasionally spend time inside Assisted Living Facilities (ALFs) shadowing our Growth, Ops & Care Delivery teams to gather context required to make excellent technical design decisions.Lead the effort to implement a de novo data infrastructure ( instrumentation, ETL, mesh architecture, warehouse, BI/reporting (Looker) and web services) to enable the care delivery workflows you help design.Understand our ‘no/low code’ approach to growth & care delivery applications at the ‘top of our stack’. Then devise a capture/instrumentation strategy to pull relevant data from Salesforce, Monday.com, Elation, and other operational applications, in order to:Enable actionable analyses/insights for the businessTrigger operational cues for our care delivery team through heuristics & modelingFacilitate efforts to build a data driven culture and cadence at Pine Park HealthSupport efforts to devise a threat model for Pine Park Health. Lead our corresponding strategy and execution plan to protect our patient and partner data; including coverage for: HIPAA, SOC2, HITRUST, PCI, disaster recovery, abuse/security, etc.What we're looking for:Someone with a history of living our core values:Stay focused: Pine Park Health is intensely focused on our goal: to build a new kind of primary care model and company for seniors, providing consistently high-quality care and reducing hospitalizations.Be an owner: Own a process, goal, or patient experience all the way to the outcome. Prioritize follow-through and earn the trust of those we work with.Solve problems with process: Pine Park Health is built on the idea that the best way to solve a repeating problem is with a repeatable process. We aim for consistent rigor and rely on building systems and processes for a high-quality experience and to minimize preventable errors.Commit to learning: We are constantly seeking to learn without ego. We stay curious and open-minded. We believe great ideas come from everywhere.Care for patient outcomes: We care. Constantly. We focus on the human beings at the center of our care, and their long-term goals and outcomes. We build to improve patient outcomes. All decisions should be made in service of this goal.Bachelor's degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.5+ years of Data Engineering experience in a variety of settings like healthcare, early & later stage companies, regulated environments, etc.Experience with statistical modeling and data analysis on large/complex, data-sets in close partnership with cross-functional teams. This includes root cause analysis on anomalous data.Experience creating data pipelines & ETL jobs to combine disparate data sources and automating dashboards & analytical tools to identify changes in business metricsFamiliarity with tools & standards like: Airflow, Azkaban, BigQuery, BitBucket, Cassandra, DataGrip, EC2, FHIR, Fivetran, Git, Github, Google Analytics, Google Cloud, HL7, Hadoop, Kafka, Looker, Luigi, Node.js, NoSQL, MixPanel, Python, PostgreSQL, PyCharm, Redshift, S3, SPAD, Spark, SQL, stata, Storm, Tableau, etc. Current Pine Park Health tools are bolded.A penchant for writing clean, well-structured, codePine Park Health is an equal opportunity employer — we aim to recruit, hire, develop, compensate, and promote regardless of of race, religion, country of origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",sf,de
24,Slalom LLC.,Business Services,4.3,Data Engineer,"San Francisco, CA",$65K - $121K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=4470&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_4248d75d&cb=1619369427642&jobListingId=3808731818,"Who You’ll Work With

At Slalom, personal connection meets global scale. Our vision is to enable a world in which everyone loves their work and life. We help organizations of all kinds redefine what’s possible, give shape to the future—and get there.

Slalom San Francisco's Data & Analytics is hiring data engineers to join the team. As a Data Engineer, you will collaborate in small teams to deliver data pipelines and data models for our clients. You will design and build highly scalable and reliable modern data platforms including data lakes and data warehouse using Amazon Web Services, Azure, Google Cloud. Your work will include a variety of core data warehousing tools, Hadoop, Spark, event stream platforms, and ETL tools such as Airflow. In addition to building the next generation of data platforms, you'll be working with some of the most forward-thinking organizations in data and analytics.

What You’ll Do

Collaborate with engineers and business customers to understand data needs, capture requirements and deliver complete BI solutions Design and build data extraction, transformation, and loading processes by writing custom data pipelines Design, implement and support a platform that can provide ad-hoc access to large datasets and unstructured data Model data and metadata to support adhoc and pre-built reporting Tune application and query performance using performance profiling tools and SQL Build data expertise and own data quality for allocated areas of ownership Work with data infrastructure to triage infrastructure issues and drive to resolution

What You’ll Bring

Bachelor’s degree in Computer Engineering, Computer Science, Information Systems or related discipline3+ years relevant experience•Experience in capturing end usersrequirements and align technical solutions to the business objectives•Understanding of different types of storage (filesystem, relation, MPP, NoSQL) and working with various kinds of data (structured, unstructured, metrics, logs, etc.)Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality•3+ years of experience working with SQLExperience with setting up and operating data pipelines using Python or SQL1+ years of experience working on AWS, GCP or AzureExperience working with data warehouses such as Redshift, BigQuery and SnowflakeExposure to open source and proprietary cloud data pipeline tools such as Airflow, Glue and DataflowExperience working with relational databasesExperience with data serialization languages such as JSON, XML, YAMLExperience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Docker, Bamboo, Jenkins)Strong analytical problem-solving abilityGreat presentation skills, written and verbal communication skillsSelf-starter with the ability to work independently or as part of a project teamCapability to conduct performance analysis, troubleshooting and remediationAbility to google any of the terms or concepts in this posting that you had questions about, bonus points if you found and understood the descriptions on stack overflow

About Us

Slalom is a modern consulting firm focused on strategy, technology, and business transformation. In 39 markets around the world, Slalom's teams have autonomy to move fast and do what's right. They are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world's top technology providers. Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 8,000 employees. Slalom has been named one of Fortune's 100 Best Companies to Work For five years running and is regularly recognized by employees as a best place to work. Learn more at slalom.com.

Slalom prides itself on helping team members thrive in their work and life. As a result, Slalom is proud it invest in benefits that include: meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability. We also offer additional benefits such as a yearly $350 reimbursement account for any well-being related expenses as well as discounted home, auto, and pet insurance.

Slalom is an equal opportunity employer that is committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veterans status, or any other characteristic protected by federal, state, or local laws.

#LI-HW1",sf,de
25,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,Systems Engineer - Bioinformatics,"San Francisco, CA",$47K - $99K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_2d39f4b5&cb=1619369427642&jobListingId=4042138992,"Thermo Fisher Scientific Inc. is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them.Location/Division Specific InformationJoin the forefront of innovation in genetic analysis for research & clinical applications. Our teams develop platforms, consumables, and reagents that help bring criminals to justice, ensure reproductive health, accelerate disease research, advance methods for syndromic testing of infectious diseases and viruses, and keep the world’s food supply safe. As the leading provider of genetic analysis solutions and leveraging the resources of a $24B enterprise, our technologies have great impact worldwide. And as a member of our team, you can play a critical role in helping us fulfill our global mission of making the world healthier, cleaner, and safer.How will you make an impact?You will lead system definition & system integration aspects of product development in collaboration with highly technical and specialized engineering professionals and scientists to develop instruments and applications for our world class qPCR, Capillary Electrophoresis, Rapid DNA, and Microarray platforms in both RUO and IVD markets.What will you do?Exercise judgement and experience in qPCR assays to understand customer needs and goals to deliver on optimal product requirements on performancePartner with technical leads in chemistry, assay design, and system hardware to design products and conduct/facilitate performance trades between the different technical disciples to deliver optimized product performanceWork with a team to develop new highly multiplexed IVD qPCR assays including data analysis, troubleshooting and optimizationWork with a team to develop new automated qPCR systems including integration, troubleshooting and optimizationTechnical lead for troubleshooting interface between system and application challengesContribute to data-driven decision making by designing multifactorial experiments, analyzing, and presenting resultsHow will you get here?EducationBachelor’s degree in Bioinformatics, Biochemistry, Computer Science, Bioengineering or related technical discipline; Master’s or PhD degree is highly preferredExperience5+ years experience with life science instrumentation, consumables, and assays in R&D setting, preferably in genomics2+ years experience serving regulated markets in a commercial environmentExperience in BioinformaticsStrong computational analysis utilizing Matlab, Python, etc.Experience in developing/analyzing multiplexed PCR and qPCR assays and the full product development life cycle process through customer care is highly preferredSuccessful track record in delivering RUO and IVD products with a thorough understanding of quality systemsHands on lab experience including nucleic acid sample extraction, purification, preparation and characterization from a variety of biological sourcesKnowledge, Skills, AbilitiesExcellent organizational skills, including the ability to efficiently evaluate, prioritize and handle multiple and changing programs/projects and prioritiesFoster collaborative relationships and builds credibility across leadership teamsMaintain a high level of professional expertise through familiarity with current engineering/scientific literature, competing technologies, and/or products as well as attendance of seminars and meetingsAbility to travel up to 25%, domestic or internationallyThis position has not been approved for relocation assistance.Our global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.Apply today! http://jobs.thermofisher.com*EVRD2020 *GTSDouble",sf,de
26,Atomwise,Biotech & Pharmaceuticals,5,Data Engineer,"San Francisco, CA",$106K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_cae4cd4d&cb=1619369427643&jobListingId=4041269206,"Data EngineerAt Atomwise, we invented the first deep learning neural networks for structure-based small molecule drug discovery and we’re currently deploying it in one of the largest applications of machine learning for life sciences. We work on Alzheimer’s, cancer, diabetes, drug-resistant antibiotics, safe pesticides, among treatments for other diseases. We’ve partnered with 4 of the top-10 US pharma companies, raised over $170M from top VCs, and have 100+ diverse projects currently running.The company was founded from academic roots, which contributes to a collaborative and transparent culture that fosters scientific and technical discussion. We strongly believe that data wins over opinions, and aim for as little dogma as possible in our decision making. Our team members have expertise in a wide range of disciplines-from computational chemistry and structural biology to cloud-native best practices-and we regularly have internal seminars open to anyone interested in learning about these topics.About the roleWe are looking for a data engineer with strong database and software engineering skills to join our Engineering team. The team is relatively small, so there are lots of opportunities for both career growth and substantial contribution towards our success.You willContribute to the design, development, and deployment of massive cheminformatic datasets for machine learningBuild tooling for data wrangling and discoverability for our drug discovery projectsCreate scalable data pipelines to process complex and diverse external datasetsImplement systems to track data quality and consistencyPartner with domain experts, machine learning scientists, and other data engineers to provide access to foundational datasets to enable self-service research and developmentRequired QualificationsBachelor's degree with 3+ years of industry data or backend engineering experienceSolid understanding of RDBMS concepts, data structures, and distributed data processing patternsExperience with data warehouses and building scalable data processing pipelinesStrong computer science fundamentalsProficiency in at least one high-level programming language (Python, Java, C++, etc)Ability to work with people from diverse disciplines within cross-functional teams Preferred QualificationsExperience with cloud computing environments (AWS/GCP/Azure)Familiarity with front end technologies (we use Django/FastAPI for internal tools)Comfort with the Linux command-line environmentKnowledge of statistics, data analytics, and data visualizationBackground in bioinformatics, cheminformatics, drug discovery, or a related fieldCompensation & benefitsCompetitive salary, commensurate with experienceStock compensation plan – you’ll be an Atomwise co-ownerPlatinum health, dental, and vision benefits401k with 4% matchFlexible work scheduleGenerous parental leaveRelaxed work environmentGreat colleaguesAtomwise is an equal opportunity employer and strives to foster an inclusive workplace. Our mission is to develop better medicines faster, and we know that we need a diverse team to develop medicines that serve diverse populations. Accordingly, Atomwise does not make any employment decisions (including but not limited to, hiring, compensation, and promotions) on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, veteran status, disability status, or any other characteristics protected by applicable federal, state, and local law.We strongly encourage people of diverse backgrounds and perspectives to apply.Atomwise is not currently offering visa sponsorships for any position. Please only apply if eligible to work in the U.S.Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",sf,de
27,Teladoc Health,Health Care,3.9,Senior Data Engineer,"San Francisco, CA",$119K - $210K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_71fe2ba6&cb=1619369427643&jobListingId=3733775463,"RemoteThe OpportunitySimply stated, Teladoc Health exists to empower people with chronic conditions to live better and healthier lives. Teladoc Health is seeking an engineer with an emphasis on data processing, transformation, fidelity and scalability. The applicant should have a strong interest in the interface between real-time and reporting systems, pulling data from multiple sources into central data storage, and collaborating with internal Livongo teams to help provide for their data needs.What makes a Senior Data Engineer at Teladoc Health different?It is engineering! Members are why we come to work every day and our engineers design and developing the product, product features, and tools for members to have a best in class health consumer experience throughout their journey with LivongoStrong communication skills especially around collaboration with internal Livongo teamsAfter our Members, data is pretty significant at Livongo and our engineers design and develop data pipelines to manage how data flows between our disparate systemsDevelop real time member registration with our CRM, integrating data systems across businesses like MyStrength, Retrofit, Livongo, etc.Work with Scala, Python, Tensorflow, Keras, SKL (or Scala/DL4J) to build production-grade machine learning (ML) pipelines and toolsCreate tools and data sets to assist data sciencePerform continuous integration to ensure that every step of an ML pipeline is testable and automatedAssist in maintaining data integrity in production systemsUse trained models to enable rapid experimentationParticipate in Agile planning around data feature requests and advocate for the best data engineering projects in priority planning.Collaborating closely with Teladoc Health's ML experts, Data Scientists, Product Managers and clinical researchers to build products that help people live better lives Candidate ProfileExperience with big data technologies such as Hadoop and Spark, and a strong depth of expertise with at least one of theseUnshakeable (nearly innate) grasp of software engineering fundamentalsSpecific experience creating and maintaining production pipelinesKeen attention to detail and a knack for prioritizing competing objectivesThe ability to solve real-life business problems with dataA passion for using your work to improve livesBS degree in Engineering, Computer Science or a related field. In lieu of degree, relevant work experience and/or trade school is acceptable7+ years' experience in software development3+ years in a data engineering roleStrong SQL development experience (Postgres / AWS Redshift/MySQL)Expertise in Scala, Java, or PythonPeople and culture are Teladoc Health's greatest and most valued assets! We've built a culture we are proud of that reflects our values of diversity and inclusion where everyone's voice is equally important.Our Benefits IncludeCompetitive compensation packagesComprehensive medical, dental, vision and 401KGenerous PTO policy10 paid holidays each yearLunch provided Monday through Thursday (in office)An endless variety of healthy snacks and beverages to fuel your creativityEmployee Stock Purchase PlanEmployee Referral Bonus ProgramTeam events and social gatheringsPet-friendly environment in Mountain View, CA and DenverDiabetes Care Prescription ReimbursementDiscount/Subsidy program for gym membershipProvide the full line of Livongo programs and services to all employees and their familiesWhy Join Teladoc Health?A New Category in Healthcare: Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person's health journey.Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.Focus on PEOPLE: Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.Diversity and Inclusion: At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.Growth and Innovation: We've already made healthcare history, yet we remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding – we have a mother's room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.#LI-Remote",sf,de
28,Levi Strauss,Retail,4,Data Engineer,"San Francisco, CA",$89K - $156K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=242900&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_e821484a&cb=1619369427643&jobListingId=4039754233,"JOB DESCRIPTIONAt Levi Strauss & Co, we are revolutionizing the apparel business and redefining the way denim is made.

We are taking one of the world’s most iconic brands into the next century:

from creating machine learning-powered denim finishes to using block-chain for our factory workers’ wellbeing, to building algorithms to better meet the needs of our consumers and optimize our supply chain.

Be a pioneer in the fashion industry by joining our global Data, Analytics & AI “startup with assets,” where you will have the chance to build exciting solutions that will impact our Global business and at the same time be part of a bigger, across-continents, data community.

As a Senior Big Data Engineer, you will bring to life and execute architecture blueprints & help our teams by mapping out solutions to some of their complex technical challenges. You’ll provide technical expertise, mitigate risk and offer solutions tailored for their business needs. From migrations of existing workloads to building advanced cloud solutions, you’ll help shape and execute to increase agility, improve security, reduce costs and meet utilization targets.

This role will work closely with the Data Engineering, Data Science, Infrastructure & Platform and will focus on creating blueprints to nourish a culture of engineering excellence. We need someone who will bring thoughtful perspective, empathy, creativity, and a positive attitude to solve problems at scale.

Responsibilities:

Experience in at-scale infrastructure design, build and deployment with a focus on distributed systems.Build and maintain architecture patterns for data processing, workflow definitions, and system to system integrations using BigData and Cloud technologies.Evaluate and translate technical design to workable technical solutions/code and technical specifications at par with industry standards. Drive creation of re-usable artifacts.Actively scan and evaluate relevant new technologies which drive standardization and reduction of complexity within the enterprise.Contribute to and promote good software engineering practices across the team.Works on the collaborative Enterprise team and deliveries work products that support a digital transformation by leading assigned product and solution teams.Embody the values and passions that characterize Levi Strauss & Co., with empathy to engage with colleagues from a wide range of backgrounds.Performs technical design reviews and code reviews, to include cloud-based architecture and integrations.Communicate clearly and effectively to technical and non-technical audiences.

What We Are Looking For:

Bachelor's Degree or higher in Computer Science or related disciplineMinimum of 7 years in a hands-on technical role as an engineer and/or Data engineering role.Experience with at least one cloud provider solution (AWS, GCP, Azure)Strong experience working with Big Data technologies ex: Spark, Spark SQL, Pyspark Structured Streaming, Kafka.Experience designing various consumption patterns on top of data lake/lake house to cater to different personas within organization.Strong experience with at least one object-oriented/functional languages: Python, Java, Scala, etc.Strong knowledge of data pipeline and workflow management tools (Airflow).Hands-on experience in Data engineering Spectrum, for e.g. developing metadata based framework based solutions for Ingestion, Processing etc., building Data Lake/Lake House solutions.Strong experience working with a variety of relational SQL and NoSQL databases and ability to choose a database based on the need.Working knowledge of Git hub /Git Toolkit.Strong experience with MPP Database systems like Teradata, Oracle or SAP Hana.Experience with data modeling, data warehousing, KPI generation etc.Proficient in documenting use cases, requirements and functional specifications.Ability to effectively prioritize and execute tasks in a high-pressure environment is crucial.Working in a collaborative environment and interacting effectively with technical and non-technical team members equally well.

EOE M/F/Disability/VetsLOCATIONSan Francisco, CA, USAFULL TIME/PART TIMEFull timeCurrent LS&Co Employees, apply via your Workday account.",sf,de
29,Callisto Media,Media,2.8,Data Engineer,"Emeryville, CA",$89K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_b24ce73a&cb=1619369427643&jobListingId=4011038082,"We combine the power of Big Data, technology, and lean economics. We discover the information people are searching for and provide it. We help transform lives.Callisto will be unmatched in providing products, services, and experiences to a diverse universe. From mainstream populations to groups that traditional companies believe are too small or economically unfeasible to address, we will meet their needs.Today, we’re the fastest growing company in the $106 billion global publishing industry, and our primary method for meeting peoples’ needs is through long-form content in books. But creating books for them is only the beginning.Data Engineer to join our small engineering team. Design, code, test, and support projects to manage the company’s data that will directly impact publishing efforts.ResponsibilitiesCollaborate with architects to implement data solutions that solve business problemsDesign conceptual, logical and physical data modelsImplement effective and scalable end-to-end data pipeline solutionsImport data from a multitude of external systemsBuild metrics and reportsQualificationsBachelor's degree in Computer Science/Engineering or equivalent industry experience2+ years professional development experienceFluency in SQL, preferably MySQLFamiliar with data storage mechanisms, e.g. Hadoop, NoSQL, etc.Experienced in ETL developmentUnderstanding of dimensional and normalized database models and their applicationsGood knowledge of the Linux operating system, networking, and toolset (bash, ssh, vim, etc.), especially text processing commands (sed, awk, etc.)Experience in OOP (e.g. C++, Python, etc.)Strong software engineering best practices (unit testing, code reviews, design documentation)Good verbal and written communication skillsOther useful skills/experienceExperience using GitKnowledge of JavaScriptKnowledge of Business Intelligence (BI) / Data Warehousing (DW) principles and software (e.g. Tableau, Looker, etc.)Experience with cloud-based SaaS platformsExperience with clustered and/or distributed systemsExperience developing within large codebasesExperience with web development: CGI, HTML, Javascript, ApacheExperience with REST APIsJoin us! We are a team where data drives our decisions. Where culture matters. We put our customers first and they embody our core values. We’re entrepreneurial and focused in our approach. We challenge each employee to experiment and drive results while feeling empowered to do their best work each and every day.Callisto Media offers a competitive salary, full benefits, 401k, stock options, for full-time employees, as well as a friendly working environment. This is a full-time, onsite position.",sf,de
30,Thermo Fisher - America,Biotech & Pharmaceuticals,3.8,Staff Systems Engineer,"San Francisco, CA",$126K - $153K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1044074&s=58&guid=0000017909f07fcc9c931c70f0ce77c8&src=GD_JOB_AD&t=SR&vt=w&cs=1_c16f6b2b&cb=1619369427643&jobListingId=4042138765,"Thermo Fisher Scientific Inc. is the world leader in serving science, with annual revenue exceeding $25 billion. Our Mission is to enable our customers to make the world healthier, cleaner and safer. Whether our customers are accelerating life sciences research, solving complex analytical challenges, improving patient diagnostics and therapies or increasing productivity in their laboratories, we are here to support them.Location/Division Specific InformationJoin the forefront of innovation in genetic analysis for research & clinical applications. Our teams develop platforms, consumables, and reagents that help bring criminals to justice, ensure reproductive health, accelerate disease research, advance methods for syndromic testing of infectious diseases and viruses, and keep the world’s food supply safe. As the leading provider of genetic analysis solutions and leveraging the resources of a $24B enterprise, our technologies have great impact worldwide. And as a member of our team, you can play a critical role in helping us fulfill our global mission of making the world healthier, cleaner, and safer.How will you make an impact?You will lead system definition & system integration aspects of product development in collaboration with highly technical and specialized engineering professionals and scientists to develop instruments and applications for our world class qPCR, Capillary Electrophoresis, Rapid DNA, and Microarray platforms in both RUO and IVD markets. In this role, you will also provide direction and focus to drive business objectivesWhat will you do?Exercise judgement and experience in qPCR assays to understand customer needs and goals to deliver on optimal product requirements on performancePartner with technical leads in chemistry, assay design, and system hardware to design products and conduct/facilitate performance trades between the different technical disciples to deliver optimized product performanceWork with a team to develop new highly multiplexed IVD qPCR assays including data analysis, troubleshooting and optimizationWork with a team to develop new automated qPCR systems including integration, troubleshooting and optimizationTechnical lead for troubleshooting interface between system and application challengesContribute to data-driven decision making by designing multifactorial experiments, analyzing, and presenting resultsHow will you get here?EducationBachelor’s degree in Bioengineering, Engineering or related technical discipline; Master’s or PhD degree is highly preferredExperience7+ years experience with life science instrumentation, consumables, and assays in R&D setting, preferably in genomics2+ years experience serving regulated markets in a commercial environmentExperience in developing/analyzing multiplexed PCR and qPCR assays and the full product development life cycle process through customer care is highly preferredSuccessful track record in delivering RUO and IVD products with a thorough understanding of quality systemsHands on optics, hardware development and lab experience including nucleic acid sample extraction, purification, preparation and characterization from a variety of biological sourcesKnowledge, Skills, AbilitiesStrong understanding of robotic liquid handling systems (e.g. Tecan/Hamilton)Excellent organizational skills, including the ability to efficiently evaluate, prioritize and handle multiple and changing programs/projects and prioritiesDemonstrated ability to effectively build and manage internal and external relationships at senior levelsMaintain a high level of professional expertise through familiarity with current engineering/scientific literature, competing technologies, and/or products as well as attendance of seminars and meetingsAbility to travel up to 25%, domestic or internationallyThis position has not been approved for relocation assistance.Our global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.Apply today! http://jobs.thermofisher.com*EVRD2020 *GTSDouble",sf,de
