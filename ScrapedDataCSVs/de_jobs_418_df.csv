,company,industry,rank,job_title,location,salary_range,link,description,search_city,search_job
0,Amobee,Business Services,3.8,"Software Engineer, Data Systems (Remote)","Austin, TX",$62K - $129K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1182935&s=149&guid=00000178e78aa0d9bc68a5cd62a1c064&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_8f244962&cb=1618792326164&jobListingId=4006018599,"The Software Engineer position in Amobee's Platform Data team is a hands-on role that contributes to Amobee's success through expertise in large-scale systems and advanced database architecture. You will leverage the Hadoop ecosystem to create the next generation of our analytics product. Qualified individuals will have a solid background in the fundamentals of computer science, distributed computing and large-scale data processing.ResponsibilitiesBuild BigData systems – work on improving and adding new functionality to Amobee’s Data Systems backbone.Design and implement features evolving our online advertising and data management product offerings.Design, implement our proprietary cutting edge Hadoop/Spark based systemsScale up and tune our syndication pipeline. Challenges come in the form of using multiple syndication protocols, concurrency, data scale, and computational efficiencyLarge-scale data ingestion and integration – design, implement scalable ETL processes to collect and store large amount of data from multiple data centers and diverse external partnersCollaboration on requirements – Work with the Engineering, Product Management and Business Intelligence teams to come up with features that would help us and our clients be more productive and improve the bottom lineKeep it running – Help troubleshoot application operational issuesRequired QualificationsA degree in Computer Science or related fieldExperience with Java or Scala required; experience with C++ or C# is acceptableExperience with Hadoop (MapReduce, Spark), or similar, large-scale data processing systems is preferred2+ years of relevant experience (appropriate PhD program project work acceptable)Experience with LinuxProficiency in relational and NoSQL databases is preferredSome experience with distributed systems, advanced applications building, large-scale data processing or application partitioningExperience with AWS and working knowledge of AWS data management, DevOps processes and technologies (Jenkins/Travis, Docker, Kubernetes, monitoring systems, etc) is a plusGood understanding of Object Oriented programming and design patternsStrong knowledge of common algorithms and data structuresMust be hard working, team oriented, bright, creative, cooperative, and an exceptional problem solverSolid understanding and working knowledge of modern operating systems and/or application scalability techniques is a plus#LI-AR1About Amobee The world’s leading independent advertising platform, Amobee unifies all advertising channels—including TV, programmatic and social—across all formats and devices. We provide marketers with streamlined, advanced media planning capabilities powered by in-depth analytics and proprietary audience data. Our platform and technology, provides the most advanced advertising solutions for the convergence of digital and advanced TV— including linear TV, over the top, connected TV, and premium digital video. Enabling advertisers to plan and activate across more than 150 integrated partners, including Facebook, Instagram, Pinterest, Snapchat and Twitter. Amobee has been named to Fortune’s Top 10 Best Workplaces in Advertising and Marketing. Amobee’s platforms have been widely recognized amongst our industry winning numerous awards in technology innovation, see all Amobee Awards. We are a wholly owned subsidiary of Singtel, one of the largest telco companies in the world, reaching over 700 million mobile subscribers in 21 countries. Amobee operates across North America, Europe, Middle East, Asia and Australia. For more information, visit amobee.com or follow @amobeeIn addition to our great environment, we offer a competitive base salary, employee development programs and other comprehensive benefits. Please send a cover letter along with your resume when applying to the position of interest located at Amobee.com. We are an Equal Opportunity Employer. No phone calls and no recruiting agencies, please.",aus,de
1,recruitAbility,N/A,5,"Data Engineer - SQL, Azure Cloud","Austin, TX",$60K - $117K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044072&s=149&guid=00000178e78aa0d9bc68a5cd62a1c064&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_aa4bbafe&cb=1618792326044&jobListingId=4060424391,"Our client, headquartered in the “Silicon Hills” of Austin, Texas, offers an experience as unique as the city in which it operates. The firm supports more than 1,700 independent financial advisors in delivering comprehensive securities and investment advisory services to their clients. With a culture rich in reinvention and advisor advocacy, they have developed integrated business management technology that, combined with its personalized consulting services, offers exceptional scale and efficiencyThey are looking for a passionate Data Engineer to join our growing Data and Analytics team. Join this exciting journey in modernizing their legacy solutions to the next-generation cloud platform. You will be responsible for working in a cross-functional team to expand, optimize, and improve overall data quality and set up next-generation data orchestration using modern cloud tools and technologies. As a Cloud Data Engineer, you will be designing and building secure and resilient architectures, with the goal of providing actionable insights to our Advisors for them to optimize their business.Primary Responsibilities of the Data EngineerDesign and develop data pipelines to extract data from a wide variety of data sources using Azure, Snowflake Cloud, and cloud-native technologies.Build a data model to get actionable insights from data, operational efficiency, and other key business performance metrics.Design and manage inbound and outbound data processes and monitoring. Work with the data provider to bring in new feed into our data eco-system.Enjoy working in Agile as part of a scrum team and deliver high-quality products incrementally in an interactive manner.Write Test Driven Development based code to meet overall data quality standards as defined by the users.Automate the data testing processes and integrate them with monitoring systems.You are a team player who enjoys working with and supporting an Application Engineering team, DBA, Infrastructure, and Project Management Office.Analyze existing systems (including legacy) and data sets to help Business Analysts define the functional and non-functional requirements.Meet with the business users, assist with data-related technical issues, and support their data infrastructure needsPrimary Requirements for the Data EngineerStrong experience with NoSQL database, including PostgresBackground in working with Azure Cloud Services: Data Factory, SQL database, Functions, Data Lake, Databricks, Logic Apps, and Azure Automation.Fluent in object-oriented and functional script language: Python, Scala, and C#.Advanced working knowledge of SQL Server database - writing advanced SQL script, profiling, and optimization.Working knowledge of Business Intelligence tools: Microsoft Integration Services, Reporting Services, and Analysis Services, as well as PowerBI.Experience with other Big Data tools such as Spark, Snowflake, and KafkaPreference for background in Financial Services, ideally in the Wealth Management/Independent Broker-Dealer/RIA industryBachelors/Masters in Computer Science, MIS/Information Management, Engineering or related fieldWhat’s in it for you as a Data Engineer with a growing company?Excellent salary and comprehensive benefits package for this full-time positionA world-class team of professionals, casual work environment, and rich cultureChallenging projects now and on the Technology Roadmap going out several yearsCareer path, training support, and opportunities for advancement withinAward-winning, a stable leader in their market space and still growingA solid compensation plan includes comprehensive benefits and a bonus planFull health, vision, dental. 401(k) plans along with a host of voluntary plans such as car insurance, legal services, and more.A brand new state of the art building in Southwest Austin with a basketball court, volleyball court, baseball field, walking trails, unlimited coffee, tea, and sparkling waterINDSJ",aus,de
2,Neos Consulting,N/A,-1,Sr. Data Engineer,"Austin, TX",$125K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044072&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_77c7f3c7&cb=1618792326069&jobListingId=4063838792,"Neos is a leading Austin-based IT Staffing and Consulting firm. Neos was recognized as a 2019 Best Places to Work inAustin by the Austin Business Journal, and also recognized as one of the fastest-growing companies in America two yearsin a row by Inc. MagazineNeos is seeking a Sr. Data Engineer for a long-term project with our client in Austin, Texas.******** Telecommuting is currently in place until the client resumes normal office operations*************The Data division is part of the OAG’s technology organization and is responsible for building data assets to provide value added products and services to drive innovation for our partners and clients. As a Senior Data Engineer, you will help design, enhance and build solutions dealing with real-time data in a fast-paced environment working with/on cutting-edge data and cloud technologies. You will work with colleagues who will support and challenge you daily. We believe in self-managing Agile teams who build products end to end, focusing on unit testing, code reviews and continuous integration for excellent code quality.The ideal Senior Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data focused applications. You are committed to data automation and integrity, are highly analytical, and can work on multiple projects at once. You will use your skills to engineer, automate, and manage data systems across multiple cloud services platforms and toolsets. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by Texas OAG are core reasons people enjoy working as part of the Data Division.II. CANDIDATE SKILLS AND QUALIFICATIONSMinimum Requirements:Candidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity.YearsRequired/PreferredExperience8RequiredExperience in large-scale IT Project/Product delivery with at least 3 years of work experience in current data streaming, messaging, management, and database technologies8RequiredAbility to establish and always maintain effective and professional working relationships with others in the course and scope of conducting business8RequiredExcellent communication, problem-solving, and organizational skills5RequiredStrong data integrity, analytical, and multitasking skills4PreferredGraduation from an accredited four-year college or university with major coursework in Computer Science or Engineering3PreferredExperience creating producer and consumer applications with Kafka2PreferredExperience with designing and building data platforms2PreferredExperience in tuning and troubleshooting streaming/messaging platforms2PreferredExperience coding and scripting (Python, Java, Scala) and design experience2PreferredExperience with ELT methodologies and tools2PreferredHands-on experience with AWS and/or Azure2PreferredExperience with KStreams and KSQL2PreferredExperience with designing and automating build and deployment solutions/process for data solutions2PreferredFamiliarity with data visualization, warehouse, and analytics tools/platforms such as Qlik, SAS Viya, Kibana, Snowflake2PreferredExperience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)1PreferredBasic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)1PreferredAble to work independentlyIND123",aus,de
3,Neos Consulting,N/A,-1,"Data Engineer, Platform & Infrastructure","Austin, TX",$86K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044072&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_b8bf083f&cb=1618792326072&jobListingId=4063838824,"Neos is a leading Austin-based IT Staffing and Consulting firm. Neos was recognized as a 2019 Best Places to Work inAustin by the Austin Business Journal, and also recognized as one of the fastest-growing companies in America two yearsin a row by Inc. MagazineNeos is seeking a Data Engineer for a Platform and Infrastructure team for a long-term project with our client in Austin, Texas.******** Telecommuting is currently in place until the client resumes normal office operations*************Working as part of the Platform & Infrastructure Data Engineering team to engineer, install, configure, standardize, and automate best in class data services and capabilities in a secure fashion for the organization. The ideal Advanced Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data management systems. You are committed to data automation and integrity, are highly analytical, and can work on multiple projects at once. You will use your skills to engineer, automate, and manage data systems across multiple cloud services platforms and toolsets. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by Texas OAG are core reasons people enjoy working as part of the Data DivisionII. CANDIDATE SKILLS AND QUALIFICATIONSMinimum Requirements:Candidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity.YearsRequired/PreferredExperience6RequiredExperience in large-scale IT Project/Product delivery with at least 2 years of work experience in current data streaming, messaging, management, and database technologies6RequiredAbility to establish and always maintain effective and professional working relationships with others in the course and scope of conducting business6RequiredExcellent communication, problem-solving, and organizational skills4PreferredStrong data integrity, analytical, and multitasking skills4PreferredGraduation from an accredited four-year college or university with major coursework in Computer Science or Engineering2PreferredExperience with designing and building data platforms and setting up data tools2PreferredExperience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)2PreferredExperience in tuning and troubleshooting streaming/messaging platforms2PreferredExperience creating producer and consumer applications with Kafka2PreferredExperience coding and scripting (Python, Java, Scala) and design experience2PreferredExperience with ELT methodologies and tools2PreferredHands-on experience with AWS and/or Azure2PreferredExperience with KStreams and KSQL2PreferredExperience with designing and automating build and deployment solutions/process for data solutions/tools/platforms2PreferredFamiliarity with data management, visualization, warehouse, and analytics tools/platforms such as Qlik, SAS Viya, Kibana, Snowflake, Qualtrics, and Spirion1PreferredBasic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)1PreferredAble to work independently IND123",aus,de
4,Enverus,"Oil, Gas, Energy & Utilities",3.9,Senior Site Reliability Engineer,"Austin, TX",$119K - $163K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_0095046e&cb=1618792326186&jobListingId=3804344327,"Senior Site Reliability EngineerWhy YOU want this positionSince our founding as a groundbreaking provider of oil & gas data, we have evolved our solutions to cover oil & gas analytics, trading & risk, and business automation for customers across the energy industry. Enverus represents this growth while bringing us closer together as one team. Enverus delivers business-critical insights to the global energy industry through a state-of-the-art SaaS platform built on industry-leading data and energy analytics. Our solutions deliver value across the entire energy value chain, empowering customers to be more agile, efficient, and competitive. The range of energy industry participants we serve includes exploration and production (E&P) companies and related businesses such as oilfield services, midstream, capital markets, power generators and utilities, energy traders, and downstream commercial & industrial energy consumers.We are currently seeking a highly driven Senior Site Reliability Engineer to join our Technology Engineering team in Austin, TX. This role offers the opportunity to join a rapidly growing company delivering industry-leading solutions to customers in the world’s most dynamic and fastest-growing sector. Enverus is the right company at the right time.Performance ObjectivesWork in a team that manages, deploys, and improves our Commodity Data Solutions infrastructure and customer installations.Your team will be responsible for keeping our infrastructure humming as new releases and maintenance updates are rolled outYou will help organize, secure, and automate existing infrastructure and deploymentsYou will work closely with developers to provide feedback and drive operational improvements within our products and operations infrastructureYou will be responsible for ensuring that our platform is stable and balancedMaintain high site uptime, while embracing rapid change and growthScale infrastructure to meet increasing demand and evolving technologyHelp the dev teams working on our codebases realize zero downtime deploymentsDevelop and improve operational practices and proceduresImplement, monitor, and maintain CI/CD frameworksYou will coordinate and participate in on-call rotationsAutomate, automate, automateCompetitive Candidate ProfileYou have excellent communication and collaboration skillsYou demonstrate the ability to succeed in a high-pressure environment with rapidly changing prioritiesYou are an excellent problem solver, and willing to roll up your sleeves to take on any issue thrown your wayYou have a desire not just to resolve problems, but to fully understand them and prevent them in the future5+ years of professional Windows and Linux server administration3+ years of Amazon Web Services (AWS) administration2+ years of experience within a high-performance, 24x7, DevOps or SysOps teamYou seek out opportunities to improve, fix bugs, and challenge assumptionsYou have experience working with global teams (North America, Europe, Asia)You have experience with the following technologies:DockerContainer Orchestration (Nomad, Kubernetes, ECS)Configuration Management tools (Chef, Puppet, Ansible)Infrastructure as Code (Terraform, CloudFormation)ActiveMQWildflyJava, Ruby, or Python programming experience is a plusYou have proven experience in mentoring more junior team membersYou prefer to lead the charge, not just keep up with it",aus,de
5,LPL Financial,Finance,3.8,Senior DevOps Engineer,"Austin, TX",$100K - $124K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_e5b1a1ac&cb=1618792326186&jobListingId=4060116956,"Are you passionate about implementing industry leading Enterprise wide DevSecOps solutions? Are you excited about scripting who loves to develop CI/CD tools to enable the developers to deliver efficiently with quality?If yes, then this could be the role for you!We have an exciting opportunity to join our Technology organization as a Senior DevOps Engineer supporting various Advisor & Client Technology. This team oversees trading, fee billing, data, service transformation by delivering a transformed multi-channel service experience to our advisors leveraging artificial intelligence, machine learning, straight through processing, and other innovative capabilities.Responsibilities:Provide technical leadership and mentoring to teammates through technical design of CI/CD processes and process orchestration, code reviews and implementation, adhering to industry standard best practices.Create standards and tools that enable faster delivery of software features with governance enforcement of coding and test standardsDrive implementation of CI/CD to enable frictionless delivery of changes to production with quality in collaboration with Engineering and Infrastructure teams.Responsible for establishing security and operations governance enforcement as part of the tooling framework to ensure stability and reliability.Implement tools that integrate with the organization change control platform providing greater transparency on the changes adhering to the audit/compliance guidelines.What does your success look like in the first 90 days?Learn the LPL key components including architecture, operations & tooling, how domain teams interact with the DevSecOps team and how the integrations are done between the CI/CD pipelines. Understand the functionality and operational characteristics of the components being worked on. Explore the options to enhance the reliability of various components and ready to take charge on building/improving the CI/CD solutions for the developer community. Demonstrate proactive and corrective actions as needed.What are we looking for?We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.Requirements:6+ years overall technology experience with min 3 years of DevOps experience with SDLC3+ years’ experience working with infrastructure engineers and software development teams.3+ years’ experience with Microsoft stack including PowerShell scripting2+ years of experience with AWS and ability to design AWS deployment pipelines.Strong working knowledge of one or more of the following listed below:GitHub, TFS/Azure DevOps, TeamCity, Artifactory, Octopus Deploy, Ansible, Puppet, Chef.Software security standards and best practicesConcepts such as DevOps, Continuous Integration/Delivery, Test Driven Development, Scaled Agile.Git source control implementation and common branching strategiesCore Competencies:Ability to articulate the vision influencing the adoption of the DevSecOps culture promoting effective delivery.Excellent soft skills; service oriented, ability to work with software and infrastructure engineers as well as non-technical clients.Effective at planning, prioritization, task execution and time management.Comprehensive knowledge of containerization and related tooling to integrate container applications into CI/CD.Expert level scripting with PowerShell and Bash, can handle any DevOps scripting task independently.Solid understanding of practices to provide administration, maintenance, troubleshooting, performance optimization and stability support for critical DevOps supported software and tooling under minimal guidance.Can take primary ownership of the DevOps CI/CD pipelines and custom solutions of the major platforms such as Mulesoft, ForgeRock, Appway, FICO/DMS, NICE.Preferences:AWS or Azure Certification",aus,de
6,BlackBerry,Information Technology,3.4,Senior / Principal Big Data Engineer,"Austin, TX",$104K - $135K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_cb7effa1&cb=1618792326185&jobListingId=4007426293,"Worker Sub-Type:Regular Job Description:*We are open to remote applicants.At BlackBerry, we develop state-of-the-art machine learning algorithms to solve long-standing problems in computer security. We discover novel ML techniques and applications, build systems to handle petabytes of ludicrously high dimensional data, and protect people from bad actors.We’re looking for a Senior/Principal Big Data Engineer to work with a team of 20 scientists and engineers and lead efforts to automate the model training data pipelines underlying all of our security products across millions of endpoints as well as in the cloud. This position will partner with many peer engineering, product, and research teams to define requirements and deliver insights, so written and in-person communication skills are extremely important.WHAT YOU WILL DODesign, build, and maintain scalable, automated data pipelines in Python and ScalaDesign, build, and maintain big data products for use within our AWS cloud environmentRegularly contribute to documentation of our data pipelines and productsLead technical efforts, including design and code reviews, and mentor staff appropriatelyCommunicate with internal teams and stakeholders to understand project requirementsWHO ARE WE LOOKING FOR?Experience developing and scaling big data processing using Scala and SparkExperience writing and maintaining production-grade Python in a collaborative teamExperience automating infrastructure to build and maintain big data pipelinesExperience leading technical projects and mentoring junior team membersExperience with software build and release processes, unit testing, version control, etc.Excellent written and verbal communicationSolid understanding of the *nix command line5+ years in industry with a Master’s or 8+ years with a Bachelor’s degreeABOVE AND BEYONDExperience using AWS (S3, EMR, Batch, Athena, Glue Data Catalog, etc.)Experience with big data catalog technologies like the Hive MetastoreExperience managing Apache Spark clustersExperience building and using Docker containersJob Family Group Name:Product DevelopmentScheduled Weekly Hours:40",aus,de
7,BigCommerce,Information Technology,4.2,Senior Applications Security Engineer,"Austin, TX",$87K - $140K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2b81fc10&cb=1618792326185&jobListingId=4059698709,"BigCommerce is disrupting the e-commerce industry as the SaaS leader for fast- growing, mid-market businesses. We enable our customers to build intuitive and engaging stores to support every stage of their growth.BigCommerce is seriously growing its information security team, get in whilst the Security team is still small and you'll have the ability to influence the culture and direction moving forward.As the BigCommerce e-commerce SaaS platform handles information at a large scale, we need to anticipate and protect against attackers targeting BigCommerce or our customerOur engineers are called on to wear many hats, you'll be very well rounded, with experience as a software developer, penetration tester, and able to work independently to provide technical expertise to other software developers.Named a ""Best Place to Work"" in Austin and Sydney, ""Best and Brightest"" place to work in San Francisco is looking for a full-time Senior Applications Security Engineer who wants to make an impact to every level of society through powering innovators, creative thinkers, entrepreneurs and business owners around the world to be successful at each stage of their business.What you'll doRespond to information security incidents, providing technical expertiseProvide security guidance and experience to BigCommerce engineering teamsReview project technical designs and stay involved through their implementation to assist BigCommerce engineering staff with the finer points of application securityHelp build internal security tooling, to help us be proactive in the battleUtilise data to help generate insights into threats, and build solutionsMentoring team members in best practice around information security standardsRegular and ongoing pen testing of BigCommerce's changing environmentEvangelize security within BigCommerce and be an advocate for BigCommerce customersProtect BigCommerce Merchants, Shoppers and the companyWho you areBachelor's degree in CS, EE or MIS; or equivalent experienceGood understanding of how web works, Web Application Security concepts, threats, exploits and preventionSkills to Test, Triage, review and provide recommendations to vulnerabilities3 plus years of experience in application security-related fields (code reviews, application penetration testing, security engineering)Passionate about security and willingness to learn, unlearn and relearn if neededKnowledge on development and integration tools and technologies(Ex. CI/CD)2 plus years of software development experience in PHP, Ruby, Java, or similar relatable technology skill-setThe ability to explain security issues to developers, engineers and productStrong communicator with a bias towards honesty and transparencyExperience working on global teamsOur Hiring Processes Might IncludeWe want to see your problem-solving and analytical skills. Be prepared to write good, clean, scalable code. You don't need to know our entire stack, but we're looking for practical experience, someone who can solve production problems in the cloud.Recruiter Phone ScreenHiring Manager ScreeningFinal Team InterviewNote: Visa Work Authorization Sponsorship Supported and Relocation Assistance Provided#LI-GC1INDSPDiversity, Equity & Inclusion at BigCommerceWe have the opportunity to build not only a great business but a great company, with soul. Our beliefs and commitment to diversity, equity and inclusion are a central part of achieving that.Our dedication to DEI is grounded in two things: a moral belief in the dignity, value, and potential of every individual, and a practical belief that diverse, inclusive teams will create the best outcomes for our customers, partners, employees, and company. We welcome everyone to be a part of our journey.Current BigCommerce Employees: Please use the internal job board to apply for openings",aus,de
8,Computer Services Incorporated,Finance,4.1,Software Engineer - .Net Core,"Austin, TX",$59K - $87K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_303ad8f6&cb=1618792326185&jobListingId=4062546739,"Software Engineers at CSI work in a team environment to research, design, code, test and maintain software solutions. You will work cross functionally to ensure end user requirements are met and CSI’s goal of providing innovative technology solutions to our customers is accomplished.In this role the Software Engineer will be a key contributor in the continuing evolution and expansion of our core applications to highly scalable, distributed, and resilient to four 9’s. She/He will be responsible for delivery of high value code that is maintainable, testable, operable, and secure. We are looking for a contributor comfortable at multiple levels - hands on coding, troubleshooting, and innovation.Ideal candidates have a background building and operating SAAS platforms using the Microsoft technology stack with modern services-based architectures.CSI builds and runs software in a sane, repeatable way - everyone contributes.Responsibilities:Participate in all phases of our Agile/SCRUM SDLC - working in concert with our Product, QA, and DevOps teamsCode, test and maintain applications for our customers and internal teamsStay up-to-date on emerging technologies and how they might be used to meet goalsBring new ideas to the team, teach best practices, pitch and lead adoption of changeDocuments and demonstrates solutions by developing documentation, flowcharts, layouts, diagrams, charts, proofs of conceptContribute to feature delivery from technical design through execution and release within our iterative cycleIdentify root cause, propose solutions, and assist in the resolution of production issuesBe involved in the maintenance and updating of legacy codeDesired Skills and ExperienceCore technologies:Current .NET technologies with a focus in WCF, Web.API, ASP.net.NET Core, C#, , Node, Containers, SQL, NoSQL (Couchbase, Mongo, Cassandra, Cosmos), Javascript (Angular, Bootstrap, KO, JQuery)Comfort with working in an Agile/SCRUM environmentExperience with cloud technologies such as Azure or AWSExperience developing microservice-based architecturesExperience with Event Driven ArchitectureMicrosoft stack - IIS, MSMQ, SQL ServerKnowledge of relational database design and stored procedure development using Microsoft SQL Server 2008 and upStrong understanding of object-oriented software designExtensive use of APIs and understanding of HTTP and REST architectureStrong understanding of design patternsProven ability to work in a rapid release production environmentExperience with developing scalable software systemsExperience with Unit Testing frameworks (NUnit, XUnit, MSTest)TDD or BDDNice to have:Experience with big dataMVC, TPL and latest async/await coding standardsAutomationMachine Learning",aus,de
9,All Web Leads,Insurance,3.8,Senior Software Engineer,"Austin, TX",$93K - $111K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044077&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f5e4dbd2&cb=1618792326184&jobListingId=4063555157,"As our Senior Software Engineer based in Austin, TX, you will use your experience in back-end and front-end technologies to help us evolve our application software platform. You will work in an agile development environment, enhancing and extending our in-house software-as-a-service (SaaS) platform responsible for processing and managing hundreds of thousands of dollars in revenue each and every day. You will be working closely with senior engineering leaders to design robust, scalable software that meets both the immediate and future needs of our constantly evolving business environment.Just be willing to relocate to Austin, TX.Must be eligible to work in the United States. Visa sponsorship for employment will not be providedGeneral Responsibilities:Designing and implementing highly reliable components for our business-critical applicationsWorking closely with engineering leadership and key stakeholders to build new features to address business-critical needsWorking closely with our Operations team to ensure the proper implementation and configuration of software and hardware resourcesWorking closely with our QA team to ensure on-time release and product qualityParticipation in the full software development lifecycle process – “You build it, you run it.”Requirements:5+ years of experience in a back-end C# /.NET software development role with increasing responsibilitiesExperience building, tuning and supporting large scale, high-availability SaaS platformsEnjoy working within a small, fast-paced, Agile team in a TDD and CI/CD environmentExperience consuming/creating JSON-based, RESTful APIsExposure to Polyglot persistence: SQL/NoSQL (MySQL, PostgreSQL, MongoDB, Redis, etc.)Knowledge of Domain Driven Design and SOLID principlesExperience with message-based architectures (Akka, RabbitMQ, ActiveMQ, JMS)Bachelor’s degree in Computer Science, Engineering or related field* Must be eligible to work in the United States. Visa sponsorship for employment will not be providedPreferred:Exposure to Contact Center or Cloud Telephony technologyExperience with Modern JavaScript/Typescript, HTML, and CSSPrevious work with Python, Flask, and Python-based data science toolingExposure to AWS, Docker, KubernetesJob Type: Full-timePay: $92,602.00 - $188,795.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceFlexible scheduleFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offParental leaveReferral programRetirement planVision insuranceSchedule:Monday to FridaySupplemental Pay:Bonus payWork Location:One locationCompany's website:https://www.allwebleads.com/jobsWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredPlastic shield at work stationsTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",aus,de
10,silicon tech solutions,Information Technology,4.4,Data Engineer,"Austin, TX",$98K - $137K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_10471f7a&cb=1618792326183&jobListingId=3670859460,"4+ years – Working in both Linux and/or UNIX environments4+ years – Working in an Oracle Environment; PL/ SQL expert4+ years – Developing, testing, and managing complex ETL/ELT solutionsExperience with Business Intelligence tools (For example - Business Objects, Informatica PowerCenter)4+ years – Korn and/or Bash shell scriptingPreferredPreferred experience with C Programming LanguagePreferred experience supporting TX Medicaid systemsPreferred experience working with CRON",aus,de
11,Crowdskout,Information Technology,3.5,Data Engineer,"Austin, TX",$60K - $117K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_cf23e145&cb=1618792326182&jobListingId=3670582404,"Crowdskout believes that a more equitable world will be built by people with organizing superpowers. To achieve this vision, we are building one seamless, intuitive, and intelligent platform that integrates data, tools, and experiences to give anyone those superpowers. Our customers are organizations engaged in political and social advocacy that drive big change over the long-term using a portfolio of strategies on a multi-partisan basis. Most importantly, our customers believe that people organizing in their communities are the ultimate agents of durable change.Crowdskout is looking for a Data Engineer to build out our expanding data infrastructure. Crowdskout's product has most recently been centered in the CRM space, but we are looking to change that. Currently, we process millions of data points through multiple data pipelines to feed into a suite of databases. We are preparing for 10x growth both in the volume of data processed and the speed in which that data can be available and actionable. To accomplish this we are looking for someone who can build out highly scalable data solutions.If you're highly motivated, super passionate about our democracy, and want to join a team that is looking to build great things together, Crowdskout may be for you. Even better if you think like a scientist, bring creative solutions, and can obsess about quality. This is a full-time position reporting to the Senior Director of Data Platform. Crowdskout is a remote first company.ResponsibilitiesCreate highly scalable and robust data solutions for use by our products and clientsDesign, build, and maintain multiple performant data pipelines & ETL / ELT flows against massive datasetsEnsure data accuracy and reliabilityRequirementsStrong SQL experience (any flavor)Development experience using PythonExperience building large scale streaming and batch data pipelines (e.g. Python, Java)Experience building out data warehouse and/or data lake infrastructureExperience with data modeling and physical database designExperience using Big Data technologies (e.g. Spark, Presto, Kafka)Experience with SQL & NoSQL databases (e.g. MySQL, MongoDB)ExtrasAWS data stack (e.g. Kinesis, Glue, RDS, Athena, Redshift etc.)Software development using PHP and PythonGraph database experienceWorkflow management engine experienceKnowledge of data security best practices (e.g. data encryption, tokenization, masking)Crowdskout is an equal opportunity employer that encourages diversity across all spectrums in its hiring, without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, or any other protected factor. With that being said, we wouldn't be able to accommodate candidates in need of work sponsorship at this time since we are a small company. If you find this role interesting and you hit on the elements above, please apply!",aus,de
12,Applied Information Sciences,Information Technology,4.4,Data Engineer,"Austin, TX",$95K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_ce86b117&cb=1618792326181&jobListingId=4007899703,"Intro (Use Font Arial 12):As a Data Engineer, you will use cutting-edge cloud and data technologies to help global brands and federal agencies solve challenging problems through innovative technology solutions. Work on exciting projects, future-proof your skills, and grow into your dream job alongside some of the most talented, knowledgeable, and dedicated technologists in the industry.What You'll Be Doing:Work in a team using cutting edge technologies to solve challenging business problems and build solutionsApply your skills in Azure Cognitive Services, Azure PaaS, data science, data analytics, and data warehousing to pioneer Azure cloud and data servicesInteract directly with our client(s) to understand their needs and meet, or exceed their expectations by meeting delivery deadlinesLocation and Travel Details:This is a remote position with occasional to one of the following SIPR locations:Adelphi, MDAberdeen, MDFt Eustis, VAAustin, TXProfile of Success:Minimum of interim Secret security clearance is requiredMinimum of six years of comparable data engineering experienceDeep knowledge of data ingestion strategies and understanding of the V-dimensions of data (velocity, volume, variety, veracity)Extensive experience with the Azure storage technologies (Azure Data Lake, Azure SQL Data Warehouse, Azure SQL Database)Extensive experience with Azure data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Data Bricks, Stream Analytics)Comfortable with Microsoft SQL data technologies (SSAS/SSIS/SSRS)Desirable Skills:Microsoft related certificationsExperience with visualization tools such as Power BI or TableauAbout AIS:AIS, Dedicated to Our PeopleAIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee's success; however, they define it.It's our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.We Invest in Individuals Committed to InnovationAIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals.We are looking for:Smart people with a passion for technologyStrong technical capabilities with a consultancy mindsetClose involvement with local technical communitiesA willingness to think outside of the box to provide innovative solutions to clientsAbility to solve challenging technical business problemsSelf-directed professionalsOur Core ValuesClient SuccessContinued Learning and Technical ExcellenceStrong Client RelationshipsCitizenship and CommunityEEO Statement:Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status or any other basis covered by law. Employment decisions are based solely on qualifications merit, and business need.",aus,de
13,Apple,Information Technology,4.3,Data Engineer,"Austin, TX",$113K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_ec02b27f&cb=1618792326180&jobListingId=4005998124,"SummaryPosted: Feb 16, 2021Weekly Hours: 40Role Number:200223310Do you love problem solving and thinking beyond an obvious solution? Are you passionate about data accuracy and improving operational efficiency by managing complex data and information delivery? We are!The Retail Business Intelligence team is looking for a resourceful, energetic Data Engineer / Information Analyst to lead and assist with the data needs of projects by crafting creative solutions to deliver data to end users. You’ll work with cross-functional teams to stitch data from various systems into unified, high-performance and low-latency reporting layers for end-to-end analyses of projects. Join us, and you’ll help provide the data needed for the organization to effectively manage the business and improve our customer experiences across the world.Day-to-day responsibilities in the Retail Business Intelligence team include partnering with IT teams to build critical data pipelines, ad hoc data analyses, troubleshooting data and supporting project teams during all stages of projects including, requirement gatherings, gap reviews, development and testing.If you are a strategic problem solver who can lead and work with cross-functional teams to handle changes, perform data analyses, and execute project requirements to support an ever-changing data landscape, apply today!Key QualificationsStructured thinking with ability to easily break down ambiguous problems and propose impactful solutionsAbility to lead, take action and provide goal-oriented direction in the face of ambiguityStrong business mentality - ability to grasp business needs, translate into technical needs; ability to communicate complex technical concepts to business leadersAbility to multi-task and own activities across diverse scope, business units and geographical boundariesProactive in bringing new, innovative ideas to the table and inspiring change across projects, programs and processesSelf-starter who can take a project from start to finish with minimal directionCreate and maintain comprehensive project documentationData savvy in understanding existing data sets and applications when designing new, flexible reporting layersExcellent problem solving and debugging skills with attention to detailExpert SQL skills and deep relational database design understandingAbility to pick up new tech skills independentlyAbility to react to re-sets and changes in a dynamic environmentKnowledge of Apple Retail and core products and operating systems preferredMinimum of 6 years experience in data/technology fieldDescriptionThe Data Engineer / Information Analyst is responsible to encourage, mobilize and lead the data track of projects with a focus on common deliverables, goals and timelines. This role will partner with teams across Apple including IS&T, Retail (Online & Stores), Operations, Apple Media Products, and Finance. The following strengths are crucial to success in this role:- Deal with Ambiguity: be comfortable and confident working in a dynamic environment, partnering with teams to move through the unknown- Flexibility when handling directional changes and ability to concurrently balance multiple large-scale work streams- Confidence in the ability to listen and be patient with others — working across dynamic organizations will highlight differences on how Apple departments operate- Work closely with project managers, stakeholders and IT to deliver data requirements- Participate in regular design and code reviews and perform debugging and coding to resolve issues- Provide technical guidance and mentoring to fellow Analysts to help improve overall team growth- Demonstrate solid understanding of data management, system integration and development methodologies including unit testing- Continuously look for ways to improve and enhance data reliability and performanceEducation & ExperienceCandidate must possess a Bachelor’s Degree in Information Technology, Mathematics, Computer Science, or equivalent with a minimum of 8 years relevant work experience. Master’s degree is preferred with 6+ years of experience directly related to role requirements.",aus,de
14,OverHaul,Transportation & Logistics,4.5,Data Engineer,"Austin, TX",$86K - $101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_67776f5e&cb=1618792326179&jobListingId=4035912898,"Who We AreOverhaul is a supply chain integrity solutions company that allows shippers to connect disparate sources of data into the first fully transparent situational analysis engine designed for the logistics industry. Data that is transformed into critical insights can instantly trigger corrective actions, impacting everything from temperature control to handling requirements or package-level tracking, ensuring cargo arrives at its destination safely, undamaged, and on time. We are a dynamic, innovative, and fun team who is highly committed to our customers' experiences and our Mission and VisionThe RoleThe Overhaul team is looking for an experienced Data Engineer to serve in a role supporting the data insights / data science workflow and infrastructure (the queries and pipelines) for Overhaul and our customers.As a member of our Data Science and Analytics team, you will establish yourself as a key expert and evangelist on our data, working cross-functionally to ensure data self-service and generate insights about our business in support of key initiatives. You'll develop infrastructure, schema, and pipelines that become a part of Business Intelligence workflows, Data Science processes, and the product itself. You will build and iterate on a modern, SaaS-based data warehouse, analytics, visualization, and catalog infrastructure stack.We're looking for someone who is able to clearly communicate and collaborate with others and is passionate about working with data.Key Responsibilities:Collaborate with business groups at Overhaul to gather requirements around key insights and reporting needsDevelop effective schema and queries on structured data in support of insights for both internal-facing and customer-facing use cases, and effective repositories of unstructured data in support of sameDevelop new data and analytics capabilities for our customer-facing across a variety of initiativesAdminister and optimize our SaaS-based data warehouse and BI infrastructure in support of self-service analytics dashboards, ad hoc analytics, and reportingCreate a star schema data model (or better!) and architecture to ensure performance and usefulness across the organizationWrite and maintain containerized (e.g. Docker) ETL code using Python, R, or other programming languageWrite and maintain SQL jobs in support of ETL/ELT and BI analysis, reporting, and visualization, ability to troubleshoot SQL jobs as requiredEngage and coordinate with data science, engineering, analytics, and others at Overhaul in support of data initiativesMaintain diagrams and documentation of data models and data flows as needed to support understanding and troubleshooting of data infrastructureBuild and maintain internal data catalog including data dictionaries, glossary, and curated datasets in support of easy consumption by the rest of the companyManage and drive improvements for the metrics collection pipeline, data processing, and self-service data & insight toolsBe stewards and evangelists for data driven culture and data best practices within the companyBe customer zero, leveraging our product and providing feedback as one of the key target personas that the product intends to provide value forMinimum requirements:3+ years of experience working with BI or data warehouse technologies in support of insights and reporting3+ years of SQL experience with ability to write and tune SQL jobs for a variety of usage patterns3+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics3+ years of experience in scripting languages like Python etcBachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)Experience with AWS services including S3, EKS, ECR, EMR, and KinesisStrong interpersonal skills and experience interfacing with others internally and externally from the companyUnderstanding of ETL, ELT, star schema, and other data model and data warehouse concepts, techniques, and best practicesGood communication and presentation skills with the ability to explain concepts and conclusions around data and insights in a clear, concise, and compelling wayExperience working with Snowflake or other applicable SQL data warehouse technologiesExperience with Data Lake architectures, and with combining structured and unstructured data into unified representationsExperience with Docker and KubernetesExperience with data pipeline tools such as Airflow or PachydermExperience working with Tableau, Looker, or other modern data visualization toolsAbout youProven work experience as a Data Engineer or similar roleCollaborative, communicative, and consultative work styleDetail-oriented with the ability to effectively manage multiple competing prioritiesAbility to succeed in a fast-paced, innovative, and rapidly evolving industry and business organizationExcellent time-management skillsWhat we commit to youCompetitive starting base salary with performance-based increasesProgressive advancement opportunity and career mobilityTop employee health and well- being benefitsUnlimited vacation policyRotating company perks at work programCaregiver/adoption/family leaveFree parkingFlexible WorkingOur CultureWe are guided by our core values of Diversity and Synergy, Creativity, Problem Solving, Authenticity and Receptivity, Trust, Encouragement, Teaching and Learning, Wellness and Integrity. These values help us recruit aligned talent to join our rapidly expanding team around the globe. It is important to us that each and every Overhauler is not only eager to challenge themselves and knows how to get work done, but is also an awesome addition to our company culture.",aus,de
15,Jobot,Business Services,4.8,Data Engineer,"Austin, TX",$88K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=798489&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_5ece977b&cb=1618792326178&jobListingId=4059240462,"Growing Financial Services Company Seeks a Data Platform Engineer / Data Analyst in Austin!This Jobot Job is hosted by: Reed KellickAre you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.Salary: $100,000 - $160,000 per yearA bit about us:Based in Austin, we are a rapidly-growing financial services company that is looking to expand its data and analytics team. As a Cloud Data Engineer / Big Data Software Engineer on our team, you will help modernize our solutions to the next-generation cloud platform.Why join us? Competitive Base Salary between $100k and $160k, depending on experience! 15% annual bonus! $2k - $5k relocation assistance! 401k match up to 3%! 18 days PTO per year! 11 paid holidays per year! Very competitive benefits package: health / dental / vision! High-growth company! Backed by best Private Equity firm! Strong strategy and execution! Fast-paced agile team environment! Opportunity to learn! Working with latest and greatest technologies! Flexible work options in the near future (week on/off for in-office/remote)! Modern workspaces! Car parking spaces! Fantastic city!Job DetailsAs a Big Data Engineer / Software Engineer on our team, we are looking for: Strong experience with NoSQL database, including Postgres Background in working with Azure Cloud Services: Data Factory, SQL database, Functions, Data Lake, Databricks, Logic Apps, and Azure Automation. Fluent in object-oriented and functional script language: Python, Scala, and C#. Advanced working knowledge of SQL Server database - writing advanced SQL script, profiling, and optimization. Working knowledge of Business Intelligence tools: Microsoft Integration Services, Reporting Services, and Analysis Services, as well as PowerBI. Experience with other Big Data tools such as Spark, Snowflake, and Kafka Bachelor's or Master's in Computer Science or related would be preferred Financial industry background would be helpful, but not necessaryInterested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",aus,de
16,Epic Placements,Business Services,-1,DevOps Engineer (REMOTE) - Full Time,"Austin, TX",$67K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044072&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f55d7828&cb=1618792326175&jobListingId=4059298826,"MUST BE AUTHORIZED TO WORK FOR ANY EMPLOYER. No 3RD PARTIES, C2C / Corp-to-Corp or Sponsorship AvailableWe are working with a growing company in Denver, CO and helping them find energetic technical professionals who are searching for growth in their devops careers. Our client is looking for engineers who have a passion for devops cultures and enjoy working with various platforms, languages and technologies.Our client offers the ability to gain hands-on experience with enterprise setups, progressive devops techniques, devops in high-scaling environments and so much more. You will have the opportunity not only to use the skills you already have and enjoy, but also learn new and emerging technologies/setups in devops cultures.You may have a Software Development background, an Operations background, or you were raised in a DevOps culture from the start of your career. The field of DevOps covers a wide range of organizational design, process design, and information technology engineering. If you recognize yourself in the following, we want to hear from you!Overview:Our client loves Terraform. From authoring templates to modifying existing, they leverage this tool for the majority of their clients.Strong capabilities in configuration management. Puppet, Chef, Ansible, will help clients automate their workflows using all of these tools. If you are an expert in one, our client will teach you to become an expert in the others.Docker, Kubernetes and RancherPython, Golang, Ruby and Shell Script are often used with client interactions.DevOps automation ranging from Git, Jenkins, Docker, Chef, Puppet, Ansible, Selenium, xUnit, and othersYour commitment to meeting deadlines and exceeding client expectations is equal to your commitment to writing great code.Lead day-to-day pilot team implementations with clients and provide a diverse set of Agile and DevOps consultative services ranging from project management, requirements, design, development, testing, environment management, change and release, and supportTechnologies:Provisioning: TerraformConfiguration Management platforms: Puppet, Ansible, ChefLanguages: Python, Golang, Ruby, JavaScript and BashDatabases: MySQL/MariaDB, PostGRES, Amazon RDSEngineering & Monitoring tools: Bootstrap, Jenkins, Github, Nagios, Sensu, Zabbix, OpsGenie, JIRARuntime: Docker, Kubernetes, Angular, Prometheus, ElasticsearchClouds: AWS, Azure, GoogleCloud tool proficiency: AWS CLI, az, cloudinitOnsite Virtualization: VMware, OpenStack, KVMRequirements5+ years experienceExperience designing and deploying production-grade software via version controlExperience with object designExperience writing distributed systemsExperience developing in different compiled languages such as Go, Java, C++, and CExperience scripting with JavaScript, Python, or BashExperience with web application development using HTML, CSS, and AngularExperience with data transport using XML, YAML and JSONExperience developing and debugging software on a network stack IP, TCP, HTTP, RESTExperience using SQL and NoSQL databasesAbility to navigate and administer Linux and Windows operating systemsUnderstanding of how to scale server-side applicationsDemonstrated application of software engineering best practicesExperience working on Agile teams, specifically using the Scrum methodExcellent communication skillsWilling to take ownership of problems and see them through to resolutionBS in Computer Science or equivalent experience#EP1",aus,de
17,Hired Recruiters,Information Technology,-1,Data Engineer,"Austin, TX",$56K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2d640655&cb=1618792326073&jobListingId=3670579085,"The Data EngineerCOLLABORATE | OPTIMIZE | EVOLVEAs a Data Engineer at A Cloud Guru, you will ensure the data platform infrastructure and architecture supports the evolving requirements of the Data Engineering and Data Analytics teams as well as other parts of our business! You will work closely with the Director of Data Engineering to develop a strategy for our long term Data Platform architecture to identify gaps in the data processes and drive improvements while mentoring and coaching other team members. Thanks to your contributions, our data platform will continue to optimize and revolutionize. This role reports to the Director, Data Engineering.Hello, we're A Cloud GuruOur friends call us ACG.A Cloud Guru was built by engineers for everyone, everywhere. Here, you’ll have the freedom to follow your curiosity. We’re not afraid to just try, because when you’re working with cutting edge technologies, experimentation and trying out new ideas have to be encouraged and celebrated. Our engineers are building the world’s largest (and most awesome) cloud learning platform. Why? Our mission is to teach the world to cloud. Our fun, practical courses have helped over 1.5 million people learn to cloud, and we’re just getting started.We’re not a training company that just decided to sell training courses. We grew up out of the cloud ecosystem. We were a bunch of cloud engineers who pulled people together to create a training platform. That’s why we’re genuinely passionate about what we create. And we are known for practicing what we preach.What makes the Product & Technology team awesome...Learning to the cloud means unlocking a world of possibilities for our students. Using the latest tech, we design the tools to teach people to cloud faster and better. The team is talented (and a little quirky), and we’re all in it together.Cutting-edge tech We’ve built a cloud-first Serverless Architecture with tools like Lambda, API Gateway, GraphQL, ReactJS,Founded by engineers Having a CEO who’s also an engineer is nice — he knows the effort it takes to make things awesome.We don’t bite We’re friendly, down-to-earth, and collaborative. There are no high-performing jerks and no heroes. Just great teams.Hungry and humble We’re dedicated to learning all the things to create the best product possible.You'll do well at ACG if you're open to learning and trying new things, and you like to be surrounded by other friendly, passionate, and driven people. –Natasja, Makeup Guru (and Software Developer)As a Data Engineer at ACG, you’ll get to:Be an essential part of designing and building ACG’s new data platform, as we evolve the existing databases into a cutting-edge solution to meet the needs of our 2021 data plans and beyondExplore and contribute to discussions around technologies under consideration, such as Snowflake, Kappa/Lambda architecture, Delta Lakes and Data VaultDevelop, test and maintain existing architecture, including databases, data pipelines, and large-scale processing systemsCollaborate with the Analytics team on transformation processes to populate data modelsRecommend ways to improve data reliability, efficiency, and quality of the data platform and optimize for performance, scalability, and costDiscover opportunities for data acquisition and explore new ways of using existing dataIdentify gaps in data processes and drive improvementsWe are looking for someone who can:Utilize a variety of languages and tools (e.g. scripting languages) to marry systems togetherRecommend ways to improve data reliability, efficiency, and quality for the whole data platformOptimize solution designs for performance, scalability, and costsWhat you bring to the tableWe focus on hiring values-aligned people because we believe the right person can learn all the things to be successful in their role. Self-confidence plays a big part in what you apply for. We encourage all job applicants to apply even if they are nervous to do so. College degrees aren't required for any roles, and career gaps or switches are totally welcome.Essential2+ years of Data Engineering, Data Warehousing, or related experience2+ years of development experience with Python or similar scripting language2+ years of SQL experience, including experience with schema design and dimensional data modelingExperience working with AWS services such as DynamoDB, Glue, Lambda, Step Functions, S3, CloudFormation or RedshiftExperience with ETL development, metadata management, and data qualityDesirableKnowledge of software engineering best practices with experience with implementing CI/CD, monitoring & alerting for production systemsExperience with complex data structures and No-SQL databasesExperience with open source orchestration platforms (e.g. Airflow)We want people who care about doing a good job. The ones who have humility and hunger to learn. - Sam Kroonenburg, Co-Founder and CEOMore than a jobWhere you work isn’t just a career decision - it’s a life decision. We get it. That’s why we want all of our Gurus to feel a sense of belonging that comes from feeling supported in all areas of their lives. Everyone has family, friends and interests outside of their careers, so we offer perks and benefits to make work, work better for you.4 weeks PTO, plus 10 sick days, and holidays. Whether it's hiking to a waterfall in Costa Rica or bonding with your couch, we all need downtime. All Gurus get four weeks paid time off, 10 sick days, and enough holiday to make a banker blush.Let's get lunch. Lunches are catered three times per week, and our kitchen stays stocked with a smorgasbord of the team’s most requested snacks and drinks.Parking is on us. We have your Downtown parking covered. We offer paid garage parking near the office. We also have perks for going green by walking and taking public transit.We’ve got you covered. We offer insurance plans that pay for 100% of your medical, dental, and vision and 80% for your family/dependents.Gender-neutral paid parental leave. Expanding your family? We offer 12 weeks of gender-neutral paid parental leave and reimburse up to $10,000 for eligible adoption expenses.$1,000 continuing education budget. All Gurus get $250 a quarter to spend on personal development and 2 hours each week reserved for learning something new.What’s the interview process like at ACG?Applying for a job can feel intimidating and like a full-time job of its own. You shouldn’t have to burn through a week of sick time or all your best out-of-office excuses just to put feelers out for a new career opportunity. We want to be as transparent about the process as possible to help ease your mind. It’s our goal to provide you a fair, efficient interviewing experience that respects you and your time — and to do it all with a sidecar of delight.Once you submit an application, we’ll review it. If you’re a good fit, you’ll have an initial chat with a recruiter over the phone. A phone interview with a manager typically follows. Depending on your role, you might then be asked to do a little homework (but nothing too time consuming). Then we’ll schedule a Zoom call to meet other members of the team, answer any questions you have, and give you a feel for what it’s really like to work at ACG. If you're on the fence, just give it a try.Keep being awesome, Cloud Gurus.",aus,de
18,Vrbo,Information Technology,3.7,Data Engineer III,"Austin, TX",$92K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_2a61de2c&cb=1618792326074&jobListingId=4034604458,"What You'll Do:Develop fast, scalable, highly available, and reliable property status software that will control the enabled status for all of Expedia’s propertiesYou will scale our services to tens of thousands of requests per secondUse real-time data to understand performance and ensure system scalabilityDockerize our apps and services for cloud deploymentYou will develop property status funnel features that will drive our business through real-time feedback loopsScale our public API’s to give other partners the ability to leverage new Expedia Group servicesScale our private API’s to allow enhanced Expedia UI experiencesSimplify our core property status workflow to enhance both our travelers’ & suppliers’ experienceTechnologies We Use:Java 8, Python, Scala, Spark, K-Streams, Hadoop, Elasticsearch, Jetty, and LinuxResponsibilities:Backend development building applications from concept to completionYou will commit to vigilantly rewriting, refactoring, and perfecting codeDedicated to delivering tested and optimized high performance code for a distributed SOA environmentDevelop quality scalable, tested and reliable applications using industry standard methodologiesWork in an agile environment with product management and operationsCreate and maintain quality software using premier tools: Git, Splunk, Datadog, New Relic, etc.Participate in resolution of production issues and lead efforts toward solutionsOpportunities to showcase your work on our tech blog and internal & external conferencesWho You Are:Bachelor’s + 7 years or Master's + 5 years in Computer Science or Engineering or related experience .Experience building data pipelines with data from event streams, on distributed data systems (AWS/Hadoop)Batch and/or stream processing experience using Spark, K-Streams, KafkaExperience building low-latency data product APIsProfessional development experience in Java/Python/ScalaBenefits & Perks:Competitive health and insurance benefitsCompetitive salaryAnnual target bonus or commissionParental leave for up to 20 weeks (dependent on eligibility)Paid vacation and sick timeEmployee Stock Purchase ProgramFree snacks and beveragesFrequent company update talks with our leadership teamFree listing on Vrbo.comElectronic, adjustable stand-up deskDiscounted Metro & Rail passCasual dressWhy Join Us:Expedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and make people's lives better – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them to tools to do so.Whether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares. Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, HomeAway®, Orbitz®, Travelocity®, Wotif®, lastminute.com.au®, ebookers®, CheapTickets®, Hotwire®, Classic Vacations®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia® CruiseShipCenters®, SilverRail Technologies, Inc., ALICE and Traveldoo®About Vrbo:In 1995, Vrbo introduced a new way for people to travel together, pairing homeowners with families and friends looking for places to stay. We were grounded in one purpose: To give people the space they need to drop the distractions of everyday life and simply be together. Since then, we've grown into a global community of homeowners and travelers, with unique properties in 190 countries around the world. Vrbo makes it easy and fun to book cabins, condos, beach houses and every kind of space in between.Vrbo is part of VRBO and the Expedia Group family of brands and offers homeowners and property managers exposure to over 750 million visits to Expedia Group sites each month. To learn more, visit www.vrbo.com.Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.",aus,de
19,RetailMeNot,Information Technology,3.7,Data Engineer II,"Austin, TX",$88K - $156K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=148364&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_734355d0&cb=1618792326075&jobListingId=4033309518,"At RetailMeNot, we believe that gaining valuable insights using our data is core to our future success. The Data team at RetailMeNot is responsible for developing core datasets and for exposing data services consumed by product, data science and business teams. Daily, we collect approximately a terabyte of analytics events and process hundreds of terabytes of data. Our team works efficiently to deliver new features for real-time and batch processing services. We use primarily AWS cloud services and Kubernetes to build and deploy services quickly, at scale and with no downtime.This team is integral to the RetailMeNot business, so we need engineers who can deliver results while understanding the structure of a large system. We provide cross-team leadership that ensures that RetailMeNot code meets a consistently high standard while building the platform to support the future of the company. Your daily activities will involve oversight, mentoring, delivering key pieces of functionality, and collaborating with technology leadership to plan the technical roadmap for RMN.We are constantly evolving both the software and the teams that deliver it. If you’re someone who enjoys taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, then we want you to be a part of the team!RetailMeNot is headquartered in Austin, TX! This position is fully remote and we encourage applicants nationwide!Who You AreYou have a Bachelor's degree in computer science or equivalent STEM field, or equivalent work experienceYou have 3+ years work experienceYou are skilled using Python, Linux, Docker, Git, and Amazon Web Services (or have translatable experience with similar toolsets)You have extensive SQL experience on a variety of RDBMS, and enjoy optimizing queries as well as designing efficient data modelsYou have developed scalable solutions using both SQL and NoSQL (Hadoop) databases. Working with data sets comprised of millions or billions of records is comfortableYou strive to identify simple solutions to complex problems, can identify a minimal viable product and enjoy iterative developmentYou are able to accurately estimate tasks, identify dependencies and dedicatedly solve problems to ensure commitments are metYou recognize that your success depends upon enabling your fellow team members to succeed; taking time to help others energizes youYou enjoy gathering requirements from non-technical coworkers and delivering solutions that meet their needs and exceed their expectationsYou derive satisfaction from enabling the business to succeed and delighting coworkers, not building technology for its own sakeYou have a work ethic that inspires your fellow team members to give their bestWhat You'll DoImplement data system for both real-time and warehouse applicationsDevelop ETL processes that ensure data is accurate and available within SLAsEnhance data models by developing integrations with business partnersSeek opportunities for performance improvement and implement optimizationsCreate dashboards that provide insight into the health of data integrations, ETL processes and data setsWho We AreWe have an open environment where engineers are given a lot of responsibility and the freedom to make a huge impact.We have lots of smart people to work with and learn from.We work on large scale challenges with a variety of technologies and believe in an ever-growing diversity of technology platforms.We believe in giving prizes, bonuses, and recognition for doing what you enjoy.Rewards*We offer an opportunity to be an integral part of a company that eagerly pursues disruption in its space to continue to drive innovation and lead the competition. Benefits of being an employee of RetailMeNot, Inc. include, but are not limited to the following: - Competitive base & bonus packages; salary negotiable- Long Term Incentive Plan- Performance based rewards & recognition for your hard work and service- Very competitive benefits packages, including best-in-class parental leave- Open & flexible PTO- Cell phone & gym membership reimbursements*Some rewards do not apply to contract workers or interns. About UsRetailMeNot, Inc. is a leading savings destination bringing people and the things they lovetogether through savings with retailers, brands, restaurants and pharmacies. RetailMeNotmakes everyday life more affordable through online and in-store coupon codes, cash backoffers, and the RetailMeNot Deal Finder™ browser extension. Savings are also provided inconsumers’ mailboxes through the RetailMeNot Everyday™ direct mail package.To learn more, visit http://www.retailmenot.com/corp or follow @RetailMeNot on social media.U.S. Equal Employment Opportunity/Affirmative Action InformationAt RetailMeNot we celebrate difference. We are committed to ensuring an environment of mutual respect for every employee and proud to be an an equal employment opportunity employer who does not discriminate against any person because of race, color, creed, religion, gender, gender identity, gender expression, national origin, citizenship, age, sex, sexual orientation, pregnancy, marital status, ancestry, physical or mental disability, military or veteran status, or any other characteristic protected by law. We believe a diverse and inclusive workplace is central to our success and actively seek to recruit, develop and retain the most talented people from a diverse pool of candidates. You are being given the opportunity to provide the following information in order to help us align with federal and state Equal Employment Opportunity/Affirmative Action record keeping, reporting, and other legal requirements.",aus,de
20,PayPal,Information Technology,4.1,"MTS 1, Data Engineer-2","Austin, TX",$74K - $140K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_3f65a443&cb=1618792326076&jobListingId=4037075262,"Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 375 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.Job Description Summary: The candidate will be a Data Engineer as part of PayPal Financial Analytical Data Service’s Technical Product Manager team. The candidate will be responsible for analysis, design, coding and testing of the application code. The candidate has to interact with global cross-functional teams to address complex business requirements. The role demands the individual to possess technical skills required to perform the job in an effective manner. The individual should be self-motivated, possess creative problem solving skills and have the ability to handle multiple projects at the same time. The candidate should have passion for data & analytics. In this role, the individual will be part of the engineering team in Analytical Data Services Organization and will be responsible for. • Participating and collaborating with cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale. • Planning the execution of the project in an effective and efficient manner. • Approaching the problem, taking into account all possibilities. • Creativity and out of the box thinking is required. • Proactively anticipating problems and appropriately communicating to the team and management in a timely manner. • Being flexible and being able to support all functions of product life cycle when required. • Ability to work in a fast paced environment • Ability to deliver from coarse grained requirements.Job Description:12+ years of experience in the IT industry, experience in Data Technology space is preferred.Knowledge of Teradata and BigQuery is essential.Working experience in any MPP systems (Certified Teradata developer is a plus); Should have strong SQL programming skillsExperience in Spark, HBase and HiveKnowledge of data warehousing conceptsKnowledge of Scheduling Tools is a plusExcellent written and oral communication skillsStrong analytical skills including the ability to define problems, collect data, establish facts, and draw valid conclusionsExpertise in database programming and performance tuning techniques; Teradata experience is mustFamiliar with data movement techniques and best practices to handle large volumes of dataExperience with data warehousing architecture and data modeling best practicesExperience with File Systems, server architectures, and distributed systemsStrong communication skills and willingness to take initiative to contribute beyond basic responsibilities.Working experience in an Agile methodology is highly preferred.We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",aus,de
21,IPT Associates,Business Services,3.8,Data Engineer,"Austin, TX",$71K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1483709a&cb=1618792326076&jobListingId=4006306953,"Data EngineerAustin, TX/RemoteIPT's Technology Solutions Team is passionate about providing our customers with technical solutions that satisfy their business needs. Through collaborative interactions with customers, team members, subject matter experts (SMEs), technical leaders, and partners we design practical solutions that solve real problems for major government and business organizations. As a member of our Technology Solutions group, you will work with a team of technologists focused on delivering innovative business solutions using emerging technologies through proven successful methods.Our Team:We are looking for talented people who are enthusiastic about applying technology to deliver innovative outcomes with “fierce determination, fearless integrity, and passionate service.” Our belief is that our people are the key to success. By encouraging and enabling continued learning, our team members grow to achieve their personal career goals. We are looking for:Smart people with a passion for technologyAbility to solve challenging business problemsSelf-directed professionalsHunger to continually learn and growResponsibilities:Work with application and data science teams to support development of custom data solutionsSupport the database design, development, implementation, information storage and retrieval, data flow and analysis activitiesTranslate a set of requirements and data into a usable database schema by creating or recreating ad hoc queries, scripts and macros, updates existing queries, creates new ones to manipulate data into a master fileSupport development of databases, database parser software, database loading software, and database structures that fit into the overall architecture of the system under developmentRequirements:Bachelor’s Degree in Computer Science, Information Systems, Engineering, or other Scientific/Technical discipline and 5 years of related work experienceBe capable of supporting rapid iterations of feature engineering with the development of coding solutions to enrich existing data setsExperience with traditional, modern, and cloud native database solutionsMust meet IAT-I requirements as specified in DoD 8570.01-M (A+, Network +, etc.)Active Secret clearanceThis job posting sets forth the authorities and responsibilities of this position, which may be changed from time to time as shall be determined. IPT Associates, LLC is an Equal Opportunity/Affirmative Action employer. We are committed to providing equal employment opportunity to all qualified employees and applicants for employment. The Company does not discriminate in employment opportunities or practices on the basis of race, color, religion, sex, sexual orientation, national origin, age, physical disability, mental disability, medical condition, status as a veteran or disabled veteran or any other characteristic protected by law. We base all employment decisions, including recruitment, selection, training, compensation, benefits, discipline, promotions, transfers, lay-offs, returns from lay-off, terminations, and social and recreational programs on the principles of equal employment opportunity. Our employees have diverse backgrounds, skills, and ideas that collectively contribute to a rich working environment and greater opportunity for innovation.#clearance#dice",aus,de
22,YETI Coolers,Manufacturing,4.3,Senior Data Engineer,"Austin, TX",$84K - $148K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=8095&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_94d1dec8&cb=1618792326077&jobListingId=3802660342,"




At YETI, we believe that time spent outdoors matters more than ever and our gear can make that time extraordinary. When you work here, you'll have the opportunity to create exceptional, meaningful work and problem solve with innovative team members by your side. Together, you'll help our customers get the high-quality gear they need to make the most of their adventures. We are BUILT FOR THE WILD™.

The Senior Data Engineer will be part of a team that designs and develops YETI's enterprise Data Warehouse and Analytic systems. This position offers an extremely rare and unique opportunity to join a highly profitable, fast-growing business.

Our needs are diverse and its certain that we will build and deploy software on various platforms including but not limited to Google Big Query and Tableau. While this position specifically seeks a Senior Data Engineer, who will focus on implementing solutions in Google Cloud Environment, Google Dataflow, and Composer (Airflow), we strongly prefer candidates with a diversity of experience capable of working across more than one area.

This role requires a blend of skills typically found in the specialized roles of Business Analyst, Data Modeler, Data Analyst, and Cloud Administration. Additionally, an understanding of dynamic environments, agile development, and how to balance the need to maintain operations versus the need to build things the right way is an absolute must.

Responsibilities:

Work with business customers and data analysts to define detailed requirements from broader business challenges
Translate those requirements to logical and physical models that satisfy analytical needs
Perform data profiling and analysis to assess data quality patterns, recommend data cleansing rules, conforming data standard rules and matching algorithms
Own the system architecture and infrastructure of our Google Could Data warehouse and other related GCP services
Assist ETL and BI developers with complex query tuning and schema refinement

Qualifications and Attributes:

Bachelors degree in Computer Science or related discipline
At least 6 years' experience in the development of data warehouse, decision support, or executive information systems.
Expert in writing, analyzing and tuning complex SQL queries
Extensive experience with Python programming
Hands-on experience in any Cloud environment preferably GCP
Good understanding of Object-Oriented programming
Must have a good understanding of Dimensional Modeling and ER-Modeling.
Experience with data pipeline and workflow management tools: Airflow, Dataflow, etc.
Willing to work with new tools and learn new programming languages
Strong problem-solving ability and a positive attitude

YETI is proud to be an Equal Opportunity Employer.

#LI-CL1





",aus,de
23,PayPal,Information Technology,4.1,"MTS 1, Data Engineer","Austin, TX",$74K - $140K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_eb17b659&cb=1618792326077&jobListingId=4037075261,"Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 375 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.Job Description Summary: The candidate will be a Data Engineer as part of PayPal Financial Analytical Data Service’s Technical Product Manager team. The candidate will be responsible for analysis, design, coding and testing of the application code. The candidate has to interact with global cross-functional teams to address complex business requirements. The role demands the individual to possess technical skills required to perform the job in an effective manner. The individual should be self-motivated, possess creative problem solving skills and have the ability to handle multiple projects at the same time. The candidate should have passion for data & analytics. Responsibilities: In this role, the individual will be part of the engineering team in Analytical Data Services Organization and will be responsible for. • Participating and collaborating with cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale. • Planning the execution of the project in an effective and efficient manner. • Approaching the problem, taking into account all possibilities. • Creativity and out of the box thinking is required. • Proactively anticipating problems and appropriately communicating to the team and management in a timely manner. • Being flexible and being able to support all functions of product life cycle when required. • Ability to work in a fast paced environment • Ability to deliver from coarse grained requirements.Job Description:12+ years of experience in the IT industry, experience in Data Technology space is preferred.Knowledge of Teradata and BigQuery is essential.Working experience in any MPP systems (Certified Teradata developer is a plus); Should have strong SQL programming skillsExperience in Spark, HBase and HiveKnowledge of data warehousing conceptsKnowledge of Scheduling Tools is a plusExcellent written and oral communication skillsStrong analytical skills including the ability to define problems, collect data, establish facts, and draw valid conclusionsExpertise in database programming and performance tuning techniques; Teradata experience is mustFamiliar with data movement techniques and best practices to handle large volumes of dataExperience with data warehousing architecture and data modeling best practicesExperience with File Systems, server architectures, and distributed systemsStrong communication skills and willingness to take initiative to contribute beyond basic responsibilities.Working experience in an Agile methodology is highly preferred.We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",aus,de
24,Bmtech group,N/A,-1,Big Data Engineer,"Austin, TX",$63K - $116K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=4134&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_388d92ab&cb=1618792326077&jobListingId=4063482783,"Job Description

Minimum 6 years of Experience in large-scale IT Project/Product delivery with at least 2 years of work experience in current data streaming, messaging, management, and database technologiesAbility to establish and always maintain effective and professional working relationships with others in the course and scope of conducting businessExcellent communication, problem-solving, and organizational skillsMinimum 4 years of Experience in Strong data integrity, analytical, and multitasking skillsPreferred Graduation from an accredited four-year college or university with major coursework in Computer Science or EngineeringPreferred 2 years of Experience with designing and building data platforms and setting up data toolsPreferred 2 years of experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, Elk, Elasticsearch)Preferred 2 years of Experience in tuning and troubleshooting streaming/messaging platformsPreferred 2 years of Experience creating producer and consumer applications with KafkaPreferred 2 years of Experience coding and scripting (Python, Java, Scala) and design experiencePreferred 2 years of Experience with ELT methodologies and toolsPreferred 2years of Hands-on experience with AWS and/or AzurePreferred 2 years of Experience with KStreams and KSQLPreferred 2 years of Experience with designing and automating build and deployment solutions/process for data solutions/tools/platformsPreferred 2 years of Familiarity with data management, visualization, warehouse, and analytics tools/platforms such as Qlick, SAS Viya, Kibana, Snowflake, Qualtrics, and SpirionPreferred 1 year of Basic knowledge of database technologies (PostgreSQL, Vertica, Redshift, etc.)Able to work independently


Additional InformationAll your information will be kept confidential according to EEO guidelines.",aus,de
25,Glassdoor,Information Technology,3.8,Senior Data Engineer (Remote),"Austin, TX",$139K - $163K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b2c45390&cb=1618792326078&jobListingId=4038320996,"Senior Data EngineerLooking for your next challenge? How about helping us disrupt a $90B+ talent acquisition market! Glassdoor is the world's fastest growing career community with more than 25M members and thousands of business customers and our mission is helping people everywhere find jobs and companies they love.Our mission is to help people everywhere find a job and company they love. We're transforming an entire industry through the power of transparency. As the worldwide leader in employer branding and insights, our vision is for a world where transparency holds companies accountable to strive to become better employers.Please note this role is open to remote hiring. Our main office locations are in San Francisco, CA, Chicago, IL and Uniontown, OH.We are looking for a talented Senior Data Engineer to join our growing Data Engineering team. The ideal candidate has significant experience in building scalable data platforms that enable analytics, data science and data products. You must have strong, hands-on technical expertise in a variety of technologies and the proven ability to fashion robust, scalable solutions. You should have a passion for continuous quality improvement.We embrace a wide variety of technologies and work very closely with data scientists and business stakeholders to deliver end to end solutions. Although this is an individual contributor role, we are a tightly knit team who widely collaborate with one another. If you are interested in a fast paced environment, the latest technologies, and fun data problems, come join us!ResponsibilitiesDesign and develop big data applications using a variety of different technologies.Develop logical and physical data models for big data platforms.Automate workflows using Apache Airflow.Write data pipelines using Apache Hive, Apache Spark.Create solutions on AWS using services such as Lambda, API Gateway, Kinesis etc.Participate in rotational on-call support.Provide ongoing maintenance and enhancements to existing systems.Learn our business domain and technology infrastructure quickly.Document, share your knowledge freely and proactively with others in the team.Key Qualifications5+ years of hands-on experience with developing data warehouse solutions and data products.2+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive, Spark, Airflow, Kafka, etc.2-3 years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.2+ years of experience using Python as a programming language.Experience with scripting languages: Perl, Shell, etc.Practice working with, processing, and managing large data sets (multi TB/PB scale).Exposure to test driven development and automated testing frameworks.Background in Scrum/Agile development methodologies.Capable of delivering on multiple competing priorities with little supervision.Excellent verbal and written communication skills.Bachelor's Degree in computer science or equivalent experience.Nice To HaveExperience building customer facing products, machine learning pipelines or data products.Experience working with Tableau, Looker or other data visualization software.Familiarity with AWS or GCS technologies.Ability to program in multiple programming/scripting languages: Python, Java, JS, Scala, etcBe passionate about or have contributed to open sourced engineering projects in the past.Why Glassdoor?Work with purpose – join us in creating transparency for job seekers everywhere100% company paid medical/dental/vision/life coverage, with 80% dependent coverageLong Term Incentive Plan401(k) Plan with a Company Match to prepare for your futureGenerous paid holidays and open paid time offOur CommitmentsA values-based culture: Our values are Transparency, Innovation, Good People and Grit. We look for talented, passionate people who embody these values in how they show up to work every day.Pay transparency: We believe that with more salary transparency, you hold the information to ensure fair pay now and in the future as your career changes and grows. Pay bands and our compensation philosophy are shared publicly to ensure that everyone is paid fairly. Our annual Pay Gap Study found no gender or race/ethnicity pay gap at Glassdoor.Diversity & Inclusion transparency: We are committed to building a company that is more diverse and representative of society at large. Glassdoor externally publishes our Diversity & Inclusion report and information about our employee population to hold ourselves accountable to our commitment. We also provide programs and resources to create a greater sense of belonging for our employees.Employee feedback transparency: We believe in providing you with greater insight into what it is really like to work with us. In addition to our Glassdoor Reviews, we publicly publish our employee feedback survey responses to ensure everyone has a complete picture of what it's like to work here.Company performance transparency: We believe you should know how your work contributes to moving the company forward. That's why we share detailed business performance updates in our monthly All Hands and deeper financial results every quarter. For more insight into the performance of our parent company, you can explore the financial results of Recruit Holdings, and its HR Technology segment in particular, each quarter. Operating transparently at Glassdoor is fundamental as we advocate for transparency in the broader workforce. The ultimate goal is not just to change how we operate at Glassdoor, but for every employer to follow our lead!Glassdoor is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. Glassdoor is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.",aus,de
26,Apple,Information Technology,4.3,Finance Data Engineer,"Austin, TX",$113K - $178K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_7a33bc3f&cb=1618792326078&jobListingId=4038245841,"SummaryPosted: Mar 17, 2021Weekly Hours: 40Role Number:200217551Apple’s Finance Business Process Reengineering team is seeking a Data Engineer to join our organization. In this role you will help architect, maintain and continually improve data analytics and automation capabilities. Sitting inside a business unit, you must adapt to varied and shifting needs. You will be working with business users, Apple IS&T developers, and data analysts on your team to deliver complete, accurate, well-secured data that enables reporting and analytics across all Finance functions. Comfort with and ability to learn and perform a wide variety of development and engineering tasks combined with knowledge of Finance business processes sets you apart in this role. We are open to candidates in Austin, TX or SF Bay Area.To succeed in this role, several of the following should apply:Key Qualifications5+ years hands-on experience in data architecture, relational database/data warehouse developmentVery strong SQL skills; Teradata experience a big plusExcellent with Python, shell scriptingExperience with various database technologies including Teradata, Snowflake, Oracle, MySQL, PostgreSQL, MongoDb, and other NoSQL databasesExposure to container technologies like DockerExposure to cloud/orchestration architectures such as AWS, KubernetesExperience with scripted SQL interactionExperience with ETL tools and job orchestration. Airflow experience a plus.Experience with GitUnderstanding of tools like Splunk, Nagios, and other monitoring technologyUnderstanding of data cataloging/lineage tracking concepts and implementationExperience developing performant, secured data sources for TableauExperience preparing data for and using traditional BI tools like Business Objects, Essbase, Crystal, etc., a plusAble to quickly learn new technologiesExperience with applying data encryption and data security standardsExperience leading complex projects from inception through production supportExcellent oral and written English communication skillsDescriptionThe Finance Business Process Reengineering (BPR) organization supports every AppleFinance function worldwide. Our Finance Data team within the BPR org enables the Finance organization by providing quality data accessibility, analytics, reporting and automation services. We are looking to expand capabilities in the areas of data privacy, high-performance computing, advanced analytics and general business intelligence.A Finance Data Engineer is a technical expert and works tightly with other data engineers and data analysts on a team to create data integrations, ETL, pipelines and codebase to drive innovative analytics projects from initial experimentation to production level deployment. They work on critical data engineering problems, building bespoke, reliable, accurate, consistent, and architecturally sound solutions that are aligned with business needs.The Finance Data Engineer architects, maintains and continually improves data analytics and automation capabilities. The role requires working cross-functionally with business users, Apple IS&T developers, and data analysts to deliver complete, accurate, well-secured data that enables reporting and analytics. This role is required to learn and perform a wide variety of development and engineering tasks, on top of growing their knowledge of Finance business processes to efficiently identify data applicable business questions.Finance Data Engineers work predominately in Apple’s enterprise data warehouse (EDW), identifying and combining data in an efficient, scalable manner to help answer business questions. When the necessary data is not available on an enterprise system or is generated offline by business users or third parties, the Finance Data Engineer must develop methods to reliably source, validate, and integrate the data into EDW.The Finance Data Engineer must learn and understand a variety of available IS&T solutions, when and how to use them, and when to develop custom solutions. This paired with a proven record of excellent problem solving and a sharp, open mind will be more important than deep expertise in any one area.Education & ExperienceUndergraduate degree in Computer Science, MIS, Engineering, Mathematics or other quantitative field required.",aus,de
27,SpringML,Information Technology,4.5,Big Data Engineer,"Austin, TX",$70K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_d1ed6c6a&cb=1618792326079&jobListingId=3670574705,"At SpringML, we are all about empowering the ‘doers’ in companies to make smarter decisions with their data. Our predictive analytics products and solutions apply machine learning to today’s most pressing business problems so customers get insights they can trust to drive business growth. We are a tight knit, friendly team of passionate and driven people who are dedicated to learning, get excited to solve tough problems and like seeing results, fast.Your primary role will be to design and build data pipelines. You will be focused on designing and implementing solutions on Hadoop, Spark, Pig, Hive. In this role you will be exposed to Google Cloud Platform including Dataflow, BigQuery and Kubernetes so the ideal candidate will have a strong big data technology foundation and bring a passion to learn new technologies. If you believe you have these skills please email your resume to info@springml.com.Required Skills:4-7 years Python and Java programming3-5 years knowledge of Java/J2EE3-5 years Hadoop, Big Data ecosystem experience3-5 years of Unix experienceBachelors in Computer Science (or equivalent)Duties and Responsibilities:Design and develop applications utilizing the Spark and Hadoop Frameworks or GCP components.Read, extract, transform, stage and load data to multiple targets, including Hadoop, Hive, BigQuery.Migrate existing data processing from standalone or legacy technology scripts to Hadoop framework processing.Should have experience working with gigabytes/terabytes of data and must understand the challenges of transforming and enriching such large datasets.Additional Skills that are a plus:C, Perl, Javascript or other programming skills and experience a plusProduction support/troubleshooting experienceData cleaning/wranglingData visualization and reportingDevops, Kubernetes, Docker containersdpFhuZNHdz",aus,de
28,Rev.com,Information Technology,3.4,MLOps Engineer; Data,"Austin, TX",$43K - $78K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=8095&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_31586db1&cb=1618792326080&jobListingId=4063828164,"About the Position

Do you want to work at a high-growth company where your impact is seen and rewarded? Are you looking for the autonomy to do your best work? We are seeking an MLOps Engineer to accelerate our pace of R&D. You will report to Joshua Dong.

Qualifications


Strong understanding of software testing, benchmarking, and continuous integration
Comfort working with NoSQL queries for experiment and data analysis
Experience architecting big data systems
Familiarity with debugging to diagnose computational bottlenecks
Comfort with Linux administration
AWS proficiency

Responsibilities


Terabyte-scale data warehousing of audio and text data
Design, automate, and improve the data pipeline that spans data ingestion, feature extraction, dataset versioning, and evaluating AI models against live data
Design and build tooling to better understand and explain our data and AI models from ingestion to production
Collaborate with researchers to improve automation, reproducibility and consistency of ML experiments and measurement

Life at Rev

Rev is a profitable, growth-stage startup that specializes in meeting the speech-to-text needs of hundreds of thousands of customers annually through its unmatched combination of the world's most accurate speech A.I. and the world's largest community of freelancers working side-by-side.

Rev's suite of products includes transcription, captioning, subtitling, as well as a live-captioning app for Zoom video conferencing. Rev also boasts seamless integrations with YouTube and Vimeo, as well as custom APIs for enterprise clients who need novel speech-to-text solutions.

Founded in 2010 by five MIT alumni, Rev has raised millions of dollars in venture capital from top Silicon Valley VCs and experienced exceptionally rapid growth, both internally and externally. Rev was recently named by Forbes as one of America's Most Promising Artificial Intelligence Companies and is a destination for the world's foremost engineers and speech scientists.

Our mission is to help the world overcome the limits of the spoken word. Our vision is to transcend all barriers of communication. Joining Rev means joining a team of smart, passionate, and friendly people with different backgrounds, shared ideas, and similar goals. Oh, and tons of perks!


Get Paid: Be generously compensated by a well-funded startup. Enjoy full benefits, options, and a 401k.
Customize Your Workspace: Want a stand-up desk? Need plants? Ergonomic chair? No problem. Your budget, your choices.
Make a Difference: Be measured by your impact, not your effort. Help create real jobs for real people.
Work Where You Want: Be free to stay at home, come to the office, or work from a coffee shop.
Have Fun: Plan and participate in events like field day, baseball games, ski trips and happy hours.
Stretch Yourself: Learn new skills, talk to customers, drive product improvements, or learn to design. We will push you to your limits.

Rev is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and pregnancy-related conditions), gender identity or expression (including transgender status), sexual orientation, marital status, military service and veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable federal, state or local laws and ordinances. Rev.com's management team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities, access to facilities and programs and general treatment during employment.

*We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.",aus,de
29,Forcepoint,Information Technology,3.2,Data Engineer II,"Austin, TX",$88K - $94K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136006&s=58&guid=00000178e78aa0d99e03b2f9d6de0c5f&src=GD_JOB_AD&t=SR&vt=w&cs=1_c96370ee&cb=1618792326081&jobListingId=4059248187,"ResponsibilitiesBuild, document, test and launch new data extract, transform and load (ETL) processes for one or more core data sets.Collaborate with Business Intelligence team and other stakeholders for data requirementsCollaborate with Data Management team to provide quality data to stakeholders.Build data expertise and learn company history needed to effectively design data pipelines.General RequirementsHighly collaborative and empathic approach to problem solvingNaturally curious with the drive to learn what is needed to identify root causeCapable of actioning high-level, sometimes ambiguous requirements into operational tools/dashboardsDemonstrated organizational skills, attention to detail and ability to work independently while staying integrated with the broader Data Engineering team as well as stakeholdersA strategist with sound business and technical acumen. Proven ability to influence at various levels of leadership, without direct authorityStrong problem-solving skills (critical, strategic, and evaluative thinking)Ability to synthesize complex data concepts into easily comprehended messagesTechnical Skill RequirementsData Collection ToolsSSMS & T-SQL: 2+ yrsETL Automation (SSIS Packages): 2+ yrsRelational Data Base Architecture: 2+ yrsPython experience preferredData Analysis & Dashboarding ToolsSSAS / Tabular Modelling: 2+ yrsTableau experience preferredEducation & ExperienceBachelor's degree required in related fieldMinimum 5 years related work experienceOngoing education in an area related to Data Analytics (Data Sciences, Mathematics, Statistics, Industrial Psychology, Organizational Behavior, or Finance/Accounting) preferredExperience working in a high growth company preferredWe are mission driven.We are passionate about our mission because our solutions protect businesses, critical infrastructures, and governments around the world.Find out more about Forcepoint’s Mission, Vision, and Values at www.Forcepoint.com and follow us on Twitter at @ForcepointSec.Find us on social at #forcepoint #forcepointculture #lifeatforcepoint to find out what its really like to work here from the team themselves.*Other dutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.Forcepoint Is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. We are committed to hiring and retaining a diverse workforce, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.Certain positions with Forcepoint require access to controlled goods and technologies subject to the International Traffic in Arms Regulations or the Export Administration Regulations. Applicants for these positions may need to be ""U.S. Persons,"" as defined in these regulations. Generally, a ""U.S. Person"" is a U.S. citizen, lawful permanent resident, or an individual who has been admitted as a refugee or granted asylum.If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talentcoordinators@forcepoint.com. We will make every effort to respond to your request for disability assistance as soon as possible.Applicants must have the right to work in the location to which you have applied.We are committed to hiring and retaining a diverse workforce, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.",aus,de
35,Dun & Bradstreet,Information Technology,3.4,Data Scientist,"Austin, TX",$92K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1206941&s=58&guid=00000178e78b99718bd7f9d48ad88867&src=GD_JOB_AD&t=SR&vt=w&cs=1_37e2995e&cb=1618792389584&jobListingId=3695210051,"Why We Work at Dun & BradstreetWe are at a transformational moment in our company journey - and we’re so excited about it. Each day, we are finding new ways to strengthen our award-winning culture, and to accelerate creativity, innovation and growth. Our purpose is to help customers improve business performance with Dun & Bradstreet’s Data Cloud and Live Business Identity, and we’re wildly passionate and committed to this purpose. So, if you’re looking to make an immediate impact at a company that welcomes bold and diverse thinking, come join us!

​

As a Data Scientist within Dun & Bradstreet's Analytics team, you will participate in all aspects of modeling engagement, including design, development, validation, calibration, documentation, approval, implementation, monitoring, and reporting. You will research complex business issues and recommend solutions, including model features and end products and any data required to support growing Dun & Bradstreet initiatives.

Key Responsibilities:

Develop Global Analytic Solutions inclusive but not limited to statistical models based on D&B’s established best practices, methodologies, and tools.Research complex business issues and recommend solutions, including model features and end productsCreate features and validate them against diverse set of objectives utilizing both internal and external data sources while maintaining business relationships and serving as subject matter expert.Utilize latest data science techniques across both supervised and unsupervised machine learning methodologies, NLP in automating and scaling internal business processes and development of new capabilities for the business.Establish and maintain strong relationships with key business stakeholders.Engage clients and D&B colleagues to identify business needs and develop, implement, and manage solutions.Serve as a Subject Matter Expert on predictive models within the Advanced Analytic Services team and with business users; consult with the business, as appropriate, on predictive modeling solutions.Share academic literature and industry best practices. Identify business relevance of new methods and work with cross functional teams to create prototypes, assist in creating business case, and go to market strategy.Drive timely retrieval of risk analytics data from external vendors, existing systems to create.Build relationships with external data vendors and aggregators to support analytical initiatives and products, building and testing of POC algorithms that meet business needs.Search for new alternative data based on the use cases - customer problems by business units, data quality and additional product needs.

As the ideal candidate, you are creative and inquisitive in nature, have the flexibility to learn and apply new methodologies, effectively communicate complex ideas to both a technical and non-technical audience and work both independently and collaboratively while managing multiple assignments.

Key Requirements:

Ph.D. or Masters in a quantitative / applied field (Statistics, Econometrics, Computer Science, Operations Research, Mathematics, Engineering). 3+ years of relevant experience in data science roles.Knowledge of evolving data science concepts and best practices including big data, NLP, feature engineering, regressive and non-regressive methods, and unstructured data synthesis.Proficiency utilizing Python, R and/ or SAS, Spark, PySpark and SQL.Working knowledge with diverse data formats and data structures.Experience building and maintaining relationships with clients and advising teams on the innovative methodologies, data sources, data science tools and environments.

Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.

We are committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with Dun & Bradstreet and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to TalentAcquisitionTeam@dnb.com. Determination on requests for reasonable accommodation are made on a case-by-case basis.

Please note that all Dun & Bradstreet job postings can be found at https://dnb.wd1.myworkdayjobs.com/Careers and all communication from Dun & Bradstreet will come from an email address ending in @dnb.com.",aus,de
37,Accenture,Business Services,4,Informatica ETL Developer,"Austin, TX",$55K - $90K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=00000178e78b99718bd7f9d48ad88867&src=GD_JOB_AD&t=SR&vt=w&cs=1_e5ca94c2&cb=1618792389585&jobListingId=4063790005,"ACCENTURE's Flexible Workforce solves clients’ toughest challenges by providing cross-industry expertise, unmatched innovation, World-class tech and talent. We help bring it all together to deliver tangible business outcomes for our clients with contractors and our extended workforce opportunities. Accenture is consistently recognized on FORTUNE’s 100 Best Companies to Work for and Diversity Inc’s Top 50 Companies for Diversity lists. And that's just the beginning. Now is the perfect time for you to consider opportunities through our Flexible Workforce.What's In It For You:Collaborate with a diverse network of peopleActively deliver innovative solutions for Accenture's clientsApply your skills and experience to help drive business transformationWork locally or remotely, significantly reducing or eliminating the demands to travelProject Description:Develop Build Informatica PowerCenter and Extract Transform and Load (ETL)Responsibilities:Extract Transform & Load - Informatica ETL Developers build and maintain the extract, transformation and load (ETL) processes for Texas Medicaid's data and analytics systems.Complete analysis, design, code, testing and deployment tasks for ETL programs and reports within approved estimatesTest system data validations and mappings using Informatica Data Validation Option (DVO) and SQLEffectively participate in Agile Scrum meetingsDocument work items and testing in Microsoft TFSCombine technical skills with Texas Medicaid business and system knowledge to deliver effective solutions.Required Skills2+ years developing and supporting ETL/ELT solutions2+ years developing data warehouse, business intelligence, and/or data analytics systems2+ years – Informatica PowerCenter development experience2+ years of SQL development experience1+ year of Oracle database development experience1+ year of Agile Scrum experienceTeamwork, technical skills, and business acumen.Bonus points if you have:ETL Developers primarily use Informatica PowerCenter to develop and test solutions.KeywordsInformatica PowerCenter , ETL, SQL, Medicaid, Agile Scrum, OracleWhat We BelieveWe have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more hereEqual Employment Opportunity StatementAccenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. Our rich diversity makes us more innovative, more competitive and more creative, which helps us better serve our clients and our communities.All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.Accenture is committed to providing veteran employment opportunities to our service men and women.For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy StatementRequesting An AccommodationAccenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.Other Employment StatementsApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",aus,de
59,recruitAbility,N/A,5,Senior Data Scientist - NLP,"Austin, TX",$91K - $147K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1044072&s=58&guid=00000178e78b99718bd7f9d48ad88867&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4e2e77e4&cb=1618792389591&jobListingId=4063556099,"Our client is a leader in the Artificial Intelligence space that offers business-critical solutions for customers in energy, manufacturing, finance, aerospace, defense, and security. A highly awarded company recognized for cutting-edge technology, This dynamic company develops AI-powered, cyber-physical software for the safety, security, reliability, and optimization of IT, OT, and the Industrial IoT. They deliver value to their customers by providing solutions that address complex customer problems.The Data Science team is looking for a Senior Data Scientist with Natural Language Processing experience to design, build, deliver and support custom powerful software solutions. This person should have a depth of experience with both computational linguistics and software engineering, along with interest in applying state-of-the-art NLP methods to development solutions for customers.Responsibilities:Lead a team of data scientists and machine learning engineers in the development of NLP applicationsLead/direct the development of new algorithms and approaches to practical NLP problemsWork with engineers to integrate new technology into core applicationsWork with professional services to apply core capabilities to customer solutionsQualificationsMasters Degree or higher with a focus on NLP and software development5+ years of experience in developing business applications using NLP technologiesExperience in Python and NLP/ML toolkits (e.g. scikit-learn)Experience in information retrieval technologies (e.g. SOLR)Experience in applying deep learning techniques to unstructured dataStrong interpersonal and leadership skillsIndependent thinking and desire to learn new techniques/technologiesWhat is in it for you as a Senior Software Developer with this company?Join a group of high-performance professionals building awesome software solutionBe a part of the AI Industry and work with some of the best and brightest engineersExcellent Salary Range and Comprehensive Benefits Package and PTO planA place where people WANT to go to work!INDSJ",aus,de
0,Sense,Information Technology,4.8,Data Engineer,"Cambridge, MA",$99K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178e78faef69efc6beafb91416e&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_7879acc1&cb=1618792657204&jobListingId=4006991273,"Data EngineerOur mission at Sense is to make all homes intelligent by keeping people informed about what's happening in their homes, and helping to make homes safer, more efficient, and more reliable.At Sense, we are serious about having a real impact on climate change.Sense was founded in 2013 by pioneers in speech recognition technologies. This background provides the team with the intuition needed to connect and unlock key data significance relating to home energy efficiency. Sense uses machine learning technology to provide real-time insights on device behavior. Customers rely on Sense for a wide range of uses including monitoring their home appliances, determining whether they left appliances running, and identifying how to reduce their energy costs.Job DescriptionWe are looking for a Data Engineer to be the first Data Engineer on our Data Science team. You will be working with our team to develop tools that learn machine learning models for detecting appliances, expand our growing fleet internationally, and modernize our data pipeline.We are looking for someone who is:Passionate about the energy sector and climate change.Excited about high-volume, real-time data and solving the challenges it poses.Motivated to learn new tools and software to develop performant and scalable systems.What you'll do:As the first Data Engineer on our Data Science team, collaborate in building the infrastructure and architecture for data generation.Work with the data science team to develop active learning tools and UIs that will facilitate the development of statistical models.Analyze, maintain, and improve our existing data systems and infrastructure.Design and implement new data pipelines and databases as needed.RequirementsWhat we're looking for:5+ years professional experience as a data or backend engineer.Solid knowledge of computer science.Experience programming in Python.Knowledge of C/C++ or the willingness to learn is a plus.Experience with relational databases such as MySQL.Experience with AWS services is a plus.Must be authorized to work in the U.S.BenefitsWhy SenseJoin Sense and be part of our mission to reduce global carbon emissions by making homes smart and more efficient. Our energy data and tools demystify home energy use, empower people to take command of their usage, and enable utilities to build a cleaner and more resilient grid.Sense is an Equal Opportunity Employer. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. Ensuring a diverse and inclusive workplace where we learn from each other is core to Sense’s values. We welcome people of different backgrounds, experiences, abilities and perspectives and are a pleasant and supportive place to work.Be a part of building something that will make a difference in the world.Have a big impact at a VC-backed consumer startup that's doing big things:Best Startups in Cambridge - Tech Tribune""One of the world's top 100 AI companies"" - VentureBeatClean Tech Company of the Year - New England Venture Capital Association50 on Fire - BostInnoTop 100 - Red HerringBest Consumer AI Technology - AI Dev WorldGlobal Cleantech 100Work with a small team of experienced entrepreneurs creating revolutionary technology.A wide range of difficult and interesting problems to be solved.Great opportunity to gain experience at a consumer smart home startup.Competitive compensation and generous healthcare benefits.Flexible hours and WFH policy.Paid parental leave.Though our company is fully remote due to the COVID-19 pandemic, we have a great office in Central Square in Cambridge, MA right by the Red Line. (re-opening July 2021 at the earliest due to COVID-19)",bos,de
1,Capital One,Finance,4.1,Master Data Engineer,"Milton Village, MA",$95K - $162K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000178e78faef69efc6beafb91416e&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_4025a46a&cb=1618792657206&jobListingId=4064288279,"314 Main Street (21020), United States of America, Cambridge, MassachusettsMaster Data EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 5 years of experience in application developmentAt least 3 years of experience in software development in at least one of the following: Scala or PythonAt least 3 years of experience in SparkAt least 2 years of experience in big data technologies (Cassandra, Accumulo, HBase, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree7+ years of experience in application development3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)2+ years of experience with Ansible / Terraform3+ years of experience with Agile engineering practices3+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)3+ years of experience with NoSQL implementation (Mongo, Cassandra)3+ years of experience developing Java based software solutions4+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)4+ years of experience developing software solutions to solve complex business problems3+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",bos,de
2,Starburst,N/A,4.5,Software Engineer - Full Stack (SaaS) (Remote Opportunity),"Boston, MA",$65K - $117K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_38256732&cb=1618792657207&jobListingId=4063634280,"Starburst is on a mission to modernize data access & analytics. Our company was founded in an unusual way; with customers and revenue from the beginning! Our growth is already ahead of some of the most successful software start-ups, and we don’t plan on slowing down.We believe our opportunity is huge. Every large company in the world suffers from a data silo problem. Traditional data warehouse products approach the problem with old solutions that breed inefficiency and ultimately can’t help business analysts run fast analytics on all their data.Starburst provides a modern solution that addresses these data silo & speed of access problems. Starburst helps enterprises harness the value of open source Trino (formerly PrestoSQL), the fastest distributed query engine available today, by adding the tools and 24x7 support that meet the needs for big data access at scale. Ultimately, Starburst helps organizations run analytics anywhere to make better business decisions.Starburst is looking for Full-Stack Engineers to work on our growing global engineering team, specifically building out our Mission Control product. This product allows users and administrators to build and maintain Trino environments quickly and easily, and is a key offering for our customers.Our team features very strong software engineering talent, with years of full stack development experience. As a Full-Stack Engineer you’ll be designing and implementing our Mission Control product, building functionality and scalability into every level as part of a dynamic and fun team. Daily tasks may include developing product features, supporting a production product, or building tools to help our products perform in a cloud-based environment.ResponsibilitiesDesign and develop components to Starburst’s Mission Control product, including a comprehensive SaaS platformLead projects from concept to completionWrite tests and contribute to ongoing automation infrastructure developmentCollaborate with teams globally across multiple time zones and operate in an Agile development environmentProvide exceptional customer support for both internal and external customersThrive in a fast-paced environment on a growing team with limitless potentialRequirementsA passion for Software Engineering and interest in all phases of the Agile software development lifecycle.Significant experience developing RESTful backend services in JavaProficiency in Javascript, preferably TypescriptProficiency using front-end frameworks such as React, Angular or BackboneComfortable with modern HTML and CSS technology stackDemonstrated experience with good engineering practices and software craftsmanship.Hands-on experience with scripting languagesAppreciation for maintainable, working, high quality software.Preferred experienceDeveloping SaaS applicationsAWS, Azure, and/or Google Cloud PlatformKubernetesHadoop, Spark, DockerUsability and user experienceHeadquartered in Boston MA with offices in Warsaw and London and employees across Europe and the Americas, we are committed to hiring where the talent is.Starburst Data, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",bos,de
3,Zyno Medical,Manufacturing,3,Risk Management Engineer - Medical Devices,"Natick, MA",$46K - $77K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044077&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f832d36b&cb=1618792657207&jobListingId=3802026418,"We are a growing medical device company looking to grow our Engineering team.The Risk Management Engineer will join a high performing team and own risk management activities throughout the life cycle of the product. The risk management engineer works independently and collaboratively to drive the appropriate activities such as leading and facilitating risk identification, assessment, and controls, guiding risk-based product and manufacturing process development, updating risk management files based on post-market feedback, and utilizing quality system data to make risk based decisions to ensure product safety. The Risk Management Engineer contributes to development and maintenance of compliant risk management systems, procedures and practices and is responsible for the Risk Management File portion of the product Design History File.ESSENTIAL JOB FUNCTIONS*Own the risk management files; Partner with product teams to create, manage, and maintain product risk management files and associated documentation in accordance with the requirements of ISO 14971 and global regulatory requirements.Provide guidance and support to design and manufacturing teams in the generation of risk management documentation, e.g., HHA, dFMEA, pFMEA, uFMEA, Fault Tree Analysis, etc.Support the development of risk-based test plans.Partner with new product development teams to ensure appropriateness and adequacy of quality management system documentation facilitating design and development planning and execution.Utilize Risk Management File and Design History File documents to assess risk resulting from design and manufacturing process changes, manufacturing events and post-market surveillance.Perform periodic reviews of Risk Management File documents to ensure the files remain reflective of data/trending signals and ongoing activities.Partner with subject matter experts in the development, maintenance and promotion of risk management processes for medical devices, including managing and maintaining global policies and procedures.Help to execute changes to Risk Management Files due to changes in standards, regulations, post market feedbacks, or industry best practices.Ensure consistency of Risk Management Files across product lines.OTHER DUTIES AND RESPONSIBILITIESPerform broad variety of tasks in support of quality operations as assigned.PREPARATION, KNOWLEDGE, SKILLS & ABILITIESA minimum of 5 years’ experience with product risk management processes (medical device industry required)Demonstrate practical knowledge and experience with ISO 14971:2019 requiredBachelor's degree in business, technical, or scientific fieldWorking knowledge of appropriate global medical device regulations, requirements, and standards, such as 21 CFR Parts 803 and 820, ISO13485, IEC 62304, IEC 62366-1, and European Medical Device Regulations (MDR) 2017/745, desiredKnowledge of medical device product design and manufacturing processesSuccessful experience working independently and on cross-functional teamsStrong computer literacy (MS Word, Excel, PowerPoint)Strong analytical and organizational skills, flexibility, and attention to detailStrong verbal, presentation, and written communication skillsJob Type: Full-timePay: $65,000.00 - $85,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceFlexible spending accountHealth insuranceLife insurancePaid time offProfessional development assistanceReferral programTuition reimbursementVision insuranceSchedule:8 hour shiftMonday to FridayApplication Question(s):What are your salary expectations for a new opportunity?Work Location:One locationCompany's website:www.zynosolutions.com and www.infutronixsolutions.comBenefit Conditions:Only full-time employees eligibleWork Remotely:Temporarily due to COVID-19",bos,de
4,Athenahealth,Information Technology,4.1,Senior Data Engineer,"Watertown, MA",$137K - $151K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_240cbd84&cb=1618792657208&jobListingId=4062370226,"Join us as we work to create a thriving ecosystem that delivers accessible, high-quality, and sustainable healthcare for all.We are looking for a Senior Data Engineer to join our athena.intelligence (a.i) team.Your job will be to help design and support the next generation of athena’s distributed data pipeline, which will allow instantaneous access to insights throughout our organization. But enough about us; let’s talk about you.You love to build solutions to complex problems. You embrace the challenge of using unstructured data to deliver real-time, actionable insights. You are a tenacious, but nimble learner, who demonstrates design and engineering excellence.The Team: Our athena.intelligence (a.i) team unleashes the power of athenahealth’s one-of-a-kind healthcare dataset by applying advanced analytics and machine learning to terabytes of data. We are a team of passionate, innovative engineers looking to make an impact and solve the most complex problems in healthcare using data.Job ResponsibilitiesPartner with the Data Science and Engineering teams to build innovative solutions that scale our ability to learn from our growing networkCreate reliable and efficient processes to move, transform and report on large amounts of healthcare dataUse your expertise in data modeling to deliver a well-crafted model that can be used by both Data Scientists and Business AnalystsDevelop and deploy code to production data environmentsTypical QualificationsBachelor’s Degree or equivalent4+ years of experience in Data Engineering, Data Management, or Data Warehousing roles, building and supporting data warehouses and ETL pipelines at enterprise scale is a mustStrong SQL skills with one or more RDBMS’ such as Oracle, PostgreSQL, MySQL, SQL Server is a mustDemonstrable experience with SQL query analysis, profiling, and optimizationExperience with Agile practices and all phases of the SDLCExperience in one or more modern high-level programming language such as: Python, Perl, Java, or NodeJSExperience working with public cloud technologies such as AWS, Azure, or GCP is desirableExperience with one or more ETL and Business Intelligence platforms such as Informatica, Talend, Tableau, PowerBI, QlikExperience with Unix/Linux systems and distributed computing technologiesExperience working with Cloud based SQL/NoSQL databases and data warehouse solutions is a plusAbout athenahealthOur Vision: To create a thriving ecosystem that delivers accessible, high-quality, and sustainable healthcare for all.Our Location: This role is based in Watertown, MA, just a few miles outside of Boston. Watertown is our Global Headquarters and our campus, the Arsenal on the Charles, is home to a number of restaurants, a local gym and large outdoor space. This office also has a cafeteria, coffee café and food trucks that rotate every day.Our Culture: At athenahealth, our employees (or “athenistas”) are committed to making healthcare smarter. Our success is dependent on the diversity, collective spirit, and contributions of our people, clients and partners. We value teamwork and believe that the strength of our team comes from supporting each other and leveraging our specialized skills. If you are looking for company that will enable you to work outside of your comfort zone to transform the healthcare ecosystem, athenahealth is the place for you.Our Perks: Along with health & financial benefits, our athenistas are offered a variety of perks that promote employee wellbeing such as commuter support (We were named one of the 2018 Best Workplaces for Commuters!), tuition reimbursement, collaborative work spaces and dog-friendly offices - just to name a few.athenahealth is committed to a policy of equal employment opportunity—that’s why we recruit and hire applicants without regard to race, color, religion, sex (including pregnancy), national origin, disability, age, sexual orientation, veteran status, genetic information, gender identity, gender expression, or any other factor prohibited by law. We’re happy to provide a reasonable accommodation, for those with a disability, to complete any part of the application process. If you are unable to access or use this online application process and need an alternative method for applying, please contact us attaoperations@athenahealth.com for assistance.https://www.athenahealth.com/careers/equal-opportunity",bos,de
5,Akamai Technologies,Information Technology,4.4,Platform Operations Engineer II,"Cambridge, MA",$77K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_9f2f771b&cb=1618792657208&jobListingId=4035817402,"Would you like to work on one of the world's most highly distributed computing platform?Do you enjoy acting quickly to solve problems?Join our Highly Visible Platform Operations teamOur highly visible Operations team provides enhanced support on technically diverse subject matter in a 24/7 environment. We collaborate with a variety of engineering groups to deliver our applications safely and securely. We have the best view of the world's largest distributed platform and are the tools that keep it running.Partner with the bestAs a Platform Operations Engineer II, you will contribute to a top-tier operations team that handles complex escalations from a variety of sources. You will resolve critical Tier 3 escalations through troubleshooting and problem solving skills. Collaborating with a global team you'll gain exposure to our large-scale network and continually develop your skills.As a Platform Operations Engineer II, you will be responsible for:Troubleshooting and resolving complex technical issues in our networking, storage and proprietary systems areas in a 24/7 environmentHandling escalations from multiple sources including NOCC, Customer Care, Engineering, and Service PerformanceParticipating in Service Incidents as SME or in another appropriate role to mitigate and resolve platform incidentsCollaborating with cross-functional teams to create technical solutions and support ongoing implementation of network improvementsPromoting best practices by improving tools, alerts, and documentation to maintain the integrity of the Akamai networkDo what you loveTo be successful in this role you will:Have 5 years of experience and a Bachelor’s degree in Computer Science or related fieldDemonstrate advanced knowledge of Linux/Unix, TCP/IP internetworking/WAN data communications as well as understanding of routing conceptsShow expertise in detailed debugging, log analysis, and troubleshooting often in critical time sensitive situationsHave proficient experience with scripting such as Perl, Python, SQL and/or a desire to learnBe able to work one day a weekend as part of regular shiftsShow the ability to collaborate with various SME's to identifying issues and bugs and provide resolutionsWork in a way that works for youWe recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:Please speak to your recruiter about your flexibility and preferencesWorking with usAt Akamai, we’re curious, innovative, collaborative and tenacious. We celebrate diversity of thought and we hold an unwavering belief that we can make a meaningful difference. Our teams use their global perspectives to put customers at the forefront of everything they do, so if you are people-centric, you’ll thrive here.Working for youAt Akamai, we will provide you with opportunities to grow, flourish, and achieve great things. Our benefit options are designed to meet your individual needs for today and in the future. We provide benefits surrounding all aspects of your life:Your healthYour financesYour familyYour time at workYour time pursuing other endeavorsOur benefit plan options are designed to meet your individual needs and budget, both today and in the future.About usInnovating on a global scale, we deliver our customers a fast, smart and secure intelligent edge platform. Working against a backdrop of digital collaboration, our highly skilled teams build progressive solutions that have the scope to transform entertainment, business, and life in ways that we have yet to imagine.Join usAre you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will challenge and inspire you! Akamai Technologies is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of gender, gender identity, sexual orientation, race/ethnicity, protected veteran status, disability, or other protected group status.",bos,de
6,Swisslog,Transportation & Logistics,3.6,"Field Service Engineer, Boston (Pharmacy Automation)","Boston, MA",$42K - $69K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_5984c9cf&cb=1618792657208&jobListingId=4059497124,"We shape the future of intralogistics with robotic, data-driven and flexible automated solutions that achieve exceptional value for our customers. Swisslog helps forward-thinking companies optimize the performance of their warehouses and distribution centers with future-ready automation systems and software. Our integrated offering includes consulting, system design and implementation, and lifetime customer support in more than 50 countries. Swisslog is a member of the KUKA Group, a leading global supplier of intelligent automation solutions with more than 14,000 employees worldwide.Swisslog designs, develops and delivers best-in-class automation solutions for forward-thinking hospitals, warehouses and distribution centers. We offer integrated systems and services from a single source – from consulting to design, implementation and lifetime customer service. Behind the company’s success are 2 300 employees worldwide, supporting customers in more than 50 countries.The Healthcare Solutions portfolio comprises automated material handling and drug management systems for hospital facilities that increase efficiency and enhance the patient experience in forward-thinking hospitals. Swisslog automated material handling solutions provide quick, flexible and safe transportation of medications, specimens and basic supplies throughout hospitals and across medical center campuses, while its medication management solutions address packaging, labeling, storage and dispensing for inpatient and outpatient pharmacies.FIELD SERVICE ENGINEER, BOSTON (PHARMACY AUTOMATION)Swisslog Field Service Engineers are critical to our customer care and support initiatives. Our Field Service Engineers are on the front-line, interfacing with our customers on a daily basis, keeping their systems up and running, ensuring optimal system performance, and improving patient safety, which in turn allows doctors and nurses to focus on critical patient care in hospitals across North America.Field Service Engineers perform all Customer Support duties and responsibilities relating to Swisslog products (AMTS and ADMS), including preventive maintenance, corrective maintenance, warranty service, emergency service, on-call service, start-up of current systems, operator maintenance and user training, and promotion of company products and services as required.YOUR TASKSPerform all Customer Support Duties and Responsibilities relating to Swisslog Material Handling Systems including:Provide scheduled preventive maintenance services to contract customers in assigned areaProvide on-demand corrective, 24/7 emergency, and paid services to customers in assigned area as requiredProvide start-up services on Translogic Systems as assignedAssist with start-up services on new Swisslog products as required, working closely with the assigned Installation SpecialistsReport product quality issues to assigned Senior Field Service Engineer and/or Customer Care Manager and file quality reports as directed/requiredTrain Swisslog customers on system and light maintenance operationsPromote parts orders, provide recommended parts lists to clients and recommend inventory stocking levels to customers as requiredConduct periodic customer care visits to monitor product performance and customer satisfaction;Maintain accountability/inventory of assigned spare parts (crash kit) and customers’ consignment inventories when inventories are contractually maintained by SwisslogAssist all customers within assigned area with parts orders, consumables, repair and return of defective parts, and requests for information pertaining to their systemsAdvise Customer Care Manager of any problems or opportunities that arise within their area of responsibilityEnsure that required administrative paperwork, Service Work Orders, Expense Reports and Downtime Reports, and start-up logs are properly filled out and processed in a timely mannerCommunicate and share information with sales personnel and support personnel as it relates to their assigned customer baseExercise proper care and accountability of all assigned company property, be mindful in spending company’s money and resources responsibly, and exercise proper care and responsibility when working with customers’ property and/or facilitiesMaintain a clean and professional appearance at all times when working with customersAdhere to and strictly enforce all company safety policies and proceduresAttend required training programs to keep current on system updatesPosition may require some travel as well as holiday and weekend workYOUR PROFILEVocational school, related military experience, or job experience equivalent1-3 years field service experience with electro-mechanical productsSuccessful candidates will have an effective communication style that builds customer's trust and satisfactionAbility to read blue prints, schematics and wiring diagrams to extract necessary technical informationExceptional interpersonal skills (customer service skills) and communication skillsPC Computer software and hardware literate/Windows Application experienceBasic computer networking skillsMust be a self-starter, well organized, and be able to work independently without supervisionDesirable but not Essential:Experience working in a mission-critical, on-call environment is desirableAssociate's Degree from a Technical or Vocational School preferredEligibility Requirements:Ability and willingness to travel 30 to 70% of the time for technical support and training purposes.Ability and willingness to work on-call hours including weekend, night, and/or holiday workAbility and willingness to lift, lower and carry objects up to 50 lbs., work from heights, climb ladders, and work in confined spacesMust have a valid driver’s license and excellent driving recordEQUAL OPPORTUNITY EMPLOYERSwisslog is an EEO Employer, Females/Minority/Veterans/Disabled/Sexual Orientation/Gender IdentitySwisslog’s FMLA policy can be found at:http://www.dol.gov/whd/regs/compliance/posters/fmlaen.pdfFederal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. If you require reasonable accommodation to complete the application or to perform your job, please contact Human Resources at jobs.healthcare.us@swisslog.com.Swisslog is an EEO Employer, Females/Minority/Veterans/Disabled/Sexual Orientation/Gender IdentitySwisslog’s FMLA policy can be found at:http://www.dol.gov/whd/regs/compliance/posters/fmlaen.pdfFederal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. If you require reasonable accommodation to complete the application or to perform your job, please contact Human Resources at jobs.healthcare.us@swisslog.com.ContactAndy LevineTalent Acquisition Manager",bos,de
7,Liberty Mutual Insurance,Insurance,3.7,Principal Data Engineer,"Boston, MA",$91K - $158K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_20e07741&cb=1618792657209&jobListingId=4061043613,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Liberty Mutual Global Cybersecurity (GCS) is actively hiring Data Engineers. This role is an important element of our modern Identity and Access Management Data Strategy that drives the best use of IAM data assets and visualizations to support operational and overall IAM health. You would be a member of a dynamic agile team that is focused on analysis, testing, documenting and implementing IAM Data Solutions.At Liberty Mutual Insurance, we believe progress happens when people feel secure.About the job:Our Cybersecurity Organization is a diverse team of security professionals who are collectively responsible for improving the overall security posture of the organization. Cybersecurity team members must continually adapt to stay ahead of a dynamic threat landscape. We are expected to continually learn and grow. This is not a passive career opportunity, but rather one that requires a passion for data, security and rigor to protect our business.In this role you will:Work with our data owners to enhance GCS IAM’s best use of our data assets.Build and design complex data models and data architecture that improve accessibility, efficiency, governance and quality of data.Make recommendations for how to improve data and drive those recommendations forward.Build in-depth knowledge of technology enablers.Consults on designing and developing of complex solutions and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science.Support can include but is not limited to identifying issues/defects, transition planning, and knowledge sharing efforts.This role might be for you if you have:A senior technical professional background with knowledge of Agile development methodologies, IAM, and data engineering.Generally 8+ years related experience with an understanding of Identity and Access Management.In-depth knowledge of data analytics, processing and BI tools.Highly developed negotiation, facilitation and consensus building skills.Highly developed oral and written communication skills; strong presentation skills.Able to make difficult and quick decisions daily with limited supervision and often with competing priorities and varying degrees of urgency.Able to influence a diverse group of stakeholders at various levels in the organization.Preferred Qualifications:8+ years of data analytic or engineering experienceUnderstanding of data analytics, processing and BI tools .An ability to code in multiple languages, including an object-oriented language.A thorough grasp of technology concepts, business operations, design and development tools, system architecture and technical standardsProficient in new and emerging technologiesExcellent trouble-shooting skillsSelf-motivated/self-starterBachelors or Master's degree in technical or business discipline or equivalent experience17",bos,de
8,Athenahealth,Information Technology,4.1,Senior Workday Engineer,"Watertown, MA",$84K - $89K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_2c454b08&cb=1618792657209&jobListingId=4062370204,"Join us as we work to create a thriving ecosystem that delivers accessible, high-quality, and sustainable healthcare for all.athenaIT is seeking an experienced Senior Workday Engineer candidate to join our Workforce Technology Team, working closely with our business stakeholders to drive our business forward. The Workday Engineer is responsible for delivering and supporting Workforce Technology initiatives by partnering with athenahealth business process owners, athenaIT (aIT) Business Systems Analysts, Project Management, and Development team members. As part of the aIT Workforce Technology team, this role will focus primarily on Workday. She/he will actively participate in the support and expansion of Workday and supporting HR platforms at athenahealth.The successful candidate will be an experienced, high-energy, detail-oriented and highly analytical with experience in the HR functions of a high-tech software company. She or he will have demonstrated the ability to transform business requirements into system enhancements that ultimately advance Workforce Tech initiatives and serve value to all employees of athenahealth. Attributes of a successful candidate are described here:Job Responsibilities:Explore Workday technical roadmaps and vision, as well as other pertinent resources to stay ahead of the technology curve with innovations in the marketplaceDrive tenant wide standardization, governance and best practicesPartner with internal organizations (Compensation, Recruiting, HR Business Partners) to support athenahealth’s ability to drive business decisions with accurate and timely dataCross functional support across Workday functional areasDefine and implement system enhancements that advance the goals of the business, advising on best practices, and recommending process improvements to ensure scalability and efficiencyGather, analyze and document functional and technical requirements for new projects, enhancements to existing solutions, and production issues reported by end usersPerform application configuration activities primarily in Workday, and occasionally other supporting Workforce applicationsPartner with HR, finance, and data stakeholders to analyze, understand and improve employee productivity and end-user effectivenessManage stakeholder relationships and prioritize aIT configuration/development activities that best support business objectives.Typical Qualifications:4-6 years work experience in a system administration and reporting roleHands-on experience with Workday functional components such as Core HCM, Recruiting, Benefits, CompensationWorkday advance reporting and security experienceExperience configuring cloud applicationsExperience creating and executing unit, integration and user acceptance test plans is preferredAutomated testing experience is a plusStrong and effective written, verbal and presentation skills with the ability to collaborate with team members and business stakeholders at all levels of the organizationAbout athenahealthOur Vision: To create a thriving ecosystem that delivers accessible, high-quality, and sustainable healthcare for allOur Location: This role is ideally located in our Watertown, MA (Boston) corporate office.Our Culture: At athenahealth, our employees (or “athenistas”) are committed to making healthcare smarter. Our success is dependent on the diversity, collective spirit, and contributions of our people, clients and partners. We value teamwork and believe that the strength of our team comes from supporting each other and leveraging our specialized skills. If you are looking for company that will enable you to work outside of your comfort zone to transform the healthcare ecosystem, athenahealth is the place for you.Our Perks: Along with health & financial benefits, our athenistas are offered a variety of perks that promote employee wellbeing such as commuter support (We were named one of the 2018 Best Workplaces for Commuters!), tuition reimbursement, collaborative workspaces and dog-friendly offices - just to name a few.athenahealth is committed to a policy of equal employment opportunity—that’s why we recruit and hire applicants without regard to race, color, religion, sex (including pregnancy), national origin, disability, age, sexual orientation, veteran status, genetic information, gender identity, gender expression, or any other factor prohibited by law. We’re happy to provide a reasonable accommodation, for those with a disability, to complete any part of the application process. If you are unable to access or use this online application process and need an alternative method for applying, please contact us attaoperations@athenahealth.com for assistance.https://www.athenahealth.com/careers/equal-opportunity",bos,de
9,Liberty Mutual Insurance,Insurance,3.7,Senior Archer GRC Software Engineer,"Boston, MA",$107K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_e179a29a&cb=1618792657210&jobListingId=4062689472,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Senior GRC Software EngineerWe deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.We are looking for a Software Engineer with RSA Archer experience to build and configure high-performing, scalable, enterprise-grade applications in a highly collaborative Agile environment. Your contribution to driving the RSA Archer platform forward will enable Liberty Mutual to continuously improve the execution of complex governance, risk management, and compliance workflows. You will also be part of a talented software team that works on mission-critical solutions for our Global Cyber Security organization.In this role, you would:Build, deploy, and maintain RSA Archer core and on-demand applications (ODA) to meet customer needsPerform peer review and testing of RSA Archer applications and ensure issues are documented and resolvedDeliver management reporting using RSA Archer, including dashboards and business intelligence integrationsPerform RSA Archer access control model reviewsLeverage continuous integration/continuous delivery methodologies to build and maintain the platformPerform software upgrades and perform server maintenance for RSA Archer using the Azure cloud platformTechnical Skills:Ability to translate business requirements into RSA Archer layouts, DDEs, and advanced workflowsFamiliarity with RSA Archer Control Panel, Archer’s installation process, and Windows servicesIntegration of RSA Archer with customer toolsets (e.g. databases, vulnerability/compliance scanning tools, CMDB platforms) with custom data feed solutions (ODBC, XML, etc.)Configuration of data feeds and data imports into RSA Archer applicationsFamiliarity with deploying, configuring, and managing Windows-based solutions (on-prem and Azure)Experience with development using scripting languages and SQL queriesMicrosoft Azure / Cloud deployment experienceWorking knowledge of design and development toolsStrong analytical, problem solving, and communication skillsNegotiation, facilitation, and consensus building skillsWorking knowledge of IT concepts, strategies, and methodologiesWorking knowledge of a business function(s) and of business operationOpenness and flexibility to learn from, adapt to, and provide feedbackQualifications:Bachelor's Degree in technical discipline (preferably computer science, information systems, or software development)3+ years of direct system administration experience with the RSA Archer platform5+ years of professional development experienceExperience working in or knowledge of Scrum/Agile Development Methodologies16",bos,de
10,Evelo Biosciences,N/A,2.3,Fermentation Process Development Engineer,"Cambridge, MA",$42K - $77K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_43921fab&cb=1618792657210&jobListingId=4058955189,"Evelo Biosciences is seeking an experienced Fermentation Process Development Engineer to join our dynamic and growing organization.Evelo Biosciences, Inc. (Nasdaq: EVLO) (“Evelo”), a clinical stage biotechnology company developing a new modality of orally delivered medicines, is seeking a Fermentation Process Development Engineer to join our Fermentation team.Evelo's vision is to improve the lives of patients with serious diseases through the development of a broadly applicable new modality of medicines. Humans have evolved over millennia with the microbes in and on our bodies. These microbes play a vital role in developing and directing immune and biological responses. Evelo is harnessing the therapeutic potential of specific strains of naturally occurring microbes and developing them as a new class of medicines, monoclonal microbials. We have validated that orally delivered monoclonal microbials modulate immunological and biological effects throughout the body after initial interactions with human cells in the gut. Evelo is pioneering the development of this new class of medicine for the treatment of autoimmune, immunoinflammatory, metabolic, neurological, neuroinflammatory diseases and cancer.This is an outstanding opportunity to join a well-funded, fast-paced company in a new exciting field of medicine. As a member of the Evelo team, you will be a vital part of helping to shape Evelo’s vision: in transforming therapies through a new modality of medicines.We are seeking a dedicated Fermentation Process Development Engineer who is interested in joining a highly dynamic and intellectually challenging team. This position will offer a tremendous opportunity to gain experience in design and scale-up of novel fermentation processes, cell physiology interrelated to process phenomena, integration of fermentation with high throughput systems, etc. In addition, this role will engage in critical collaborations with our manufacturing, microbiology, immunology, and bioinformatics teams. The successful candidate will be innovative, thrive in an intense and dynamic environment, and use his/her creative and imaginative problem solving skills to help bring new products to patients.Primary Responsibilities:Designing, performing, and analyzing fermentation experimentsEvaluating, monitoring, and reporting fermentation dataLeading a team for persistently improving and maintaining fermentation processes, laboratory, and equipmentDesired Skills & Qualifications:Demonstrated ability to work in a team environment as well as independently on projects.Strong interpersonal and communication skills and a passion for working in a fast-paced and evolving organization.Ability to self -motivate and self-direct.Persistence in pursuing objectives to completion with a focus on quality and meeting deadlines.Excellent attention to detail and careful record keeping skills.Continual focus on making enhancements and improvements to lab operations and efficiency.Education & Experience:The successful candidate will have a PhD in biochemical engineering, life sciences, microbiology, or related field or MS with 3+ years experience in fermentation engineering.Proven technical expertise with bioreactor fermentation at laboratory scale is a must.Proven technical expertise with downstream processes including lyophilization is a plus.Experience developing or operating GMP bioprocesses is a plus.About Evelo BiosciencesEvelo Biosciences is a clinical stage biotechnology company developing oral biologics that act on SINTAX™, the small intestinal axis, with systemic therapeutic effects. SINTAX plays a central role in governing the immune, metabolic and neurological systems. The company’s first product candidates are pharmaceutical preparations of single strains of microbes selected for defined pharmacological properties. Evelo’s therapies have the potential to be effective, safe, and affordable medicines to improve the lives of people with inflammatory diseases and cancer.Evelo currently has four product candidates in development: EDP1815, EDP1867 and EDP2939 for the treatment of inflammatory diseases including psoriasis, atopic dermatitis, and COVID-19, and EDP1503 for the treatment of cancer. Evelo is advancing additional product candidates in other disease areas.For more information, please visit www.evelobio.com and engage with Evelo on LinkedIn.",bos,de
11,Athenahealth,Information Technology,4.1,Senior Software Engineer – Integration Platform Team,"Watertown, MA",$70K - $142K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_6f9ed031&cb=1618792657211&jobListingId=4062370004,"Join us as we work to create a thriving ecosystem that delivers accessible, high-quality, and sustainable healthcare for all.We are looking for a Senior Software Engineer to join our Integration Platform team, within our Platform Services Engineering organization. In Integration Platform, we enable providers to deliver safe care to patients when transitioning between health systems. But enough about us; let’s talk about you.You are a developer with experience building full stack web applications, preferably in public and private cloud environments. You are an excellent communicator that is capable of quickly picking up the complicated healthcare space.As an engineer on Integration Platform team, you will have the opportunity to work on product components and workflows that enable the business processes, technical processes, and user workflows required to enable seamless access to patient data at critical moments in the client life cycle.You are a tenacious, but nimble learner, who demonstrates design & engineering excellence.The Team: This team enables the safe, correct bulk movement of millions of patients’ health data. You will build enterprise quality web applications, with a focus on stability at scale.Job Responsibilities Deliver customer value in the form of high-quality software components and services in adherence with policies on Security, performance, longevity and Integration testing Write, debug, and deploy code to production; deliver timely fixesProduce accurate, unambiguous technical design specifications to the low-level details. Contribute to agile ceremonies; scrum meetings i.e. daily stand-up, sprint planning, readouts and retrospectives. Also participate in improving team performance Perform peer code reviews to ensure quality standards. Understand and follow coding conventions, architectures, and best practices. Assist more junior developers.Typical Qualifications4-6 years of full stack software engineering experience Bachelor’s Degree in Computer Science or equivalentProficient in at least one modern programming language (Java, C++, Perl, Python, etc.) Solid relational databases, RDBMSs like Oracle, experience with SQLFamiliarity with Unix/Linux, exposure to object-oriented OOD OOA We work in Agile environment, so any Agile experience or CI/CD concepts is helpful Prior experience designing Platform Tools, and/or developing system level software a plusAbout athenahealthOur Vision: To create a thriving ecosystem that delivers accessible, high-quality, and sustainable healthcare for all.Our Location: This role is based in Watertown, MA, just a few miles outside of Boston. Watertown is our Global Headquarters and our campus, the Arsenal on the Charles, is home to a number of restaurants, a local gym and large outdoor space. This office also has a cafeteria, coffee café and food trucks that rotate every day.Our Culture: At athenahealth, our employees (or “athenistas”) are committed to making healthcare smarter. Our success is dependent on the diversity, collective spirit, and contributions of our people, clients and partners. We value teamwork and believe that the strength of our team comes from supporting each other and leveraging our specialized skills. If you are looking for company that will enable you to work outside of your comfort zone to transform the healthcare ecosystem, athenahealth is the place for you.Our Perks: Along with health & financial benefits, our athenistas are offered a variety of perks that promote employee wellbeing such as commuter support, collaborative workspaces and dog-friendly offices - just to name a few.athenahealth is committed to a policy of equal employment opportunity—that’s why we recruit and hire applicants without regard to race, color, religion, sex (including pregnancy), national origin, disability, age, sexual orientation, veteran status, genetic information, gender identity, gender expression, or any other factor prohibited by law. We’re happy to provide a reasonable accommodation, for those with a disability, to complete any part of the application process. If you are unable to access or use this online application process and need an alternative method for applying, please contact us attaoperations@athenahealth.com for assistance.https://www.athenahealth.com/careers/equal-opportunity",bos,de
12,Massachusetts General Hospital(MGH),Health Care,4.1,Data Engineer,"Boston, MA",$77K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=25073&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_daef21e3&cb=1618792657212&jobListingId=4063891863,"DATA ENGINEER, CENTER FOR PRECISION PSYCHIATRY

PROGRAM SUMMARY:

The Center for Precision Psychiatry is a new and dynamic interdisciplinary center that integrates research, clinical implementation, education and training to advance the emerging field of precision psychiatry. Precision psychiatry aims to identify and leverage individual differences in biology, lifestyle, environment, and the social determinants of health to improve the prevention, diagnosis and treatment of mental health conditions.

POSITION SUMMARY:

The successful candidate will have demonstrable professional experience in the design, implementation, integration, testing and deployment of backend software and systems, including software development in both team-based and independent projects.

PRINCIPAL RESPONSIBILITIES:

Develop, validate, test, document, deploy, and maintain clinical and research applications for precision psychiatry pathology. Applications may include but are not limited to data management systems analytics pipelines, and clinical reporting tools. Support data engineering efforts, including database and API design, data extraction/transformation/load, and data aggregation/integration.Support data science efforts, including computational statistics, machine learning, deep learning, interactive web-based visualizationSupport high performance computing efforts, including on-premise cluster computing, cloud computing, and Linux container orchestrationSupport data management, including big data storage on premises and in the cloud, life cycle management, archiving, security, and access controlMaintenance of local data/GPU workstations and server software environmentsManagement of user-account/data-privacy/security for the workstations and serversAssist group on medical data science projectsData preprocessing Software development with readable, testable code and good documentationTroubleshoot, debug and upgrade existing systemsEnsure software is updated with latest features

Qualifications

SKILLS REQUIRED:

Proven work experience as a Data Engineer or DeveloperProficiency in SQL Proficiency in setting up and maintaining GPU-capable workstations running on windows/mac/linux operating systems, and GPU-capable linux servers with K8S or SlurmKnowledgeable in statistics/machine learning theories and capability to implement in R and PythonKnowledgeable in common data science packages, such as R: tidyverse and Python: PANDAS, NumPy, Scikit-learnKnowledgeable in deep learning frameworks (preferably PyTorch) with capability to build, train and validate models end-to-endExpertise in computer programming and proficiency in at least one general-purpose programming language (Python, Java, Scala, C/C++, Go or equivalent, experience in Python strongly preferred)Knowledge of Unix/Linux-based operating systems and experience in shell scripting requiredExperience in designing RESTful APIs, architecting robust and scalable systems, and deploying and maintaining web services, including web server configuration (e.g., Apache, NGINX), message queues (e.g., RabbitMQ, Apache Kafka), microservice architectures, proxy servers, sidecar patternsExperience working in a software development team, including agile methodology, unit testing, continuous testing and integration, refactoring, code reviews, version control, release management, packaging, and distributionProven track record of delivering high-quality, production-grade softwareExperience with user interface and web development (e.g., JavaScript, React, HTML, CSS) a plusExperience with SQL as well as NoSQL databases and database management (e.g., PostgreSQL, MongoDB, Apache CouchDB, Apache Cassandra) a plusExperience with Linux containers and container orchestration systems (e.g., Docker, Kubernetes) a plusExperience with cloud computing a plusExcellent oral and written communication skills.Excellent interdisciplinary communication skillsEnthusiasm in healthcare related projects

QUALIFICATIONS AND EXPERIENCE:

BS/MS degree in Computer Science, Mathematics, Physical Sciences, Engineering, or related field

EEO Statement

Massachusetts General Hospital is an Equal Opportunity Employer. By embracing diverse skills, perspectives and ideas, we choose to lead. Applications from protected veterans and individuals with disabilities are strongly encouraged. Partner's Healthcare is acting as an Employment Agency in relation to this vacancy.",bos,de
13,DataDog,Information Technology,4.1,Data Engineer,"Boston, MA",$103K - $183K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_62e95b1f&cb=1618792657212&jobListingId=3665752634,"About Datadog:We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale—trillions of data points per day—providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies. Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way.You will:Build distributed, high-volume data pipelines that power the core Datadog productDo it with Spark, Luigi, Kafka and other open-source technologiesWork all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and moreJoin a tightly knit team solving hard problems the right wayOwn meaningful parts of our service, have an impact, grow with the companyRequirements:You have a BS/MS/PhD in a scientific field or equivalent experienceYou have built and operated data pipelines for real customers in production systemsYou are fluent in several programming languages (JVM & otherwise)You enjoy wrangling huge amounts of data and exploring new data setsYou value code simplicity and performanceYou want to work in a fast, high growth startup environment that respects its engineers and customersBonus points:You are deeply familiar with Spark and/or HadoopIn addition to data pipelines, you’re also quite good with Kubernetes and cloud technologyYou’ve built applications that run on AWSYou’ve built your own data pipelines from scratch, know what goes wrong, and have ideas for how to fix itIs this you? Send your resume and link to your GitHub if available.Equal Opportunity at Datadog:Datadog is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.Your Privacy:For more information on how we maintain the privacy of the information you submit as part of your application, please refer to our Applicant and Candidate Privacy Notice.",bos,de
14,IBM,Information Technology,3.9,Data Engineer,"Boston, MA",$70K - $92K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136006&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_e830cf79&cb=1618792657212&jobListingId=4058946013,"IntroductionHave you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.Your Role and ResponsibilitiesKey Responsibilities:Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical requirements and support their data infrastructure needs.Provide the ability to work within agile development methodology and collaborate effectively with multi-disciplinary teamsBuild modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements.Understand data architecture, build large-scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow.Have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Have expertise in data persistence solutions, experience with the latest (NoSQL) database technologies, and experience with building complex SQL queries using various (NoSQL or RDBMS) databases such as MongoDB or DB2Experience in software engineering with object-oriented design, coding and testing patterns on large-scale data infrastructuresUse DevOps best practices such as continuous integration, continuous delivery in the production implementation.GarageIBMReferred_NorthAmericaRequired Technical and Professional ExpertiseDevelop code using Python, Scala, R languagesExperience with relational SQL and NoSQL databases, including Postgres and Cassandra3+ years design & implementation experience with distributed applications3+ years of working experience in database architectures and data pipeline developmentDemonstrated knowledge of software development tools and methodologiesComputer Science with software engineering and Math background desiredPreferred Technical and Professional ExpertiseExperience with big data tools: Hadoop, Spark, Kafka, etc.Familiar with big data solutions with experience on Hadoop based technologies such as MapReduce, Hive MongoDB or Cassandra.Experience with stream-processing systems: Storm, Spark-Streaming, etc.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.Knowledge of cloud technologies such as Kubernetes, Cloud Foundry, PaaS, and IaaS (SoftLayer)NONEAbout Business UnitIBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.Impact. Inclusion. Infinite Experiences. Do your best work ever.About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.Location StatementIBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to:12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.Well-being programs to support mental and physical health.Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).Select educational reimbursement opportunities.Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.Giving and volunteer programs to benefit charitable organizations and local communities.Discounts on retail products, services, and experiences.This position is eligible for participation in an IBM sales incentive plan. Actual incentive opportunity will be based on performance and the eligible Target Incentive, as addressed in the applicable plan, all of which is subject to change.We consider qualified applicants with criminal histories, consistent with applicable law.IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",bos,de
15,Vertex Pharmaceuticals Inc (US),Biotech & Pharmaceuticals,3.7,Principal Genomic Solutions Engineer,"Boston, MA",$108K - $201K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_2486c3db&cb=1618792657212&jobListingId=3802958445,"Principal Genomic Solutions EngineerVertex currently operates at the forefront of rare disease scientific innovation and has successfully developed and commercialized multiple breakthrough medicines. Cell and genetic therapies (CGT) represent two rapidly emerging therapeutic modalities with the potential to treat — and even cure —several of the diseases Vertex is focused on, including Transfusion Dependent beta-Thalassemia (TDT), Sickle Cell Disease (SCD), Duchenne Muscular Dystrophy (DMD) and Type 1 Diabetes to list a few. At Vertex Cell and Genetic Therapies (VCGT) our research teams are bringing cutting-edge transformative therapies to patients as quickly as possible.The global Scientific Computing team at Vertex are seeking a highly motivated computational scientist to lead delivery of software and data solutions supporting these rapidly expanding cell and genetic therapy efforts. The remit includes end-to-end responsibility for software and data platforms for the new Vertex Cell and Genetic Therapies research site. This includes everything from engaging with scientists and Scientific leaders to define requirements, coordinating across user groups through to leading delivery of software.The Principal Genomic Solutions Engineer will have extensive experience building and delivering exploratory and production software in a scientific or research environment. The successful candidate will be highly communicative, thrives in a collaborative environment, and is eager to identify bold and innovative ways of helping scientists and scientific partners solve key data challenges.Key responsibilities:Build strong relationships with key stakeholders, including scientific leadership and lab scientists, across the new Cell and Genetic Therapies research site, and ensure tight alignment of solutions with business strategyDevelop in-depth understanding of strategic and operational requirements driven by research objectivesDefine a comprehensive computing strategy for the new site, in partnership with colleagues in Scientific Computing, Engineering and ResearchCollaborate with Research leadership to develop short and long-term technology roadmap for genetic and cell therapiesPartner with software and data engineering teams to define and build the data and analytics platform supporting Research activities for the siteWork collaboratively to ensure solutions are interoperable with related tools and systems used by Vertex’s computational groups, such as Computational Genomics and Computational ChemistryBasic Qualifications:Fluency in multiple modern programming languages (Python, Javascript, etc) with the ability to write clear, maintainable, and well-tested code8+ years of Software Development/architecture experience or equivalent12+ years of combined/related experienceExperience in development, testing, and delivery of production-quality software#LIExpertise in Linux/Unix environmentsExperience designing, building and delivering data processing and analysis workflows with large-scale data in a scientific environment (academic or industry)B.S., M.S., or Ph.D. in computer science, computational biology, bioinformatics, or a related fieldPreferred qualificationsStrong communication skills (both written and verbal)Experience leading/managing technical teamsExperience developing software for the cloud (AWS) and fluency with cloud servicesFamiliarity with statistical modelling of scientific data and related software (e.g., R)Experience in developing analysis pipelines for Genomic and related scientific data.",bos,de
16,Putnam Investments,Finance,3.9,"Sr Engineer, Identity & Access Management","Boston, MA",$47K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_14b15c96&cb=1618792657212&jobListingId=4063680953,"We are seeking a Sr. Engineer, Identity and Access Management, to become a key member of the Application Security team. This job requires the ability to work as part of a Digital Technology organization to deliver integrated solutions with the consensus from other subject matter experts and stake-holders across both IT and the Business.The main responsibility is to design, document, and deliver reference security architectures and standards for identity and access management systems across the firm while also working within ongoing projects to improve and enhance security.Responsibilities include:Provide operational support for all aspects related to Putnam’s Identity and Access Management Infrastructure, include Directory ServicesDevelop and maintain code that extends the functionality of commercial off the shelf (COTS) products.Develop and maintain code that facilitates integration between Putnam developed applications and our security stack. Work with application teams to ensure success.Plan, execute and roll-out routine patches, and major product upgrades and migrations for our security products.Participate and facilitate in product evaluations and proofs of concept (POCs). Perform POCs for new products, integrate these with Putnam’s existing security products. Work with vendors and Putnam’s Digital Technology staff to define requirements and lead POC projects.Identity opportunities for greater levels of automation around Identity and Access Management, and better utilizing the feature set of COTS products.Define, design and implement strategies for limiting access to data/systems where appropriate.Identity opportunities that would help improve the resiliency and 24x7 availability of our security stack. Implement any such infrastructure changes.Collaborate with peers in the Security Architecture and Engineering team to ensure that a consistent and holistic approach to security is being followed.Work with vendors towards issue resolution, enhancements, etc.Skills Required:The Sr. Engineer must have a pre-requisite knowledge of a broad range of technologies and standards including but not limited to:Identity and Access Management SystemsAWS IAMIdentity FederationOAuth / OpenID ConnectSAMLHR System IntegrationsCloud and Hosted IntegrationsMobile IntegrationsAutomated Account and Role Provisioning/De-provisioning for systems such asMessagingActive DirectoryDatabaseWebCloudWeb Architectures, Java, and Software Development PlatformsEncryptionThe ideal candidate must be self-motivated and a creative problem solver.They must have excellent verbal and communication skills.They must be capable of understanding complex technical issues and new technologies in a fast pace work environment.Bachelors’ Degree required. Master’s in Information Security (or related field) is a plusSkills desirable:Familiarity with ITIL and various Software Development Methodologies.The following certifications would be a plus:FINRA Series 6, 7, or 99SANS GIACCISSPCISMThis position has the flexibility to work in either our Andover or Boston, MA office.At Putnam, we are committed to a diverse workforce and take positive steps to ensure equal opportunity in our recruitment process. We ensure that individuals with different abilities are provided reasonable accommodation to participate in the job applicant process. We strive to hire, develop and retain the most hardworking individuals by valuing the multifaceted skills that they bring!",bos,de
17,"Healthcare Financial, Inc.",Health Care,4.2,Data Engineer,"Quincy, MA",$55K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136006&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2d02c426&cb=1618792657212&jobListingId=3803685195,"JOB SUMMARYLocal candidates only, or willing to relocate at own expense.The Data Engineer is responsible for processing structured and unstructured data, validating data quality, developing and supporting data products. The Data Analytics Engineer also plays a role in the expansion and maintenance of HFI’s data analytics solutions, gathering requirements and translating those requirements into technical specifications and design documents. Responsibilities include but not limited to:is to be responsible for supporting the expansion and maintenance of an HFI data analytics solution. You will also assist in gathering requirements and will be expected to translate those requirements into technical specifications and design documents.ESSENTIAL FUNCTIONS & RESPONSIBILITIESCreate and maintain optimal data pipeline architecture.Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, AWS ‘big data’, Google Cloud, Big Query technologies.Build analytics tools that utilize the data pipeline to provide actionable insights to clients, operational efficiency and other key business performance metrics by working closely with software developers and analytics experts.Work with stakeholders including the Managers, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.Work with data and analytics experts to strive for greater functionality in our data systems.Support and develop web applications alongside software developers and other data science team members to build scalable analytics reporting systems and portals.Support other data engineers, data analysts to develop machine learning pipelines for the data scientists to develop complex machine learning systems and models.Adapt and migrate to new technologies as needed for various projects to maintain and help HFI remain in an industry leader position.Work with DevOps to roll production grade systems and deploy highly scalable applications that are client facing ensuring industry level security protocols in place.Build dynamic analytics dashboards and reports using Tableau, SQL, Python and other analytic tools or build web application to consume such reports for the operations, finance and other teams including the executives.Ensures that all deliverables are thoroughly documented.Others duties may be assigned.MINIMUM requirementsMaster's Degree in Computer Science, Statistics, Applied Math or an equivalent combination of education and experience, Master’s, preferred.Local candidates only, or willing to relocate at own expense.2+ years of experience in a Data Engineer role.In-depth knowledge of Tableau reporting tool, required.Experience developing scalable analytics reports and dashboards and building custom reporting systems using web technologies, required.Experience with relational and non-relational databases (like MySQL, Postgres, MongoDB and Cassandra), required.Experience building and optimizing ‘big data’ pipelines, architectures and data sets and software applications (like Hive, MapReduce, Spark, etc.)Experience with data pipeline and workflow management tools (like Airflow, Azkaban, Luigi, etc.)Experience with AWS cloud services like EC2, EMR, RDS, Redshift, Lambda etc. and Google cloud services like GCP, Big Query, Firestore etc.Experience with stream-processing systems (like Storm, Spark-Streaming, etc.)Experience with object-oriented/object function scripting languages (like Python, Java, C++, Scala, Shell scripting etc.)Experience with big data tools (like Hadoop, Spark, Kafka, etc.)Experience with statistical and machine learning libraries (like Numpy, Pandas, Scikit-learn, Spark, Keras, etc.).Experience with developing automations tools (like Python, Shell scripting, Cron jobs, PHP, etc.)Experience with version control and code management tools (like Git, Github, Gitlab, JIRA, Bitbucket, etc.)Experience with software and system deployment (like PEN testing, unit testing, CD/CI, SDLC, etc.)Understanding of development and software applications using Django, Flask, API’s, JavaScript (React.js, express.js, node.js etc.), jQuery, AJAX, HTML5, CSS, Bootstrap and related web technologies is a plus.A successful history of manipulating, processing and extracting value from large disconnected datasets and developing scalable systems to serve such data.Strong analytic skills related to working with structures and unstructured datasets.Strong project management and organizational skills.Excellent written, communication and presentations skills.WORKING CONDITIONS / WORK ENVIRONMENTModerate noise level associated with open office work environment.Physical demands:While performing the duties of this job, the employee is regularly required to talk or hear; stand, walk, sit, use hands to finger, handle or feel objects, and reach with hands and arms. The employee occasionally will lift and/or move up to 25 pounds.",bos,de
18,North Easton Savings Bank,Finance,3.1,Network Security Engineer,"Easton, MA",$84K - $96K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1044077&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_65c21c7c&cb=1618792657212&jobListingId=4034355684,"North Easton Savings Bank is a mutual bank with 18 locations throughout southeastern Massachusetts. Founded in 1864, the Bank has a proven track record of growing the community through fair banking practices, financial advising, and local philanthropy. Our team maintains an engaged, rewarding, and enjoyable work atmosphere that allows each member to achieve their highest potential and personal fulfillment.Position Summary With the direction of the IT Manager, the IT Network Security Engineer is charged with supporting the Information Technology Department infrastructure, technology implementations, technical escalations and other technology initiatives as assigned by IT Management.Essential Job Functions/ResponsibilitiesThe essential functions include, but are not limited to the following: Responsible for network technology planning, design, implementation, troubleshooting, and operational support for (20+) sites and remote employees.Engineering and administration of core foundational infrastructure: LAN/WAN/WLAN, Internet, routing, switching, security (firewalls), SDWAN.Management and support of Network Security Services including SIEM, network monitoring, investigations of security alerts, and incident response procedures.Implement and support technology systems in both the on-premises data center, as well as cloud-based platforms including Azure and AWS.Life cycle planning for future technology initiatives for the bank.Work closely with the IT Manager, IT resources, internal business users and external vendors, working in a collaborative manner to ensure that end user escalations are fully addressed.Minimum Qualifications (Education/Knowledge, Skills, and Abilities)To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required to fulfill this position.Incumbent/candidate must have excellent verbal and written communication skills and be able to work with individuals at all levels within and outside of the organization.A minimum of 8 years of Information Technology experience, and 4 years in a lead role or engineering consulting role.Must possess solid, working understanding of network design concepts, including implementation/migration of routing protocols, layer 2/3 fault tolerance design, as well as secure networking technologies and concepts.Experience with network engineering, including design, implementation, security, optimization, monitoring and troubleshooting of LAN, WAN, WLAN, and SDWAN networks.Demonstrated knowledge of security technologies and procedures including firewalls, IDS/IPS, DLP, vulnerability scanning and management, malware/virus prevention, SIEM / logging, security groups and network segmentation, system hardening, and incident response.Proficient with server and desktop virtualization technologies including vSphere ESXI.Strong understanding of Azure AD and Office 365.Analytical and problem-solving skills.Ability to create high level technical documentation.Strong attention to detail and methodical approach to trouble shooting technical issues.EDUCATION and/or EXPERIENCEBachelor's degree (B. A.) from an accredited college or university in Management Information Systems, Computer Science, Information Technology, and/or equivalent work experience.Physical DemandsThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.While performing the duties of this job, the employee is regularly required to sit; use hands to finger, handle, or feel objects, tools, or controls; and talk or hear. The employee frequently is required to walk. The employee is occasionally required to reach with hands and arms and stoop, kneel, crouch, or crawl. The employee must occasionally lift and/or move up to 50 pounds. Specific vision abilities required by this job include close vision, distance vision, color vision, and the ability to adjust focus.Work EnvironmentWhile performing the duties of this job, the employee occasionally works near moving mechanical parts and is occasionally exposed to risk of electrical shock and vibration. The noise level in the work environment is usually moderate. Travel to local branches is required.NoteThe above is a description of the ordinary duties of the position. It should be expected that from time-to-time other duties (both related and unrelated to the above) may be assigned and are therefore required.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.North Easton Savings Bank is dedicated to being an equal opportunity workplace. To reach and maintain this goal, the Bank strictly prohibits harassment and discrimination based on gender, sex, race, ethnic background, age, physical disability, mental disability, and anything else protected by law. North Easton Savings Bank welcomes diversity and we believe that diversity is the root of successful teams and an overall successful workplace.Job Type: Full-timeBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programHealth insuranceHealth savings accountLife insurancePaid time offRetirement planTuition reimbursementVision insuranceSchedule:Monday to FridayAbility to Commute/Relocate:Easton, MA (Required)Application Question(s):Please list your salary requirements.Education:Bachelor's (Preferred)Experience:Information Technology: 8 years (Required)Work Location:One locationCompany's website:www.northeastonsavingsbank.comWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",bos,de
19,GNS Healthcare,Biotech & Pharmaceuticals,3,Data Engineer,"Somerville, MA",$68K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=4341&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_e4aa26d4&cb=1618792657212&jobListingId=4007400732,"Company Overview

Imagine if we could better match patients with the treatments that prove the most effective for them . . .

GNS Healthcare applies a powerful form of AI called causal machine learning to predict which treatments will work for which patients, accelerating the clinical development of new drugs, and improving individual patient outcomes while reducing the total cost of care.

Headquartered in the biotechnology center of Somerville, Massachusetts, our patented REFS technology is based on recent breakthroughs in causal machine learning and AI that transforms massive quantities of patient data into in silico patients that simulate clinical trials. These computer models are simulated to discover new drugs for serious diseases, and power up solutions that, biopharmaceutical companies utilize to slow disease progression and improve therapeutic effectiveness. Our platforms and solutions have been validated across oncology, immunology, cardiovascular, metabolic disease, and neurology, etc. and have appeared in over 50 peer-reviewed publications.

Responsibilities

Assists team members with the design and development of RWD analyses and predictive models. Designs and builds consistent, reproducible, and testable ETL pipelines to ingest, normalize, and store data from large healthcare datasets, from clinical trials, to claims, and EHRs.Supports projects including specific epidemiology, health outcomes and other observational studies to better understand disease natural history, prevalence, comorbidities, treatment patterns, and health and safety outcomes in real world patient populations. Functions as a healthcare data subject matter expert to support the design, development, testing, implementation, and support of clinical information and intelligence solutions. Provides complete documentation and communication of all processes, methods, and results. Supports production solutions, the ongoing updates, and maintenance of our reference data sources.

Qualifications

3-5 years of data engineering experience with a thorough understanding of data lake architectures.An expert in cloud data warehousing tools (e.g. Snowflake, Amazon RedShift, BigQuery, Microsoft SQL Server, Oracle, PostgreSQL, or equivalent) and ELT tools (e.g. Stitch, Fivetran, DBT, Glue). You thrive on building modern, cloud-native data pipelines and operations.Fluent in SQL scripting Experience working in healthcare, life sciences, and/or with diverse healthcare data sets (e.g. medical, pharmacy claims, and lab results) Experience with industry standard measures and code sets (e.g. ICD-10 codes, ICD-9 codes, HCPCS codes, CPT codes, HEDIS metrics, ETGs, HCCs, DRGs, etc.) and publicly available sources (e.g. HCUP) You thrive on mapping and designing ingestion and transformation of data from multiple sources, creating a cohesive data asset and Common Data Model (CDM)Experience using a scripting language (Python, R, Java, Scala, C++, C# and Bash/PowerShell) to automate processes and support proprietary software. Machine learning, R, and python skills highly preferred. Experience using Git/Bitbucket and working on shared code repositoriesExperience using Tableau or other in-app data visualization platforms

Nice to Have Skills

Background in statistics, biostatistics, public health, research design, health economics, or other related quantitative healthcare field. Experience with backend web (API) development, Kubernetes, Docker, and Tableau Experience developing data framesExperience with data processing frameworks such as Apache Spark, Beam, Dataflow, Crunch, Scalding, Storm, Hive and BigQuery Experience extracting data from REST APIs and parallel processing large datasets

Company Culture

Our philosophy at GNS is simple: we cannot transform biomedicine with anything less than an all-star team. We are seeking smart, driven people who are experts in their field, have a track record of success and a passion for creating change. We believe that strong teams supercharge the performance of individuals, create a fun and dynamic workplace and great results for our clients and the people they serve.

We are passionate about our work and believe in the ability of our technology to change the world. Our core values of integrity, collaboration, value, diversity, and game-changing guide our behaviors with each other and our clients.

GNS offers competitive salaries, stock options, unlimited vacation, health, dental and vision insurance, life insurance, long-term disability, 401(k), generous parental leave, tuition reimbursement, professional development, volunteering opportunities, virtual social gatherings, and more.

Equal Employment Opportunity

GNS Healthcare provides equal employment opportunities to all employees and applicants for employment without regard to race, color, national origin, religion, sexual orientation, gender, gender identity or expression, age, veteran status, disability, pregnancy or conditions related to pregnancy, or genetics. In addition to federal law requirements, GNS Healthcare complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.

Powered by JazzHR",bos,de
20,MassMutual,Insurance,3.9,Data Engineer,"Boston, MA",$85K - $93K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=374003&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_1f66f436&cb=1618792657213&jobListingId=4063177171,"What great looks like for this role:Our ideal Advanced Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data management systems. You’re also committed to data integrity, are highly analytical, and can work on multiple projects at once. You’ll use your skills to develop, monitor, and manage data systems across our platform. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by MassMutual are core reasons people enjoy working on the Data Engineering team at MassMutual.Objectives of this role:Design, construct, install, test and maintain highly scalable data management systems.Ensure systems meet business requirements and industry practices.Design, build, and maintain a high-performance streaming and messaging platforms to support the enterprise.Daily and Monthly Responsibilities:Design, build, and maintain a high-performance streaming and messaging platforms to support the enterprise.Create messaging standards for our messaging platforms.Develop tools and processes to support the platform.Create custom software components and analytics applications.Work across departments and business units to define patterns and data needs.Translate high-level business requirements into technical specs.Basic Qualifications:Bachelor’s degree in computer science or engineering.5+ years of experience with designing and building data platforms.5+ years of experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, etc)5+ years of experience creating producer and consumer applications with Kafka5+ years of coding and scripting (Python, Java, Scala) and design experience.Expertise in tuning and troubleshooting streaming/messaging platforms.Experience with ELT methodologies and tools.Strong data integrity, analytical and multitasking skills.Excellent communication, problem solving, organizational and analytical skills.Able to work independently.Preferred Qualifications:3+ years of experience creating producer and consumer applications with KafkaExperience with KStreams and KSQLExperience with designing an automating deployment process (CI/CD)Basic knowledge of database technologies (Vertica, Redshift, etc)MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status.",bos,de
21,OM1,Health Care,4.8,Data Engineer,"Boston, MA",$92K - $102K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_6d8e07f7&cb=1618792657213&jobListingId=3665202990,"OM1 is on a mission to improve health outcomes by unlocking the power of data. We are a healthcare data and technology company focused on improving real world clinical data and outcomes, accelerating medical research and personalizing healthcare. Our interdisciplinary team uses expertise in medicine, software, Big Data, machine learning, public health and mathematics to transform records from a diverse set of sources into enriched, research grade data. This data allows us to generate unique insights in a variety of disease areas.As a Data Engineer, you’ll build out and enhance big-data pipelines, code data-oriented product features, and analyze our complex data assets. The ideal candidate is a smart, creative, and curious analytical thinker who demonstrates strong software engineering skills and an excellent aptitude for data analysis. This is a key role within our Engineering team with responsibility for driving our high standards!RESPONSIBILITIESBuild, automate, and improve big-data pipelinesCode, test and deliver data-oriented product featuresIntegrate new data sources into our data assetModel, enhance and enrich database schemas and underlying dataCraft scalable backend software and tools using modern software engineering practicesAnalyze and interpret data flows, attributes, and qualityRequirementsStrong programming skills, preferably Python, Scala, Java, or similarExcellent SQL skillsSolid understanding of software engineering principlesComfort working in an Agile/Scrum environment with continuous deliveryA strong desire to advance healthcare and improve patient outcomesExcellent attention to detailNICE TO HAVEFamiliarity with cloud-based platforms such as AWS, Databricks, and/or Snowflake DBData processing experience with Python, Scala, Spark, and/or AirflowAutomated unit and integration testing experienceExperience with CI/CD tools such as JenkinsBackground in medical records and health insurance claimsExperience working on systems with strong security and privacy requirementsOM1 is an equal employment opportunity employer and considers qualified applicants without regard to gender, sexual orientation, gender identity, religion, race, veteran or disability status. At OM1 ensuring that people feel respected, valued, and included is essential to our success. We are committed to working together to provide a work environment that embraces the principles of diversity, equity, and inclusion.Direct applicants only - No agencies",bos,de
22,Capital One,Finance,4.1,Master Data Engineer,"Newton Center, MA",$95K - $162K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_83dddd5f&cb=1618792657213&jobListingId=4064288278,"314 Main Street (21020), United States of America, Cambridge, MassachusettsMaster Data EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 5 years of experience in application developmentAt least 3 years of experience in software development in at least one of the following: Scala or PythonAt least 3 years of experience in SparkAt least 2 years of experience in big data technologies (Cassandra, Accumulo, HBase, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree7+ years of experience in application development3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)2+ years of experience with Ansible / Terraform3+ years of experience with Agile engineering practices3+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)3+ years of experience with NoSQL implementation (Mongo, Cassandra)3+ years of experience developing Java based software solutions4+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)4+ years of experience developing software solutions to solve complex business problems3+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",bos,de
23,Panalgo,Information Technology,4.8,Data Engineer,"Boston, MA",$77K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=4341&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c65da47a&cb=1618792657213&jobListingId=4061523070,"Panalgo is one of most significant voices in healthcare analytics. With over two decades of experience, Panalgo provides novel solutions to allow the worlds largest life science companies, health plans and provider groups to better understand the clinical outcomes and value of various patient care strategies. Panalgos market-leading Instant Health Data (IHD) platform transforms the way analysts from diverse disciplines answer complex and critical questions and make insightful predictions.

We are seeking an exceptional Data Engineer to assist with the mapping of new healthcare data sources into our state-of-the-art analytics platform. In undertaking this challenge, you will be at the working with the latest distributed computing technologies to process, transform, and configure large healthcare data sources to be used by our SaaS clients. We're looking for candidates with a background in data analysis, and a strong desire to continue learning and improving their abilities in object-oriented programming concepts and big data processing.

RESPONSIBILITIES:

Provide custom coding and data manipulation for Data Integration teamIntegrate new healthcare data sources into our state-of-the-art applicationBuild and optimizing pipelines for ETL processesBuild new features/tools to improve our big data and distributed computing infrastructureBecome a subject matter expert in the structure and contents of various healthcare databasesRun ETL scripts and perform quality control tasksMaintain and ensure databases are delivered on-time to our customersConfigure our software platform to use data sets and ensure ETL instructions and documentation are up-to-date

SKILLS & REQUIREMENTS:

Bachelors degree in Mathematics, Statistics, Computer Science, or other technical/quantitative degree1-3 years of related work experienceProficient in object oriented and functional programming skills such as Java, C++, Ruby or PythonSkilled at analyzing data (SQL, Python, R) Experience working in a Linux command line environment and scriptingEager to learn new systems and technologiesExceptional attention to detail and critical-thinking skills

PREFERRED QUALIFICATIONS:

Experience working with NoSQL databases (MongoDB. Cassandra, etc.)Familiarity with distributed file systemsApache Spark experience

WHY BE A PART OF PANALGO?

Leading healthcare data analytics/big data companyWork on a team of talented and pragmatic engineers/researchersGreat mentorship and growth opportunities

Panalgo provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Powered by JazzHR",bos,de
24,DraftKings,Information Technology,4.5,Data Engineer,"Boston, MA",$102K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=348370&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_b9d37492&cb=1618792657213&jobListingId=4062512850,"We are DraftKings. We’re inspired by our shared passion for developing creative solutions to complex challenges and empowering the people around us to do their best work. We are industry leaders in the digital entertainment and technology space propelled by constant curiosity and diverse perspectives.Our teams are fueled by innovation. We are looking ahead, building what’s next, and continuously reinventing the industry. We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston, with teams around the world and an expanding global presence. Love data? We do too.We’re growing quickly and are searching for a Data Engineer to act as a creative contributor, leader, and mentor to our data analysis and scalability processes. You will use your experience and expertise to provide key insights that help us make data-driven decisions. Analytical thinking drives our business and when you join our team, you’ll not only solve new problems every day, you’ll see your data solutions immediately improve our users’ experience.What you’ll do as a Data Engineer at DraftKings:Design processes that support data transformation and structures, metadata, dependency and workload managementWork with product owners and tech leads to implement high quality, production-grade data pipelines and ETL processesPartner with our Marketing Analytics and Data Science team to help build tools to provide actionable insights into key business metricsLeverage your strong communication skills and experience working with global teams to be an evangelist for data engineering across the organizationBe flexible and able to rapidly adapt. We roll out products very quickly and priority management is keyBe key to driving a focus on performance analysis, optimization, and tuningWhat skills you’ll use:1+ years of hands-on experience in aspects of business intelligence and data engineering, including data warehousing, delivery, and operationsThe ability to test, build and optimize data pipelines, transformations, architectures, and data sets leveraging new technologiesStrong knowledge in at least one data engine (for example, SQL Server, MySQL, PostgreSQL, Amazon Aurora, Redshift) is required. Snowflake experience is a big plusA solid understanding of dimensional modeling is requiredExcellent communications skills (verbal and written) and interpersonal skills to effectively communicate with both business and technical teamsExperience with data reporting tools (e.g., Tableau), data cataloging tools (e.g., Alation) and data logging/monitoring tools (e.g., Datadog) is preferredExperience working in AWS, Terraform, Python, and with database replication tools/services (e.g., DMS, Attunity) is preferredExperience in the Regulatory, Financial or i-Gaming industry is desirableJoin Us!We strive to create a place where all feel safe, empowered, engaged, championed, and inspired. DraftKings is proud to be an equal opportunity employer. This means we do not tolerate discrimination of any kind and are committed to providing equal employment opportunities regardless of your gender identity, race, nationality, religion, sexual orientation, status as a protected veteran, or status as an individual with a disability. Ready to build what’s next? Apply now.As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment.",bos,de
25,Dun & Bradstreet,Information Technology,3.4,Data Engineer,"Waltham, MA",$84K - $92K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_7be24497&cb=1618792657213&jobListingId=3753099342,"Why We Work at Dun & BradstreetWe are at a transformational moment in our company journey - and we’re so excited about it. Each day, we are finding new ways to strengthen our award-winning culture, and to accelerate creativity, innovation and growth. Our purpose is to help customers improve business performance with Dun & Bradstreet’s Data Cloud and Live Business Identity, and we’re wildly passionate and committed to this purpose. So, if you’re looking to make an immediate impact at a company that welcomes bold and diverse thinking, come join us!Brief Description:The Data Engineer role involves developing applications designed to accumulate, derive meaning from, and apply stewardship to, large datasets.The Data Engineer will have to both be able to work with the Global People Data team’s internal datasets and tools, as well as be able to coordinate with outside groups to continuously meet their needs.The Data Engineer is expected to be a key developer of Global People Data tools and products , both in maintaining and upgrading existing tools and in developing new products using state of the art techniques and programming concepts.RequirementsBachelor’s degree (preferable in computer science or a related fieldExperience with Machine Learning and/or Artificial Intelligence Technologies2 - 5 yrs. experience with SQL for data analysis2 - 5 yrs. experience with Python for data analysis1 - 3 yrs. experience with ETL pipeline developmentAbility to work closely with others and problem solve complex situationsExperience with hosted environments (AWS, and Azure recommended)Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.We are committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with Dun & Bradstreet and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to TalentAcquisitionTeam@dnb.com. Determination on requests for reasonable accommodation are made on a case-by-case basis.Please note that all Dun & Bradstreet job postings can be found at https://dnb.wd1.myworkdayjobs.com/Careers and all communication from Dun & Bradstreet will come from an email address ending in @dnb.com.",bos,de
26,Serco North America,Business Services,3.4,Mechanical Engineer (Mid-level),"Boston, MA",$50K - $69K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1044074&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_006e2aac&cb=1618792657214&jobListingId=4062690029,"Position Description:If you love important, meaningful, and challenging projects and supporting the US Navy –Serco has a great opportunity for you!Serco supports the Navy as prime for their Amphibious Warfare program. The Boston Planning Yard team supports the Landing Craft Division in the maintenance of the Landing Craft Air Cushion (LCAC), the configuration and engineering management of the new Landing Craft Utility (LCU) 1700, and the planning of maintenance of the new Ship to Shore Connector (SSC). In this role, you will support the Mechanical Engineering team in the drafting, editing, and verification of technical manuals craft design plans.You will be part of a 12-person Engineering team consisting of mechanical, electrical, and architectural engineers that works closely with the customer in delivering quality products and services to the fleet.In this role you will:Serve as the Mechanical and Corrosion engineer in the Planning Yard for the Landing Craft, Air Cushion (LCAC) and the Ship to Shore Connector (SSC) programs.Develop and revise installation and alteration drawings for the LCAC Service Life Extension Program (SLEP) and other ongoing availabilities, Craft Change Documents (CCDs), and Liaison Action Requests (LARs).Edit new and revised technical manuals.Create, revise, and review Technical Manual Deficiency/Evaluation Reports (TMDERs).Perform on-site craft inspections to verify craft configuration and currency with documentation.Assist the customer with coordinating meetings, discussions, and action items for the Corrosion Inspection Working Group (CIWG).Maintain a 3-D CAD model database for LCAC-100 (SSC).Maintain workload and respond to tasking within the schedule and technical requirements identified in the Integrated Data Environment (IDE).Perform additional duties and responsibilities as assigned.Qualifications:To be successful in this role you will have:Bachelor’s degree plus 2 to 4 years of relevant work experience. Degree must be in Engineering. (In some cases, educational requirements may be adjusted or waived for more than 6 years of relevant military experience.)You must be able to obtain and maintain an active DoD clearance upon employment.Proficiency in AutoCAD is required.Knowledgeable in SolidWorks or ShipConstructor 3D modeling program is highly desired.Knowledge of engineering principles, methods, and techniques within a specific area of expertise.Effective organization level communication, presentation, and interpersonal skills.Knowledge of Microsoft Office suite programs, MS Word, Excel and PowerPoint.Prior experience working in engineering in the Navy or Marine Industry, while not required is desired, as it will shorten your learning curve.Company Overview: Serco Inc. (Serco) is the Americas division of Serco Group, plc. Serco serves every branch of the U.S. military, numerous U.S. Federal civilian agencies, the Intelligence Community, the Canadian government, state and local governments, and commercial clients. We help our clients deliver vital services more efficiently while increasing the satisfaction of their end customers. Headquartered in Herndon, Virginia, Serco Americas has approximately 8,000 employees and is part of a $4 billion global business that helps transform government and public services around the world. At Serco, our employees are our most valuable asset - we listen, respect and support them throughout their career at Serco. We invite you to become part of our dynamic team. Serco is an equal opportunity employer committed to diversifying our workforce (Race/ Color/ Sex/ Sexual Orientation/ Gender Identity/ Religion/ National Origin/ Disability/ Vets).",bos,de
27,Dyno Therapeutics,N/A,-1,Data Engineer,"Cambridge, MA",$90K - $126K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=8095&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_e3543dc4&cb=1618792657214&jobListingId=4062228049,"The Company

Dyno Therapeutics is reshaping the gene therapy landscape through AI-powered vectors. Through the application of our transformative technologies and strategic partnerships with leaders in gene therapy, we believe a future with life changing gene therapies for millions of people is within reach.

Our team includes world-class molecular and synthetic biologists, protein engineers and gene therapy scientists working alongside software engineers, data scientists, and machine learning experts. Dyno was named Xconomy's 2020 start up of the year!

The Role

Data Engineer. The software engineering team is at the heart of Dyno's platform, and your work as a part of this team can have a major impact on the future of gene therapy. Our team's responsibilities include automating computational and machine learning workflows, scaling databases and data processing algorithms, and controlling laboratory equipment and scientific processes. Our team is looking for candidates with a diverse set of skills and experience, and a passion for working autonomously and learning things on the fly.

How You Will Contribute

As a Data Engineer, you will take a leading role in architecting and developing the core data infrastructure that allows Dyno to reshape the gene therapy landscape. You will collaborate closely with data scientists, computational biologists, and experimental scientists to streamline the process of running complex scientific workflows and the process of capturing information from them. You will bring a thorough perspective to the complex challenges of connecting the information flowing between numerous teams with diverse functions.

Responsibilities:


Contribute to our tech stack direction for large, data driven workflows
Engineer creative solutions to track critical information lifecycles
Optimize tracking, storage and serving of biological data
Model and maintain information ontologies
Develop and maintain software best practices, including continuous integration, agile and test driven design
Architect and deploy LIMS and ELN systems in alignment with Dyno's vision
Interface with biologists and data scientists to understand opportunities to empower them with software

Who you are

Trusted partner
Team oriented
Thoughtful & detail oriented
Work with a sense of urgency
Appreciate the opportunities at the intersections of data science and biology

Basic qualifications

BS, MS, or Ph.D. in Computer Science or equivalent experience
2+ years of data engineering experience in industry
Expertise in Python and SQL
Experience using technologies to track samples through laboratory workflows
Experience deploying and maintaining production software systems

Preferred qualifications

Fluency with software life-cycle best practices and devops.
3+ years of industry experience in software development, including database design, distributed computing and data pipelines.
Experience with Lab ELNs and LIMS.
Experience with workflow orchestration systems such as Apache Airflow or Argo.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Job Type: Full-time",bos,de
28,Whoop,Information Technology,4.5,Data Engineer II,"Boston, MA",$100K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=148364&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_447ed800&cb=1618792657214&jobListingId=4033316549,"At WHOOP, we're on a mission to unlock human performance. WHOOP empowers its members to perform at a higher level through a deep understanding of their bodies and daily lives.WHOOP is seeking an experienced Data Engineer II to join the growing Data Science Infrastructure team, which is dedicated to providing the infrastructure and tooling to that enables our Data Scientists to build and train algorithms with leveraging our large and growing dataset.RESPONSIBILITIESBuild scalable infrastructure that will enable our data scientists to derive insights and build models faster and more efficiently than they can todayWork across teams to inform data model design and storage strategiesAdvocate for new technological adoptions and or third party software solutionReports to the Data Science Infrastructure technical leadQUALIFICATIONS3+ years relevant experienceExperience with Python and JavaFamiliarity with a data science platform technology such as Spark, AWS Sagemaker or other similar technologiesExperience in storing and querying large volumes in data lakes for analysis, including third-party datasetsExperience or interest in contributing to full-stack developmentStrong verbal and written communication skillsEnjoy working in a high-growth start up environment Willingness to be both a team player and an ownerThis role is based in the WHOOP office located in Boston, MA. The successful candidate must be prepared to relocate if necessary to work out of the Boston, MA office.WHOOP is an Equal Opportunity Employer and participates in E-verify to determine employment eligibility",bos,de
29,MassMutual,Insurance,3.9,Advanced Data Engineer,"Boston, MA",$82K - $96K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=374003&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_434cd473&cb=1618792657214&jobListingId=4063177052,"Since 1851, MassMutual’s commitment has always been to help people protect their families, support their communities, and help one another. This is why we want to inspire people to Live Mutual. We are people helping people.A career with us means you will work alongside exceptional people and be empowered to reach your professional and personal goals. Our employees are the foundation of what makes MassMutual a strong, stable and ethical business. We seek and value unique and varied perspectives and experiences because we believe we are stronger when all voices are heard. We invite you to bring your bright, innovative ideas to MassMutual as we continue to help millions of Americans rely on each other.Together, we are strongerWhat great looks like in this roleOur ideal Advanced Data Engineer is a collaborative leader skilled in data analytics, data modeling, and database design. You’re also committed to data integrity, are highly analytical, and can work on multiple projects at once. You’ll use your skills to develop, monitor, and manage data systems across our platform. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by MassMutual are core reasons people enjoy working on the Data Analytics team at MassMutual.Objectives of the roleDesign, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.Working on a range of projects including batch pipelines, data modeling, and data mart solutions you’ll be part of collaborative project teams working to implement robust data collection and processing pipelines to meet specific business need.Daily and Monthly ResponsibilitiesDesign, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.Executes and provides feedback for data modeling policies, procedure, processes, and standards.Assists with capturing and documenting system flow and other pertinent technical information about data, database design, and systems.Develop data quality standards and tools for ensuring accuracy.Work across departments to understand new data patterns.Translate high-level business requirements into technical specs.Basic QualificationsBachelor’s degree in computer science or engineering.5+ years of experience with data analytics, data modeling, and database design.3+ years of coding and scripting (Python, Java, Scala) and design experience.3+ years of experience with Spark framework.Experience with ELT methodologies and tools.Expertise in tuning and troubleshooting SQL.Strong data integrity, analytical and multitasking skills.Excellent communication, problem solving, organizational and analytical skills.Able to work independently.Preferred QualificationsMaster’s degree in computer science or engineering.Familiar with agile project delivery process.Knowledge of SQL and use in data access and analysis.Ability to manage diverse projects impacting multiple roles and processes.Able to troubleshoot problem areas and identify data gaps and issues.Ability to adapt to fast changing environment.Experience with Python.Basic knowledge of database technologies (Vertica, Redshift, etc.).Experience designing and implementing automated ETL processes.MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status.",bos,de
30,Velir,Business Services,3.3,Data Engineer,"Somerville, MA",$81K - $83K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1020558&s=58&guid=00000178e78faef69df6e58d24155af5&src=GD_JOB_AD&t=SR&vt=w&cs=1_a73a9454&cb=1618792657214&jobListingId=4063664840,"As a Data Engineer at Velir, you’ll help our clients store, access, process, and analyze their user data so that they can improve decision making as well as their customer experiences. Our ideal candidate has a desire to apply modern data engineering & data analysis practices towards enterprise-scale production environments for a wide range of clients and industries. Velir’s Data Integration & Activation team is small but growing, and this individual will have the opportunity to make an outsized impact in a team that’s supported by a larger company.Build new, maintainable data pipelines, automation routines, and data schemas. Common data sources include web analytics, CRM systems, email service providers, e-commerce platforms, customer data platforms, ad platforms, and social media listening tools among others.Integrate data generating systems with databases & data warehouses.Support existing data pipelines by evaluating issues as they arise, triaging, and deploying fixes in Python and/or SQL.Review requirements and specifications produced by a Data Architect and provide feedback regarding feasibility and effort. Execute work while providing timely feedback on timeline, risks, and blockers.Build reporting tables and dashboards.Complete ad hoc data analysis to support internal teams and clients.Stay on top of trends in the industry. Prototype and apply new methods and technologies as they become available.Maintain knowledge & documentation for how data solutions workAddress non-functional requirements in your work such as performance constraints and security policies.Create and monitor tests that provide quality controls over code and data.Work within and configure CDP platforms (such as Segment), cloud ETL platforms (such as Fivetran), and data orchestration tools (such as Apache Airflow) to meet data pipeline/processing requirements.Stand-up cloud data infrastructure such as data warehouses, messaging busses, serverless functions, and object storage. Handling cloud database administration tasks such as granting credentials and updating schemas will be required. Low-level database management tasks such as optimizing indices or managing backups will not be required.Ability to communicate and work with a cross-functional teams and client stakeholders. Strong written and verbal communication skills are required as well as good interpersonal skills.• Ability to identify roadblocks, raise these risks, and provide leadership towards resolutionsMust have experience with the following:Intermedia to Advanced Python, including common data libraries such as Pandas and/or SQLAlchemyGit/GitHub, Docker/DockerHubAdvanced SQLWeb-native APIsAt least 1 major cloud provider’s data products (AWS, GCP, Azure) including at least 1 OLAP database product (Redshift, BigQuery, Synapse)At least 1 BI tool (Tableau, Power BI, Data Studio, Domo, Shiny, etc)At least 1 ETL provider (Fivetran, Stitcher, Boomi, Informatica)Experience with the following is preferred, but not required:R Programming, Jupyter Notebook, Data Build Tool (dbt)Data orchestration tools (ex: Apache Airflow)Machine Learning modeling and model deployment.Marketing technologies such as Customer Data Platforms (CDPs), Customer Relationship Management (CRM) software, and web analytics tools (Ex: Google Analytics)Experience and EducationBS in Software Engineering or other STEM field5+ years working with Python3+ years working primarily on data systemsPhysical RequirementsFrequent sitting at a desk performing work on a computerReasonable accommodations may be made to enable individuals with disabilities to perform the essential functionsCore Company Values Velir is an established mid-sized agency with a top-tier portfolio of clients, ranging from the world’s largest non-profits to Fortune 500 brands. We pride ourselves on our people-first culture and a low-ego workplace that embraces experimentation, collaboration and continuous improvement. We have a fun office environment located in Davis Square (Somerville, MA) and offer competitive pay and excellent benefits.Take the Long View - Ensure the company is built to lastBe Courageous - Make the right decisions even when they aren't the easiest decisionsBe Genuine - Bring honesty and authenticity to all that you doWork with Focus + Passion - Display purpose and pride in your work and never stop learningAt this time, Velir does not sponsor candidates and unfortunately cannot accept those on OPT or CPT.",bos,de
93,Decision Point Healthcare Solutins LLC,N/A,-1,Data Engineer,"East Boston, MA",$80K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_0c24b8e4&cb=1618792859369&jobListingId=1007001733305&cpc=42BEC95245890617&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-07eab25650b78bb7&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKb2wyUUxmOEswMDREV1NvWnBubW9vblo4MUFDaTgwQUQ4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX2RUYjl3eFpoRlhiVVdGSFBBN1U5SHdTaFJmd3NzdjZDMGwydkF1UEhCYmlVWEUyd1F1bGp6NzRiSGdkQVp5aUt4ODRvZENJWHA2OHpCU1I3U0hxNjlfcVFRQTZxWWZ3RUgxRnJWRkRXbWJLMjZfa1NQb3NUenVyelR1a0FITHlaNFJZQXA2eXlOS3dpZU1tSU44SjdvcEVMMnRFQ2RJX0M0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVmN2REJHVGpjTENnY2tuUFRmWW9GaVotekkxZTNZaTJlWC1QZjQwckFiODBEY0ttLU5Pdi1kaDB4elBlUzdIYXVqOU5MWUJ3ODBFQVpjWGNOQW1nR09jaVFmcGdSLUlmOW1pTF9oZHJCWmhCYk9idnl1UFNsYVNyUWhJdVlHeE5GTkJZTlJJQVBvUENUbW92ZWhNTVNaTWlZWkZzWHRQbk93a1g2d2RSMlM2Tm5CUlBuRnh6ZXpPSm0zeTRHSlRXNzFrWGF0MGxxWGlCYkFJVXRKUmZQcTRZbGgwb2NjTkllOGc4MlhMcTNReFppVXFDN1pPc2NndFh3bFhFZ3d6MHlodVFUYXAzM2FHbHFvNDBpVkpGYXRVYWVUNzZMWXpuck91dVA5eVh4eFpocEpIUm80bmhUYmMza0dKT0d2dFdISzhVV3NBVWZULXRTZnkxMW1pQ01HUQ,"We need your help! We’re looking for a self-motivated and detail-oriented data engineer to join our DataOps team. This opportunity will enable you contribute to the operation, support, and enhancement of our mission critical data operations platform and the development of data pipelines. Our data operations platform supports high volume, high velocity data ingestion and curation to support our existing, and rapidly expanding, health plan client base.What You’ll DoAs a data engineer, you will be responsible for the execution and management of inbound client and internal service-based data pipelines. This encompasses the development, operation, and management of our client data hubs, including data intake, data quality assessment/evaluation and data curation and enrichment/preparation processes. Our client data hubs consist of various health plan data sources to support Decision Point services including our AI/ML platform, analytics platform, and OPUS application. If this interests you, read on.The PositionDesign and develop scalable data integration (ETL/ELT) processes (including ingestion, cleansing, curation, unification, etc.)Automate the processing of inbound client data feedsDesign and develop tools to support data profiling and data quality methodologiesWork with our data science team to assist with data prep, enrichment and feature engineering for AI/MLEngage with our software engineering team to ensure precise data points per application specificationProvide periodic support to our customer success teamSkills & ExperienceBS / MS in Computer Science, Engineering or applicable experience3+ years of experience with ETL/ELT and data pipeline principles3+ years of experience with Python, JavaScript, and/or PowerShell3+ years of SQL experience; Microsoft SQL Server or PostgreSQL preferredKnowledge of data manipulation methodologiesExcellent verbal and written communicationStrong data profiling skills; Ability to discover and highlight unique patterns/trends within data to identify and solve complex problemsKeen understanding of EDW and other database design principlesComfortable working with very large data sets and VLDB environmentsExperience with CI/CD and version control tools: Git preferredUnderstanding of data science and machine learning concepts preferredExperience working within hybrid cloud environment; AWS experience is a plusFamiliarity with data visualization tools such as Tableau or QuickSight is a plusFamiliarity with healthcare data is a plusSome familiarity with statistical software tools and libraries such as R and scikit-learn is a plusJob Type: Full-timePay: From $80,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceHealth insuranceHealth savings accountLife insurancePaid time offParental leaveRetirement planSchedule:8 hour shiftMonday to FridayEducation:Bachelor's (Preferred)Experience:SQL: 2 years (Preferred)Data Warehouse: 2 years (Preferred)Work Location:One locationVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobCompany's website:https://decisionpointhealth.comBenefit Conditions:Only full-time employees eligibleWork Remotely:YesCOVID-19 Precaution(s):Remote interview process",bos,de
94,Liberty Mutual Insurance,Insurance,3.7,Principal Data Engineer,"East Boston, MA",$113K - $158K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_446a79fe&cb=1618792859368&jobListingId=1007001260148&cpc=444700D72F2ECBCE&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-fd9abd2a6665650d&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT05ajJEdzFTanhOTzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpJcC05U29kZzBPZ3FRLTFOcmdFR2dURWYxalBQaEY0R0g4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX0FnektCNm1WQndpMlF2S2FVZDVkcUpXVEFYUWx1U0JQTmJSQlRkRWpCTmNaM2Fnc3o3Q2NyTVo4bWljSXpDQWVOWXRqOUFhQ0lxNTNXRXhPOUg3c3EtZTRGV19FUHlWbFZ2V0xpYVZUcE1MSjZWNkxDYzhNN3F5MFdPMEdndE1TYkhZMEg0WE0xQU0xR2t5bGJybkgwSGw3T1RQN2toS2RlT09mUy1STWRtWkpnRVRLYUpFelh1dE1HR2hlb09RdXp1ZjFDMHJmWElxMm5ycnhTWExjc3dIMmFvSnRfemRncFY0VU9VZVFvYkozY0VLVkJVbjEtMHI3UmpsWUJfRUNrNTRBUm5BcktyTkZVdEkzai1Wc2M3anY4OG5qT1hJR2dHUEdmdUFiMTVmenFzaGczbW1aRzNpTWNNc3hWUlliQ2NsWWgxenBacENYRGFLdC1lVngwTllWQWo5SDJDUWZlRXBVSXlFZkU2eGdWVFZQSWZhWGN4dzhCRUp6dUd5RExRWXE2d21OamFIQmc5MXJRQTBvbjJaRUZ2MmZOZHZSS2wzUUpMTmlXZ3BjWHlCYU16Q0F2V2ZaVGZmOVA2TTVsRkJqUHZocWR6RHg2NjhHOWxWZk4wSHFTYURadldzcXBTaHh4d3FsN05CSm85NExjTDlPclFhSXZVMVY4aFYyZFRkVVNPSDBMR1llRW9PTE1qT3RtbkFDWF9KeWh4VEYyTkhQSXo2YU04WUxkVmpPUkVPdTBmTmdRdzNjdWNBVXcwRWtrQmJ0aWNHQU5nem8zelo3emFxT05JbFNSV3JWR25rLS1pMk01NjlBTkx4SFJYMGpRemVRWWs0YS0xWWNoQWhnZHZ2Y0ZYczBJbmJpQi1jMy1QMWJZYVdKdm9OSVNodlhmdDhwaFNlTjBNem9HbjB3U2lOdE1vX3U2V29N,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.
Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion
We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.
Liberty Mutual Global Cybersecurity (GCS) is actively hiring Data Engineers. This role is an important element of our modern Identity and Access Management Data Strategy that drives the best use of IAM data assets and visualizations to support operational and overall IAM health. You would be a member of a dynamic agile team that is focused on analysis, testing, documenting and implementing IAM Data Solutions.
At Liberty Mutual Insurance, we believe progress happens when people feel secure.
About the job:
Our Cybersecurity Organization is a diverse team of security professionals who are collectively responsible for improving the overall security posture of the organization. Cybersecurity team members must continually adapt to stay ahead of a dynamic threat landscape. We are expected to continually learn and grow. This is not a passive career opportunity, but rather one that requires a passion for data, security and rigor to protect our business.
In this role you will:
Work with our data owners to enhance GCS IAM’s best use of our data assets.
Build and design complex data models and data architecture that improve accessibility, efficiency, governance and quality of data.
Make recommendations for how to improve data and drive those recommendations forward.
Build in-depth knowledge of technology enablers.
Consults on designing and developing of complex solutions and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science.
Support can include but is not limited to identifying issues/defects, transition planning, and knowledge sharing efforts.
This role might be for you if you have:
A senior technical professional background with knowledge of Agile development methodologies, IAM, and data engineering.
Generally 8+ years related experience with an understanding of Identity and Access Management.
In-depth knowledge of data analytics, processing and BI tools.
Highly developed negotiation, facilitation and consensus building skills.
Highly developed oral and written communication skills; strong presentation skills.
Able to make difficult and quick decisions daily with limited supervision and often with competing priorities and varying degrees of urgency.
Able to influence a diverse group of stakeholders at various levels in the organization.
Preferred Qualifications:
8+ years of data analytic or engineering experience
Understanding of data analytics, processing and BI tools .
An ability to code in multiple languages, including an object-oriented language.
A thorough grasp of technology concepts, business operations, design and development tools, system architecture and technical standards
Proficient in new and emerging technologies
Excellent trouble-shooting skills
Self-motivated/self-starter
Bachelors or Master's degree in technical or business discipline or equivalent experience

17",bos,de
95,Frame AI,N/A,-1,Principal Data Engineer,"East Boston, MA",$150K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c1fa0784&cb=1618792859370&jobListingId=1007002171400&cpc=B076152010A3B66C&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-df05937c6724d416&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKVkhOVEpIQjQxZGhLaHVVb0ZoYkQ2RU9DMm1JYk8xSVQ4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlOOUxpTzNKeUJVUmFkX0wycjUwTW5ZSjRzTG9QOXpIaXNtempRUlYwTGZtd0hqT09QVDZ3dVo0Rzh4dFhLaVVjR2pMc2UwYlpKRGpNZjVQdC1mNWFoNVczN240UjlaanpxODJxSlMtY0tSRkR4XzY3c2ZtNFNqR3lBT2RRVk1vYTd6X3B0OU9BXzF1VWV5VjFlZm5seFBKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSRW1Bb0hCRkJiRHppZDl4RmdrLUc2YnFiQ2lyZG83Mk1DbXhGeWxIQnFaemRGWmVjMDQyZGR4MHh6UGVTN0hhdWo5TkxZQnc4MEVBWmNYY05BbWdHT2NpUWZwZ1ItSWY5bWlMX2hkckJaaEJiT2J2eXVQU2xhU3JRaEl1WUd4TkZOQllOUklBUG9QQ1Rtb3ZlaE1NU1pNaVlaRnNYdFBuT3drWDZ3ZFIyUzZObkJSUG5GeHplek9KbTN5NEdKVFc3MWtYYXQwbHFYaUJiQUlVdEpSZlBxNFlsaDBvY2NOSWU4ZzgyWExxM1F4WmlVcUM3Wk9zY2d0WHdsWEVnd3oweWh1UVRhcDMzYUdscW80MGlWSkZhdFVhZVQ3NkxZem5yZFNqa1VfcFJoMTVwSkhSbzRuaFRiYzNrR0pPR3Z0V0hLOFVXc0FVZlQtdFNmeTExbWlDTUdR,"About Frame AIFrame AI helps companies listen actively to their customers. Building a competitive customer experience means communicating with customers on many channels: marketing chat, support help desks, communities, surveys, social… When these are handled by different teams, the data and operations are often siloed, preventing companies from understanding and acting on signals that would be obvious to a single listener.By using Natural Language Understanding (NLU) to identify and organize unstructured customer feedback, Frame AI provides large service organizations an efficient way to act upon a unified view of feedback locked within thousands of conversations spread over different channels. Frame AI deploys an early warning system that delivers prioritized customers, themes, and process gaps needing attention directly to the staff whose actions increase the quality of the customer experience and prevent churn.This RoleThis role is for a data engineer who will maintain and extend the capabilities of an innovative data pipeline powering cutting-edge machine learning, alerting, and reporting capabilities. You will coordinate and synchronize the unification and enrichment of millions of conversations using distributed iterator patterns, database locks, and other reliable techniques.What You'll DoSolve complex PostgreSQL database challenges. You enjoy diving deeply into schema designs that meet critical business logic requirements for unifying data sources, planning and executing database migrations, and poring over query plans to achieve major performance improvements.Profile and optimize production deployments of state of the art NLU systems. You will collaborate with Frame AI’s data science staff using innovative shared code and test methods that enable continuous delivery of cutting edge research to stable, secure production environments.Write job control and monitoring logic for core services in Python. You will ensure that Frame AI never misses a message and that services are visible, reliable, and maintainable.Who We’re Looking ForAlert judge of technical risks. You recognize risks to critical data infrastructure and have experience protecting it from costly errors.A continuous improver. You resist impulsive technical choices and work effectively with other senior staff to manage and implement a backlog of high impact projects.Reader of manuals. You have demonstrated success learning unfamiliar technologies and you frequently consult documentation to get the most out of your systems.Seeks a startup environment. You appreciate having a high impact role and bringing exciting new technologies to market. You respond constructively to change and team up with others who rise to the challenge.At home in the cloud. You jump easily from your local command-line to SSH terminal sessions, and you are comfortable working with AWS.Willing contributor. You are ready to solve important problems as they arise, even when they lead you into other projects or dependencies. This curiosity and knowledge allows you to better understand systems in their totality.Inclusive collaborator. You view communication as one of your strongest skills.Working at Frame AIFrame AI is an environment where skilled engineers thrive. Our existing infrastructure works reliably so you can be productive on new objectives. We embrace development and testing practices that will let you leverage your skills, making far-reaching changes that you can deploy easily and repeatedly. Our team consists of senior staff who are supportive and skilled collaborators, and this role reports directly to one of the technical co-founders. Here, you can exercise and push the limits of your data engineering skills while working with a top-notch data team on challenging, relevant, and high-impact problems.Frame AI is a diverse team motivated by both individual and team success. We embrace empowering people with clear objectives and supportive resources so they can get their work done effectively and then do other things they care about during time off. We learn quickly from failures and celebrate successes. We offer competitive compensation and benefits.Requirements4+ years using PostgreSQL 9+ in a complex time series or data product setting3+ years using Python 3.6+ within a multi-service production systemOwner of significant pieces of data infrastructure for 2 or more years consecutivelyExperience using EXPLAIN output to diagnose complex issues related to indexing, statistics, and schema designExperience performing minimal downtime schema migrations on a live systemAdvanced knowledge of Python 3 syntax and semantics including effective use of context managers and type hintingFamiliarity with Python GIL and other key runtime features affecting data applicationsExperience using memory debuggers and profilers to optimize Python 3 applicationsStrong fundamental engineering skills including proper use of standard data structures and algorithms, reproducing issues and debugging programs, and awareness of systems concerns such as networking and process managementExcellent communicator across modes from technical designs, daily progress updates, code reviews, and responding to production incidentsAbility to be productive in a remote work settingExperience using Pandas, numpy, and other scientific Python libraries a plusExperience with *nix command-line core utilities a plusImportant NotesLocation: Frame AI is based in the NYC area, so america/new_york timezone is preferred but the role is open to remote applicants!Salary package is based on qualifications and location.This role is not eligible for immigration/visa sponsorship.Please apply here instead of submitting on Indeed:  https://bit.ly/32lBQq9Job Type: Full-timePay: From $150,000.00 per yearBenefits:Dental insuranceFlexible scheduleFlexible spending accountHealth insurancePaid time offParental leaveVision insuranceSchedule:Monday to FridayApplication Question(s):Have you read through the entire description carefully?Work Location:One locationThis Job Is Ideal for Someone Who Is:People-oriented -- enjoys interacting with people and working on group projectsAdaptable/flexible -- enjoys doing work that requires frequent shifts in directionAutonomous/Independent -- enjoys working with little directionCompany's website:https://frame.aiWork Remotely:YesCOVID-19 Precaution(s):Remote interview process",bos,de
96,Frame AI,N/A,-1,Senior Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_fd2f4da8&cb=1618792859371&jobListingId=1007002154997&cpc=0C139D4CAD5A6DB2&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-df11809f4f2a36d1&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMTGxfd3ljdVNSUVNiM2hSc09QSmdtMjVKYXdVR2NHWjc4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlNN3ROblNQZHFWOE5yNVFGOHZ5eTFFaUVjUUNNYWJfQ0YxN0VWaUw0bmtaTWc2SjItazh0Mlp4VjJkREZKYXl2QlNiRWdfUTFmNF9Gdzk0MldCdDk5bmJZb1EtUjR5d05GNFJZQXA2eXlOSzdnY3FobV9kZWtPcDdYelBlVEFNVks0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVkVjUklFUXNNOHlYdnNKN0M3ZnlidWJMUk1TWUR4NUwyNXpFNEROc3VaYkh5Q3Z4dk41T3BKVzA4MTlxdEVYbEJkQlRhcTBfT01TQjg4ZGJJYy1TRVQ4VzFCN09MVmZqdU9NM0x4RTJGY19iRzVJNEtEd2FJS0FaeWk0MDc2dzVaYll3N1pMQVloRk16N1djZjhGNWRyeTVWXzloTjAtSTRWQnRmMGgtWWEyd1k1NEpYWXl5eTYyeFhjcVhTeTRXblJuU2MzRWlmUFMyZS1vTF9wZHMtY1g4d3ZCTWZpZ3BRWlJRWXo3NGFuY3pqem9OQ0l4UGZxaEtHOWQtM3ltRkpkX0xXY2tkM2Y5SmlVcUM3Wk9zY2d0WHdsWEVnd3oweS1vcFU5SW4wRlMzaEhZa0J2ZndoazJxampTSlVrVnExUnA1UHZvdGpPZXNrT05OTk82TFlBd083d0VrTnZIX3E,"About Frame AIFrame AI helps companies listen actively to their customers. Building a competitive customer experience means communicating with customers on many channels: marketing chat, support help desks, communities, surveys, social… When these are handled by different teams, the data and operations are often siloed, preventing companies from understanding and acting on signals that would be obvious to a single listener.By using Natural Language Understanding (NLU) to identify and organize unstructured customer feedback, Frame AI provides large service organizations an efficient way to act upon a unified view of feedback locked within thousands of conversations spread over different channels. Frame AI deploys an early warning system that delivers prioritized customers, themes, and process gaps needing attention directly to the staff whose actions increase the quality of the customer experience and prevent churn.This RoleThis role is for a data engineer who will maintain and extend the capabilities of an innovative data pipeline powering cutting-edge machine learning, alerting, and reporting capabilities. You will coordinate and synchronize the unification and enrichment of millions of conversations using distributed iterator patterns, database locks, and other reliable techniques.What You'll DoSolve complex PostgreSQL database challenges. You enjoy diving deeply into schema designs that meet critical business logic requirements for unifying data sources, planning and executing database migrations, and poring over query plans to achieve major performance improvements.Profile and optimize production deployments of state of the art NLU systems. You will collaborate with Frame AI’s data science staff using innovative shared code and test methods that enable continuous delivery of cutting edge research to stable, secure production environments.Write job control and monitoring logic for core services in Python. You will ensure that Frame AI never misses a message and that services are visible, reliable, and maintainable.Who We’re Looking ForAlert judge of technical risks. You recognize risks to critical data infrastructure and have experience protecting it from costly errors.A continuous improver. You resist impulsive technical choices and work effectively with other senior staff to manage and implement a backlog of high impact projects.Reader of manuals. You have demonstrated success learning unfamiliar technologies and you frequently consult documentation to get the most out of your systems.Seeks a startup environment. You appreciate having a high impact role and bringing exciting new technologies to market. You respond constructively to change and team up with others who rise to the challenge.At home in the cloud. You jump easily from your local command-line to SSH terminal sessions, and you are comfortable working with AWS.Willing contributor. You are ready to solve important problems as they arise, even when they lead you into other projects or dependencies. This curiosity and knowledge allows you to better understand systems in their totality.Inclusive collaborator. You view communication as one of your strongest skills.Working at Frame AIFrame AI is an environment where skilled engineers thrive. Our existing infrastructure works reliably so you can be productive on new objectives. We embrace development and testing practices that will let you leverage your skills, making far-reaching changes that you can deploy easily and repeatedly. Our team consists of senior staff who are supportive and skilled collaborators, and this role reports directly to one of the technical co-founders. Here, you can exercise and push the limits of your data engineering skills while working with a top-notch data team on challenging, relevant, and high-impact problems.Frame AI is a diverse team motivated by both individual and team success. We embrace empowering people with clear objectives and supportive resources so they can get their work done effectively and then do other things they care about during time off. We learn quickly from failures and celebrate successes. We offer competitive compensation and benefits.Requirements2+ years using PostgreSQL 9+ in a complex time series or data product setting2+ years using Python 3.6+ within a multi-service production systemExperience as a project owner of a key production data infrastructure component for 1 year or more consecutivelyExperience using EXPLAIN output to optimize complex OLAP queriesAdvanced knowledge of Python 3 syntax and semantics including effective use of context managers and type hintingFamiliarity with Python GIL and other key runtime features affecting data applicationsExperience using memory debuggers and profilers to optimize Python 3 applicationsStrong fundamental engineering skills including proper use of standard data structures and algorithms, reproducing issues and debugging programs, and awareness of systems concerns such as networking and process managementExcellent communicator across modes from technical designs, daily progress updates, code reviews, and responding to production incidentsAbility to be productive in a remote work settingExperience using Pandas, numpy, and other scientific Python libraries a plusExperience with *nix command-line core utilities a plusImportant NotesLocation: Frame AI is based in the NYC area, so america/new_york timezone is preferred but the role is open to remote applicants!Salary package is based on qualifications and location.This role is not eligible for immigration/visa sponsorship.Please apply here instead of submitting on Indeed:  https://bit.ly/3g7rGSpJob Type: Full-timePay: From $130,000.00 per yearBenefits:Dental insuranceFlexible scheduleFlexible spending accountHealth insurancePaid time offParental leaveVision insuranceSchedule:Monday to FridayApplication Question(s):Have you read through the entire description carefully?Work Location:One locationThis Job Is Ideal for Someone Who Is:Dependable -- more reliable than spontaneousAdaptable/flexible -- enjoys doing work that requires frequent shifts in directionDetail-oriented -- would rather focus on the details of work than the bigger pictureCompany's website:https://frame.aiWork Remotely:YesCOVID-19 Precaution(s):Remote interview process",bos,de
97,Capital One,Finance,4.1,Master Data Engineer,"Cambridge, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_68227a51&cb=1618792859369&jobListingId=1007008989320&cpc=5EFBB0462F9C6B7A&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-9a30d10750b06a23&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1xV0xITW5uTFNMQ0VCZDE1eF9GQTZud0ZWRGFCclFpaXpXSDNlQUdWR01GeEJIaU5UcGpJZ1lyajhQQlV0V0J1S2IySUF4LVFGOFZObFd2S09qUUxxSGVOSkx6Ty1IS3hBUUhEZnhOQnRzUm85VmtmMWlBMnVTMmh6THk2NDUzam1ldFVScWNnVmpILTBJaXR1SUhLNUc3c1RaNUk4ekMzWEw0TkJzQ293NXFYUkhEZHBXQWVHSXBIZ0N4WUZrUmhrb1M3SFQ5UVJBWTE2T2lGQ3d1RC04ZmJpbnlMSmQxZG1UR19wUzNBV3RIS29nMzdjWjdaM3BaSXhFS1ZCZGpSVVdQaUdFbGZZZlRJOGZucTdLVVRWbWg3em1od2JzV1VnZEs4NnUtZnV6TnQwdklZLXQ0WTdCemZsTWpmSDFscHhScWF1RlN6OW1vWWFyektGWDJrb0Z2SmxOUkZ5M19fS3llWTR3X2g4enVPRDZyOFZQN0hNUWxFUkZWMnZ4bEhmMkExY3dQX0hvdjdabG5nMVNldzZQZzFxTkF0RFh1SXlRZUtwdXZsMjdnMDRLVFEzZTRQcmRjdUwwVkpPbzd3MHpRLWNGWFFzUU9DeGJiNmxsT1k1MlVVR00tLUdwM01JeWdlZF9WTkN2Ny1TZWlCQ05VU01rR2NBVkdqQU9kaUFRNmFmWWhNWGhja1JaR1U3MHJHRWtIYjFiRzEyclVhVFZsNnMxbU9HZEpiQUlVdEpSZlBxNFlsaDBvY2NOSWU4ZzgyWExxM1F4WmlVcUM3Wk9zY2d0WHdsWEVnd3oweWh1UVRhcDMzYUdscW80MGlWSkZhdFVhZVQ3NkxZem5yeFF3RjhPRklNNFpwSkhSbzRuaFRiYzNrR0pPR3Z0V0hLOFVXc0FVZlQtdFNmeTExbWlDTUdR,"314 Main Street (21020), United States of America, Cambridge, Massachusetts
Master Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.
We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance
Basic Qualifications:
Bachelor’s Degree
At least 5 years of experience in application development
At least 3 years of experience in software development in at least one of the following: Scala or Python
At least 3 years of experience in Spark
At least 2 years of experience in big data technologies (Cassandra, Accumulo, HBase, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)
Preferred Qualifications:
Master's Degree
7+ years of experience in application development
3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink
1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
2+ years of experience with Ansible / Terraform
3+ years of experience with Agile engineering practices
3+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)
3+ years of experience with NoSQL implementation (Mongo, Cassandra)
3+ years of experience developing Java based software solutions
4+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)
4+ years of experience developing software solutions to solve complex business problems
3+ years of experience with UNIX/Linux including basic commands and shell scripting
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.",bos,de
98,Fidelity TalentSource,Business Services,3.4,Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_fc1419e2&cb=1618792859370&jobListingId=1006999083428&cpc=A65DF3A704A48F9B&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-3c7a10be43624fb2&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1mNC1nZkxqNWVaNjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpJVkd5TmE0d3JaSFh1dGVxczFpOHFOZVhoX0ZKYTRNLWY4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOGZkUkVPbUYwWFdMbWhCR0JqWExMS3ZtSlBlMEZKWGJoXzdGaUt2REd6ZGhVSzkxTm9FNTNiNHVNS2hNejVuNFoyNXVOMERERkthaFdyZEdMNWhTUjdSTkNjaWtzMUFoYTYwd1lhRjZnNUM4WWNBTFVfTlJBZEswbXdKdWNfRHRYQWZacWdtM19OMkNsWGhRNVI1Q2hzbmR3UXBVRlNmWDdTdnRHT1ZnSDhRS1RuZ0JHY0NzcXMwVlMwamVQNVd4enVPX3p5ZU01Y2dhQVk4Wi00QnZYbF9PcXlHRGVhWmtiZUl4d3l6RlZGaHNKeVZpSFhPbG1rSmNOb3EzNTVYSFExaFVDUDBmWUpCOTRTbFFqSVI4VHJHQlZOVThoOXBkek9keGJPMXY3ek1ycWJDaXJkbzcyTVFyQzNRMlVLaF8yeUdaM25KUVk3NW8wSUF3MzNyZUlXd0dNblo3VzdKSWNCR0xTV3ZJRlRJd3lwT1RuUDJpLWhtaUxfaGRyQlpoQmJPYnZ5dVBTbGFTclFoSXVZR3hORk5CWU5SSUFQb1BDVG1vdmVoTU1TWk1pWVpGc1h0UG5Pd2tYNndkUjJTNk5uQlJQbkZ4emV6T0ptM3k0R0pUVzdHR1JxczJHMUViWkpZcHJMeXZ4d2tIR3RzWXdPY3VFQnFVb2NjY0twZXpTQ0FSZE1vN2hjdFFpeThuakFwS1YxSmkxMy1VMFdUSVUyeWFQUjVSTkYyaXRwVXdFb21GZlRCTm4zemNfQ1VobkxIbmNwUUlic2ExV2cxdm9SMmk4RlNCcFJ5dmZzS1BodS1iTTVlbC1GM0E,"Fidelity TalentSource is your destination for discovering your next temporary role at Fidelity Investments. We are currently sourcing for a Data Engineer to work in the Workplace Investing Group in Boston, MA.
The Team
 The squad is within the Managing the Work and Portfolio Outcomes Tribe, whose mission is to bring an understanding of the work, outcomes and value being delivered through Fidelity’s technology function and enable data-driven decision making around the portfolio of work (prioritization, capability alignment, and dependency management). Enable a consistent, strategic, and transparent approach to technology management to ensure that Fidelity Technology has the capabilities to drive our digital business transformation.
The Expertise You Have
Bachelor’s degree required.
5-7 years of related experience in Data Engineering.
A learning and growth approach with passion for solving customer problems and delivering engaging digital solutions.
Experience with Fidelity’s enterprise data lake strategy and use of Snowflake.
Demonstrable experience in understanding multi-functional enterprise data, navigating between business analytic needs and data, and being able to work together with other members of technical teams to execute on product roadmaps to enable new insights with our data.
Your proven experiences in effectively implementing data requirements allows you to understand the impact of design decisions on the data strategy and on end consumers
You've experienced working in technology or a related field, with experiences preferred in one or more of the following: data engineering, analysis, data warehouses, data lakes.
Experience working on an agile team and embodies an agile mentality.
Financial services experience preferred.
The Skills You Bring
Proven track record of working in a team to deliver high quality data solutions in a multi-developer agile environment following design & coding standard methodologies.
Outstanding SQL skills and experience performing deep data analysis on multiple database platforms.
Ability to write SQL queries on Snowflake (AWS).
Ability to develop ELT/ETL pipelines to move data to and from Snowflake data store using combination of Python and Snowflake SnowSQL.
Experience in working with AWS, MS Azure or other cloud providers.
Experience on Snowflake Architecture - Warehouse sizing, data structures, RBAC.
Experience in Snowflake performance optimization for large data volumes.
Data Ingestion using NiFi is a plus.
The Value You Deliver
Highly motivated and a quick learner.
Good attention to detail, analytical and consulting mindset- in asking engaging questions to help tease out requirements details and technical implementation options often from more senior team members.
Excellent verbal and written communications skills.
Love working with data and are confident in your SQL and data movement skills
Have a passion for data engineering and are adept at navigating and mastering data held within transactional, warehouse and data lakes possessing the ability to communicate findings to the squad leader, data analysts and business partners.
Are a collaborative and constructive teammate within a newly formed local and globally distributed team.
Adaptable, flexible and thrives in a changing, dynamic environment, managing multiple tasks at a given time.

Company Overview

Fidelity TalentSource, formerly Veritude, is the in-house temporary staffing provider for Fidelity Investments, one of the largest and most diversified global financial services firms in the industry. We recruit individuals from a variety of backgrounds, including technology and customer service, to fill assignments across Fidelity’s U.S.-based regional and investor center locations. If you would like to experience Fidelity’s diverse and inclusive workplace while expanding your skill set and developing your professional network, consider a role with Fidelity TalentSource. For information about working at Fidelity TalentSource, visit FTSJobs.com.

We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.

Fidelity TalentSource will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, please contact our HR team at HR@ ftsjobs.com .

Information about Fidelity Investments

At Fidelity, we are focused on making our financial expertise broadly accessible and effective in helping people live the lives they want. We are a privately held company that places a high degree of value in creating and nurturing a work environment that attracts the best talent and reflects our commitment to our associates. We are proud of our diverse and inclusive workplace where we respect and value our associates for their unique perspectives and experiences. For information about working at Fidelity, visit FidelityCareers.com.

Fidelity Investments and Fidelity TalentSource are equal opportunity employers.",bos,de
99,DISQO,Business Services,4.8,Senior Data Engineer (Remote - US),United States,$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_cffe973b&cb=1618792859372&jobListingId=1006998901294&cpc=B076152010A3B66C&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-dd715747b2ab57a4&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMM3dsZHVrSjFTOUlOODlHeDcxY2p3VXlDb2hPbUxEem44cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlNN3ROblNQZHFWOE5yNVFGOHZ5eTFFQVNxUWNpNURXTUFPcmtNVE5fc3RBRmY4bWFYd2pXTkdrb2VrWDFrc2dTUHZkVTdDQVFkdFN3MTdFel9aX3ZPYnBBNC0yQjhxLXBwNUJFcjhuVHM1Q2ZfeEhnU0VGcVY1R3lBT2RRVk1vYTR0QnVmQ3BDZ25nWHRVVGRtSUtJR1NKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSeUVHNktvSzdOT3J5ajE0Y2V3ajZWYnFiQ2lyZG83Mk0tc0xkRHhUWmYwTU9XLTB0QzUzTnNoMHh6UGVTN0hhdWo5TkxZQnc4MEVBWmNYY05BbWdHT2NpUWZwZ1ItSWY5bWlMX2hkckJaaEJiT2J2eXVQU2xhU3JRaEl1WUd4TkZOQllOUklBUG9QQ1Rtb3ZlaE1NU1pNaVlaRnNYdFBuT3drWDZ3ZFIyUzZObkJSUG5GeHplek9KbTN5NEdKVFc3MWtYYXQwbHFYaUJiQUlVdEpSZlBxNFlsaDBvY2NOSWU4ZzgyWExxM1F4WmlVcUM3Wk9zY2d0WHdsWEVnd3oweWh1UVRhcDMzYUdscW80MGlWSkZhdFVhZVQ3NkxZem5ydkdxY3pmVTFMWlJwSkhSbzRuaFRiYzNrR0pPR3Z0V0hLOFVXc0FVZlQtdFNmeTExbWlDTUdR,"DISQO is changing the way that the world’s largest brands, agencies and consumer intelligence companies get to know their consumers. We’ve built the first identity-based platform that combines consumer attitudes and behaviors together to power the most accurate and predictive insights solutions for our customers, and we do all of that with the willing participation of our consumers and without using outdated technologies like third-party cookies. We help our customers get a cross-platform view into consumer sentiment, measure advertising effectiveness, analyze consumer purchase journeys, and ultimately grow their brands.Our mission at DISQO is to engage people to share their opinions and behaviors openly to help our customers make the right decisions. With over one million active members sharing their attitudes and behaviors, DISQO is looking to expand, improve and create world-class applications for people to openly share their data for research.Check out the DISQO Developer Blog for the latest from our DISQOTECH team.What you will do:Leverage your software development and data engineering skills to impact our business by taking ownership of key projects requiring coding and data pipelinesCollaborate with product managers, software engineers and data engineers to design, implement, and deliver successful data solutionsDefine technical requirements and implementation details for data solutionsDesign, build and optimize performant databases, data models, integrations and ETL pipelines in RDBMS and NoSQL environmentsMaintain detailed documentation of your work and changes to support data quality and governanceEnsure high operational efficiency and quality of your solutions to meet SLAs and support commitment to the customersBe an active participant and advocate of agile/scrum practices to ensure health and process improvements for your teamWhat you bring to the table: 5+ years of experience designing and delivering large scale, 24/7, mission-critical data pipelines and features using modern big data architectures3+ years of Scala3+ years of Spark2+ years of experience with AWS data ecosystem (Redshift, EMR, Glue, Athena, ...)Deep knowledge in various ETL/ELT tools and concepts, data modeling, SQL, query performance optimizationExperience with building stream processing applications using Kinesis or KafkaExperience with workflow management tools (Airflow, Oozie, Azkaban, Luigi, etc.)Comfortable working in Linux environmentAbility to thrive in an agile, entrepreneurial start-up environmentPerks & Benefits: 100% covered Medical/Dental/Vision for employee, 80% for dependentsEquityUnlimited VacationFlexible work hoursCatered lunches 3x a weekStocked pantryHappy HoursOnsite Fitness ProgramDiscounted Gym MembershipQuarterly Offsites401KLife InsuranceFSAPaid Maternity/Paternity leaveDisability InsuranceTravel Assistance Program24/7 Counseling Services offered to employees*DISQO is an equal opportunity employer. Discovery, innovation, and growth are possible when we open ourselves to new possibilities, perspectives, and approaches. That’s why, at DISQO, we welcome, support, and empower individuals from diverse backgrounds. Exceptional teams are rooted in extraordinary people, each with a unique story and a compelling set of skills. DISQO does not discriminate against employees based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws.*Recruiting firms that submit resumes to DISQO without first entering into a written contract will not be entitled to any compensation for candidates referred by that firm.Job Type: Full-timeSchedule:8 hour shiftCOVID-19 Precaution(s):Remote interview processVirtual meetings",bos,de
100,Atrium Staffing,Business Services,3.9,Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_6217b38f&cb=1618792859372&jobListingId=1007008821716&cpc=F4EED0218A761C36&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-6b3570aafd220ec7&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT13MXNxczYzWkdyaTgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLUUNOU2ZDTHY0VFc5NEw0TE9nN0tNR1BKLXYwcTBxWG44cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FoN0FTTmlWX0hJdHo5VU5WSGozaUU4VjBKZWJXWDUxbXJDR2ZpMGlVNVExSmZ1b1p6UFJUYmlhMVA1RlA3b1FBMXlheGI0VUs2SjNXUnNOWkNiT2xsRE9Ed3p0bHMxSjU4Um5BU205ZE42MXdFNndPUTYySi1FR3ZIclFvOVJPc2NObW1WV0w1b19sVFQxYkFoWnFrOVEyQzd1LVBubXp2VjIzcmN0VVlSWFBMTFZxYXF3dE1MX1RtbGphenFnWk44UXNucGkwUFhndzlCWjFkV1VrbXF6d0hzQkR5blRZcWZYYUU1c1kyYWgwT0VyTUlQUDZ6ZDQyUUphOWxTa2xCS2pNLWQ3bkd6Tl9CbHFKT1I4MmpnR21GSXFZaWwtc1RSNUl0cjFWSGVucmVaeDN6WUVrTG11R01xX1V4ajJxRDNUSDVwSktHblZhTkJqTDhCQ0owV2tEM0NWdV9vYlpBRHlJbTMwN1BIX0p1NWRYS1ZwYmVEWWoyQ3pENmZMRzhrOFJ3RUhQbnZGcmZ4N2lmOGtqcm92U1ZNcmtqYkYtWndXUnBVeDRBZVFidFEwOFdfbE1UYXAtZ0tMOHFlbFNFMlNaNElBWUc3Q0xNUG9wOVZnMUgyVnc5czZlUG5wV1phMmhVVXQ4YkVXQ3ZrdmdmWi1qdVF3R2dZRVFIS21WVjVWNkdsMzl0M3Y2aHhPV0hsaWRsQmRXTTRCVVF6bkJ0blNDMGlOa1JraUJPYzVxRDhLOEhDSkhidGJ3UWU2SWQ4dEcyVmp2RVY2cFB3UGVtaTU5aDdESXhmUG4tUFN6akFjbDI0UmNZZEQycTc5YUgxdGhrLWxydW9GU0RkTGQyekptNm8yNE5xZ0d3d3BrZE9PRklhR25lTkpMek8tSEt4X0JYcjB1dExWY1FqR1RsSkRDQUxWQjF2RERqWlBmQW1xbUs0U0FPYXNZaTBkZ0hsZ1JiU0xSZWE3RFlZUnFhRU1idzdOVjItUlhFX0RENzFGemJkOWFzbFozUmVuSksxZ01pYjFTcEU4WDR3OTRzVHdDUUdVY0JNQmM4bnFRc1JZa2ZQYTI0MzVkUzZtd29xM2FPOWpJd1lnSk1FN09hQVBRLS1EUDZHUDVRek1wSjVET01TWkRPSzU5dUNyUElhV2ZaVGZmOVA2TTVsRkJqUHZocWR6RHg2NjhHOWxWZk4wSHFTYURadldzcXBTaHh4d3FsN05CSm85NExjTDlPclFhSXZVMVY4aFYyZFRkVVNPSDBMR1llRW9PTE1qT3RtbkFDWF9KeWh4VEZuVm5Gd2ZHM2o1LWpDTlBLMWFfNVRrcXhaVi1TR1REcXFRVFV1SnFHZWRCRTNMVnBRb29rcE5zbWowZVVUUmRvcmFWTUJLSmhYMDViQzZDUW1NM1ItVmFEVy1oSGFMd1ZJR2xISzktd28tS0lrcWxfRnRDOVhqWGwzaDREMEhfS3RMRS1vYTVQeHp2MDZabV9kNW1zSWF2QnM1SWc0VXZr,"Our client is a rapidly-growing healthcare technology company based in Boston, MA that focuses on streamlining healthcare data and providing analytics. They are seeking a Data Engineer to join their team. This position is remote but candidates local to Boston, MA and the East Coast are preferred.

Salary/Hourly Rate:

Dependent on experience

Position Overview:

This Data Engineer will assist with mapping of healthcare data into the analytics platform. This Data Engineer should be willing to continue to learn and improve their abilities in object-oriented programming concepts and big data processing.

Data Engineer Responsibilities:
Provide custom coding and data manipulation for the Data Integration team
Integrate new healthcare data sources into the state-of-the-art application
Build and optimize pipelines for ETL processes
Build new features/tools to improve the big data and distributed computing infrastructure
Run ETL scripts and perform quality control tasks
Maintain and ensure databases are delivered on-time to customers
Data Engineer Qualifications:
1-3 years of related data engineering work experience
Proficiency in object-oriented and functional programming skills such as Java or Python
Skilled at analyzing data (SQL, Python, R)
Experience working in a Linux command line environment and scripting
Eager to learn new systems and technologies

Preferred Experience:

Experience working with NoSQL databases (MongoDB. Cassandra, etc.)
Familiarity with distributed file systems
Apache Spark experience
Education Requirements:
Bachelor’s degree in Mathematics, Statistics, Computer Science, or other technical/quantitative degrees

The post Data Engineer appeared first on Atrium.",bos,de
101,DraftKings,Information Technology,4.5,Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_78f427c0&cb=1618792859372&jobListingId=1007002803977&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-3cfd7e1c7229f1c4,"We are DraftKings.
We’re inspired by our shared passion for developing creative solutions to complex challenges and empowering the people around us to do their best work. We are industry leaders in the digital entertainment and technology space propelled by constant curiosity and diverse perspectives.
Our teams are fueled by innovation. We are looking ahead, building what’s next, and continuously reinventing the industry. We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston, with teams around the world and an expanding global presence.
Love data? We do too.
We’re growing quickly and are searching for a Data Engineer to act as a creative contributor, leader, and mentor to our data analysis and scalability processes. You will use your experience and expertise to provide key insights that help us make data-driven decisions. Analytical thinking drives our business and when you join our team, you’ll not only solve new problems every day, you’ll see your data solutions immediately improve our users’ experience.
What you’ll do as a Data Engineer at DraftKings:
Design processes that support data transformation and structures, metadata, dependency and workload management
Work with product owners and tech leads to implement high quality, production-grade data pipelines and ETL processes
Partner with our Marketing Analytics and Data Science team to help build tools to provide actionable insights into key business metrics
Leverage your strong communication skills and experience working with global teams to be an evangelist for data engineering across the organization
Be flexible and able to rapidly adapt. We roll out products very quickly and priority management is key
Be key to driving a focus on performance analysis, optimization, and tuning
What skills you’ll use:
1+ years of hands-on experience in aspects of business intelligence and data engineering, including data warehousing, delivery, and operations
The ability to test, build and optimize data pipelines, transformations, architectures, and data sets leveraging new technologies
Strong knowledge in at least one data engine (for example, SQL Server, MySQL, PostgreSQL, Amazon Aurora, Redshift) is required. Snowflake experience is a big plus
A solid understanding of dimensional modeling is required
Excellent communications skills (verbal and written) and interpersonal skills to effectively communicate with both business and technical teams
Experience with data reporting tools (e.g., Tableau), data cataloging tools (e.g., Alation) and data logging/monitoring tools (e.g., Datadog) is preferred
Experience working in AWS, Terraform, Python, and with database replication tools/services (e.g., DMS, Attunity) is preferred
Experience in the Regulatory, Financial or i-Gaming industry is desirable
Join Us!
We strive to create a place where all feel safe, empowered, engaged, championed, and inspired. DraftKings is proud to be an equal opportunity employer. This means we do not tolerate discrimination of any kind and are committed to providing equal employment opportunities regardless of your gender identity, race, nationality, religion, sexual orientation, status as a protected veteran, or status as an individual with a disability.
Ready to build what’s next? Apply now.
As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment.",bos,de
102,Alexander Technology Group,Business Services,4.4,Data Engineer,"Cambridge, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_03e8ae68&cb=1618792859373&jobListingId=1006998588098&cpc=AC285F3A3ECA6BB0&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-2d2b0ac4d50adafc&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1hSWNSZ05QQTE1eTgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKM0RGcUppempqbkcyMXlUOTB2UGZEWFI0VEpodHhibXo4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOXY1V1Q0dTFDeEFFNVNhSEFHYXViazB3cFl5T1lhVUVIaDhadkRHcGhWdGROaEdxbmxMbDMyalZJMjlDcEJPekQ5OTd1NDVNQ0ZXdi1LeTZlWGprNVFOQWxSZWZQTDRCdVRWbzBHRU5mZ0tUNFVKWVhtRWJTM1B1TjFINXlIRzhpdnRXc09xMGVtNUFuMUVWU3ByNTNiZWQzLWNpdl9lVTBOb19hbF83WXc0bTNWZVpTU2gzTVpHckxFd29xU3ZibGtEUlZ1OTZCc3ByaEFNaW9MRFVOUS1ZTnFoQjEta0tvRlN6c2xPVzNKVFVNZXRNQ0tuZjJsdUxNNXdpcmY3ZkhfNU44bDBwYWc3YnZxT1JBSzBheHZ1R19VOTk4Q2hXdTZ1dzNUNTRQbUtJWWMzUHJWYlFxbFppb0xKQVJtLUhOR2g2b3VFMmZsb2FwNGtOLXJGV3d2dDJEZVR0UUlBTmZ1aVJGSDdiSldrbnU1M0ViWk8xVEhDemF2VXAtQml3N1JmR2VURUxrRzFSbWNsVEx2a3hSUGNXQlA5SGFxcWlGd1lQZGEwQU5LSjNRN0lRVXVzVi1BeVpVSE83TFNLa1FPR1V2TEZPdHFYbC1Ibk1pb3N1X0xFUU5RcHkwZFd4Uzl4Njd0a25sLUVZXzBDR1lUSnRqdnBWanlNbjV3VlotRDQtazlKaWZGX0lqYWhSblBGV2pVN2Vyb2ptaFZMcVZQZ3ZWbWZVbXZqMkhOUXFWeEp2YTFzZVJKXzB2MUE1OEdOdHl5eWdtTUw5b20td01NOU04V2Z6QzhFeC1LQ2xCbEZCalB2aHFkek9QT2cwSWpFOS1xRW9iMTM3ZktZVWwzOHRaeVIzZF8wbUpTb0x0azZ4eUMxZkNWY1NERFBUS1lDQ1ozZFJXbGZzc2VkeWxBaHV4clZhRFctaEhhTHdWSUdsSEs5LXdvLUc3NXN6bDZYNFhj,"The Alexander Technology Group is working with a Boston based Life Sciences startup to identify a qualified Data Engineer for a direct hire position. This Data Engineer must have a versatile skill set including but not limited to: Data Mapping, SQL, and learning and vetting new data systems. This is a hands on position that is looking for someone to hit the ground running. Prior Life Sciences experience is preferred, but not necessary.

This Data engineer will be responsible for the design, development, and maintenance of their data pipeline, and load processes and help scale as the company moves into IPO stages later this year.
Some key qualifications:

Strong SQL skills
ETL experience
Creating a Data Directory
Data Mapping
Meta Data
Data Cleansing
Data warehousing is good to have (but not needed at this point in the startup)
BI skills and exposure is good to have (but not needed at this point in the startup)
Must be able to communicate effectively


Upcoming projects as the company grows:

DataWarehouse implementation, vetting and selecting DWH technology and implementing
BI tool selection and implementation


An idea of their current tech stack:

O365
AWS
NetSuite
Salesforce
HRIS
LIMS
If interested and qualified, please email your most updated resume to Rich Demling at rdemling@alexandertg.com and follow up with a call at 339-298-3643.


No third party candidates will be considered for this role

This position requires quarterly attendance to their Boston Location
Unfortunately no relocation assistance can be provided for this position


*MONATG*

#LI-RD1

ATG456",bos,de
103,Bentley University,Education,4.4,Senior Data Engineer,"Waltham, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_c311fcc4&cb=1618792859373&jobListingId=1006999614228&cpc=4B86475FAF393599&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-eb584abf16305e10&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpKUjBWa1lXVkZRNUxPZ19pXzQ3cVM5RVBoMDIwMjBLRVg4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX0wyajY5ZU82Wkp2cDE4QXpyUTFKMVloYWJtazhLb2FUZl9MWW5jNW9FWUNjTkVUT052ZnBwc0pWZzVTTV91XzBhNk9fOTYtZXNSQlhfajNLZWU5ODRJYU5mVDVFMmRNOXd3VHFtZTZSTEFQOVl1QXE2RXpkN01zZDhNb2VFUUtYNWcycUVIWDZRcXFIOU1ka2ZXR2doUXg2MHdJcWRfYVc0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVkxWMEtBLTd5aDlodXViYnpyd3dCLWp0Xy1wWG45b1ZtMllrSUxwRGVkaC1lS0U4NUNtWTN4Vk0yQV9QbTB2cGxHUE5nVHVtQXFkeV91Z0FGRXhOSFI2bEtISEhDcVhzMC1UNWRwVnllYzA1OU53Q3Aya2QwdHdoRU5kUnU5UzNlTUR5WmJOSFZGb0t3MnR6V1lKbTllaGxuS3hTMEdoMDhLekVBWGg4OW9BblZGR2U2ajRtMUw3T29CSVNvZWVZaC0wRHRoSTV4eUV0ODJCRERkeTV3QlREUVNTUUZ1Mkp3WUEyRE9qZk5udk5xbzQwaVZKRmF0VWFlVDc2TFl6bnIwQTB2RWRGZlNORE41QmlUaHI3VmgxZjZIMFpzeHk0T0FpaGNjUklMQWpjX1Z0aHBZbS1nMGhLRzlkLTN5bUZKNDNRek9nYWZUQktJMjB5ai03cGFndw,"Bentley University

Job Description Summary

Bentley University is looking for a strong technical, creative, and motivated individual to join a motivated team in the IT enterprise reporting and analytics group. The Senior Data Engineer will report to the Director, Data and Analytics Operations and will be responsible for supporting ongoing mission critical efforts to develop a modern integrations and analytics environment as well as supporting day-to-day operations.

The ideal candidate will have excellent analytical skills and extensive experience in a modern enterprise data warehouse (DWH) environment. They will have solid hands-on experience with extract, transform and load (ETL) processes and tools. They will also have strong communications skills and the ability to work collaboratively with technical and non-technical staff in multiple business areas.

Minimum Qualifications
Bachelor's degree.
5-7+ years of experience working in data warehouse, ETL and data integrations environment
Proven experience with a commercial ETL product, for example, Informatica, Fivetran or other ETL tools.
Solid command of current data warehouse, reporting and analytics concepts and technologies.
Proven ability to troubleshoot ETL data mappings, data flows, and data transformations within the data warehouse environment.
Strong interpersonal and teamwork skills with both IT colleagues, business analysts, analytics staff and other report users at Bentley.
Ability to understand and synthesize data and transformation requirements working with business users.
Ability to work with IT development staff to understand (data) source applications and associated environments.
Ability to write, troubleshoot, and resolve issues with SQL.
Ability to document and communicate designs, analyses, and other plans both verbally and in writing.
Hands-on experience with at least one commercial relational database (for example, Oracle, SQL Server).
Experience with data reporting and analytical tools, e.g. Tableau, Power BI, etc.
Experience with cloud-based systems - SaaS, PaaS and understanding of industry-standard enterprise data management practices.
Knowledge of the impact of source system data management practices on the data warehouse environment.
Preferred Qualifications
Knowledge of modern, SaaS based integration tools such as Fivetran.
Knowledge of cloud based and SaaS data warehouse solutions (for example Snowflake or Microsoft Synapse).
Knowledge of Microsoft data management tools (for example, Azure Data Factory, Logic Apps).
Knowledge of analytics tools (for example Tableau, Power BI, or other similar toolsets).
Practical experience working in data management or data governance frameworks, and using tools to develop them in a small to medium sized environment (higher education experience preferred but not required).
Work Environment
Typical office setting with extensive sitting and computer work
Ability to travel around campus for meetings and other work related events


Bentley University requires references checks and may conduct other pre-employment screening.

Bentley University is an Equal Opportunity Employer, building strength through diversity. The University is committed to building a community of talented students, faculty and staff who reflect the diversity of global business. We strongly encourage applications from persons from underrepresented groups, individuals with disabilities, covered veterans and those with diverse experiences and backgrounds.
PI133997218",bos,de
104,"V-Soft Consulting Group, Inc.",Business Services,3.7,Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_fb47ee81&cb=1618792859374&jobListingId=1007001943404&cpc=2CAED5C921A5F994&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-39f1bbfc4b0a39a3&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMREJtNExHUzF4RzlhdkhBVC1Remd3SUdFV0FSWjdjWm44cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyLUw1SU0tNzdVaFk3bVY4cDZhVnZuc09wNjB4eFdzNzdsVVMwSWx2czlmdlBINEQwWTFYMGZTVm44WVJMRTZvcUd3VHpCSndGRUpDOHVjYVFvdmZYX2xWamJPV3FjTU9nakk0LVBsckhZS3VGYmVNQzJzUk90X0h6aVdkLUNGQXZabEY5em80RG1aMlFxdzlMZS1Wd0VvSlI1M0VKVTIwYUZHS2ZBMHZVdmgwR2JvMnhlQ3czUkxKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSUDZoODR2OHEwUnIyWjJ1a0J5YkdjM1JXQW54MFg2NlJBdWhjVDgwTy1RQnRQTmZhclJGNVFYUHV5SF9mZ1RGRGljbXRjQXRMaUtvcEgwSm5IXzJTVmVUS21ibUMzNWJWTWhablpob21ramFZdllKaDZTdzY2Z3ZkbFVaUElMZlpINFNjYTlGYWVBVTJWaTFFRkRVT2poRnRzX0puV25jNVFMLWlVeTZKeTRlRmNJMEcxZ1lUMkdXZFozU0xMdXpndktPY1VHYVVwVmhvbkFWZG0xQzYtWnhtV3NqZ0JMS2JrOUNDMDFlQjNFTE41QmlUaHI3Vmh5VmEtQVFqTEU4XzQ4NkRRaU1UMzZvU2h2WGZ0OHBoU1FFNWotcTV5aTd0R1FkTi1ZWTd4UVUyeWFQUjVSTkYyaXRwVXdFb21GZlRVcDBld1dEQkl1TUdJREFnRlFrM19n,"Data Engineer
Primary Location – Boston, Massachusetts

V-Soft Consulting is currently hiring for a Data Engineer for our premier client in Boston, Massachusetts. This is a contract position in the financial services industry.

Education and Experience »
Bachelor’s degree required.
5-7 years of related experience in Data Engineering.
Experience with data lake strategy and use of Snowflake.
Your proven experiences in effectively implementing data requirements allows you to understand the impact of design decisions on the data strategy and on end consumers
You've experienced working in technology or a related field, with experiences preferred in one or more of the following: data engineering, analysis, data warehouses, data lakes.
Experience working on an agile team and embodies an agile mentality.
Financial services experience preferred.
Experience in working with AWS, MS Azure or other cloud providers.
Experience on Snowflake Architecture - Warehouse sizing, data structures, RBAC.
Experience in Snowflake performance optimization for large data volumes

Knowledge, Skills and Abilities »
SQL w/ Snowflake strongly preferred, AWS, ETL for data move into Snowflake.
Ability to write SQL queries on Snowflake (AWS).
Ability to develop ELT/ETL pipelines to move data to and from Snowflake data store using combination of Python and Snowflake SnowSQL.
Proven track record of working in a team to deliver high quality data solutions in a multi-developer agile environment following design & coding standard methodologies.
Outstanding SQL skills and experience performing deep data analysis on multiple database platforms.
Data Ingestion using NiFi is a plus.

WHAT YOU’LL DO:
Job Responsibilities »
Highly motivated and a quick learner.
Good attention to detail, analytical and consulting mindset- in asking engaging questions to help tease out requirements details and technical implementation options often from more senior team members.
Excellent verbal and written communications skills.
Love working with data and are confident in your SQL and data movement skills
Have a passion for data engineering and are adept at navigating and mastering data held within transactional, warehouse and data lakes possessing the ability to communicate findings to the squad leader, data analysts and business partners.
Are a collaborative and constructive teammate within a newly formed local and globally distributed team.
Adaptable, flexible and thrives in a changing, dynamic environment, managing multiple tasks at a given time.

Interested? Qualified candidates should apply or send their resume to AHussain@vsoftconsulting.com

V-Soft Consulting is a trusted partner with experience across diverse technology stacks to help business get IT done. What makes V-Soft different? Our expertise is derived from over 20 years of delivering world-class IT staffing, consulting, engineering and managed services to Fortune 1000 and mid-market companies in the U.S., Canada, and Asia.
V-Soft is headquartered in Louisville, KY with strategic locations in India, Canada, and across the U.S., including Madison, Chicago, Denver, Harrisburg and Atlanta. V-Soft has been recognized among the top 100 fastest growing staffing companies in North America, and is known for the ability to provide highly qualified consultants for any project at any scale. V-Soft has a wide variety of partnerships across diverse technology stacks, and holds such titles as MuleSoft Certified Delivery Resource, Oracle Gold Partner, ServiceNow Partner, Microsoft Partner, and Cisco Registered Partner, amongst many others.
Like what you hear? Apply with V-Soft today! For more information or to view all our open jobs, please visit www.vsoftconsulting.com or call (844) 425-8425.",bos,de
105,MassMutual,Insurance,3.9,Kafka Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_563992ea&cb=1618792859375&jobListingId=1007006597209&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-9c42029207cfbe56,"What great looks like for this role:
Our ideal Advanced Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data management systems. You’re also committed to data integrity, are highly analytical, and can work on multiple projects at once. You’ll use your skills to develop, monitor, and manage data systems across our platform. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by MassMutual are core reasons people enjoy working on the Data Engineering team at MassMutual.
Objectives of this role:
Design, construct, install, test and maintain highly scalable data management systems.
Ensure systems meet business requirements and industry practices.
Design, build, and maintain a high-performance streaming and messaging platforms to support the enterprise.
Daily and Monthly Responsibilities:
Design, build, and maintain a high-performance streaming and messaging platforms to support the enterprise.
Create messaging standards for our messaging platforms.
Develop tools and processes to support the platform.
Create custom software components and analytics applications.
Work across departments and business units to define patterns and data needs.
Translate high-level business requirements into technical specs.
Basic Qualifications:
Bachelor’s degree in computer science or engineering.
2+ years of experience with designing and building data platforms.
2+ years of experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, etc)
2+ years of experience creating producer and consumer applications with Kafka
2+ years of coding and scripting (Python, Java, Scala) and design experience.
Expertise in tuning and troubleshooting streaming/messaging platforms.
Experience with ELT methodologies and tools.
Strong data integrity, analytical and multitasking skills.
Excellent communication, problem solving, organizational and analytical skills.
Able to work independently.
Authorized to work in the USA with or without sponsorship.
Preferred Qualifications:
3+ years of experience creating producer and consumer applications with Kafka
Experience with KStreams and KSQL
Experience with designing an automating deployment process (CI/CD)
Basic knowledge of database technologies (Vertica, Redshift, etc)
MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status.",bos,de
106,Panalgo,Information Technology,4.8,Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_bab6619e&cb=1618792859375&jobListingId=1007002721882&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-bcc797644f378aa6,"Panalgo is one of most significant voices in healthcare analytics. With over two decades of experience, Panalgo provides novel solutions to allow the world’s largest life science companies, health plans and provider groups to better understand the clinical outcomes and value of various patient care strategies. Panalgo’s market-leading Instant Health Data (“IHD”) platform transforms the way analysts from diverse disciplines answer complex and critical questions and make insightful predictions.
We are seeking an exceptional Data Engineer to assist with the mapping of new healthcare data sources into our state-of-the-art analytics platform. In undertaking this challenge, you will be at the working with the latest distributed computing technologies to process, transform, and configure large healthcare data sources to be used by our SaaS clients. We're looking for candidates with a background in data analysis, and a strong desire to continue learning and improving their abilities in object-oriented programming concepts and big data processing.
RESPONSIBILITIES:
Provide custom coding and data manipulation for Data Integration team
Integrate new healthcare data sources into our state-of-the-art application
Build and optimizing pipelines for ETL processes
Build new features/tools to improve our big data and distributed computing infrastructure
Become a subject matter expert in the structure and contents of various healthcare databases
Run ETL scripts and perform quality control tasks
Maintain and ensure databases are delivered on-time to our customers
Configure our software platform to use data sets and ensure ETL instructions and documentation are up-to-date
SKILLS & REQUIREMENTS:
Bachelor’s degree in Mathematics, Statistics, Computer Science, or other technical/quantitative degree
1-3 years of related work experience
Proficient in object oriented and functional programming skills such as Java, C++, Ruby or Python
Skilled at analyzing data (SQL, Python, R)
Experience working in a Linux command line environment and scripting
Eager to learn new systems and technologies
Exceptional attention to detail and critical-thinking skills
PREFERRED QUALIFICATIONS:
Experience working with NoSQL databases (MongoDB. Cassandra, etc.)
Familiarity with distributed file systems
Apache Spark experience
WHY BE A PART OF PANALGO?
Leading healthcare data analytics/big data company
Work on a team of talented and pragmatic engineers/researchers
Great mentorship and growth opportunities
Panalgo provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
XjuSEcdlN9",bos,de
107,Dyno Therapeutics,N/A,-1,Data Engineer,"Cambridge, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_95a06f13&cb=1618792859375&jobListingId=1007005999327&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-94cdb087965ed980,"The Company

Dyno Therapeutics is reshaping the gene therapy landscape through AI-powered vectors. Through the application of our transformative technologies and strategic partnerships with leaders in gene therapy, we believe a future with life changing gene therapies for millions of people is within reach.

Our team includes world-class molecular and synthetic biologists, protein engineers and gene therapy scientists working alongside software engineers, data scientists, and machine learning experts. Dyno was named Xconomy's 2020 start up of the year!
The Role

Data Engineer. The software engineering team is at the heart of Dyno's platform, and your work as a part of this team can have a major impact on the future of gene therapy. Our team's responsibilities include automating computational and machine learning workflows, scaling databases and data processing algorithms, and controlling laboratory equipment and scientific processes. Our team is looking for candidates with a diverse set of skills and experience, and a passion for working autonomously and learning things on the fly.

How You Will Contribute

As a Data Engineer, you will take a leading role in architecting and developing the core data infrastructure that allows Dyno to reshape the gene therapy landscape. You will collaborate closely with data scientists, computational biologists, and experimental scientists to streamline the process of running complex scientific workflows and the process of capturing information from them. You will bring a thorough perspective to the complex challenges of connecting the information flowing between numerous teams with diverse functions.

Responsibilities:

Contribute to our tech stack direction for large, data driven workflows
Engineer creative solutions to track critical information lifecycles
Optimize tracking, storage and serving of biological data
Model and maintain information ontologies
Develop and maintain software best practices, including continuous integration, agile and test driven design
Architect and deploy LIMS and ELN systems in alignment with Dyno's vision
Interface with biologists and data scientists to understand opportunities to empower them with software

Who you are

Trusted partner
Team oriented
Thoughtful & detail oriented
Work with a sense of urgency
Appreciate the opportunities at the intersections of data science and biology

Basic qualifications

BS, MS, or Ph.D. in Computer Science or equivalent experience
2+ years of data engineering experience in industry
Expertise in Python and SQL
Experience using technologies to track samples through laboratory workflows
Experience deploying and maintaining production software systems

Preferred qualifications

Fluency with software life-cycle best practices and devops.
3+ years of industry experience in software development, including database design, distributed computing and data pipelines.
Experience with Lab ELNs and LIMS.
Experience with workflow orchestration systems such as Apache Airflow or Argo.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Job Type: Full-time",bos,de
108,Velir,Business Services,3.3,Data Engineer,"Somerville, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_f433184e&cb=1618792859375&jobListingId=1007008046743&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-9fe193f67d17aea2,"Overview:

As a Data Engineer at Velir, you’ll help our clients store, access, process, and analyze their user data so that they can improve decision making as well as their customer experiences. Our ideal candidate has a desire to apply modern data engineering & data analysis practices towards enterprise-scale production environments for a wide range of clients and industries. Velir’s Data Integration & Activation team is small but growing, and this individual will have the opportunity to make an outsized impact in a team that’s supported by a larger company.
Responsibilities:
Build new, maintainable data pipelines, automation routines, and data schemas. Common data sources include web analytics, CRM systems, email service providers, e-commerce platforms, customer data platforms, ad platforms, and social media listening tools among others.
Integrate data generating systems with databases & data warehouses.
Support existing data pipelines by evaluating issues as they arise, triaging, and deploying fixes in Python and/or SQL.
Review requirements and specifications produced by a Data Architect and provide feedback regarding feasibility and effort. Execute work while providing timely feedback on timeline, risks, and blockers.
Build reporting tables and dashboards.
Complete ad hoc data analysis to support internal teams and clients.
Stay on top of trends in the industry. Prototype and apply new methods and technologies as they become available.
Maintain knowledge & documentation for how data solutions work
Address non-functional requirements in your work such as performance constraints and security policies.
Create and monitor tests that provide quality controls over code and data.
Work within and configure CDP platforms (such as Segment), cloud ETL platforms (such as Fivetran), and data orchestration tools (such as Apache Airflow) to meet data pipeline/processing requirements.
Stand-up cloud data infrastructure such as data warehouses, messaging busses, serverless functions, and object storage. Handling cloud database administration tasks such as granting credentials and updating schemas will be required. Low-level database management tasks such as optimizing indices or managing backups will not be required.
Skills & Qualifications:
Ability to communicate and work with a cross-functional teams and client stakeholders. Strong written and verbal communication skills are required as well as good interpersonal skills.
Ability to identify roadblocks, raise these risks, and provide leadership towards resolutions
Must have experience with the following:
Intermedia to Advanced Python, including common data libraries such as Pandas and/or SQLAlchemy
Git/GitHub, Docker/DockerHub
Advanced SQL
Web-native APIs
At least 1 major cloud provider’s data products (AWS, GCP, Azure) including at least 1 OLAP database product (Redshift, BigQuery, Synapse)
At least 1 BI tool (Tableau, Power BI, Data Studio, Domo, Shiny, etc)
At least 1 ETL provider (Fivetran, Stitcher, Boomi, Informatica)
Experience with the following is preferred, but not required:
R Programming, Jupyter Notebook, Data Build Tool (dbt)
Data orchestration tools (ex: Apache Airflow)
Machine Learning modeling and model deployment.
Marketing technologies such as Customer Data Platforms (CDPs), Customer Relationship Management (CRM) software, and web analytics tools (Ex: Google Analytics)
Experience and Education
BS in Software Engineering or other STEM field
5+ years working with Python
3+ years working primarily on data systems
Physical Requirements
Frequent sitting at a desk performing work on a computer
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions
Core Company Values
Velir is an established mid-sized agency with a top-tier portfolio of clients, ranging from the world’s largest non-profits to Fortune 500 brands. We pride ourselves on our people-first culture and a low-ego workplace that embraces experimentation, collaboration and continuous improvement. We have a fun office environment located in Davis Square (Somerville, MA) and offer competitive pay and excellent benefits.
Take the Long View - Ensure the company is built to last
Be Courageous - Make the right decisions even when they aren't the easiest decisions
Be Genuine - Bring honesty and authenticity to all that you do
Work with Focus + Passion - Display purpose and pride in your work and never stop learning
At this time, Velir does not sponsor candidates and unfortunately cannot accept those on OPT or CPT.",bos,de
109,Cognition Financial Corporation,N/A,5,Senior Data Engineer/SQL Developer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_7dedd851&cb=1618792859375&jobListingId=1007009079545&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-bae7bd23614262ba,"We are looking for a curious Senior Data Engineer to join our growing team of data analysts and scientists to manage our core data warehouse. The Senior Data Engineer will be responsible for maintaining and expanding a data warehouse to support the underwriting, operational management, analytics, and reporting on student loan portfolios. As part of an interdisciplinary team of technologists, analysts, statisticians, and modelers, the Senior Data Engineer will be primarily responsible for building and maintaining the data pipelines that support our data-driven decisioning processes.

The Senior Data Engineer will be involved in the full analytics life-cycle based on agile and iterative development methodologies as well as data management best practices. Responsibilities include business requirements gathering, design and maintenance of data pipelines and architectures, and finding and implementing alternative datasets to support new insight into the student loan ecosystem.

The Senior Data Engineer knows the difference between a data lakehouse and a data vault, between ETL versus ELT, and can build a data pipeline against webservice APIs.

The ideal candidate for this position is self-directed and comfortable working in a fast-paced environment supporting the data and analytics needs of multiple cross-functional teams. The candidate must love working with disparate data and be able to write efficient SQL against large data sets. This role rewards creative multi-disciplinary thinking and willingness for life-long learning.

ESSENTIAL JOB FUNCTIONS:
Build and maintain complex data load and transformation processes
Implement data transformations and data enrichment to unlock new insight in a variety of internally and externally sourced datasets
Work with individual business units to provide sustainable solutions to their data needs
Work with data management team to architect effective and efficient data solutions
Develop an intimate knowledge of the data warehouse’s varied data sources, increase data quality issues, and re-architect as needed
Design and enhance data models, data marts, and metadata
Implement analytics tools to optimize decision-making

QUALIFICATIONS:

Preparation, Knowledge, & Previous Experience:

At least 4 years of progressive experience building data pipelines and data architectures
Experience with SQL RDBMS (SQL Server 2017 or newer) and programming languages (SQL, R, Python, …)
Experience with code development and quality assurance testing concepts and tools
Knowledge of dimensional modeling principles, data warehousing, data lakes, or data vaults
CDMP, CDP, CBIP certification a plus

Skills, Abilities & Competencies:

Data-driven and analytics approach to problem-solving
Prior experience with SQL, SAS, Python or R code for data processing and PowerBI or Tableau for reporting
Track record of continuing education via webinars, conference attendance, or local technology support group involvement
Experience with cloud computing platforms like Microsoft Azure or Amazon AWS helpful
Excellent analytical ability, consultative, communication skills, strong judgment and the ability to work effectively with both business and technical staff
Highly organized self-starter who can own projects and act with limited supervision
Ability to remain focused in a high-pressure, “open office” environment
Financial services data management experience, particularly in student/consumer lending or mortgage finance, is a plus

Level of Education Required:

Bachelor’s degree in Information Technology, Engineering, Science, or analytical discipline",bos,de
110,MassMutual,Insurance,3.9,Advanced Data Engineer,"East Boston, MA",$130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_ae17cc39&cb=1618792859375&jobListingId=1007006597146&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-749ac63199891cab,"Since 1851, MassMutual’s commitment has always been to help people protect their families, support their communities, and help one another. This is why we want to inspire people to Live Mutual. We are people helping people.
A career with us means you will work alongside exceptional people and be empowered to reach your professional and personal goals. Our employees are the foundation of what makes MassMutual a strong, stable and ethical business. We seek and value unique and varied perspectives and experiences because we believe we are stronger when all voices are heard. We invite you to bring your bright, innovative ideas to MassMutual as we continue to help millions of Americans rely on each other.
Together, we are stronger
What great looks like in this role
Our ideal Advanced Data Engineer is a collaborative leader skilled in data analytics, data modeling, and database design. You’re also committed to data integrity, are highly analytical, and can work on multiple projects at once. You’ll use your skills to develop, monitor, and manage data systems across our platform. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by MassMutual are core reasons people enjoy working on the Data Analytics team at MassMutual.
Objectives of the role
Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.
Working on a range of projects including batch pipelines, data modeling, and data mart solutions you’ll be part of collaborative project teams working to implement robust data collection and processing pipelines to meet specific business need.
Daily and Monthly Responsibilities
Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.
Executes and provides feedback for data modeling policies, procedure, processes, and standards.
Assists with capturing and documenting system flow and other pertinent technical information about data, database design, and systems.
Develop data quality standards and tools for ensuring accuracy.
Work across departments to understand new data patterns.
Translate high-level business requirements into technical specs.
Basic Qualifications
Bachelor’s degree in computer science or engineering.
5+ years of experience with data analytics, data modeling, and database design.
3+ years of coding and scripting (Python, Java, Scala) and design experience.
3+ years of experience with Spark framework.
Experience with ELT methodologies and tools.
Expertise in tuning and troubleshooting SQL.
Strong data integrity, analytical and multitasking skills.
Excellent communication, problem solving, organizational and analytical skills.
Able to work independently.
Preferred Qualifications
Master’s degree in computer science or engineering.
Familiar with agile project delivery process.
Knowledge of SQL and use in data access and analysis.
Ability to manage diverse projects impacting multiple roles and processes.
Able to troubleshoot problem areas and identify data gaps and issues.
Ability to adapt to fast changing environment.
Experience with Python.
Basic knowledge of database technologies (Vertica, Redshift, etc.).
Experience designing and implementing automated ETL processes.
MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status.",bos,de
111,Mapdwell,N/A,-1,"Data Engineer, Building Science","Charlestown, MA",$110K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_3b4c6938&cb=1618792859377&jobListingId=1007006087300&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-dbb0c7dc518cdac2,"Mapdwell is looking for a Data Engineer to join our Building Science team and build powerful information experiences around energy and sustainability. You will be working with massive datasets across our geospatial data pipeline, working to develop, automate and improve building simulation techniques, algorithms and workflows. You will also be involved with data sourcing, normalizing, vetting, processing, storage, analysis and maintenance, machine learning models, data visualization, back-end services, APIs and deployment.About MapdwellMapdwell, an MIT spinoff, is a software and data intelligence startup that provides advanced tools for energy decision-making. We level the field for consumers by providing intuitive and actionable tools and leverage user engagement into powerful data intelligence for industry. Mapdwell uses hard science and data intelligence to uncover opportunities that align good business and best practices with a more resilient, healthier and more sustainable future by driving demand and empowering industry. Learn more at [mapdwell.com](https://mapdwell.com).ResponsibilitiesDevelop building energy models at scale in an automated fashionResearch, implement and document state-of-the-art building modeling techniquesDevelop data and financial models for energy investmentsPerform statistical analyses on large structured and unstructured datasetsDevelop data pipelines and automate data processing tasksWork with the engineering/product teams to develop software featuresThe EssentialsFamiliarity with building performance (or BEM) software (e.g., EnergyPlus, OpenStudio, Radiance, Ladybug, Ecotect, Revit, DesignBuilder, Diva)3D modeling and analysis (e.g., LIDAR, Rhino, point clouds, photogrammetry)Coding and Scripting (e.g., Python, Grasshopper)Data Science, Statistics or Machine Learning (e.g., R, TensorFlow, Keras)Bachelor’s degree in Computer Science, Architecture, Math or Engineering, or equivalent experienceIt’d be nice if you had…1+ years working with large datasets in a professional environmentExperience consuming data-driven APIsFamiliarity with cloud infrastructure and web services (e.g., AWS, Azure, Docker)GIS software, tools and frameworks (e.g., PostGIS, QGIS, GDAL/ogr, ArcGIS, Grass)Big Data tools (e.g., MapReduce, Spark, Hadoop)Master’s degree or PhD in Building Technology, Environmental Science, Energy Modeling or a related fieldJob Type: Full-timePay: $110,000.00 - $130,000.00 per yearBenefits:401(k)Dental insuranceDisability insuranceHealth insuranceLife insurancePaid time offParental leaveProfessional development assistanceReferral programVision insuranceSchedule:8 hour shiftMonday to FridaySupplemental Pay:Bonus payEducation:Bachelor's (Preferred)Experience:Python: 1 year (Required)Building Energy Modeling: 1 year (Required)Work Location:One locationCompany's website:mapdwell.comCompany's Facebook page:https://www.facebook.com/mapdwellBenefit Conditions:Only full-time employees eligibleWork Remotely:YesCOVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",bos,de
112,New England Quality Care Alliance (NEQCA),N/A,-1,Healthcare Data Engineer,"Braintree, MA",$110K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_23688a2b&cb=1618792859375&jobListingId=1007007488805&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-24954d1bbb54fcf6,"I. GENERAL SUMMARY:

The Healthcare Data Engineer will be an instrumental contributor to the development and execution of NEQCA's data management strategy. As a domain expert in data engineering for the department and the organization, the Data Engineer will work with stakeholders from across Wellforce and the Analytics team to establish the necessary tools and technology to support our mission to help people achieve better health and live their best lives.

II. PRINCIPAL DUTIES AND ESSENTIAL FUNCTIONS:
Key Accountabilities:

1. Essential Functions

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

2. Challenges/ Problem Solving:

Ensure optimal data delivery architecture is consistent throughout ongoing projects.
Optimize or even re-design our company's data architecture to support our next generation of products and data initiatives.
Supporting the data needs of multiple teams, systems and products, simultaneously


III. JOB REQUIREMENTS:

Collaboration and Communication

Maintains collaborative, team relationships with peers and colleagues in order to effectively contribute to the working group's achievement of goals, and to help foster a positive work environment.
Display strong verbal, communication and presentation skills to all levels of the organization.
Provide strong customer focus and ability to work effectively in matrix environment.
Ability to work independently, results oriented, and flexibility with new or varied responsibilities.

Technical Skills

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing 'big data' data pipelines, architectures and data sets.
Experience with data pipeline and workflow management tools
Experience with object-oriented/object function scripting languages
Experience with Azure cloud services (preferred, not required)

Healthcare Knowledge

Understanding of healthcare security (i.e. HIPAA, HITECH)
Understanding of healthcare application ecosystem
Previous experience with Epic Cogito Analytics (preferred, not required)
Previous experience with Arcadia Analytics (preferred, not required)

Experience
3+ years of relevant experience including:
2+ years of hands-on data development
1+ years of healthcare experience
IV. WORKING CONDITIONS/PHYSICAL DEMANDS:
Work is in a fast paced office-based setting.
Reliable transportation is necessary. The NEQCA office is located in Braintree with travel to Local Care Organizations and community hospitals.
Work often includes meetings outside of normal business hours

AMERICANS WITH DISABILITIES STATEMENT:

 Must be able to perform all essential functions of this position with reasonable accommodation if disabled.

he above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed, as an exhaustive list of all responsibilities, duties and skills required of personnel so classified. New England Quality Care Alliance reserves the right to modify position duties at any time, to reflect process improvements and business necessity.",bos,de
113,CyberCoders,Business Services,4,Sr. Data Engineer- AWS - Venture Backed Big Data Company,"East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1110586&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1b13d3ac&cb=1618792859375&jobListingId=1007006594847&cpc=FA84DF7EA1EC2398&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-2b8625334960102c&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT03aUFqZWNQZXcxMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMcFJCcm16TjNpd2d3RnB4Wi1hd0JGSlkySEZNU2paeVg4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWh2ZXVkWkFua050SHoteWw0NG11TXRxR25Kd0x1bVFENVNyYmliczhXbUo0SkEyTnBQQlVpZEEyeW1sUlp2UDM4OU5rX2NuMmc2RjBzaFotajYwVXQtWDFIem1BN2hnWFR4alpjRWJ5QkZXcjJFNVVKN080MnRwUm1Ib1lZTlZ0TGhUakNfeTg3ZjVjY3NJNHhlUFo1b3NaZF8xUy1UU3dmWTNKLTI3dEluVkVGbTVIYmhKeEx3RjFKeUt1Q2R3LThCYTRuMFJ5MFp5MDc1ZThkaUpuV0NuYmlCa3lHY2l4N19qT1dnTzFMdmc1ejVKQ3gzMVRxRDYtMERZYXNFRmYtTEw5XzRCcE5lVi1WLTB3bDBJUlVHMXhBdFJnamRUMkFhYnFqODBwSWR5YTlpdE04Tkdad2N3TVFpZWdzZzgwSXBEbHRnVG13cUxaWk9ZSE94QURrR0JicGt1c3l0MTM1RmNQNXpUVWVtcktWaDZ1aGs2dEgzNndZYlFwaWc0eDN6RHM2bFlFOC0tdEc5TFoyTXZIaV9vdW5yOW1JajA1OU96a0pyR2wza1dOQks2Q1E0Z0lUZkM5LTQyd1lMM1hRdnhodFkweS1tVjktYm8yT0Zsc1pnZmwxdkRTdG5FbmlQM2FyQTZKaGdUN1VzU3VoN0tFbXVHZmVUMDY2LVFnVEI0UzJoX2Q1UmpjUFhMazl5V003amVzQWQ0bV9tYzZCNGJiN1g0Q3BSbjE0UllBcDZ5eU5Ld3dtYVNMRXNReDhwN1h6UGVUQU1WSzRzem5DS3RfdDhmX2szeVhTbHFEdHUtbzVFQXJSckctNGI5VDMzd0tGYTdxN0RkUG5nLVlvaGh6Yy10VnRDcVZtS2dza0JHYjRjMGFIcWk0VFotV2hxbmlRMzZzVmJDLTNZTjVPMUFnQTEtNkpFVWZ0c2xhU2U3bmNSdGs3Vk1jTE5xOVNuNEdMRHRGOFo1TVF1UWJWYlpLemxuMVlaYTlsb1VGWWhNVG5zY1lFdGVqZnlweFc2SGZfZ29ka1diZDFvSHdqeTJkTjlJc2doUTRzTDd0a0pMY1V3bWFnVFBVMDRLVFEzZTRQcldZeklnVHhIX0RXUEhycndiMlZWODNRZXBKb05tOWF5cWxLSEhIQ3FYczBFbWozZ3R3djA2dEJvaTlUVlh5RlhaMU4xUkk0ZlFzWmg0U2c0c3lNNjJhY0FKZjhuS0hGTVdkV2NYQjhiZVBuNk1JMDhyVnJfbE9TckZsWDVJWk1PcXBCTlM0bW9aNTBFVGN0V2xDaWlTazJ5YVBSNVJORjJpdHBVd0VvbUZmVGxzTG9KQ1l6ZEg1Vm9OYjZFZG92QlVnYVVjcjM3Q2o0aEZkbGtqZG43Ny1OZVhlSGdQUWY4cTBzVDZocmtfSE9fVHBtYjkzbWF3aHE4R3praURoUy1R,"Sr. Data Engineer- AWS - Venture Backed Big Data Company
If you are an experienced Sr. Data Engineer (Fully Remote) with experience in Data Warehousing/Architecture, please read on!

With multiple offices and campuses across the US, we are an expanding enterprise BioInformatics Big Data company with a growing, global presence, dedicated to threat management and security supporting the expanding B2B communication and content management ecosystem. We are expanding our strategic operations team throughout the U.S., supporting our Global Infrastructure across our domestic and international datacenters.


If you have an excellent background in data pipelines, migrations, and data warehousing as well as Cloud Infrastructures (AWS Kubernetes, Azure, Google), please read on. If that's you, we'd love to speak with you!
Top Reasons to Work with Us
AWARD WINNING Culture + FOUNDATION ~Established Enterprise Customers (i.e. Macy's, Kohl's, Ulta Beauty)
EXCELLENT Compensation (150k - 180K + Merit Bonuses)
REMOTE Working (Continental US)
INCREDIBLE SUITE of Benefits (Medical, Vision, Dental, 401K Match)
What You Will Be Doing
The position involves working with multiple internal customers and groups, using industry standard tools and software, and creating resilient infrastructure on which to run applications and services.


Responsibilities
Design and implement a data warehouse to integrate multiple types of dataCompare different database platforms and tools for implementing warehouse, ETLT, and querying capabilitiesProvide justification for selection of most appropriate toolsWork with data visualization engineers to make data easily accessible to scientistsCollect, codify, and load data from animal health records and lab and multi-omics experiments into data warehouseBuild QC and validation tools to ensure the quality of warehouse data and resultsBuild and maintain data warehouse in the cloud
What You Need for this Position
Qualifications:
5+ years with data warehousing, data architecture, ETL data pipeline, data engineering environmentsExperience in database design and implementation; data warehouse experience preferable5+ years experience in software development; Python, Django or FlaskSchema Design and optimiaztionPostreSQLAWS, RedshiftExperience with iterative software design, and with working with users to iteratively improve our databases and software tools
What's In It for YouCompetitive Salary and BenefitsFully Remote401K MatchUnlimited VacationExcellent Benefits
So, if you are a talented Sr. Data Architect, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",bos,de
114,Intone Networks,Information Technology,4.4,Cloud/Data DevOps Engineer,"East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_95ec698d&cb=1618792859375&jobListingId=1007007715042&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-19f7e52a491f3122,"Years of Experience: 4-7 Requirements: DevOps background, Java, Python, AWS and/or GCP, some exposure to Big Data",bos,de
115,Moderna,Biotech & Pharmaceuticals,4.1,"Sr. Data Engineer, Informatics","Cambridge, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_b34f9b94&cb=1618792859376&jobListingId=1007001601595&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-e8dbe18c8dbe9d3d,"The Role:
We are looking for a collaborative and bold Sr. Data Engineer to join our Digital Informatics team, who has experience architecting and implementing technical solutions as part of a greater data analytics strategy. This role is responsible for hands on sourcing, manipulation and delivery of data from enterprise business systems to data lake and data warehouse. The Sr. Data Engineer will create, troubleshoot and support ETL pipelines and the cloud infrastructure involved in the process.
Here’s What You’ll Do:
Closely partner with business stakeholders and other technical team members to acquire and migrate initial data sources that are most relevant to business needs and goals.
Demonstrate deep technical and domain knowledge of relational and non-relation databases, Data Warehouses, Data lakes among other structured and unstructured storage options.
Determine which tools and architectures are best suited to develop a pipeline for a particular data source.
Develop data flow pipelines to extract, transform, and load data from various data sources in various forms, including custom ETL pipelines that enable model and product development.
Write custom scripts to extract data from unstructured/semi-structured sources.
Provide clear documentation for delivered solutions and processes, integrating documentation with the appropriate corporate stakeholders.
Identify and implement internal process improvements for data management (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability).
Stay current with and adopt new tools and applications to ensure high quality and efficient solutions.
Here’s What You’ll Bring to the Table:
BS/BA degree in Computer Science or equivalent with 8+ years of relevant experience
Minimum 5 years of experience designing, developing, testing, and implementing ETL solutions using any enterprise ETL tools.
Proven experience working with Cloud Environments, AWS preferred.
Experience working in regulated environments with GXP experience in pharma/biotech strongly preferred.
Extensive knowledge of data warehouse design and data modeling principles.
In-depth understanding of database management systems and scripting (SQL, NoSQL and distributed databases).
Experience with BI tools such as Spotfire and Looker preferred.
Scripting experience with Python.
Strong communication skills, a customer service attitude, and demonstrated problem solving ability.
Here’s What We’ll Bring to the Table:
On-site subsidized cafeteria or catered lunches
Company-provided iPhone
Free parking, monthly subway pass or a subsidized commuter rail pass
Free annual corporate membership to Bluebikes
Highly competitive healthcare coverage including: medical offered through BCBS (HMO/PPO), dental, and vision offered through VSP
Flexible Spending Accounts for medical expenses and dependent care expenses
16 weeks of 100% paid parental leave for all new parents
16 weeks 100% paid family caregiver leave
20 weeks 100% paid medical leave
Eligible for “Moderna Month” (one month paid sabbatical after five years of service and eligible for additional one month paid sabbatical every 3 years thereafter)
Adoption assistance and discounts to local childcare centers, as well as access to care.com
401k (traditional and Roth offered) with 50% match on first 6% deferred. Match is vested immediately
A suite of Moderna paid insurance coverage, including: life insurance, short-term and long-term disability
Voluntary legal assistance plan
15 days’ vacation and 7 sick days per year, in addition to a discretionary winter shut down and 11 company paid holidays (includes 2 floating holidays)
About Moderna:
In 10 years since its inception, Moderna has transformed from a science research-stage company advancing programs in the promising-but-still-unproven field of messenger RNA (mRNA), to an enterprise with its first medicine having treated millions of people, a diverse clinical portfolio of vaccines and therapeutics across six modalities, a broad intellectual property portfolio in areas including mRNA and lipid nanoparticle formulation, and an integrated manufacturing plant that allows for both clinical and commercial production at scale and at unprecedented speed. Moderna maintains alliances with a broad range of domestic and overseas government and commercial collaborators, which has allowed for the pursuit of both groundbreaking science and rapid scaling of manufacturing. Most recently, Moderna’s capabilities have come together to allow the authorized use of one of the earliest and most-effective vaccines against the COVID-19 pandemic.
Moderna’s mRNA platform builds on continuous advances in basic and applied mRNA science, delivery technology and manufacturing, and has allowed the development of therapeutics and vaccines for infectious diseases, immuno-oncology, rare diseases, cardiovascular diseases and auto-immune diseases. Today, 24 development programs are underway across these therapeutic areas, with 13 programs having entered the clinic. Moderna has been named a top biopharmaceutical employer by Science for the past six years. To learn more, visit www.modernatx.com .
Moderna is a smoke-free, alcohol-free and drug-free work environment.
Moderna is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person’s race, color, gender, age, religion, national origin, ancestry, disability, veteran status, genetic information, sexual orientation or any characteristic protected under applicable law. Moderna will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law.

",bos,de
116,"Flagship Pioneering, Inc.",Biotech & Pharmaceuticals,4.1,"Data Engineer/Architect, R&D Informatics","Cambridge, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_047b974f&cb=1618792859376&jobListingId=1007007750612&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-65375836f714e6cd,"We are seeking an experienced and driven colleague who shares our vision of data as a strategic asset and passion for organizing and mapping data to enable cutting edge research. You will be joining a creative and collaborative team of researchers dedicated to leveraging emerging insights in RNA biology to develop a novel class of oligonucleotide-based human therapeutics. In this role you will be creating data architecture in support of the company's R&D pipeline and building solutions that facilitate current projects and enable rapid growth. Please apply if you feel that you can contribute to growing our team and advance our mission.

Flagship Labs 63, Inc. was founded by Flagship Pioneering, an innovation enterprise that conceives, resources and grows first-in-category life science companies (including the now familiar drug and vaccine innovator, Moderna Therapeutics). The firm's institutional innovation foundry, Flagship Labs, is where teams of scientific entrepreneurs systematically evolve ideas and turn previously undiscovered areas of science into real-world ventures. Flagship has created over 100 scientific ventures resulting in >$19 billion in aggregate value, 500+ issued patents, and >50 clinical trials for novel therapeutic agents. Flagship's portfolio companies include Sana, Seres, Codiak, Rubius Therapeutics, and Indigo Agriculture.

As an early member of a privately held, well-funded, early-stage platform biotechnology company, you will have an opportunity to contribute to building our digital strategy and significant influence on technology platform development, with many options to apply your skills and talent as the company continues to expand.

Core Responsibilities:

Lead the data architecture/data engineering function of the FL63 R&D Informatics group
Maintain and optimize the current research informatics systems including electronic laboratory notebook software, research databases (reagent inventory, protocols and datamaps, testsets), and ensure FAIR principles across the entire company data universe
Building on the existing IT and research informatics systems, maintain and expand the infrastructure to include LIMS and integration with laboratory automation group
Serve as the liaison between R&D Informatics and research project teams, ensure that the data structure and tools match well with current and upcoming projects,
Develop tools that support data QC and curation. Develop, build, populate, and maintain platform-related databases and tools to query the information
Establish and maintain a data/process integration and best practices implementation function to ensure the data are captured in a timely manner and according to the SOP. Serve as a point person and in-house expert to train and enable researchers and other stakeholders to be aware of all relevant processes, tools and best practices related to data generation, capture, storage, and analysis
Support NGS data storage and processing, data lake organization and maintenance
Facilitate data mining and analytics; ensure that all company data are compatible with existing and planned research informatics pipelines; are ML/AI ready and compliant
Establish and maintain effective relationships with contract research organizations (CROs) and external consultants. Design, contract and manage work at CROs and external consultants to deliver functional modules and solutions.
Be a strong and vocal advocate for data quality and operation within FAIR data principles across the company
Help to build a world-class R&D Informatics team at FL63

Qualifications and Preferred Skills:

MS or Ph.D. degree in a scientific field coupled with relevant computational chemistry experience, including at least 3 years in an industrial setting
Established track record of successful research database construction, data mapping and warehousing; data cleanup and tagging
Demonstrated track record of building and implementing electronic laboratory notebooks, ELN – research database integration and two-way information flow
Understanding of and direct experience with using AWS and other cloud storage solutions for NGS data and other large datasets, understanding of data integration approaches and solutions
Deep understanding of visualization tools (Tableau, Spotfire, Excel graphing capabilities) and their application in research data reporting; generation of project dashboards and project/data reports
Skilled in clear and concise written communication, presentations targeted to various levels of the organization. Ability to present concepts and data to varied audiences that help drive decision-making
Excellent organizational skills, effective project leader

Core Values:

Fast-acting/efficient. Moves quickly and proactively with a strong work ethic to produce high-quality results while fostering a positive work environment. Focuses on key priorities. Demonstrates tenacity and willingness to go the distance to get something done.

Integrity. Does not cut corners ethically. Earns trust and maintains confidences. Does what is right not just what is politically expedient. Speaks plainly and truthfully. Follows-through on commitments. Expects a high level of personal performance and team performance.

Critical thinking. Learns quickly. Demonstrates ability to proficiently understand new information and independently achieve meaningful outcomes. Able to structure and process qualitative/quantitative data and draw insightful conclusions.

Creativity & Innovation. Generates new and creative approaches to problem solving. Positive 'can-do' attitude. Views the toughest challenges as the greatest opportunities for personal growth and company innovation.

Teamwork. Fully engaged in facilitating personal and team success. Reaches out to peers and cooperates with the team to establish an overall collaborative work environment. Often solicits and responds well to constructive feedback. Possesses good written and oral communication skills with the ability to clearly and concisely convey ideas and opinions.

Flexibility/adaptability. Adjusts quickly to changing strategic and tactical priorities. 'Wears multiple hats' and is comfortable with ambiguity.

Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, ""FSP"") do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering's internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.",bos,de
117,MassMutual,Insurance,3.9,Software Data Engineer,"East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_e63d8b3d&cb=1618792859376&jobListingId=1007006597263&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-772d60a92e1f8b9f,"Since 1851, MassMutual’s commitment has always been to help people protect their families, support their communities, and help one another. This is why we want to inspire people to Live Mutual. We are people helping people.
A career with us means you will work alongside exceptional people and be empowered to reach your professional and personal goals. Our employees are the foundation of what makes MassMutual a strong, stable and ethical business. We seek and value unique and varied perspectives and experiences because we believe we are stronger when all voices are heard. We invite you to bring your bright, innovative ideas to MassMutual as we continue to help millions of Americans rely on each other.
Together, we are stronger
What great looks like in this role
Our ideal candidate is someone who enjoys designing, building and delivering complex systems. You understand the complexities of data and the value that mature data platforms can provide in accelerating the development of new data projects. You love architecting simple solutions to difficult problems. You are comfortable developing multi-tiered enterprise applications and look to leverage 3rd party and open-source tools, as appropriate.
You keep current with new technologies and are team orientated, mentoring and leading others as needed. You are a good communicator and passionate about your work.
Objectives of the role
Design, develop and deliver scalable, robust and highly re-usable components using technologies such as Python, Java, AWS serverless (Lambda, Glue), Apache Spark, Apache Kafka and REST
Participate in all aspects of development from design to delivery, acting as both developer and component lead
Interact closely with data users, including data engineers and data scientists to understand & refine requirements
Develop code, unit tests and conducts code reviews
Debug and troubleshoots problems in code and data pipelines
Evaluate and recommend tools, technologies, processes and reference architectures
Identify areas for process improvement, automation and simplification (e.g. use of existing open source technologies)
Collaborate closely with other developers and provide mentorship as appropriate
Collaborate with other peer organizations (e.g., Business Analyst, Data Modeler, QA, technical support, etc.) to prevent and resolve technical issues
Work in Agile development environment, attending daily stand-up meetings and delivering incremental improvements.
Basic Qualifications
Strong experience using object-oriented and functional programming concepts; good grasp of design patterns and architectural principles
Python: Expertise building complex backend systems using modern technologies
Data: Good understanding of data & data processing tools (e.g. SQL, Spark, Kafka), of relational database technologies and of analytics databases (e.g. Redshift, Vertica, Snowflake)
Git: Expertise with workflow steps, including branching, merging, rebasing, pull requests; working knowledge of reversion and alternative git flows
CI/CD: Experience with CI/CD tools and processes and application deployment with Docker/Kubernetes
Testing: experience writing unit, integration, integration and load tests
Communication: Excellent communication, problem solving, organizational and analytical skills
Willingness to work as a full stack developer
Able to work independently and also to provide leadership to small teams of developers
Preferred Qualifications
Development: 6+ years Python development, 6+ years Java development
Cloud: Experience building with and deploying to cloud platforms such as AWS and leveraging serverless architectures (e.g. Lambda, Glue)
Big Data & Streaming: 2+ years using big data and/or streaming technologies (e.g. Apache Spark, Apache Kafka, Apache Flink)
Data Platforms: Good understanding of modern data platform design (e.g. ingestion, governance, transformation)
APIs: Proficiency with one or more RESTful Frameworks (Java Spring boot and/or Python Django) and with creating API specifications (e.g. using Swagger)
UI: Experience developing with 1 or more JavaScript frameworks (e.g. Angular, ReactJS, Vue)
Documentation: proficiency writing wiki pages for technical documentation including troubleshooting, tutorials, and reference material
MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status.",bos,de
118,Harvard University,Education,4.4,Principal Data Engineer,"East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_4b11dc6a&cb=1618792859376&jobListingId=1007004696234&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-28956ae6e52bc1fe,"Job Summary
Lead comprehensive applications/web development for highly complex projects; typically work as part of a team to implement complex business solutions. Deliver strategic and expert coding; focus on overarching development strategy for a large, complex, multi-faceted application. May manage a number of projects simultaneously.
Job-Specific Responsibilities
The Center for Computational Biomedicine (CCB) is a new center within the Blavatnik Institute at Harvard Medical School. Our mission is to provide cutting-edge computational capabilities, data analysis, and data integration technologies to support medical and biological research within the Medical School.

We seek a highly motivated, collaborative individual with excellent communication skills to join our team of technologists and scientists as a Principal Data Engineer. You will help build out the necessary data warehousing infrastructure to support the downstream machine learning analysis and integration of large, complex data sets that will provide a nuanced longitudinal perspective on population- and individual-level health outcomes and disease trajectories. These data sets include healthcare insurance claims, electronic health records, genomics, environmental exposure, and other data modalities. The integration of these data will allow our research teams to make ground-breaking advances in the areas of precision medicine, healthcare AI, healthcare policy/economics, and basic science, all with the goal of improving patient outcomes.
In this role, you will work to develop innovative solutions for warehousing and integrating these large data resources. You will have frequent opportunities to dive deep to troubleshoot complex technical issues in large data management systems, working hand-in-hand with our world-class Information Technology and Research Computing teams. Your work will involve a wide variety of technologies including analytic relational data warehouses (column and row stores), graph databases, array databases, object stores, key/value stores, scale-up and scale-out storage platforms, containerized services, and others. Solutions will be deployed both on-premises and in private and public cloud environments.
Typical Core Duties
Participate fully in software development life cycle
Lead development of technical solutions to deliver business requirements
Participate in long term strategic planning for the application portfolio(s)
Establish and maintain internal/external stakeholder relationships
Abide by and follow the Harvard University IT technical standards, policies and Code of Conduct
Basic Qualifications
Minimum of seven years’ post-secondary education or relevant work experience
Additional Qualifications and Skills
MS in Computer Science or related field, with expertise in relational database technologies and 2+ years experience in enterprise data management and data warehousing, or an undergraduate degree in Computer Science with 5+ years experience preferred
Proven understanding of database modeling concepts: entities/tables, relations/constraints, attribute data types, and column data times, with proficiency in SQL
Strong software engineering experience, with a thorough grasp of IT concepts, design and development tools, system architecture and technical standards, shared software concepts, and layered solution and designs
Proven understanding of database modeling concepts: entities/tables, relations/constraints, attribute data types, and column data times, with proficiency in SQL
Strong software engineering experience, with a thorough grasp of IT concepts, design and development tools, system architecture and technical standards, shared software concepts, and layered solution and designs
Experience designing and maintaining multi-terabyte analytic relational databases, including index and query optimization
Experience collaborating with information security teams and working within compliance and data governance constraints
Experience with Microsoft SQL Server or cloud-based data warehousing technologies
Experience with non-relational database systems (graph, key/value, document, array data stores)
Certificates and Licenses
Completion of Harvard IT Academy specified foundational courses (or external equivalent) preferred
Working Conditions
Work is performed in an office setting
Additional Information
This is a one-year term position with strong potential for renewal.

We are committed to cultivating an inclusive workplace culture of faculty, staff, and students with diverse backgrounds, styles, abilities, and motivations. We appreciate and leverage the capabilities, insights, and ideas of all individuals. Harvard Medical School Mission and Community Values

Harvard University offers an outstanding benefits package including:
Time Off: 3 - 4 weeks paid vacation, paid holiday break, 12 paid sick days, 12.5 paid holidays, and 3 paid personal days per year.
Medical/Dental/Vision: We offer a variety of excellent medical plans, dental & vision plans, all coverage begins as of your start date.
Retirement: University-funded retirement plan with full vesting after 3 years of service.
Tuition Assistance Program: Competitive tuition assistance program, incredibly affordable classes directly at the Harvard Extension School, and discounted options through participating Harvard grad schools.
Transportation: Harvard offers a 50% discounted MBTA pass as well as additional options to assist employees in their daily commute.
Wellness options: Harvard offers programs and classes at little or no cost, including stress management, massages, nutrition, meditation, and complementary health services.
Harvard access to athletic facilities, libraries, campus events, and many discounts throughout metro Boston.
The Harvard Medical School is not able to provide visa sponsorship for this position.

Not ready to apply? Join our Talent community to keep in touch and learn about future opportunities!
https://app.jobvite.com/TalentNetwork/action/campaign/w/NzM2NjU
Job Function
Information Technology
Location
USA - MA - Boston
Job Code
I0759P Applications Professional V
Sub-Unit
-
Department
Department of Biomedical Informatics
Time Status
Full-time
Salary Grade
059
Union
00 - Non Union, Exempt or Temporary
Pre-Employment Screening
Criminal, Education, Identity
Schedule
35 hrs. per week | Monday - Friday | 9:00 am - 5:00 pm
EEO Statement
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",bos,de
119,Splunk,Information Technology,4.1,"Data Engineer, DevOps - Remote OK","East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_d43ec9b8&cb=1618792859376&jobListingId=1007008052896&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-a270d33c63751e92,"As a Data DevOps Engineer in the Enterprise DataWarehouse team you will work closely with a team of Data, Business Intelligence and Dev/Prod Ops engineers to help automate CI/CD deployment in a consistent and reliable way to non-production and production data infrastructure, at scale. As part this team, you will build CI/CD automation across GitLab/Github/Bitbucket, Airflow, Python ETL/ELT, Database scripts, containerization (Docker) and container-orchestration systems such as Kubernetes. You will work towards supporting deployment, data flow architecture and automation to deliver the highly available, performant and secure environments of Splunk’s Enterprise Data Warehouse.
Responsibilities
Iterate on release management methodologies to increase the quality & velocity of data warehouse deployments. Deploy and maintain CI/CD pipelines across multiple environments
You will collaborate with Production Engineering team’s on-call responsibilities in rotation.
Experience working with Python based ETL/ELT, API and Cloud Data Warehouse databases. Data warehousing, Data Engineering experience, particularly with Snowflake is a plus.
Design, develop and operate terabyte-scale data pipelines and services that meet goals of low latency, high availability, resiliency, security and quality .
Define best practices, work with data engineering teams on best practices and ensure they are followed. Teach others how to do the right things. Automate everything.
Enable self-service as much as possible via automation so that application teams can do what they need without you, focus on the engineering aspect primarily
Automate schema updates/migration via common pipelines and pattern to be used by application teams in their deployment processes
Requirements:
8+ years of relevant work experience surrounding CI/CD, Test Automation and data infrastructure operations.
Demonstrated ability to develop advanced CI/CD pipelines in GitLab, Python, Airflow (e.g. using dynamic data pipelines, automated unit testing, performance testing, etc.)
Experience in writing and troubleshooting ETL jobs (Python, Airflow) and complex database SQL scripts.You have a strong python programming background in writing clean, testable code. Develop monitors and build alerts around error conditions and performance.
Experience in data technologies server administration, SLA/incident management, RBAC automation and controls, user communication and support.
Strong problem solving skills and ability to work independently or in team settings on complex production issues. Participate in On-Call support as needed.",bos,de
120,Thermo Fisher Scientific,Biotech & Pharmaceuticals,3.8,Data Engineer(IES),"East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_03021268&cb=1618792859376&jobListingId=1007003859229&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-1b8606f4cff76a15,"What Will You Be A Part Of?

When you’re part of the team at Thermo Fisher Scientific, you’ll do important work, like helping customers in finding cures for cancer, protecting the environment or making sure our food is safe. Your work will have real world impact, and you’ll be supported in achieving your career goals.

Where Will You Be?

Launched in 2011 to enhance customer productivity, the Instrument and Enterprise Services (IES) division provides a single source for integrated lab service, support and supply management. IES encompasses over 3600 hard-working global service professionals with the broadest service portfolio in the market coupled with access to a deep bench of domain expertise.

How Will You Make An Impact?

Enabling our internal teams at scaled, Data Engineer will join our IES Data and Analytics team and will be responsible for data engineering and analytics for IES Organization working with Corporate IT team members to develop data driven applications and automations across a variety of infrastructure(both On-Prim and Cloud). Data Engineer must be able to collaboratively work in an Agile team to design, develop and maintain data structures for the Enterprise data platform. This position offers an exciting opportunity to work on processes that interface with multiple systems including AWS, Oracle, Middleware and ERPs. The candidate will lead development projects, pilots, and advance best design practices.

What Will You Do?
Develop, Improve and Support data engineering solutions for IES organization
Investigate and effectively partner with core team to address data quality
Design, develop, test, deploy, and maintain mission critical IES data applications
Design, develop, test, deploy, support, enhance data integration solutions seamlessly to connect and integrate Enterprise systems into our Enterprise Data Warehouse and Data Platforms.
Innovate for data integration in Apache Spark-based Platform to ensure the technology solutions leverage cutting edge integration capabilities.
Facilitate requirements gathering and process mapping workshops, review business/functional requirement documents, author technical design documents, testing plans and scripts.
Assist with implementing standard operating procedures, facilitate review sessions with functional owners and end-user representatives, and leverage technical knowledge and expertise to drive improvements.

How Will You Get Here?
Have strong experience in data lake, data analytics, big data or business intelligence products
Ability to work independently and as a member of a cross-functional team
Willingness to learn, be mentored, and improve
Is passionate about applications, data analytics, end-user productivity
Exceptional customer focus
Desire to teach other team members about technology in the area of expertise
Experience on project management framework Agile (Jira toolset)
Master's degree in computer science engineering from an accredited university (desired)
4-year degree with major in computer science engineering (or equivalent) from an accredited university (preferred) will substitute for minimum 5 years’ professional IT experience.
Experience in ETL/ELT(Data extraction, data transformation and data load processes)
Experience in Data lake, analytics & visualizations
Experience in Oracle, SQL Server or AWS Redshift type databases

Tool & Technology Skills
Overall, 5-6 years of experience in the Enterprise Data Warehouse Development environment
3-5 years of experience at Enterprise-level ETL development & architecture in Informatica Power Center 10.x and Informatica Cloud environment.
Use Microsoft Power BI and Microsoft Excel: Pivot Table, Power Query, Power Pivot, and Data Models to gather information from multiple sources and deliver information to the end user.
Act as a Microsoft Power BI, visualization, and dash-boarding subject matter expert
2+ years working experience in data integration and pipeline development.
2+ years of Experience with AWS Cloud on data integration with Apache Spark, Databricks, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems
2 - 3 years of experience working (Agile/Waterfall) environment
1 - 2 years of computer programming in Python, R, MATLAB, etc
Demonstrated skill and ability in the development of data warehouse projects/applications (Oracle & SQL Server)
Strong real-life experience in python development especially in pySpark in AWS Cloud environment.
Design, develop test, deploy, maintain and improve data integration pipeline.
Experience in Python and common python libraries.
Strong analytical experience with database in writing complex SQL queries, query optimization, debugging, user defined functions, views, indexes etc.

Knowledge, Skills, Abilities
Highly self-driven, execution-focused, with a willingness to do ""what it takes” to deliver results as you will be expected to rapidly cover a considerable amount of demands on data integration
Strategic Thinking - Think big picture. Set priorities aligned with major goals. Encourage innovation by backing good people who take smart risks.
Critical Thinking - Question conventional wisdom by identifying and challenging assumptions made that cause actions or inaction. Strive to inject independent thinking, checking biases, promotes action and decision-making.
Communication - communicate effectively in the way reach audiences with ease, clarity, and transparency: one-to-one, small group, full staff, email, social media, and of course, listening.
Provide organizational support for relationship development to foster teamwork, build relationships, and promote collaboration to cultivate and strengthen a network for the exchange of ideas
Problem-solving (analytical)",bos,de
121,Kagr Llc,"Arts, Entertainment & Recreation",4.3,Data Engineer 3,"Foxborough, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_638bb228&cb=1618792859377&jobListingId=1007008299798&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-5d49eeecf75e0d75,"SUMMARY:
The Data Engineer 3 will drive the planning, design, and development of integration processes to build and improve the data warehouse. The Data Engineer will be responsible for performing ETL and ELT from many disparate systems into the data warehouse and will have the opportunity to complete projects from beginning to end.

DUTIES AND RESPONSIBILITIES
Data Integration
Using the enterprise ETL tool, create modify, and improve integration pipelines
Translate business requirements into data warehouse pipelines using ETL/ELT methodologies
Extract and load many disparate systems into a centralized data warehouse
Assist in gathering requirements for new pipelines
Documentation and Data Auditing
Implement data auditing strategies and processes to ensure data integrity
Document complex integration pipelines into easy-to-understand technical specifications
Perform data modeling to document existing and new tables in the data warehouse
BIDW Continuous Development
Monitor and troubleshoot data problems
Identify ways to improve existing processes
Handle multiple projects and meet deadlines
Special projects and assignments as business dictates
Responsible for the maintenance, creation and control of all personally identifiable information or any other information protected by any Confidentiality or Privacy Standards or Company policies that you have access or knowledge of, including but not limited to any state or federal regulations including HIPAA
SUPERVISORY RESPONSIBILITIES
This position has no supervisory responsibilities.

SKILLS AND QUALIFICATIONS
Bachelor's Degree in Computer Science, Information Systems, or related field.
3-5 years of experience working with data using SQL or similar technology
3+ years of experience using a data integration platform, such as Snaplogic, SSIS, or Informatica
Strong understanding of data warehousing principles and methodologies
Ability to manage multiple projects in a fast-paced environment
Strong communication skills to all levels of technical expertise
Very high attention to detail
Familiarity with BI Visualization tools
PHYSICAL DEMANDS
Sitting for extended periods of time
Dexterity of hands and fingers to operate a computer keyboard, mouse, and other computing equipment
The employee frequently is required to talk or hear
The employee is occasionally required to reach with hands and arms
Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

WORK ENVIRONMENT
The noise level in the work environment is usually moderate
Fast paced office environment
Ability to work nights and weekends as business dictates
CERTIFICATES, LICENSES, REGISTRATIONS
None required

OTHER DUTIES
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.

This company is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.",bos,de
122,Splunk,Information Technology,4.1,Senior Data Engineer,"East Boston, MA",$140K - $200K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136043&s=58&guid=00000178e792c5559fc171d38f63f9bd&src=GD_JOB_AD&t=SR&vt=w&cs=1_3a9b993f&cb=1618792859377&jobListingId=1007008052912&jrtk=1-1f3jp5hbou4tt801-1f3jp5hcau52v800-384b692d4359421b,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.
As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.
What you'll do: Yeah, I want to and can do that.
Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.
Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.
Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.
Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.
Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.
Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.
Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.
Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.
Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.
Requirements: I’ve already done that or have that!
8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data Scientist
Savviness with complex SQL queries and knowledge of database technologies including window and analytical functions
Experience with Python analytic libraries and Business Intelligence tools such as Tableau.
An ability to provide technical guidance, direction and problem solving to data engineering team members.
Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.
A familiarity working with an AGILE/SCRUM process management.
Preferred knowledge and experience: These are a huge plus.
Knowledge of Splunk products
Agile certifications
Education: Got it!
Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.
What We Offer You: Wow, I want that.
A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.
A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.
Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.
A stable, collaborative and supportive work environment.
We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment
This isn’t a job – it’s a life changer – are you ready?
Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.
Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",bos,de
0,PATRA,Insurance,3.7,Data Engineer - Remote,"Chicago, IL",$77K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178e79503f08136d01c5a150566&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_7cb4ff06&cb=1618793006533&jobListingId=4059226195,"About PatraPatra is a leading provider of Technology-Enabled Services to the insurance industry. Patra's team of global experts allow brokers, MGAs, wholesalers and carriers to capture the Patra Advantage - profitable growth and organizational value.Patra powers insurance processes by optimizing the application of people and technology; supporting insurance organizations as they sell, deliver and manage policies for their customers.About this jobAs part of the Data & Analytics team, the Data Engineer will facilitate the development of enterprise data management solutions in support of Patra's strategic initiatives. This individual will work closely with Data Analysts and Data Scientists to develop and implement data strategies that support the democratization, integration, and standardization of data at an enterprise level, ensuring consistency of business definitions and data quality. The ideal candidate will possess strong technical and communication skills, as well as proven experience in data management, information management, and the insurance industry in general.Core DutiesProvide Business Intelligence and Data Warehousing solutions in support of analyticsBuild a robust, fault-tolerant data pipeline that cleans, transforms, and aggregates unorganized and messy data into databases or data sourcesWork with business teams to define requirements and translate to dataRecommending new data streams and ensuring data integritySupporting and providing data in a ready-to-use form to data scientists who are looking to run queries and algorithms against the information for predictive analytics, machine learning and data mining purposes.Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leaderIdentifying new projects and opportunities, and the associated data requirementsMaintain technical knowledge by attending educational workshops, reviewing publications, establishing personal networks, and participating in technical societiesMinimum Requirements - Education & ExperienceBachelor's degree in Computer Science or related technical degreeWork experience as a data engineer or in related field, 5-10 years preferredMaster's degree preferredP&C Insurance and Consulting experience preferredMicrosoft BI Certified Engineer preferredKnowledge, Skills and AbilitiesAbility to analyze existing tools and databases, and provide recommendationsAbility to translate business requirements into non-technical, lay termsIntermediate to Advanced working SQL knowledge and experience working with relational databases as well as working familiarity with a variety of databases.Understanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball)Experience in methodologies and processes for managing large scale databases on premise as well as cloud solutionsExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementDemonstrated experience in handling large datasets, structured and semi-structured data formatsBuild processes supporting data transformation, data structures, metadata, dependency and workload managementA successful history of manipulating, processing and extracting value from large disconnected datasets.Understanding of metadata standardsWorking ConditionsWork from homeMinimum internet speed of 6 mbps download and 3 mbps upload; no satelliteCompensationCompetitive Salary / Benefits / PTOPhysical Requirements*Constantly perform desk-based computer tasksFrequent sittingOccasionally stand/walk, writing by hand, use of telephone, lift/carry/push/pull objects that weigh 11-20 poundsSort/file paperwork, rarely twist/bend/stoop/squatConsistent with its obligations under the law, the Patra Corp will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.Work StandardsInterpersonal Skills: Demonstrates the ability to work well with Patra colleagues and clients and with external organizationsPromotes Culture of Respect & Safety: Demonstrates commitment to personal responsibility and value for safety and respect; communicates concerns; uses and promotes safe respectful behaviors based on training and lessons learnedSubject to and expected to comply with all applicable Patra Corp policies and procedures",chi,de
1,PATRA,Insurance,3.7,Data Engineer,"Chicago, IL",$77K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000178e79503f08136d01c5a150566&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_18fd9d75&cb=1618793006533&jobListingId=4059226220,"About PatraPatra is a leading provider of Technology-Enabled Services to the insurance industry. Patra's team of global experts allow brokers, MGAs, wholesalers and carriers to capture the Patra Advantage - profitable growth and organizational value.Patra powers insurance processes by optimizing the application of people and technology; supporting insurance organizations as they sell, deliver and manage policies for their customers.About this jobAs part of the Data & Analytics team, the Data Engineer will facilitate the development of enterprise data management solutions in support of Patra's strategic initiatives. This individual will work closely with Data Analysts and Data Scientists to develop and implement data strategies that support the democratization, integration, and standardization of data at an enterprise level, ensuring consistency of business definitions and data quality. The ideal candidate will possess strong technical and communication skills, as well as proven experience in data management, information management, and the insurance industry in general.Core DutiesProvide Business Intelligence and Data Warehousing solutions in support of analyticsBuild a robust, fault-tolerant data pipeline that cleans, transforms, and aggregates unorganized and messy data into databases or data sourcesWork with business teams to define requirements and translate to dataRecommending new data streams and ensuring data integritySupporting and providing data in a ready-to-use form to data scientists who are looking to run queries and algorithms against the information for predictive analytics, machine learning and data mining purposes.Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leaderIdentifying new projects and opportunities, and the associated data requirementsMaintain technical knowledge by attending educational workshops, reviewing publications, establishing personal networks, and participating in technical societiesMinimum Requirements - Education & ExperienceBachelor's degree in Computer Science or related technical degreeWork experience as a data engineer or in related field, 5-10 years preferredMaster's degree preferredP&C Insurance and Consulting experience preferredMicrosoft BI Certified Engineer preferredKnowledge, Skills and AbilitiesAbility to analyze existing tools and databases, and provide recommendationsAbility to translate business requirements into non-technical, lay termsIntermediate to Advanced working SQL knowledge and experience working with relational databases as well as working familiarity with a variety of databases.Understanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball)Experience in methodologies and processes for managing large scale databases on premise as well as cloud solutionsExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementDemonstrated experience in handling large datasets, structured and semi-structured data formatsBuild processes supporting data transformation, data structures, metadata, dependency and workload managementA successful history of manipulating, processing and extracting value from large disconnected datasets.Understanding of metadata standardsWorking ConditionsWork from homeMinimum internet speed of 6 mbps download and 3 mbps upload; no satelliteCompensationCompetitive Salary / Benefits / PTOPhysical Requirements*Constantly perform desk-based computer tasksFrequent sittingOccasionally stand/walk, writing by hand, use of telephone, lift/carry/push/pull objects that weigh 11-20 poundsSort/file paperwork, rarely twist/bend/stoop/squatConsistent with its obligations under the law, the Patra Corp will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.Work StandardsInterpersonal Skills: Demonstrates the ability to work well with Patra colleagues and clients and with external organizationsPromotes Culture of Respect & Safety: Demonstrates commitment to personal responsibility and value for safety and respect; communicates concerns; uses and promotes safe respectful behaviors based on training and lessons learnedSubject to and expected to comply with all applicable Patra Corp policies and procedures",chi,de
2,Uline,Manufacturing,3.6,Financial Data Analyst (North of Chicago),"Chicago, IL",$65K - $79K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_2d02705f&cb=1618793006533&jobListingId=4062980309,"Financial Data AnalystCorporate Headquarters12575 Uline Drive, Pleasant Prairie, WI 53158At Uline, Finance isn’t just about the numbers; it’s about supporting the entire business.Better together than apart. This position is on-site, and we are looking for good people who share our passion.Uline is proud to operate as a drug-free workplace. All new hires must complete a pre-employment hair follicle drug screening.Position ResponsibilitiesAnalyze current manual processes for improvement opportunities.Define problem scope and think critically about potential solutions.Develop process-improvement solutions that make use of Excel / VBA to automate procedures.Minimum RequirementsBachelor's degree in finance or accounting.Strong analytical skills with attention to detail and accuracy.Adept at creating queries, writing reports and presenting findings.Strong SQL skills a must.VBA (or similar) programming knowledge required.BenefitsComplete insurance coverage that includes medical, dental, vision and life insurance, Flexible Spending Accounts and wellness programs.401(k) with a 5% employer match.Paid holidays and generous paid time off.Bonus programs that include annual performance, sales goals and profit sharing.Scholarship program for children of employees.Employee PerksOn-site café with executive chefs and seasonal dinner-to-go options.First-class fitness center with complimentary personal trainers.Over four miles of beautifully maintained walking trails.Numerous employee appreciation events throughout the year.Professional development classes and monthly in-house speakers.About UlineUline is North America's leading distributor of shipping, industrial and packaging materials. We're a family-owned company known for incredible service, our 800+ page catalog of over 38,500 quality products and same-day shipping of our huge in-stock inventory. With over 7,000 employees across 12 locations, it's time you joined Uline.Uline provides the essential supplies needed to keep organizations operational and productive. To protect the health and safety of our employees, we have modified our normal operating policies in response to COVID-19.Each resume submitted gets individually reviewed by our team and retained for 24 months in case a great opportunity opens for you to join our Uline family.EEO/AA Employer/Vet/Disabled#LI-TE1#CORP",chi,de
3,Trexin Consulting,Business Services,4,Big Data Senior Developer,"Chicago, IL",$98K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044077&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ddd0cd71&cb=1618793006533&jobListingId=4063411497,"Founded on the principles of trust, experience, and innovation, Trexin Consulting specializes in strategy execution – the effective implementation of business strategy to achieve a specific business goal. Also referred to as applied strategy, strategy execution situations that Trexin frequently leads include: scaling capabilities for growth, optimizing operations for cost reduction, driving synergies for M&A, and recovering projects in distress. Trexin’s services are right-sized for our Clients’ needs, ranging from our “Diamond Team” service when our Clients want Trexin to own an outcome and share delivery risk, to Expert/Advisory services for senior-level guidance, to Strategic Staffing services for execution-oriented tasks and roles. Our expertise spans Healthcare, Life Sciences, Financial Services, and Products & Distribution, overlaid by multidisciplinary skills in the five capabilities essential to executing strategy: Aligned Enterprise, Program Execution, Technology, Innovation, and Analytics.Trexin Consulting is currently seeking a Big Data Senior Developer contractor to join our team in Chicago/Dallas and consult at our Healthcare client.Key Areas of Responsibility: Ownership, maintenance, and support of a Hadoop data lake, supporting incident and problem resolution and providing end-to-end resolution to ensure completion of all jobs within defined objectivesCoordination of platform maintenance, including change and release management (planned and emergency deployments, configuration, and patching)Real-time system monitoring (custom and off-the-shelf tools) and engineer and implementcustom monitoring solutions if neededParticipation of Run books developmentEngagement with applications development teams and other platform owners as necessaryResponsible to ensure that the applications met their required service levelResponsible to support process improvements to continuously improve the stability and performance of the platformIdentify system bottlenecks and opportunities for process improvementsPerform in-depth research and identify sources of production issuesEffectively perform root cause analysis of issues and report outcomes to business community and ManagementDevelop / utilize core support tools and processes to perform work while improving day-to-day practices for support team members with the goal of delivering service improvements to the businessKey Desired Skills, Experience and Knowledge:Extensive hands-on experience in designing, developing, and maintaining software solutions on Big Data platform such as Hadoop eco-system.Experience with strong UNIX shell scriptingExperience with one of the IDE tools such as Eclipse.Working experience with Spark and Scala/Python.Preferred experience with developing Pig scripts/Hive QL, HBASE, SQOOP, UDF for analyzing all semi-structured/unstructured/structured data flows.Preferred experience with developing MapReduce programs running on the Hadoop cluster using Java/Python.Not mandatory but a big advantage to have prior experience using Talend with Hadoop technologies7-10+ years of professional experience in ITBS/BA Degree in Computer Science or related fieldStrong communication skills, with prior experience in requirements gathering and working with SMEs and Stakeholders at various leadership level.Strong experience with SDLC Methodology - Agile / Scrum / Iterative Development and utilization of Agile management tooling like JIRA. Be able to take user stories and work with teams to organize them into tasks, sprints, releases as well as some experience in backlog grooming, change management tasks, etc.Knowledge of Data Modeling, Data Warehousing and ETL security and permission schemesKnowledge of at least one RDBMS such as Hadoop, DB2 / TeradataExposure to Big Data patterns and data formats.Ability to support project and/or product teams on functional and technical design activities; acting as Subject Matter Expert (SME); basic knowledge of project mgmt. functionsSharp problem-solving, analytical and innovation skillsStrong oral/written communication skills with the ability to translate complex ideas into simple language for non-techniciansKeen leadership and project management skills, ability to drive projects from inception to completionPrevious experience from a management consulting environment desirableTrexin is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. Trexin is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Trexin are based on business needs, job requirements, and individual qualifications. Trexin strictly prohibits and does not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth, or related medical conditions), gender (including gender nonconformity and status as a transgender individual), sexual orientation, age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state, or local law.Trexin complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Trexin will reasonably accommodate qualified individuals with a disability if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. Trexin will also, where appropriate, provide reasonable accommodations for an employee's religious beliefs or practices. Trexin strictly prohibits discrimination against protected veterans, and Trexin utilizes affirmative action to recruit, hire, promote, and retain veterans.Trexin Consulting does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Trexin Consulting vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Trexin Consulting Recruiting Team and such candidate was submitted to the Trexin Consulting Recruiting Team via our Applicant Tracking System.Job Types: Full-time, ContractPay: $1.00 per yearWork Location:Multiple locations",chi,de
4,Trexin Consulting,Business Services,4,Big Data Technical Development Lead,"Chicago, IL",$82K - $148K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044077&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a1482ee6&cb=1618793006533&jobListingId=4063411502,"Founded on the principles of trust, experience, and innovation, Trexin Consulting specializes in strategy execution – the effective implementation of business strategy to achieve a specific business goal. Also referred to as applied strategy, strategy execution situations that Trexin frequently leads include: scaling capabilities for growth, optimizing operations for cost reduction, driving synergies for M&A, and recovering projects in distress. Trexin’s services are right-sized for our Clients’ needs, ranging from our “Diamond Team” service when our Clients want Trexin to own an outcome and share delivery risk, to Expert/Advisory services for senior-level guidance, to Strategic Staffing services for execution-oriented tasks and roles. Our expertise spans Healthcare, Life Sciences, Financial Services, and Products & Distribution, overlaid by multidisciplinary skills in the five capabilities essential to executing strategy: Aligned Enterprise, Program Execution, Technology, Innovation, and Analytics.Trexin Consulting is currently seeking a Big Data Technical Development Lead contractor to join our team in Chicago/Dallas and consult at our Healthcare client.Key Areas of Responsibility: Ownership, maintenance, and support of a Hadoop data lake, supporting incident and problem resolution and providing end-to-end resolution to ensure completion of all jobs within defined objectivesCoordination of platform maintenance, including change and release management (planned and emergency deployments, configuration, and patching)Real-time system monitoring (custom and off-the-shelf tools) and engineer and implementcustom monitoring solutions if neededParticipation of Run books developmentEngagement with applications development teams and other platform owners as necessaryResponsible to ensure that the applications met their required service levelResponsible to support process improvements to continuously improve the stability and performance of the platformIdentify system bottlenecks and opportunities for process improvementsPerform in-depth research and identify sources of production issuesEffectively perform root cause analysis of issues and report outcomes to business community and ManagementDevelop / utilize core support tools and processes to perform work while improving day-to-day practices for support team members with the goal of delivering service improvements to the businessKey Desired Skills, Experience and Knowledge:Strong Experience with designs, troubleshooting, identifying technical challenges, etc. from a leadership perspectiveExtensive hands-on experience in designing, developing, and maintaining software solutions on Big Data platform such as Hadoop eco-system.Experience with strong UNIX shell scriptingExperience with one of the IDE tools such as Eclipse.Working experience with Spark and Scala/Python.Preferred experience with developing Pig scripts/Hive QL, HBASE, SQOOP, UDF for analyzing all semi-structured/unstructured/structured data flows.Preferred experience with developing MapReduce programs running on the Hadoop cluster using Java/Python.Not mandatory but a big advantage to have prior experience using Talend with Hadoop technologies10-12+ years of professional experience in ITBS/BA Degree in Computer Science or related fieldStrong communication skills, with prior experience in requirements gathering and working with SMEs and Stakeholders at various leadership level.Strong experience with SDLC Methodology - Agile / Scrum / Iterative Development and utilization of Agile management tooling like JIRA. Be able to take user stories and work with teams to organize them into tasks, sprints, releases as well as some experience in backlog grooming, change management tasks, etc.Knowledge of Data Modeling, Data Warehousing and ETL security and permission schemesKnowledge of at least one RDBMS such as Hadoop, DB2 / TeradataExposure to Big Data patterns and data formats.Ability to support project and/or product teams on functional and technical design activities; acting as Subject Matter Expert (SME); basic knowledge of project mgmt. functionsSharp problem-solving, analytical and innovation skillsStrong oral/written communication skills with the ability to translate complex ideas into simple language for non-techniciansKeen leadership and project management skills, ability to drive projects from inception to completionPrevious experience from a management consulting environment desirableTrexin is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. Trexin is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Trexin are based on business needs, job requirements, and individual qualifications. Trexin strictly prohibits and does not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth, or related medical conditions), gender (including gender nonconformity and status as a transgender individual), sexual orientation, age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state, or local law.Trexin complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Trexin will reasonably accommodate qualified individuals with a disability if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. Trexin will also, where appropriate, provide reasonable accommodations for an employee's religious beliefs or practices. Trexin strictly prohibits discrimination against protected veterans, and Trexin utilizes affirmative action to recruit, hire, promote, and retain veterans.Trexin Consulting does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Trexin Consulting vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Trexin Consulting Recruiting Team and such candidate was submitted to the Trexin Consulting Recruiting Team via our Applicant Tracking System.Job Types: Full-time, ContractPay: $1.00 per yearWork Location:Multiple locations",chi,de
5,Echo Global Logistics,Transportation & Logistics,3.7,Staff Data Science Engineer,"Chicago, IL",$96K - $174K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_48e89f29&cb=1618793006534&jobListingId=4062309483,"At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo! Echo Global Logistics is a leading provider of technology-enabled transportation management services. As a third-party logistics provider, we simplify transportation management for our clients and carriers, handling crucial tasks so they can focus on what they do best. From coast to coast, dock to dock, and across all major transportation modes, Echo connects businesses that need to ship their products with carriers who transport goods quickly, securely, and cost-effectively.Position Overview:As a Staff Data Science Engineer on the Echo Global Logistics team, you will contribute to engineering of large scale web-based applications to enable Echo’s business while supporting architectural vision of quality, scalability, performance and function. Our proprietary software is created with the goal to simplify transportation for our customers and carriers, and is one of our largest competitive advantages in an ever growing market.Echo Global Logistics was recently ranked in 2020 by Crain's Business as a Top 25 Tech Company in Chicago and we are continuing to see increased growth in virtually all of our technical teams. We look forward to continued success with you as part of our team!What You’ll Do:Build and maintain machine learned models, algorithms and scalable automated data pipelines from the ground up to solve for real-world business challenges.Lead the data science engineering practice within the IT organization, mentor members of the team, represent the practice to groups outside of the IT organization.Lead the evaluation and adoption of new technologies and techniques.Strategically partner with various Echo stakeholders and business teams to understand measurement requirements, help define them into Key Performance Indicators. Then, working with the Data Science Engineering team, drive and deliver insights and business operation improvements through reliable, regular and repeatable data models and/or data services.Strategically partner with other data science teams to build and improve prescriptive analytics and predictive modeling.Work with Echo's data engineering and product teams to define and validate data sources, instrumentation, and operational data flow.Support regular ad-hoc data and analysis needs to better understand customer and/or stakeholder behaviors. Support teams in running growth programs and A/B tests through analyzing results and communicating findings and insights.Understand, monitor, QA, translate, collaborate with business teams to ensure ongoing data quality.Responsibilities:Leading contributor to technical design, including overall solution architecture of data servicesProduce performant and valid data models using current methods and technologiesDrives interactions with Business Stakeholders and Technical team membersProduce high quality code using proper industry best practices in an Agile environmentLeading contributor to the selection of appropriate tools & technologies to effectively implement enterprise software solutionsParticipate in Quality Assurance practices by contributing in test planning and executionParticipate in CI/CD practices by contributing to automation of application build, deployment and configurationRequirements:10+ years of relevant professional experienceBachelor’s Degree preferred or equivalent related work experienceProblem Solver - optimistically work within constraints to drive consistent value delivery for your product/business/technical domainAptitude - Understands both the broader technical and business context domains, and effectively applies appropriate technology solutions.Communication - Concise, accurate, impactful, timely and proactive, ability to speak with Senior Business Leaders and Executive Technical LeadershipComputer Science Knowledge - consistently & effectively apply & evangelize OOP, Data Structures, Machine Organization, Algorithms, Software / Enterprise patterns, Big O in both implementation and enterprise scaleInfluencer- Is seens as a change agent across the IT orgDecision Making - Ensures team tactical decision making is in alignment with the strategic goals of the org.Leadership - Ability to mentor and teach to the IT org around specific areas of technological expertise.Adaptability - able to deal with constant change and ambiguity to maintain progress in alignment with product area/domain objectivesWork environment/physical demands summary:This job operates in an office environment and uses a computer, telephone and other office equipment as needed to perform duties. The noise level in the work environment is typical of that of an office with an open seating floor plan. The employee may encounter frequent interruptions throughout the work day. The employee is regularly required to sit, talk, or hear.All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, status as a qualified individual with a disability, or Vietnam era or other protected veteran.",chi,de
6,Luminex,Biotech & Pharmaceuticals,3.7,Manufacturing Engineer-Senior- US,"Northbrook, IL",$57K - $116K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_78740f81&cb=1618793006534&jobListingId=4059207631,"Manufacturing Engineer-Senior- USNorthbrook, IL 60062, USA Req #1535 Friday, April 9, 2021Luminex is seeking dedicated and talented individuals with a proactive and positive ‘can-do’ attitude to join our team. If changing the diagnostic landscape and revolutionizing patient care sounds like something you would like to be a part of, we invite you to apply today! Together, we can help healthcare providers improve patient outcomes, make a differencein fighting the COVID-19 outbreak, and tackle the world’s most pressing health issues. You can learn more about our values, mission, and vision by visiting our website https://www.luminexcorp.com/about-luminex/.A Brief OverviewThe Manufacturing Engineering, Senior will be responsible for:Direct technical support for Instruments and Consumable Manufacturing operations in ISO 13485 and FDA regulated medical device setting. Representing Operations in design teams for new and on market product design and development, design transfer, and market phases. Facilitating in the definition of project tasks, establishing timelines, and fulfilling responsibilities for product design transfer and related process engineering. Collaborating on the development and assuming full ownership at Production release of material specifications/drawings, manufacturing processes, repair/refurb processes, fixtures, test methods, analysis tools, and related acceptance criteria for new or on market product. Leading and supporting product, supplier, and process sustaining engineering initiatives to scale manufacturing throughput and improve quality, compliance, safety, yields, efficiency, reliability, and cost. Leading and supporting the investigation and resolution of findings identified through audits, non-conformances, corrective/preventative actions, or customer complaints. Task-specific and change control training of Manufacturing personnel. Key technical leader responsible for providing technical leadership for cross-functional projects spanning multiple operations and sites.What you will doRepresent Operations in cross-functional design teams to deliver transfer of design changes or new product introduction of instruments and consumables through product development, validation, and market release phases.Assume full ownership of sustaining engineering support for on-market productsLead or assist in sustaining engineering initiatives to support obsolescence management.Lead or assist in product, supplier, and process sustaining engineering initiatives to improve quality, compliance, safety, efficiency, reliability, cost, and scale throughput.Provide technical support for supplier issuesParticipate and drive development and implementation of process automation strategies and solutionsParticipate in the design, specification development and selection of new production equipment, such as, test fixtures, manufacturing aids, and automation equipment; includes scale-up of existing processes and development of new processesLead and assist in engineering change control and document change control activities; participate in change control reviews.Collaborate with R&D on development and assume full design transfer ownership for Production and Market release of material specifications/drawings, manufacturing processes, repair/refurb processes, fixtures, test methods, analysis tools, work instructions and related acceptance criteria for new or on market product.Establish and maintain standard architecture of BOMs and routings; interface with Cost Accounting for new or on-market product COGs roll-up.Collaborate with R&D on OQ process validation planning and execution. Assume full ownership of PQ process validation planning, execution, and reporting.Assume full ownership of equipment, test fixture, test method, analysis tool validation planning, execution, and reporting; collaborate with R&D as required.Ensure effective training of Manufacturing and Quality Control personnel for transfer of new processes.Lead and support the investigation and resolution of findings impacting the organization identified through audits, non-conformances, corrective/preventative actions, or customer complaint escalation.Effectively apply problem solving tools (5 Whys 2 Hows, Is/Is Not, Fishbone, Cause-and-Effect, etc.) toward systematic resolution of issues.Lead and assist in design input, implementation and validation plans, and implementation oversight of infrastructure improvement projectsProvide technical leadership for external technology transfers and contract manufacturing transfers.Provide packaging and labeling design support.Lead and participate in cross-functional teams supporting business process improvement and alignment initiativesResponsible for knowledge transfer of new product designs being integrated into operation.Participate in or conduct applicable departmental, interdepartmental and intra-departmental training.Ensure personal compliance and promote operational compliance with the Quality System and other regulations.Ensure compliance to NFPA, OSHA, lock-out, and other applicable safety standards.Other duties as assigned.Education QualificationsBachelor's Degree Bachelors of Science in the field of Mechanical, Electrical, Industrial, Bio-medical, or Biomechanical Engineering. requiredExperience Qualifications8+ Years Experience and technical leadership supporting process improvement and sustaining engineering in a ISO 13485 and/or FDA regulated Life Sciences, Medical Device, or Medical Technology industry. required5+ Years Experience working independently or as a team member in a fast-paced relevent environment with rapidly changing priorities requiredTraining and SkillsThorough knowledge of ISO 13485 and FDA Quality System requirementsKnowledge of Enterprise Resource Planning, including applied knowledge of engineering functionalityProficiency in the use of Product Lifecycle Management, including applied knowledge of Engineering Change ControlApplied knowledge of Process and Test Method Validations as required by FDA Quality System guidelinesKnowledge of Design Control requirements as defined by the FDA Quality System guidelinesProven results through application of Six Sigma and Lean Manufacturing principles, including applied knowledge of statistical design of experimentsMathematics and statistics aptitude.Data analysis and technical writing aptitude.Excellent oral and written communication skills.Geometric Dimensioning & TolerancingPLC programmingKnowledge of BTP, equipment specification; injection molding, material coatingsProficient in Microsoft Word, Excel, and PowerPoint programs.Highly organized with proven time management and prioritization skillsAbility to work independently and with minimal supervisionAbility to handle the pressure of meeting tight deadlinesTravel Requirements10% Travel may be requiredLuminex Corporation is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, disability status of an otherwise qualified individual, citizenship status, membership or application for membership in a uniformed service, or any other protected characteristic or category protected by applicable law.Other detailsJob Family US Pay Type Salary Employment Indicator Regular Required Education Bachelor’s Degree",chi,de
7,Loyola Medicine,Health Care,3.4,Sr. System Data Analyst/Tableau Developer,"Maywood, IL",$67K - $77K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044077&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_99359bc5&cb=1618793006534&jobListingId=4063412120,"Loyola Medicine is a leader in academic medicine and healthcare services based in Chicago's western suburbs and a member of Trinity Health, one of the nation's largest Catholic health systems.Loyola University Medical Center in Maywood, IL (Remote Work Eligible) has an exciting opportunity for an Experienced Senior Systems Data Analyst and Tableau Developer. The Decision Support Services Team is seeking a future colleague who:Delivers analytical and programming expertise using SQL server in support for decision support including product/patient and service line costing, productivity reporting and analysis, statistical reporting analysis, and ad hoc reporting as requiredRecommends and implements solutions to enhance the functionality of applications and business intelligence reporting (Tableau Reporting Development), including but not limited to Revenue Cycle and Clinical statistical reportingLeads and participates in project teams associated with the further development and/or implementation of electronic health records and/or other Finance-IT applicationsProvides support in the analysis and validation of business and financial data reported across the Loyola University Health System organizationMonitors and reconciles extracts from source systems along with loading and posting of that data into the Decision Support System (DSS)Reports on key performance metrics across the businessDesigns, develops, implements, modifies, automates, and maintains Finance-IT applicationsDevelops SQL server objects views, stored procedures, and functionsReviews and documents current and future processesWork Schedule: 40 hours/weekRequirements: 3-5 years experienceBachelor's Degree Required / Master's Degree PreferredEPIC Certification Preferred – Clarity Data Model and Revenue Data ModelHospital Experience RequiredComputer Skills:Microsoft SQLTableauBusiness ObjectsCrystal ReportsEPICMicrosoft ExcelTrinity Health's Commitment to Diversity and InclusionTrinity Health employs about 133,000 colleagues at dozens of hospitals and hundreds of health centers in 22 states. Because we serve diverse populations, our colleagues are trained to recognize the cultural beliefs, values, traditions, language preferences, and health practices of the communities that we serve and to apply that knowledge to produce positive health outcomes. We also recognize that each of us has a different way of thinking and perceiving our world and that these differences often lead to innovative solutions.Trinity Health's dedication to diversity includes a unified workforce (through training and education, recruitment, retention, and development), commitment and accountability, communication, community partnerships, and supplier diversity.Job Type: Full-timeBenefits:401(k)401(k) matchingDental insuranceEmployee assistance programEmployee discountFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offTuition reimbursementVision insuranceSchedule:8 hour shiftDay shiftMonday to FridayEducation:Bachelor's (Preferred)Experience:SQL: 1 year (Preferred)System Data Analyst: 3 years (Required)Tableau: 1 year (Required)License/Certification:EPIC Certification: Clarity Data Model Revenue Data Model (Preferred)This Job Is Ideal for Someone Who Is:Dependable -- more reliable than spontaneousDetail-oriented -- would rather focus on the details of work than the bigger pictureAutonomous/Independent -- enjoys working with little directionThis Job Is:A job for which military experienced candidates are encouraged to applyA job for which people with disabilities are encouraged to applyCompany's website:https://loyolamedicine.orgCompany's Facebook page:https://www.facebook.com/LoyolaHealth/Work Remotely:NoCOVID-19 Precaution(s):Personal protective equipment provided or requiredTemperature screeningsSocial distancing guidelines in placeSanitizing, disinfecting, or cleaning procedures in place",chi,de
8,Hopkins Manufacturing Corporation,N/A,3.4,eCommerce/Marketing Data Analyst,"Arlington Heights, IL",$61K - $73K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_8fb13c1a&cb=1618793006534&jobListingId=3698722858,"The e-commerce analyst will work with the Director of eCommerce to determine the business KPI’s and create and maintain standardized reporting for the team, as relates to the company's online retail presence. They are responsible for analyzing and reporting trends in customer purchases and changes in the online retail market to the Director, so they are well-informed when making business decisions. The analyst will also track the company's web analytics, search engine ranking, advertising campaign results, and other brand metrics and to propose actions that enhance Hopkins’ progress towards its short and long-term goals.Essential Functions:Gather data that includes sales, rankings, customer reviews, and the standing of a company's online competition.Track, report and analyze online metrics including, but not limited to: homepages, landing pages, on-site demographics, platform performance, customer purchase analysis (retention & increase purchase frequency), and bounce rate by page.Conduct shopping funnel analysis and reporting to inform new technical projects that will result in conversion improvements.Capture daily, weekly, monthly, and yearly eCommerce KPI’s and analyze trends over time.Perform deep-dive analysis into our key KPI’s to understand the “why” of our customer’s behavior.Submit recommendations to improve the revenue opportunities for the business, based upon data collected.Track and analyze targeted competitor products to assess changes in competitive standing. Offer recommendations for appropriate actions/corrective actions that should be taken.Stay current on eCommerce industry trends and how they can apply to our business while providing input on opportunities and risks.Support and implement various development projectsEffectively undertake the requirement elicitation, document and analysis, solution design, testing definition, and execution.Interact with the product teams and work closely with them to understand their business needs and opportunities.Undertake conversion of data to the new system and work with the application support personnel for the implementation of system software.Education & Experience:Bachelor’s degree in business management, systems management, or marketing.Should possess experience using software used to track online sales and create multi-variable graphs to predict changes.Experience analyzing conversion rate optimization activities (such as A/B testing) and reporting on findings.Should have a strong understanding of the rules of web design and branding so as to understand the necessary steps to make a consistent brand image and user-friendly site that maximizes potential sales, improving site conversion.3-5 years of related eCommerce analytical experience.",chi,de
9,HUB International,Insurance,3.7,Digital Data Analyst,"Chicago, IL",$48K - $60K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_bc62a11a&cb=1618793006534&jobListingId=4035259433,"About the Position:In partnership with the Vice President of Analytics, you will manage the analytics, insights, reporting, and distribution of key marketing performance indicators to stakeholders. The ideal candidate has strong background in analytics and has a proven track record of delivering insights that have successfully driven new revenue and strengthened brands. Through partnering with the marketing team, agencies and IT the data analyst will provide insights that will enhance personalization capabilities, campaign execution, performance/predictive analytics, and help develop models for future improvements. This position can be based anywhere in the U.S. and can be remote.Role Description & Responsibilities:Work with the marketing team, agency partners, and sales teams to conduct ad hoc and in-depth analysis of customers, marketing initiatives and P&L to identify key insights to drive optimization and identify opportunities across the businessDevelop monthly, quarterly and annual reporting dashboards that bring together multiple data sources from across the marketing funnel and generate insights and inform business decisionsDevise processes for data collection and monitoring to uphold data integrity; reconcile data from a number of sourcesEmbed best practice and champion data standards into the business and be an advocate for improving data governance and qualityBe seen as a trusted advisor to key business stakeholders on data drivenAssist A/B testing, from identifying opportunities, running test, analyzing results and delivering recommendations to the business on optimization-based resultsMonitor technology trends related to data capabilities such as data analytics and reporting to identify new and emerging opportunitiesJob Requirements:2+ years experience in data and analytics supporting marketing or eCommerce teams working with large datasets including data visualization2+ years experience with web analytics tools such as Google Analytics or Adobe AnalyticsStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracyStrong knowledge of and experience with reporting packages (Business Objects, etc.) and databases (SQL etc.)Proficient with data visualization tools such a Tableau, Google Data Studio or Power BI (preferred)Extensive experience with ExcelAdept at queries, report writing and presenting findingsExperience with CRM systems is a plus (Microsoft Dynamics CRM preferred)Experience in programming language is a plus (XML, Javascript, or ETL frameworksB.S. in quantitative field such as Computer Science, Statistics, Math, or Analytics/BI related field a plusJoin a Winning Team at HUB InternationalWhen you join the team at HUB International, you become part of the 5th largest global insurance broker, providing a broad array of property, casualty, risk management, life and health, employee benefits, investment and wealth management products and services. Becoming a part of HUB means that you thrive in an entrepreneurial and fast paced team environment supported by over 12,000 professionals in 450 offices across North America. You will be able to actively contribute to our track record of year over year growth fueled by innovative new products and services, mergers and acquisitions, and a great team of people. As part of our talent engine, you will exemplify our strong core values which drive our unique corporate culture. HUB’s entrepreneurial spirit is evident in our people, products and philanthropic initiatives and we are passionate about our talent!\#LI-KR\#LI-RemoteDepartment MarketingRequired Experience: 2-5 years of relevant experienceRequired Travel: No Travel RequiredRequired Education: Bachelor's degree (4-year degree)HUB International Limited is an equal opportunity and affirmative action employer that does not discriminate on the basis of race/ethnicity, national origin, religion, age, color, sex, sexual orientation, gender identity, disability or veteran's status, or any other characteristic protected by local, state or federal laws, rules or regulations. The EEO is the Law poster and its supplement is available here athttp://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm.EEOAA PolicyE-Verify ProgramWe endeavor to make this website accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact the US Recruiting Team toll-free at (844) 300-9193 orUSRecruiting@hubinternational.com. This contact information is for accommodation requests only; do not use this contact information to inquire about the status of applications.Hi, we’re HUB.In a rapidly changing world, we advise businesses and individuals on how to prepare for the unexpected.When you partner with us, you're at the center of a vast network of experts who will help you reach your goals through risk services, claims management, and compliance support.And this gives you the peace of mind that what matters most to you will be protected — through unrelenting advocacy and tailored insurance solutions that put you in control.About HUB InternationalHeadquartered in Chicago, Illinois, HUB International Limited (HUB) is a leading full-service global insurance broker providing property and casualty, life and health, employee benefits, investment and risk management products and services. From offices located throughout North America, HUB’s vast network of specialists provides peace of mind on what matters most by protecting clients through unrelenting advocacy and tailored insurance solutions. For more information, please visit hubinternational.com.",chi,de
10,Echo Global Logistics,Transportation & Logistics,3.7,Sr. Software Engineer,"Chicago, IL",$61K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_24621784&cb=1618793006534&jobListingId=4062309346,"At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo! Echo Global Logistics is a leading provider of technology-enabled solutions and supply chain management. We utilize technology to simplify transportation management for our clients and carriers by handling the critical tasks on their behalf so they can focus on what they do best. From coast to coast, dock to dock, and across all major transportation modes, Echo connects businesses that ship their product with carriers who transport those goods quickly, securely, and cost-effectively.Echo Global Logistics has recently been ranked in Crain's Business as a Top 25 Tech Employer in Chicago along with other recognitions as the top 3PL provider. We are looking for incredible people to join our team and help carry out our mission of providing our clients with best in class service and technology!Position PurposeAs a Senior Software Engineer on the Echo Global Logistics team, you will be a major contributor to the design and implementation of a modular and adaptive service-based enterprise platform in line with our organizational mission of quality, scalability, performance and function. Our proprietary software powers the ever growing North American freight industry by simplifying transportation logistics for shippers and carriers.ResponsibilitiesEcho Software Engineers work on a Scrum team comprised of developers of all skill levels, QA engineers, product owners, and business stakeholders.Additionally:Work with system architects to contribute to high-level technical designsProduce consistent, high quality code by following industry best practices and company standardsLeverage automation across testing, integration, and deployment activitiesWork hand-in-hand with product owner to break down features into actionable user storiesWork to continuously advance your professional and technical skill setCarry out root cause analysis on defects; ensure fixes are happening in the right wayManage software risk; balance priorities; go above and beyond the call of dutyPosition Requirements5+ years developing distributed, enterprise-scale software applications leveraging the following:Object-Oriented programming languages: Java, C#, PythonRelational databases: MySQL, PostgreSQL, Oracle, MS SQL ServerEnterprise messaging systems: RabbitMQ, KafkaData structures and algorithmsNoSQL databases: MongoDB, Redis, Neo4jService-based architecture: Microservices, WCF,Automated CI/CD pipelines: Jenkins, Azure DevOps, GitLab, Git, ArtifactoryDocker containers: Docker, Kubernetes, Swarm, NomadCloud services: AWS, Azure, GoogleProven track record in working in a fast paced environmentProven ability to mentor junior candidates and work with business and leadershipWork environment/physical demands summary:This job operates in an office environment and uses a computer, telephone and other office equipment as needed to perform duties. The noise level in the work environment is typical of that of an office with an open seating floor plan. The employee may encounter frequent interruptions throughout the work day. The employee is regularly required to sit, talk, or hear.All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, status as a qualified individual with a disability, or Vietnam era or other protected veteran.",chi,de
11,Echo Global Logistics,Transportation & Logistics,3.7,Senior Software Engineer,"Chicago, IL",$95K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_9c1f44d8&cb=1618793006535&jobListingId=4062309362,"At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo! Echo Global Logistics is a leading provider of technology-enabled solutions and supply chain management. We utilize technology to simplify transportation management for our clients and carriers by handling the critical tasks on their behalf so they can focus on what they do best. From coast to coast, dock to dock, and across all major transportation modes, Echo connects businesses that ship their product with carriers who transport those goods quickly, securely, and cost-effectively.Echo Global Logistics has recently been ranked in Crain's Business as a Top 25 Tech Employer in Chicago along with other recognitions as the top 3PL provider. We are looking for incredible people to join our team and help carry out our mission of providing our clients with best in class service and technology!Position Purpose:The Sr. Software Engineer will report to the Sr Manager, Software Engineering in our downtown Chicago IL headquarters. This role contributes to the Engineering of large scale solutions that enable Echo's business while supporting the strategic architectural vision of quality, scalability, performance and function. The Sr. Software Engineer is an active member on a dynamic team looking build Best in Class software. The ideal candidate for this role not only is able to produce high quality work quickly, but also serves as a resource to their peers around them and provides mentoring whenever possible.Responsibilities:Active member of a product team that solves complex challenges and builds working softwareProduces high quality code that’s ready to use quicklyDependable and highly skilled development resource for peersPromotes collective code ownership so that everyone has visibility into the feature codebaseSupports and is accountable for timely releases and adherence to release activitiesResolves defects in a timely and effective mannerIdentifies tactical risks and raises/resolves issues effectively.Contributes to merge up/down through development processEnsures that operational teams are effective during deployment (dry-run or production)Carries out root cause analysis on defects to ensure fixes are happening in the right wayWorks hand-in-hand with Product Owner to break down user stories into small functional slicesEncourages integration and promotes obtaining shared goals with team membersAlways open to new ideas and encourages innovative practices amongst peersWillingness to promote and participate in new initiatives (i.e. CoE initiatives)Position Requirements5+ years developing commercial-grade business applicationsMust be proficient with C#, ASP.NET and Object-Oriented Programming (OOP)Proficiency with SOLID Principals and Design Patterns.Experience with REST API design methodologies using .Net Core 3.x (C#)Solid understanding of RESTful Services, Event Driven DevelopmentBuild or maintain fault tolerant systemsData structure and algorithmsSOA architectureStrong problem-solving skills, and the ability to learn and apply new ideas quickly.Web Front-End Development leveraging newer technologies like Angular –Experience with implementing responsive designs which work across platformsFamiliarity with Docker & KubernetesKnowledge of AWS, Azure or Google Cloud are a plusWork environment/physical demands summary:This job operates in an office environment and uses a computer, telephone and other office equipment as needed to perform duties. The noise level in the work environment is typical of that of an office with an open seating floor plan. The employee may encounter frequent interruptions throughout the work day. The employee is regularly required to sit, talk, or hear.All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, status as a qualified individual with a disability, or Vietnam era or other protected veteran.",chi,de
12,Azul 3D,Manufacturing,5,Software Engineer,"Chicago, IL",$70K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_87089704&cb=1618793006535&jobListingId=4060627468,"A BIT ABOUT AZUL 3DAzul 3D is an early-stage, high growth company poised to revolutionize 3D printing technology. Spun out of Northwestern University, Azul 3D was founded to pursue highspeed, large-scale 3D printing for manufacturing. Recently, there has been growing demand in the manufacturing sector for additive manufacturing techniques to move beyond prototyping and onto the factory floor. Azul 3D's innovative technology is primed to meet this growing demand and be the first company to achieve high-throughput production runs using 3D printing, no matter the size of what is being printed.We're looking for a mid-level graphics software engineer to become a member of the Azul 3D team. You will be working on a wide range of software development projects, which includes collaborating with electrical and mechanical engineers for hardware development, chemists and material engineers for materials advancement, and product designers and engineers for the development of software in the 3D printing processes. This role will have you working on OpenGL and OpenCV projects.THE OPPORTUNITYThis person will work within the software team to solve a never-ending supply of technical challenges as we commercialize and scale our 3D printers. S/he will report to the Director of Software Engineering and be a part of a greater multi-disciplinary team working to continually push the boundaries of what is possible in the 3D market.Specifically, this person will:Experience writing OpenGL.Have excellent C++ language skills.Experience writing test code using gtest (or similar) and writing tests for code coverage.Be able to read and understand UML diagrams.Experience using git and configuration management.Experience using CMake and Conan.Write clean code and follow coding standards.Be comfortable working with embedded devices.Understanding of how network protocols work.Experience working in containerized environments.Java experience is preferred.ABOUT YOUNow that you know about the job itself, here is a little bit about you.Extremely smart when it comes to software, and a deep understanding of object-oriented language principles.Understand how multi-threaded applications interact, and the difference between synchronized and asynchronized communication.Thrive on working with very smart people from different disciplines and know how to motivate them, especially when the going gets tough.Are a problem-solver and trouble-shooter. When something does not work, you do what it takes to figure it out. The phrase ""I don't know"" is always followed by ""but I'm going to figure it out.""Are creative. You think about things through multiple lenses so that you come up with great solutions to complex problems. You do not default to the tried and true unless it makes sense to do so.Are a strong collaborator. You can work solo, but you enjoy sharing the lane with others.Take initiative. You do not wait for someone to tell you what to do. You see a need and you take it on.Are not fazed by a fast-paced and, sometimes, even chaotic environment. We are ambitious with our timelines and milestones, and often take risks to make larger leaps forward in progress.Have a deep sense of integrity. You believe in doing things well, not cutting corners, and treating people with respect.HERE IS HOW WE ANTICIPATE YOUR FIRST SIX MONTHS TO LOOK LIKE, AS YOU RAMP UPWithin one month, you will:Dive deep into the product to fully understand the printer, including its subsystems.Gain a deep understanding of target customer needs.Contribute toward the software development timeline.Get to know the cross-functional team, including developing an understanding of each person's focus areas and skill sets (spanning the hardware, software, and materials teams) Within three months, you will:Have a deeper understanding of each subsystem and their role.Take a deep dive into applications on the 3D printer with embedded software.Learn the high-speed data transfers and Linux Realtime Embedded OS.Within six months, you will:Contribute towards cloud applications and embedded systems.Use AI to help solve for the 3D printing challenges.Neural networks for future extraction.Be exposed to Open GL for rendering or image processing.A BIT MORE ABOUT WHAT IT IS LIKE TO WORK HEREWe are a start-up, so we very much share a ""we are all in this together"" mentality. You will be work side-by-side with virtually everyone at some point – chemists, hardware engineers, software teams, the executives/leaders, the businesspeople, and everyone else who joins the team. Our culture is defined by curiosity and passion for creating something new. There is a lot of opportunity to help shape our culture moving forward. We are constantly looking to evolve ourselves, including what we offer in terms of benefits. Here is our current offering:Medical, dental and vision insurance401k planPaid Time OffPotential for equity participationAzul 3DTM is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status",chi,de
13,Echo Global Logistics,Transportation & Logistics,3.7,DevOps Engineer,"Chicago, IL",$56K - $94K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_68ebf646&cb=1618793006535&jobListingId=4062309527,"At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo! Echo Global Logistics is a leading provider of technology-enabled solutions and supply chain management. We utilize technology to simplify transportation management for our clients and carriers by handling the critical tasks on their behalf so they can focus on what they do best. From coast to coast, dock to dock, and across all major transportation modes, Echo connects businesses that ship their product with carriers who transport those goods quickly, securely, and cost-effectively.Echo Global Logistics has recently been ranked in Crain's Business as a Top 25 Tech Employer in Chicago along with other recognitions as the top 3PL provider. We are looking for incredible people to join our team and help carry out our mission of providing our clients with best in class service and technology!Overview:As a DevOps Engineer, you will work closely with Echo’s Infrastructure teams to ensure smooth delivery and maintenance of developed applications into production. This role will assist and guide the Operations teams to learn and adopt continuous delivery practices and efficient use of tools to accomplish their goals. As technical problems arise, you will partner with Operations team to find solutions. Additionally this role will work with the Operations Engineers to refine and improve the tools that and procedures that Echo Global Logistics uses to improve operational excellence across all of IT.Responsibilities:Principal Accountability | AutomationDesign, develop, test and document new automated solutions to improve current or create new processesResearch new technologies and best practices to improve current or create new processesSchedule and perform system maintenance to maximize the efficiency of IT effortsReduce build, deployment and configuration complexity for custom and third-party applications through automated solutionsPrincipal Accountability | ProgrammingCreate new high end applications using PowerShellUse scripting to support fully automated deploymentsCode user dashboardsUse scripting to capture metrics and correlate them to the events that happen in our InfrastructurePrincipal Accountability | TroubleshootingTroubleshoot legacy programming code written in multiple different languagesField incoming problem requests from end users to resolve application and software issues within a Windows environment and other mission-critical systemsPrincipal Accountability | PerformanceDesign, execute and document baseline performance of build and deployment processAnalyze performance results and recommend optimizations to hardware/software configurations and environment setupProvide coaching and assistance to the development teams for the creation and execution of newly developed functionalityBuild, execute and analyze proof-of-concept performance enhancementsWork with development team to profile and optimize architecture and infrastructurePrincipal Accountability | Team MemberOpen to new ideas and encourages innovative practices amongst peersPractices positive interactions - leans on encouragement in place of judgment.Impresses responsibility on others by displaying ownership in tasks.Acts in the interest of the overall team.Actively works on broadening or adding skillsAsks for assistance when problems become challengingBalances best practice decisions with delivering high business valueContributes to the success of the teamAble to multi-task in a fast paced, fluid work environmentCapable of presenting technical ideas and concepts in business -friendly languageQualifications:Minimum undergraduate degree in Computer Science or related technical discipline or equivalent years of experienceExcellent oral and written communication skills including technical documentation skillsSelf-managed and motivatedAbility to follow through with tasks to their completion, organized, and detail orientedWillingness to learn new technologiesStrong analytical and problem-solving skillsSAN/Data Layouts, Clustering, High Availability and DR2+ years of PowerShell Experience2+ years of CruiseControl.Net or Jenkins CI Experience2+ years of Subversion ExperienceExperience with Web Servers (REST, HTTP/S, TCP/IP) is requiredExperience with the Windows Server Environment is requiredExperience with Scrum/Agile methodologies is preferredUnderstanding of Object-Oriented programming techniques (.Net), SDLC, Unit Test Techniques, Debugging/Analytical Techniques a plusExperience with Microsoft Virtual Machine Manager is a plusExperience with NANT, ANT, MSBUILD, NUNIT is a plusExperience with Git is a plusKnowledge of Linux, Python and nginx a plusWork environment/physical demands summary:This job operates in an office environment and uses a computer, telephone and other office equipment as needed to perform duties. The noise level in the work environment is typical of that of an office with an open seating floor plan. The employee may encounter frequent interruptions throughout the work day. The employee is regularly required to sit, talk, or hear.All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, status as a qualified individual with a disability, or Vietnam era or other protected veteran.",chi,de
14,SMS Assist,Business Services,3.2,Senior Data Scientist,"Chicago, IL",$88K - $144K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1206933&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_811e0358&cb=1618793006535&jobListingId=3800167919,"SMS Assist Summary

At SMS Assist, we’re not just in the business of fixing properties—we’re fixing an entire industry. Typically, facilities maintenance is tough work—both in the nature of the job (plumbing, HVAC, snow removal) and the lack of clarity throughout the experience. We decided a better way wasn’t only possible, but essential. Through our award-winning technology platform, built and powered by SMSers, we connect local contractors to our customers and help manage an experience that surpasses expectations.

Recognized on Forbes’ Cloud 100 list, Deloitte’s Technology Fast 500, Chicago Crain’s Top Tech Employers, and more, SMS Assist manages more than 186,000 properties where people live and work. Our customers’ livelihoods are in our hands—think a restaurant manager whose only fryer goes down on a busy Friday night or a family in Florida without power after a hurricane. We work across the industries that make up your community, including retail, food service, banking, residential, and more, and we help them find the right provider in our network (we call them Affiliates) in more than 45 trades.

We’re innovators, disruptors, and out-of-the-box thinkers. We set each other up for success in the office and for the perfect spike on the volleyball court during an intramural game. We’re community volunteers, karaoke partners, and lifelong friends. We’re passionate about the people we serve, and we give our all because we care. We want to make every property better, and we want your help to make it happen.

Job Summary

The Senior Data Scientist II role is part of the Software Development Data Team which is overseeing the activities of the junior data scientists and provides advanced expertise on statistical and mathematical concepts for the broader Data Team. The Senior Data Scientist applies and inspires the adoption of advanced data science and analytics across the business.

The Data Scientist synthesizes and leverages the business’s dataset and data to enhance the business’ capabilities for overall goal achievement. The Senior Data Scientist is instrumental in helping the business continue its evolution into an analytical and data-driven culture.

This role of the Senior Data Scientist supports relevant stakeholders through quantitative analytics, and the application of appropriate advanced analytics for the business’s key initiatives.

Responsibilities

Develop advanced predictive models and exploratory data analyses that will unveil key data insights leveraging both structured and unstructured data.Work closely with Data Engineering and the business team to determine what data insights need to be derived and the problem statement that should guide the analysis in order to solve business problemsAct as a key communicator of analytical results and insights to various stakeholders across and outside the companyDrive all analytics efforts supporting the product development lifecycle.Use machine learning to improve and automate processes in SMS proprietary toolsApply data mining techniques to make recommendations based on data and communicates results through insightful visualizations, reports and presentationsImprove the dataset (or data repository) quality by cleaning the company’s data and collecting information from new sourcesTranslate business analytics problems into technical approaches in diverse domains such as vendor recommendation, work scheduling and technician dispatch, etc.Collaborate with different teams to develop, refine, and scale procedures and workflows.Foster a positive team environmentEnsure confidentiality of internal and external dataPerform ad-hoc projects and other duties as assigned

 Professional Skills

These are the professional skills we would expect from an individual fully established in this role.

Verbal Communication - Proficient Written Communication - ProficientTeamwork - ProficientRelationships - ProficientNegotiation - ProficientOrganizational Awareness - ProficientLearning Agility - ProficientAnalysis - ProficientProblem Solving - ProficientProcess Orientation - ProficientPrioritization - Advanced

Role Specific Skills

Ability to independently develop advanced statistical and machine learning models using a variety of techniques (e.g. GLM, Neural Networks, Tree-based learning methods)Expert level knowledge in one or more languages commonly used in data analytics (Python, R, Java, Scala, etc.). Python / R proficiency is strongly preferredExpert level knowledge in SQL and database management, both relational and big-data platforms.Experience in managing, validating, and manipulating large, complex datasetsStrong ability to communicate complex analyses and concepts to non-technical audiences within and outside of the organizationComfortable performing independent research to support analytics decisions as part of the product lifecycle

Qualifications

Minimum Qualifications

Bachelor’s degree in a quantitative or technical field such as mathematics, statistics, computer science, or engineering with 8 or more years of experience in a data science and/or predictive analytics role or a Masters or Ph.D. degree in a relevant discipline with 3 or more years of experience in a data science and/or predictive analytics role (Masters or Ph.D. strongly preferred)

Other Relevant Qualifications

Experience with natural language processing.Advanced knowledge of Data Warehousing and BI best practicesExperience with big data tools such as Spark, Hadoop, etc.Experience with Tableau or Superset.

­­­­­

Please note, this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities, and schedule may change at any time with or without notice.

SMS Assist is an Equal Opportunity Employer (EOE) that welcomes and encourages all applicants to apply regardless of age, race, color, religion, sex, sexual orientation, gender identify and/or expression, national origin, disability, veteran status, marital or parental status, ancestry, citizenship status, pregnancy or other reasons prohibited by law.",chi,de
15,CoventBridge Group,Insurance,3.5,Data Analyst II,"Chicago, IL",$51K - $57K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_adec6576&cb=1618793006536&jobListingId=4063537810,"Overview:Data Analyst II - REMOTECompany Overview:CoventBridge Group is the leading worldwide full-service investigation solutions company providing: Surveillance, SIU and Compliance, Claims Investigation, Counter-Fraud Programs, Desktop Investigations, Social Media, Record Retrieval, Canvasses and Vendor Management programs. With offices in the UK and U.S. the company provides top tier data privacy and security practices, deploys robust case management technology customized to clients’ needs and delivers worldwide coverage via its 1000 employees and affiliates worldwide.About the Opportunity:The Data Analyst II will primarily be responsible for performing in-depth evaluation and analysis of potential fraud cases and requests for information using claims information and other sources of data. In addition, it will support the development of complex cases that involve high dollar amounts, sensitive issues, or that otherwise meet criteria for referral to law enforcement, recoupment of overpayment, and/or administrative action based on reactive and proactive data analysis.In assuming this position, you will be a critical contributor to meeting CoventBridge Group's objective: To provide services to our clients that exceed their expectations and contribute to improved healthcare delivery by identifying and eliminating fraud, waste and abuse.The Data Analyst II position will report to the Data Supervisor and will work in our Grove City, OH office or if not local, remotely from a home office.Responsibilities/ Requirements:Responsibilities:Work with local management, investigators, and analysts to provide reactive and proactive case development support and to fulfill law enforcement data requests.Communicate effectively with internal and external customers, including federal law enforcement officers.Validate data analysis results and analytically identify potential fraud, waste and/or abuse situations in violation of Medicare/Medicaid laws, guidelines, policies, and regulations.Support management requests for CMS reporting requirements.Utilize data analysis techniques to detect aberrancies in Medicare/Medicaid claims data and proactively seeks out and develops leads and cases received from a variety of sources including CMS and OIG, fraud alerts, and referrals from government and private sources.Work with Statisticians and Data Analysts to provide proactive data analysis results with statistically high probabilities of producing case referrals to law enforcement, overpayments, and/or administrative actions.Prepare, develop and participate in provider, beneficiary, law enforcement, or staff training as related to Medicare fraud, waste and/or abuse data analysis.Maintain chain of custody on all documents and follow all confidentiality and security guidelines.Comply with and maintains various documentation and other reporting requirements as needed.Perform other duties as assigned.Requirements:2 years’ experience in data analysis as well as demonstrated knowledge of health care and claims or a combination of education and equivalent work experience.Demonstrated knowledge of various database management systems in order to input, extract or manipulate information.Demonstrated experience and knowledge of health care information (health claims data; specifically, Medicare and Medicaid, ICD-9-CM and ICD-10-CM codes, physician specialty codes, pharmaceutical data including NCPDP file formats and codes, provider identifiers, etc.) is preferred.Have high proficiency level with MS Access and MS Excel.Requires a working knowledge of SAS and/or other applications to perform various types of data analysis.Knowledge of Medicare and Medicaid rules and regulation is a plus.Educational Qualifications:Bachelor’s degree in statistics or related discipline with preference given to MA or MS recipients, and at least (2) two years of experience in data analytics.Associate must have and maintain a valid driver’s license issued by his/her state of residence.Benefits:Benefits:Medical, Dental, Vision plansLife, LTD and STD paid by the employer401(k) with company match up to 4%Paid Time Off and company paid holidaysTuition assistance after 1 year of service*CoventBridge is proud to be an EEO-AA employer M/F/D/V.*IND123",chi,de
16,Endurance Warranty Services,Insurance,4.7,Contact Center Engineer,"Chicago, IL",$30K - $76K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044077&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_7764d114&cb=1618793006536&jobListingId=4062751634,"Contact Center Telecom Engineer Contact Center Engineer OverviewIn your role as Contact Center Engineer you are accountable for the set of applications and telephony infrastructure that supports contact center employees across all of Endurance. In this “hands on” role, you will use your knowledge of contact center best practices to support a cloud first, modern call center. Bring your background in any mainstream, established vendor’s contact center platform. Training will be provided on administration of Fuze and Nice inContact platforms in order to be successful in the role.How will you succeed in this role?Are you fearless? Can you embrace new technologies knowing that you can learn new things? Are you creative? Can you find new ways to solve old problems? Are you driven? Do you see beyond what customers are requesting to fulfill their unstated needs? Do you use data to make decisions?Responsibilities· Support technical aspects of contact center solutions and services including but not limited to inbound ACD/IVR, outbound dialer, omni-channel, recording, quality management, workforce management· Tier 2/3 contact center incident escalation· Identification of chronic issues for problem management· Implementation of project assignments with guidance from contact center specialistQualifications: · Bachelor’s degree in Computer Science, related field, or equivalent industry experience required.· 2 or more years of experience in a technical capacity, with direct hands on delivery of any mainstream contact center platform (example: Nortel, Cisco, Avaya, Broadsoft, Genesys, Aspect, Five 9, Nice inContact)· Passion for helping customers & exceeding customer expectations.· Excellent interpersonal skills and ability to build effective relationships with staff at all levels.· Ability to travel to other Endurance locations, as required.Job Type: Full-timePay: $80,000.00 - $85,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceHealth insurancePaid time offParental leaveVision insuranceSchedule:8 hour shiftEducation:Bachelor's (Preferred)Experience:Telecommunication: 1 year (Preferred)Call center management: 1 year (Preferred)Work Location:One locationCompany's website:https://www.endurancewarranty.com/careers/Work Remotely:NoCOVID-19 Precaution(s):Remote interview processVirtual meetings",chi,de
17,Capital One - US,Finance,4.1,Data Engineer,"Chicago, IL",$90K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=133055&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_b58f4bac&cb=1618793006536&jobListingId=4008264775,"77 West Wacker Dr (35012), United States of America, Chicago, IllinoisData EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 2 years of experience in application developmentAt least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree3+ years of experience in application development1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)1+ years of experience with Ansible / Terraform2+ years of experience with Agile engineering practices2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)2+ years of experience with NoSQL implementation (Mongo, Cassandra)2+ years of experience developing Java based software solutions2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)2+ years of experience developing software solutions to solve complex business problems2+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",chi,de
18,CNA Insurance,Insurance,3.6,Sr. Data Scientist,"Chicago, IL",$83K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_db86e5c0&cb=1618793006536&jobListingId=4033336415,"Sr. Data Scientist -INF0001YEDescriptionAnalytics Sr. Consultant – Sr. Data Scientist – R&DDescriptionHeadquartered in the heart of downtown Chicago, CNA is a leading commercial and specialty insurer, offering a diverse range of insurance products including Workers Compensation, Property, General Liability, Professional Liability, Cyber Insurance, Surety, and Warranty. We are one of the world leaders in underwriting non-medical professionals, from lawyers and accountants to architects and management consultants. What CNA offersA collaborative data science team with diverse skills and experiences, combined with deep expertise in statistical modeling, machine learning, and applications to insuranceModern cloud computing environment that enables you to explore data and new tools, build and deploy sophisticated models that impact key areas such as underwriting, pricing, claims management and risk controlSponsorship of continued professional growth through support for attending technical conferences, meetings and symposiaThe successful candidate will:Research and implement novel statistical, machine learning approaches to address complex business questions in order to advance our approach to data scienceImplement, maintain and document internal proprietary data science libraries to facilitate efficient and reusable processesDive into new methods and technologies and embrace the ambiguity of research problem solvingUse statistical methodologies and machine learning techniques to build state-of-the-art predictive models to solve business problems across CNA.Essential Duties & ResponsibilitiesDevelop a deep understanding of the underpinnings of advanced algorithms while using their own expertise to create new solutions for business problems across CNAUpdate and improve existing data science proprietary tools to incorporate new featuresImplement creative quantitative solutions into high quality, reusable and well documented code librariesCollaborate with Technology to rapidly prototype algorithms and code for proof-of-concept demonstrations to advance our cloud analytical capabilities.Communicate research findings and solutions in a clear manner and participate in training other data scientists in using the newly developed toolsCollaborate closely with team members to advance the data science capabilities at CNA and contribute to the team’s intellectual capitalChampion the use of data science to drive change and to provide superior decision supportParticipate in special data science projects requiring advanced quantitative expertise and interpret the results of algorithms to business decision-makersRequired Skills, Knowledge & AbilitiesProven experience in coming up with creative analytical approaches demonstrated through impactful business solutions or academic publicationsAdvanced knowledge of R and /or Python demonstrated through advanced statistical/ ML algorithms implementation and library developmentDeep expertise in applying statistical and machine learning methods to solve complex problems using structured and unstructured dataPractical experience with version control tools such as gitIntellectual curiosity and drive to continuously learn new tools and methodsStrong analytical, problem solving and critical thinking skillsAttention to detail and accuracy of work, ability to spot and correct issuesStrong writing skills, including writing coherent documentation and reportsStrong interpersonal and communication skillsAbility to interpret algorithm results and communicate insights to technical and non-technical audiencesAbility to work collaboratively with colleagues with diverse perspectives and backgroundsStrong time management skillsCapable of operating with little supervision and thinking independently and innovativelyPreferred Skills, Knowledge & AbilitiesExperience with applying deep learning methods to natural language processing problemsExperience with using C++ for advanced algorithm implementationExperience with Machine Learning Model Interpretation methodsExperience in working with data and tools to design processes in a cloud environment, preferably Google Cloud PlatformReporting RelationshipDirector or aboveEducation & ExperienceAdvanced degree in a quantitative discipline such as Statistics, Computer Science, Applied Mathematics, Operational Research with three or more years of relevant work experience.LI-KC1Job Information SystemsPrimary LocationUnited States-Illinois-ChicagoOrganization Technology - AnalyticsJob Posting Mar 1, 2021Unposting Date Ongoing",chi,de
19,Equity Residential,Real Estate,4.2,Data Engineer,"Chicago, IL",$80K - $105K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_49077c06&cb=1618793006537&jobListingId=3804910726,"As a Data Engineer, you will implement the data models and data structures needed for each use case, in the most convenient format to be used by the Data Science and Business Intelligence teams. Through regular interactions with stakeholders and functional business unit leaders, you will build high-performance data pipelines, tools, and a platform that influences EQR's data storage, ingestions, and usage. Additionally, you will participate in data requirements, modeling and testing activities. Each day will be unique, requiring an ability to think strategically and on your feet, be creative, take initiative, and employ a diverse set of skills.WHO YOU AREKnowledgeable, Analytical, and Solution-Oriented . Without a doubt, you’ve got strong quantitative skills and are comfortable analyzing large data sets, spotting trends and patterns, and synthesizing relevant observations. You use a hypothesis-driven approach to engage in analysis that will deliver on your client questions. You like thinking outside the box to come up with innovative points of view on new challenges, relying on your previous analytic work and experience to help guide you along the way.Results-Oriented . You demonstrate an inherent sense of urgency to drive great results, while being precise in executing your work. You are facile with creating and communicating a clear project plan, tracking progress, and keeping your business partners in the loop along the way.Intellectually Curious . You're inherently interested in the ""why"" so that you can identify opportunities that represent unconventional solutions to the problems you are trying to solve.Strong Communicator . Your writing and speaking skills are concise, articulate, and effective, providing an ability to interact with all levels/various teams across the organization, be understood, and develop trust and rapport within the organization.Technologically Savvy . You exhibit mastery of SQL along with a strong skill set in one or more general programming languages (Python, Java, Scala, C++)A Trusted Team Player . You enjoy partnering with others and build constructive working relationships that foster the collaboration necessary to deliver great results. You are accountable to your teammates and follow through on commitments.Organized and Confident . You are flexible, composed, and able to prioritize multiple tasks and deadlines simultaneously, while confidently interacting with a variety of individuals, across all levels of the organization. You handle pressure well and do so with confidence.WHAT YOU’LL DOLead the effort to democratize data at EQR, providing the right endpoints for the right user (e.g. report, API, table, etc.)Assist in standardizing our data management best practices, including codebase management, work and issue tracking, testing and quality control/assurance measures, data dictionaries, and a documentation hub for both production level code and ad hoc analyses.Interact with stakeholders and functional subject matter experts to understand and gather requirements to develop effective data models that can be translated into business insights reports/analysesCreate data models and data processes, providing the right format and structure for use case solutions.Build and deploy pipelines to ingest and transform in our rapidly growing data platformPartner with IT and Functional Teams on internal/external data integration and acquisitionResearch modern technologies and frameworks to discover uses for new and existing data.Propose and effect changes to our data generation processesProduce clean, well-tested, and documented codePREVIOUS EXPERIENCE & REQUIREMENTSBachelor's Degree required, preferably in Computer Science, Mathematics, Statistics, Finance or related technical field.3+ years developing end-to-end Business Intelligence or Analytic solutions (i.e. data modeling, ELT/ELT, reporting/analysis)Experience working with data warehouses, including technical architectures, infrastructure components, large-scale ETL/ELT pipelines, automation, database optimization, and reporting/analytic tools and environments.Experience writing software in one or more languages: Python, Java, C++3+ years utilizing SQL based data management systems (preferred NoSQL experience as well)Experience with Azure or other cloud providers (AWS, GCP) is strongly preferredPreferred experience with data platforms and technologies such as Kafka, Presto, Delta Lake, Spark, etc.Demonstrated experience working with diverse data sets and frameworks across multiple domainsDemonstrated experience using software engineering best practices like Continuous Integration/ Deployment to deliver complex software projectsTeam oriented and flexible with a proven track record in collaborating with multiple stakeholders.Must be available for overnight travel (approximately 10%) to any of Equity’s major core markets, as required.Authorization to work in the US (without need for Visa sponsorship from employer) is required.Working for Equity Residential (EQR), a leading multi-family real estate investment trust (REIT), means living our purpose: creating communities where people thrive. It means striving to provide the best in apartment living, speaking boldly about new ideas for innovation, and inspiring creativity in the ways we work together.Our portfolio of high-quality properties in urban growth markets – New York City, Boston, Washington DC, Seattle, San Francisco, Southern California, and Denver – provides homes where people most want to live, work and play. We've got the best people in the business, as evidenced by our employee engagement scores and customer loyalty ratings. That’s why our employees say they are proud to work at Equity, a company that gives our residents a place where they can Live Remarkably, and offers a culture where our employees have the opportunity to thrive.Equity RewardsWhen you join Equity Residential, you won’t be treated as simply another employee — you will be considered a partner in our shared success. As such, we are committed to investing in your personal success through a benefits program that supports your Total Wellbeing.We recognize that everyone has different needs outside of work. That’s why, in addition to a competitive benefits package (medical, dental, vision and paid time off), we offer many unique benefits options to employees, like a comprehensive wellness program, pet insurance, new parent benefits, and paid time off for community service projects. In addition to your next job, you can also find your next home with us! Rent discounts on Equity Residential apartment homes are available to our benefits-eligible employees. The amount of the discount offered is determined based on the market, ranging upwards from 20%.Equity ValuesAt Equity Residential, like our residents, our employees come from everywhere. A richly diverse work environment captures top talent, cultivates the best ideas, and creates the widest possible platform for success. By focusing on inclusion, these differences are harnessed to create value — in ideas, business practices, relationships, and employee engagement. As an Equal Opportunity Employer, we are committed to maintaining a diverse, inclusive and equitable work environment where our employees can thrive.All aspects of the employment process are merit-based. Every Equity employee is expected to maintain a work environment that is free from discrimination and harassment. Equity Residential does not discriminate against any employee or job applicant because of race, religion, color, creed, sex, sexual orientation, gender, sexual/gender identity/expression, age, pregnancy (including childbirth, lactation or related medical conditions), physical or mental disability, national origin, citizenship status, military (including uniformed service member or protected veteran) status, marital status, genetic characteristic or information, ancestry or any other characteristic protected by law. Equity Residential also prohibits retaliation against individuals who report harassment or discrimination, or participate in investigations into such conduct.",chi,de
20,BDO,Accounting & Legal,3.8,Data Analytics Engineer,"Chicago, IL",$61K - $118K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_98b17706&cb=1618793006537&jobListingId=3778257036,"BDO’s Core Purpose is Helping People Thrive Every Day. Our Core Values reflect how we manage our work, our relationships and ourselves. As an employee of the firm, you will live true to our Core Values of people first, being exceptional every day in every way, embracing change, feeling empowered through knowledge and choosing accountability. Our Core Values are the standards by which we conduct ourselves day in and day out, both internally and externally.BDO Digital, LLC, a subsidiary of BDO USA, LLP, provides a holistic portfolio of technology, transformation services and solutions. We are an organization that values your time, talent, and contributions. Collaborate with BDO Digital’s cross-disciplinary team who work together to solve digital needs and unearth new opportunities to drive competitive advantage. Our commitment to each other is why BDO Digital is a recognized leader for our culture, employee satisfaction and career growth. We’re looking for people with the same drive; to combine teamwork with technology to produce amazing results.This role is seeking intermediate experience within a Data Analytics (DA) development lifecycle using Microsoft Business Intelligence (BI) technologies. This position will be working closely with our clients to provide outstanding customized cloud data analytics solutions. This role is exposed to a wide range of software technologies, roles and client environments.ResponsibilitiesInteracts with customers and project leaders to define and document project specificationsDesigns, develops, tests, and implements data analytics or business intelligence solutionsParticipates in support activities for existing softwareData visualization using PowerBI or Tableau for data analysis and reportingPartakes in technology training to learn various Data Analytics / Business Intelligence technologiesOther duties as requiredQualificationsEducation:Bachelor's degree from an accredited university, requiredBachelor’s degree in Computer Science or a related field from an accredited university, preferredExperience:Two (2) or more years of Software Development experience within Data Analytics / Business Intelligence development using Microsoft technologies, requiredSoftware:Any one of the following experience required:SSISSSASSSRSStream Analytics or Data Lake AnalyticsMicrosoft Azure SQL or SQL Data WarehouseAzure Data FactoryPowerBI or TableauAWS with RedshiftOther Knowledge, Skills & Abilities:Strong SQL Server skills is a must along with SQL queries and stored proceduresExcellent organizational and time management skillsStrong written and verbal communication skillsExperience with the following technologies, preferred:Semantic ModelsIntegration Services (SSIS)Analysis Services (SSAS – Multidimensional and Tabular cubes)Reporting Services (SSRS)Machine LearningStream Analytics or Data Lake AnalyticsMicrosoft Azure SQL or SQL Data WarehouseAzure Data FactoryPowerBI or TableauAmazon Web Services (AWS) with RedshiftMust be open to local travel to client sites, if neededKeywords: Software Developer, Data Analytics, Business Intelligence, BI Developer, BI, SQL Developer, SSIS, SSAS, SSRS, Machine Learning, Data Lake Analytics, Stream, BI Stack, Cube, Microsoft, SQL Server, Tableau, Qlik, PowerBI, Machine Learning, Azure Data Factory, RedShift#LI-KN1Multiple LocationsAtlanta, Grand Rapids, Houston, Indianapolis, New York, Oak Brook, Washington, DC",chi,de
21,Kraft Heinz,Manufacturing,3.4,Data Engineer,"Chicago, IL",$68K - $87K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=8095&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_caeb5254&cb=1618793006537&jobListingId=3804313277,"WHO WE ARE

We're one of the world's largest food and beverage companies and a trusted producer of high-quality, great-tasting, and nutritious foods, earning us a spot on 97% of American household tables. As the guardians of our beloved brands and the creators of innovative products, we're dedicated To Sustainably Grow by Delighting More Consumers Globally.

We are on a journey to create a digitally-powered, agile-enterprise. At the heart of this journey is our ambition to create an enterprise where powerful AI solutions augment humans and where small mission-based teams are in relentless pursuit to solve tangible problems for our consumers, customers, and the enterprise.

That ambition requires us to create a modern cloud and data ecosystem - a one of its kind that becomes the neural network of our company. We want you to bring your tech-self to us. We use Python, R, Spark, React, Tableau, Snowflake, Azure, and others to solve the problem on hand. In-turn, you can look forward to high-impact challenges, no bureaucracy, entrepreneurial small teams and an unique opportunity to create and build something bold, awesome, and impactful!

WHAT YOU'LL DO

As a Data Engineer, you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling Kraft Heinz to advance data-driven decision-making capabilities across the enterprise. You will have a deep understanding of data architecture, data engineering, data analysis, and reporting -- and a basic understanding of data science techniques and workflows, as well as the business processes supported by the data pipeline. Examples of problems you will tackle include helping R&D determine the next generation of household products, revolutionizing consumer engagement with personally relevant content, and reinventing our supply chain to eliminate food waste. Furthermore, you will:


Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for Business Intelligence Engineers, Business Analyst and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
Partner with machine learning engineers, business intelligence engineers and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics.

WHO YOU ARE

Bachelor's degree required; Computer Science, MIS, or Engineering preferred
Expertise in ETL and data analysis and experience with SQL and at least one programming language (Python/R preferred)
Experience developing and maintaining data warehouses in big data solutions e.g. Snowflake
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)
Database development experience using Hadoop, SPARK or BigQuery and experience with a variety of relational, NoSQL, and cloud database technologies
Worked with BI tools such as Alteryx, Tableau, Power BI, Looker
Conceptual knowledge of data and analytics, such as dimensional modeling, ELT, reporting tools, data governance, data warehousing, structured and unstructured data.
Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred)
Familiarity with the Linux operating system
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
An agile learner who brings strong problem-solving skills, and enjoys working as part of a technical, cross functional team to solve complex data problems
A hard worker and consensus gainer who brings a strong numbers sense; you are intellectually curious and willing to adjust your position based on additional information

WHY US?

We're accelerating our ambition to become a best-in-class Digital leader by making data-driven investments that drive smarter business decisions. We're dedicated To Sustainably Grow by Delighting More Consumers Globally, and what we build today helps bring joy to customers, consumers, and communities around the world tomorrow. Here at Kraft Heinz, we're not afraid to challenge the status quo. We are bold. We embrace new ideas. We value diverse perspectives. And we dare to do better every single day. We reward courage in the face of uncertainty. And every day, we are transforming our industry. We are creating the future of food, and we invite you to join us.
Equal Opportunity Employer minorities/females/veterans/individuals with disabilities/sexual orientation/gender identity",chi,de
22,IBM,Information Technology,3.9,Data Engineer,"Chicago, IL",$65K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_14b132d4&cb=1618793006537&jobListingId=4058958939,"IntroductionHave you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.Your Role and ResponsibilitiesKey Responsibilities:Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical requirements and support their data infrastructure needs.Provide the ability to work within agile development methodology and collaborate effectively with multi-disciplinary teamsBuild modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements.Understand data architecture, build large-scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow.Have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Have expertise in data persistence solutions, experience with the latest (NoSQL) database technologies, and experience with building complex SQL queries using various (NoSQL or RDBMS) databases such as MongoDB or DB2Experience in software engineering with object-oriented design, coding and testing patterns on large-scale data infrastructuresUse DevOps best practices such as continuous integration, continuous delivery in the production implementation.GarageIBMReferred_NorthAmericaRequired Technical and Professional ExpertiseDevelop code using Python, Scala, R languagesExperience with relational SQL and NoSQL databases, including Postgres and Cassandra3+ years design & implementation experience with distributed applications3+ years of working experience in database architectures and data pipeline developmentDemonstrated knowledge of software development tools and methodologiesComputer Science with software engineering and Math background desiredPreferred Technical and Professional ExpertiseExperience with big data tools: Hadoop, Spark, Kafka, etc.Familiar with big data solutions with experience on Hadoop based technologies such as MapReduce, Hive MongoDB or Cassandra.Experience with stream-processing systems: Storm, Spark-Streaming, etc.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.Knowledge of cloud technologies such as Kubernetes, Cloud Foundry, PaaS, and IaaS (SoftLayer)NONEAbout Business UnitIBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.Impact. Inclusion. Infinite Experiences. Do your best work ever.About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.Location StatementIBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to:12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.Well-being programs to support mental and physical health.Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).Select educational reimbursement opportunities.Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.Giving and volunteer programs to benefit charitable organizations and local communities.Discounts on retail products, services, and experiences.This position is eligible for participation in an IBM sales incentive plan. Actual incentive opportunity will be based on performance and the eligible Target Incentive, as addressed in the applicable plan, all of which is subject to change.We consider qualified applicants with criminal histories, consistent with applicable law.IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",chi,de
23,Cooper's Hawk Winery & Restaurants,"Restaurants, Bars & Food Services",4,Data Engineer,"Downers Grove, IL",$84K - $93K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=4347&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_c5d4ce1c&cb=1618793006537&jobListingId=4059357612,"We are looking for a Data Engineer to join our team in helping to support our modern data platform in Azure. This person will primarily be responsible for the development and support of our data pipelines, data lake, and our data warehouse solution along with finding ways to unlock value from our data to support our finance, marketing and operation teams.

Duties & Responsibilities:
Acquire, ingest, and process data from multiple source systems into the data lake
Plan and execute data integration strategies and approaches for batch data
Create data integration strategies and approaches for real-time streaming data
Assist in the development and maintenance of the data lake and the data warehouse
Participate in architectural design and discussions
Work with business owners to identity new types of data that are of interest to be pulled into the data warehouse

Candidate Attributes:

Strong and effective communication skills with an ability to engage business stakeholders in discussion or resolution of issues
Self-starter who can identify and develop data solutions with minimal direction and pivot based on dynamically changing business priorities
Demonstrated desire to continuously learn and evolve Cloud and programming skill sets within the Azure tech stack and elsewhere
Demonstrated ability to meet deadlines
 Proven track-record of developing creative data solutions to solve complex business issues
Proven track-record of ownership of entire project lifecycle

Technical Qualifications:

Proven experience developing data pipelines for acquisition, cleansing, and integration
Proven experience creating data movement solutions using Azure Data Factory (ADF)
Understanding of error handling best practices
 Understanding of the benefits of data lakes
Working knowledge of dimensional data warehouse best practices and techniques
Working knowledge of scaling data solutions in the Azure stack
5+ years of experience developing SQL Server code, including stored procedures, views, CTEs etc.
3+ years of experience developing solutions using cloud technologies
Working knowledge of SQL Server optimization techniques and best practices
Exposure to developing solutions in Spark and/or Databricks and Python

Cooper's Hawk is an Equal Opportunity Employer",chi,de
24,CITADEL ENTERPRISE EUROPE LIMITED,Finance,3.9,Data Engineer,"Chicago, IL",$107K - $184K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_35285a30&cb=1618793006537&jobListingId=3665632336,"Data EngineerAt Citadel, data is the core of the investment process. Data Engineers architect and build our data platforms which drive how we source, enrich, and store data that integrates into the investment process. These Data Engineers own the entire data pipeline starting with how we ingest data from the outside world, transforming that information into actionable insights, and ultimately designing the interfaces and APIs that our investment professionals and quantitative researchers use to monetize ideas. Throughout the process, our Data Engineers partner with top investment professionals and data scientists to design systems that solve our most critical problems and answer the most challenging questions in finance.YOUR OPPORTUNITY:Develop solutions that enable investment professionals to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, sensor collection), transformations (Spark, SQL, Kafka, Python/C++/Java), and interface (API, schema design, events)Partner with the industry’s top investment professionals, quantitative researchers, and data scientists to design, develop, and deploy solutions that answer fundamental questions about financial marketsBuild tools and automation capabilities for data pipelines that improve the efficiency, quality and resiliency of our data platformDrive the evolution of our data strategy by challenging the status quo and identifying opportunities to enhance our platformYOUR SKILLS & TALENTS:Passion for working with data in order to accurately model and analyze complex systems such as a publicly traded company, commodity market, economy, or financial instrumentsStrong interest in financial markets and a desire to work directly with investment professionalsProficiency with one or more programming languages such as Java or C++ or PythonProficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or HadoopExperience with any of the following systems: Apache Airflow, AWS/GCE/Azure, Jupyter, Kafka, Docker, Kubernetes, or SnowflakeStrong written and verbal communications skillsBachelor’s, Master’s or PhD degree in Computer Science or equivalent experienceAbout CitadelCitadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For thirty years, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.With an unparalleled ability to identify and execute on great ideas, Citadel’s team of investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.",chi,de
25,Northwestern Memorial Healthcare,Health Care,4.1,"Data Engineer - Analytics, Full time, Days","Chicago, IL",$62K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=4134&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_a0df6569&cb=1618793006537&jobListingId=4034085532,"Company DescriptionAt Northwestern Medicine, every patient interaction makes a difference in cultivating a positive workplace. This patient-first approach is what sets us apart as a leader in the healthcare industry. As an integral part of our team, you'll have the opportunity to join our quest for better healthcare, no matter where you work within the Northwestern Medicine system. At Northwestern Medicine, we pride ourselves on providing competitive benefits: from tuition reimbursement and loan forgiveness to 401(k) matching and lifecycle benefits, we take care of our employees. Ready to join our quest for better?Job DescriptionThe Data Engineer reflects the mission, vision, and values of NM, adheres to the organization’s Code of Ethics and Corporate Compliance Program, and complies with all relevant policies, procedures, guidelines and all other regulatory and accreditation standards.

Working in Analytics at Northwestern Medicine, we help our clinical and administrative leadership through the development of thoughtful, highly engaging analytics products that will impact the clinical and financial areas of our health system. We do this by engaging with our customers to understand opportunities for improvement and then applying the right analytic solution to drive that improvement. Our health system looks to us to be thought-leaders in Analytics, which requires us to be analytical problem solvers by nature. We also strive to develop a deep understanding and empathy for our internal customers and communicate the value and purpose to stakeholders. Through tenacity and resilience, we will strive through ambiguity, drive impactful projects, and overcome challenges.

Northwestern Medicine is looking for a data driven, business-minded, results-oriented Data Engineer to join our team. The Data Engineer uncovers insights that drive strategy and optimal decision making for the executive team and leaders across the organization. In this role, you will be charged with understanding the ‘who, what, and whys’ of our business - working cross-functionally to realize the value of NM’s data assets.

Responsibilities:

The Data Engineer is responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data, building analytical solutions, and administering systems to deliver information to the health system. Serves as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions.Applies knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures.Collaborates with the Architecture team in the design and execution of solutions.Ensures that new and existing data models and databases are consistent with approved data architecture standards.Provide facilitation, analysis, design, and execution of architecture solutions and ensure solutions are leveraged. Create, document, and communicate the integration approach of all the components of the solution.Define key solutions and ensure they are managed for consumption by users and across teams. Research, analyze, determine capabilities and propose solution alternatives to address specific business needs and product/service strategies.Maintain knowledge of current trends and development in the field. Actively explores emerging technologies.Independently work with business users to gather and scope requirements and recommend analytical solutions to meet business needs.Assists with ETL design and development including data analysis, source-target mapping, quality profiling, change data capture, code performance.Evaluate data quality and interpret results in a clear, concise manner.Document all programming changes and design, system modifications and their associated maintenance. Own analytics projects and be accountable for collaborating with the business to gather requirements, execute to provide analytical solutions, which exceed customer expectations.Work collaboratively with and support multi-departments efforts and projects.Mentor staff by sharing skills, experience, knowledge, and expertise on analytic tools and solutions.Serve as subject matter expert within the department.Provide training and support through the organization on the use of analytics tools.Performs other duties and functions as assigned.


QualificationsRequired:

Bachelor’s degree or equivalent experience in relevant fieldFive or more years of experience in a role querying, analyzing data, and/or data modeling/architectureExperience working with a variety of data warehousing models and design fundamentals (e.g. Inmom Kimball)Experience with developing and maintaining ETL / data pipeline (e.g. Microsoft SSIS, Azure Data Factory)Experience with OLAP or Tabular cube softwareExperience using SQL for data extraction, manipulation, and reportingPrevious experience working in an Agile environmentStrong knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored proceduresExperience with report writing and data visualization tools such as: Microsoft Power BI, Tableau, Crystal Reports, SSRS, etc.

Preferred: 

Experience developing, designing and supporting applications and relational databases Experience using a software package for statistical analysis (R, Python, etc)Previous experience working with Epic Clarity dataPrevious healthcare experience, ideally with a health system

#LI-RW1Additional InformationNorthwestern Medicine is an affirmative action/equal opportunity employer and does not discriminate in hiring or employment on the basis of age, sex, race, color, religion, national origin, gender identity, veteran status, disability, sexual orientation or any other protected status.",chi,de
26,Epic Placements,Business Services,-1,DevOps Engineer (REMOTE) - Full Time,"Chicago, IL",$67K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1044072&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_3f7e6573&cb=1618793006537&jobListingId=4059300494,"MUST BE AUTHORIZED TO WORK FOR ANY EMPLOYER. No 3RD PARTIES, C2C / Corp-to-Corp or Sponsorship AvailableWe are working with a growing company in Denver, CO and helping them find energetic technical professionals who are searching for growth in their devops careers. Our client is looking for engineers who have a passion for devops cultures and enjoy working with various platforms, languages and technologies.Our client offers the ability to gain hands-on experience with enterprise setups, progressive devops techniques, devops in high-scaling environments and so much more. You will have the opportunity not only to use the skills you already have and enjoy, but also learn new and emerging technologies/setups in devops cultures.You may have a Software Development background, an Operations background, or you were raised in a DevOps culture from the start of your career. The field of DevOps covers a wide range of organizational design, process design, and information technology engineering. If you recognize yourself in the following, we want to hear from you!Overview:Our client loves Terraform. From authoring templates to modifying existing, they leverage this tool for the majority of their clients.Strong capabilities in configuration management. Puppet, Chef, Ansible, will help clients automate their workflows using all of these tools. If you are an expert in one, our client will teach you to become an expert in the others.Docker, Kubernetes and RancherPython, Golang, Ruby and Shell Script are often used with client interactions.DevOps automation ranging from Git, Jenkins, Docker, Chef, Puppet, Ansible, Selenium, xUnit, and othersYour commitment to meeting deadlines and exceeding client expectations is equal to your commitment to writing great code.Lead day-to-day pilot team implementations with clients and provide a diverse set of Agile and DevOps consultative services ranging from project management, requirements, design, development, testing, environment management, change and release, and supportTechnologies:Provisioning: TerraformConfiguration Management platforms: Puppet, Ansible, ChefLanguages: Python, Golang, Ruby, JavaScript and BashDatabases: MySQL/MariaDB, PostGRES, Amazon RDSEngineering & Monitoring tools: Bootstrap, Jenkins, Github, Nagios, Sensu, Zabbix, OpsGenie, JIRARuntime: Docker, Kubernetes, Angular, Prometheus, ElasticsearchClouds: AWS, Azure, GoogleCloud tool proficiency: AWS CLI, az, cloudinitOnsite Virtualization: VMware, OpenStack, KVMRequirements5+ years experienceExperience designing and deploying production-grade software via version controlExperience with object designExperience writing distributed systemsExperience developing in different compiled languages such as Go, Java, C++, and CExperience scripting with JavaScript, Python, or BashExperience with web application development using HTML, CSS, and AngularExperience with data transport using XML, YAML and JSONExperience developing and debugging software on a network stack IP, TCP, HTTP, RESTExperience using SQL and NoSQL databasesAbility to navigate and administer Linux and Windows operating systemsUnderstanding of how to scale server-side applicationsDemonstrated application of software engineering best practicesExperience working on Agile teams, specifically using the Scrum methodExcellent communication skillsWilling to take ownership of problems and see them through to resolutionBS in Computer Science or equivalent experience#EP1",chi,de
27,Kin Insurance,Insurance,4.4,Data Engineer,"Chicago, IL",$75K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=4128&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_b722e22a&cb=1618793006537&jobListingId=4061736027,"Kin Insurance is on a mission to change home insurance from what it could be to what it should be. We’re proud to offer affordable insurance coverage in areas most impacted by climate change, like Florida, California and Louisiana, that pay more for insurance than anywhere else in America.

We are also proud to be recognized as Built In’s 2021 Best Midsize Companies to Work For in Chicago and Forbes 2021 Best Startup Employers in America. We are growing super fast, and we need forward-thinking, inspired game-changers like you to help lead the way.So, what’s the role?Data is central to Kin’s operations and success. As a data engineer, you will be part of a data management team that supports and enables our product, operations, analytics, and data science teams, amongst others. As we scale, you will be integral in how we manage, structure, and store our data, as well as develop new solutions related to data architecture and ETL pipelines.A day in the life could include: 

Creating, designing, and maintaining ETL pipelinesWorking with data science and BI teams to create data sets to be used in various projectsParticipating in daily stands and weekly retrosCollaborating with cross-functional team membersProviding subject matter expertise and support

I’ve got the skills… but do I have the necessary ones?

3+ years of data engineering experience Experience with the entire ETL pipeline: Data Integration tools, Databases, Big Data Platforms, and cloud based data platforms.Exposure to and support of data visualization tools, such as Looker.Experience in building from the ground up a modern next generation data warehouse platform.

Oh, and don’t worry, we’ve got you covered! 

Medical, Dental and Vision Insurance (including 100% employer-paid plans)Remote Work (due to Covid-19) and flexible work hours Flexible PTO policy Very generous equity options and 401KParental LeaveContinuing education and professional development Disability and Life Insurance Onsite gym membership - when we return to the office (Chicago office only) The excitement of joining a high-growth Insurtech company and seeing your work make an impact

About Kin:In an industry that hasn't budged in more than 100 years, our technology transforms the user experience, cuts inefficiencies that waste billions of consumer dollars, and customizes coverage homeowners want. We believe insurance was always meant to be a digital product – we’re making that a reality.

Our approach to the industry makes us unique, and the people at Kin help us excel. We’re a team of problem solvers, collaborators, builders, and dreamers who are passionate about creating positive change in the lives of our customers and in our industry. Kin is more than just our name – it’s how we treat each other. That’s one of the many reasons we’ve been recognized as a great place to work by Built In, Forbes, and Fast Company.EEOC StatementKin is proud to be an Equal Employment Opportunity and Affirmative Action Employer. We don't just accept difference – we honor it, nurture it, and celebrate it. We don’t discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",chi,de
28,CNA Insurance,Insurance,3.6,Data Engineer,"Chicago, IL",$74K - $139K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_f2ae2181&cb=1618793006538&jobListingId=4034323700,"Data Engineer-OPE00016ZSupervisory Position: NoDescriptionJob SummaryLong Term Care Data & Analytics Team has an exciting new role available to help grow its Data Science capabilities. This role acts as a key data partner for all Long Term Care (""LTC"") functions (Operations, Finance, Actuarial) to support the growth and maintenance of their evolving Google Cloud Platform data universe. This successful candidate will utilize strong technical skills to improve processes and build and deliver new tools for improving business outcomes.As a Data Engineer, you will have the opportunity to utilize R, Python, Looker, SQL, Tableau and Alteryx to aid in the development of data pipelines/processes supporting Machine Learning, Business Intelligence and process automation. You will support LTC’s efforts to adhere to Data Governance best practices. You will partner with LTC business functions to deliver data-driven solutions to complex business problems while adhering to data engineering best practices. This role will come with plenty of opportunity to expand upon your current skills by researching and developing the latest tools and techniques in Data Science.Essential Duties & ResponsibilitiesPerforms a combination of duties in accordance with departmental guidelines:Uses knowledge and expertise to influence the organization at every level towards best in class data science tools and techniques.Supports projects as Data Science SME; Collaborates with stakeholders to help define data requirements.Effectively communicates with project stakeholders by presenting complex or technical concepts in business terms.Builds data pipelines and develop model features for Machine Learning projects.Supports process automation by leading smaller scale efforts to convert existing processes to Google Cloud Platform.Aggregates disparate structured and unstructured data to create meaningful datasets that drive analytical insights.Adheres to data governance best practices by leveraging Alation to build data dictionaries for new and existing data sources.Maintains and expands capabilities for data testing, validation and quality control.Supports data modeling in Looker, our cloud-based business intelligence platform.Works independently, receiving minimal guidance; acts as a resource for colleagues with less experience by providing instruction, guidance, and advice.May actively partner with other analytical teams across the organization and/or participate in special projects.Adheres to coding and documentation best practicesResponds to and fulfills ad hoc data requests.May perform additional duties as assigned.Reporting RelationshipTypically Manager or above.Skills, Knowledge & AbilitiesAbility to recommend analytical solutions to business problems and execute.Strong SQL knowledge and proven experience working with relational databases.Experience using R, Python, SQL, and other business related software.Experience with Linux servers on Google Cloud Platform or other cloud provider.Practical experience with version control, preferably Git.Experience using Looker or other data visualization tools a plus.Solid knowledge of core functions of insurance companies and general insurance acumenSolid interpersonal, communication and presentation skills. Effectively interacts with all levels of CNA's internal and external business partners.Solid analytical, critical thinking and problem solving skills to effectively resolve complex situations and issues.Solid project management, organization and planning skills with the ability to manage multiple projects effectively and lead teams. Ability to solve issues with a sense of urgency; utilizes and manages the available resources to make informed decisions and achieve superior results.Education & ExperienceBachelor's Degree in Business, Economics, Mathematics, Finance, Statistics, or related field.Typically up to two years of related work experience.EEO Statement: CNA is an Equal Opportunity Employer committed to a diverse work culture. M/F/D/V.Job OperationsPrimary LocationUnited States-Illinois-ChicagoOther LocationsUnited StatesOrganization LTC-Long Term Care - FinanceJob Posting Mar 16, 2021Unposting Date Ongoing",chi,de
29,Avanade,Information Technology,4,Front-End Software Engineer,"Chicago, IL",$100K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1044074&s=58&guid=00000178e79503f0bb450717d88d1efc&src=GD_JOB_AD&t=SR&vt=w&cs=1_9bdfa5e3&cb=1618793006538&jobListingId=4003653673,"Do you want to put companies back in control of their code? So do we.You take the best from open-source applications to craft bespoke solutions that are both creative and agile.About The RoleAs a client-facing Senior Front-End Software Engineer you’ll have the opportunity to learn our client’s business, their organization, systems, challenges, and goals. You’ll partner directly with clients to define and clarify requirements, work with your team to build accurate project and task estimates, and deliver outstanding client results.About YouYou’re passionate about the latest technologies in modern web development and have at least three years of front-end development experience. You can code JavaScript like a champ and keep abreast of all the latest JS frameworks. You are personable and hardworking, looking to join a team of others like you. You likely have experience as a consultant, working with external clients on a periodic basis.Day-to-day, You WillDeliver exceptional client results and project successConsistently develop and deliver high-quality and low-defect features on scheduleConsistently maintain accurate estimates surrounding your tasks and effortsLead by example through the implementation of challenging and complex componentsEnsure quality through adherence to technical best practices, mentorship, and feedbackFollow design patterns to create componentized, layered, maintainable, and extensible software productsYour Skills IncludeSingle Page Application design and development (such as React, Angular, Vue, or even Knockout)Expertise in HTML5, Cascading Style Sheets (CSS3), JQuery, JavaScript across libraries (interactive development), such as Angular, React, Vue, and NodeJSBuild mock-ups and prototypes using tools such as Zeplin, Sketch, or InVisionExperience using graphics software such as Adobe PhotoshopExperience using data exchange technologies like JSONExperience in writing coded unit tests in one of unit testing frameworks like Jest, Karama, Mocha, Jasmine, Enzyme, CypressExperience working in a DevOps environment, and using industry-standard tools (GIT/OneStash, JIRA) including Unit TestingExperience with responsive web development (e.g. bootstrap, material design, cssgrid, zurb foundation, styled-components, etc.)Experience with multifaceted stylesheet languages (e.g. SASS, LESS)Agile experience and participation in daily scrum meetingsComputer Science (CS) and development fundamentals, including Object Oriented Programming (OOP)Nice to HaveBuilding Progressive Web Apps (PWA), RESTful web services, Webpack to configure builds, data engineering technologies like Python, Spark, no SQL DB, and serverless cloud computing technologies like Azure Functions or AWS LambdaPreferred Years of Experience3-5 years of experience in software engineering with Microsoft technologiesRequired EducationBachelor's Degree in Computer Science, Computer or Electrical Engineering, Management Information Systems, or related field is requiredManagement ExperienceNone required",chi,de
0,Tri-Search,Business Services,4.2,Data Engineer,"Denver, CO",$72K - $108K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044076&s=149&guid=00000178e79a20f2a4264a4d5eca4cf6&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_ffe05e9a&cb=1618793341736&jobListingId=4063583206,"CPG company, position can be located in Denver or Los AngelesWHAT WE ARE LOOKING FOR:The Data Engineer reports to our Director, Enterprise Data and is responsible for designing, developing, testing, debugging, improving and supporting new and existing applications, reports and interfaces within the Microsoft technology stack. This individual will work closely with our Finance, Marketing, Operations and Sales teams to meet company objectives and improve customer productivity and efficiency. The Data Engineer will support and enhance our D365 ERP system through the creation of reports, interfaces and PowerApps, as well as assist the direct-to-consumer (DTC) business on Shopify through functionality enhancements and modifications as needed by the Ecommerce team.This individual should possess a problem-solution attitude and exceptional interpersonal + organizational skills to help understand the organization from the perspective of our teams. The Full Stack Applications Developer should thrive working in a multi-developer, multi-project environment with the ability to deliver clean and efficient code, as well as continuous best in class security practices.KEY RESPONSIBILITIES:Support the company's direct-to-consumer website hosted on Shopify and AmazonBuild Interfaces between applications, databases and servicesWork with project managers, business analysts, application support and QA to refine requirements and designsDevelop reports based upon team needs in various delivery methodsSupport and enhance the functionality of the company ERPDocument system requirements, designs and training materials, as neededPeer review IT team member work and enforce coding standardsIdentify opportunities for process improvement through the use of Microsoft Office 365 suite of tools and applicationsParticipate / Lead special projects and assignments, as requiredParticipate in all other miscellaneous SMPL and departmental tasks, as requiredAttend departmental/cross-functional meetingsSKILLS / KNOWLEDGE:Strong leadership and interpersonal skills to interact with Executives and team leads across the company,Architecture, design and development expertise within the languages stack and Microsoft Azure architectureRESTful service development; Database developments (normalization and warehousing)Thorough understanding of SDLC concepts; Knowledge of the following: Azure Data Lake, or related cloud-based storage, SQL Server Integration Services, Azure Data Factory, TFS, Git, Azure Devops version control and deployment, HTML5, CSS, JavaScript, jQuery, Microsoft Entity Framework and Responsive Design ConceptsAbility to manage projects simultaneously; Adjust to changing priorities; Drive strategic projects to successful deliveryBASIC QUALIFICATIONS:Bachelor’s degree and/or minimum 6 years relevant work experience, requiredMinimum 6 years relevant experience; CPG and in-house experience, strongly preferredFunctional understanding of MS SQL Server Database administrationCross functional experience, requiredExperience coding to Active Directory AuthenticationExperience supporting and developing Ecommerce platforms (i.e. Amazon and Shopify)ERP experience, a must ; D365 or Dynamics AX, preferredTechnical lead experience, preferredJob Type: Full-timePay: $95,000.00 - $115,000.00 per yearBenefits:401(k)Dental insuranceHealth insurancePaid time offTuition reimbursementVision insuranceSchedule:Monday to FridaySupplemental Pay:Bonus payApplication Question(s):What is your target salary range?Are you authorized to work in the US without sponsorship?Experience:ERP systems: 2 years (Preferred)Power BI: 2 years (Preferred)SSIS: 1 year (Preferred)Work Location:One locationCOVID-19 Precaution(s):Remote interview process",co,de
1,West Metro Fire Rescue,Government,4.7,Data Engineer/ Analyst,"Lakewood, CO",$73K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044077&s=149&guid=00000178e79a20f2a4264a4d5eca4cf6&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_d1ba4ae5&cb=1618793341737&jobListingId=4062448364,"IMPORTANT: To be considered for this position, you MUST apply at www.westmetrofire.org on the ""Jobs"" pageNATURE OF WORK The data engineer / analyst is primarily responsible for the fulfillment of West Metro Fire Protection District(District) analytics and application programming interface needs. This includes building, automating, and maintaining data pipeline architecture for all district systems, including replication of transactional and operational data to centralized infrastructure; data modeling, analysis, and reporting; and integration of technology. The position develops and maintains information visualization tools; and identifies, designs, and implements infrastructure solutions driving continuous improvement for District operational and administrative functions.This position reports to the risk management and accreditation chief and collaborates with the information technology (IT) division on a regular basis.ESSENTIAL DUTIES Fulfill the District’s analytics needs through data interpretation; present findings by creating charts, graphs, tables, and dashboards reflecting District outcomes and performance.Align IT and data architecture with the District's strategic goals.Conduct research and development in assigned areas, including analyzing emergency response performance data and information using SQL, Python, and Tableau; completing reports and presentations related to emergency and non-emergency response activity.Assisting in administrative areas such as performance measurements, cost allocations, budget development, expenditure tracking, staffing analysis, and surveys.Create, automate, and maintain optimal data pipeline architectures.Integrate large, complex data sets into the District's cloud infrastructure and across organizational functions.Design and build data lake/data warehouse infrastructure.Build and support APIs to effectively extract, transform, and load business data into various systems to facilitate critical business processes.Identify, design, and implement infrastructure improvements by automating manual processes and optimizing infrastructure for greater scalability and performance.Document technical design specifications for applications such as data management plans or process maps.Utilize data pipelines to provide actionable insights and predictive analysis for response performance, continual improvement, and accreditation.Communicate findings to management, district personnel, agency stakeholders, citizens, and other officials.Prepare reports and update dashboards to provide near real time data analytics for use and viewing by all divisions.Perform District liaison functions with data consultants to fulfill the District’s needs.Participate in the processes of strategic planning teams, provide guidance and expertise on system options, risk, impact and costs vs. benefits, create and share operational requirements and development forecasts to allow for timely and successful execution of projects.The above listed essential duties are not an all-inclusive list; this person will have other duties assigned to meet District needs and priorities.REQUIRED KNOWLEDGE, SKILLS, AND ABILITIES SQL knowledge and experience working with relational databases, query authoring (p/SQL), as well as working familiarity with a variety of databasesKnowledge of, or ability to rapidly become familiar with the District’s technology stack including cloud infrastructure, staffing software, financial software, record management software, etc.Successful history of, processing, extracting value from, and modeling information from disparate datasetsStrong project management and organizational skillsetsStrong interpersonal and communication skills with the ability to write proposals or papers, make presentations, and work closely with upper managementSkills in math, statistical analysis, and technical problem solvingExperience with implementing, administering, and supporting large database solutions (cloud preferred - such as Azure, AWS, etc.)Experience with industry standard programming languages (for example, Python, Java, etc.)Ability to build and optimize data pipelines and / or data streaming architecture, and extract / transform / load(ETL) architectures and data setsAbility to formulate and execute an organizational data governance strategyAbility to build processes supporting data transformation, data structures, metadata, dependency, and workload managementAbility to identify trends with machine learning and make predictions based on data trendsAbility to prioritize, work independently, keep records, and develop reportsAbility to support cross-functional teams in a dynamic environmentAbility to travel for classes and conferences to support professional developmentAbility to understand and follow oral and written instructionsAbility to utilize data visualization tools (for example, Tableau, PowerBI) to present real-time meaningful information to internal and external stakeholdersMATERIALS AND EQUIPMENT DIRECTLY USED Operates general office equipment including telephones, calculators, computer terminals, personal computers, copy machine, printer, fax, camera, presentation audiovisual equipment, smart devices and various computer programs, hardware, and software.JOB REQUIRMENTS, EDUCATION AND EXPERIENCE ENTRY*Bachelor’s degree in computer science, data science, information systems, statistics or equivalent with a preference for a data engineering concentrationAbility to use and operate a wide variety of office automation equipment and software including analytics applications, database management, record storage, retrieval systems and word processingExperience with one or more programming languages (Python, SQL, Java, etc.) and knowledge of business intelligence solutions (Tableau, Power BI, Alteryx, etc.)Understanding of the District’s product/tools/systems and functionalityPossess interpersonal skills necessary to effectively work with district staff and third-party providerAbility to analyze data using standard statistical methods, interpret the results, and provide summaries through multiple reporting platformsTwo to five years related work experience desirableKnowledge of continuous improvement programs such as Lean management or TQM (total quality management)*MASTERY Master’s degree in related fieldTen years’ experience in roles that required highly technical expertise and experience working across one or more products or a suite/subset of activities of internal business systemsFive years’ experience working in a data engineer/analyst role for a fire districtAchieved position specific continuing educationDemonstrate ability to effectively communicate internally and externallyAbility to multi-task, prioritize and meet assigned deadlinesProvides excellent customer service to all clients, personnel and elected officialsOTHER NECESSARY SPECIAL REQUIREMENTS Must be at least 18 years of age. Must possess a valid Colorado Driver's License (or be eligible to obtain by time of employment) and exhibit a safe driving record. Failure to maintain a valid Driver’s License and safe driving record is subject to Administrative Procedure #4104 Operation and Use of District Vehicles.Background investigation, polygraph, physical examination, and a substance screening required prior to employment.Must demonstrate the ability to meet the physical demands of the job including the ability to retrieve information and supplies from various locations in the office when needed. May include exposure to periods of high activity and high stress under demanding conditions. The position requires a great deal of communication with district staff, the public, and outside agencies. While performing the duties of this job, the employee is regularly required to sit, talk and hear. The employee is occasionally required to use hands to finger, handle, or feel objects, tools, or controls; reach with hands and arms, stoop, kneel, crouch, and crawl.IMPORTANT: To be considered for this position, you MUST apply at www.westmetrofire.org on the ""Jobs"" pageJob Type: Full-timePay: $87,000.00 - $93,000.00 per yearBenefits:Dental insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offRetirement planTuition reimbursementVision insuranceSchedule:Monday to FridayEducation:Bachelor's (Required)Work Location:One locationCompany's website:ww.westmetrofire.orgCOVID-19 Precaution(s):Temperature screeningsSocial distancing guidelines in placeSanitizing, disinfecting, or cleaning procedures in place",co,de
2,A2Z Sync,Information Technology,-1,Systems and DevOps Lead Engineer,"Greenwood Village, Arapahoe, CO",$151K - $187K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_292de94c&cb=1618793341737&jobListingId=4060266760,"We are growing again and we need a Systems Infrastructure and DevOps Lead to join our team!A2Z Sync is a disruptor in the automotive industry - transforming the sales process into a transparent experience for customers and providing the tools necessary for dealers to transition to a single point of contact.Duties and ResponsibilitiesThis role is not only a supporting function, but one of leadership as well. We need opinionated individuals that are able to craft new infrastructure solutions, and are ready to help us with our platform infrastructure. We are a multi-tenant platform with a rapidly growing customer base. Our infrastructure is scaling rapidly, and we need you to come help us plan for the future.This position will be involved in all aspects of DevOps and System Administration in support of our SaaS application. This includes designing and enhancing AWS cloud environments, optimizing and maintaining CI/CD workflows, and leading future architecture planning both for our core functional infrastructure and data pipelines.We need an expert in AWS services (Networking, Compute, Databases, Logging and Metrics), Container Orchestration, DevOps tools, Infrastructure as code, Cloud security. This role is an essential part of a broad effort to bring together Architecture, Systems Engineering, Software Development, Quality, and Security to build automation solutions that are highly reliable, resilient, and extendable.This position is based in Denver, Colorado. We are looking for local candidates or candidates that are willing to relocate.Skills and ExperiencePreferred:Experience leading a team, and driving forward ideas from concepts to practical projectsBuild and Manage AWS cloud infrastructure and automationBuild and manage CI/CD platform and release processesDeploy scalable and secure microservices applicationsPerform architecture and security reviews, identify gaps and develop remediation plansDefine, document, and maintain a strategic DevOps architecture roadmap that includes business, product, and technical considerationsStaying up to date on new devops tools & techniques, and act as a driver of innovation and process maturityComputing cloud cost models, network topology, platform services, and common storage optionsExpert level with Agile methodologiesHands-on experience with automated deployment of resources, Serverless deployments, Kubernetes clusters, AWS environmentsExperience with automated testing frameworksComfortable with ambiguity and fast change with an ability to adapt quickly and easilyStrong coding experienceBash, PowerShellSQL, REST, queuing frameworksDevOps tools; Ansible, Chef, Terraform, CloudFormation, JenkinsExtensive experience with logging and metrics tools3 or more years of experience working with cloud architecture on AWS, including, but not limited to EC2, RDS (MySQL), Elasticache, VPC, Security Groups, S3 and CloudfrontUnderstanding of Blue/Green deployment strategiesExperience with implementing auto-scaling strategies on AWSExperience with Linux server administrationExperience with application and server monitoringExperience identifying and implementing security protocols to protects network resources and application data, including proficiency working with SSL/TLS certificates and VPN tunnelsWorking with the development and QA teams to maintain and enhance CI/CD workflows using tools such as Jenkins and CircleCIExperience with Docker or Kubernetes, or other container technologiesCan create and maintain documentation pertaining to all aspects of DevOps and System AdministrationWorking with external APIsNice to Have:Understanding of AWS data pipeline tools such as RedShift, Glue, and Data visualization toolsPositive and flexible attitudeA belief that people should not be called “Resources”Strong organizational, project and time management skillsA2Z Sync is a fast paced, and innovative company seeking to make life better for our customers. We offer you a fun, casual, collaborative culture. We also foster an environment where you work hard, see your results, and feel your impact. We are committed to our employees and this starts with proving benefits that allows you to care for yourself and your family.Here’s how we are doing it:A2Z Sync offers comprehensive medical, dental and vision benefitsWe cover your STD/LTD and life InsuranceMatching 401k planUnlimited paid time off, including 9 paid holidaysGenerous employee referral programGym on-site plus nearby trails for outdoor activityOpportunity to work with a great team where your insights and expertise will be valuedA2Z Sync is located across the street from Belleview Station which is a walkable district offering cutting edge shopping and dining. Belleview Station is located at the I-25 corridor with easy access to Light Rail and RTD.A2Z Sync is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, veteran status, basis of disability or any other federal, state or local protected class.",co,de
3,CoBank,Finance,3.9,Senior Software Engineer- Salesforce Administrator,"Greenwood Village, Arapahoe, CO",$77K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_dee96108&cb=1618793341737&jobListingId=4063695401,"Benefits Overview:A career at CoBank can offer you the opportunity to make a personal impact on the people and communities where we do business. When you choose a career with CoBank, you make a difference by standing for something that matters. In order to be the best, we hire the best!Remarkable Benefits offered by CoBankCareers with a purpose-stand for something!Competitive Compensation & IncentiveBenefits Packages, including: Medical, Dental and Vision coverage, Disability, AD&D, and Life InsuranceCoBank University robust curriculum –associate training and development, including higher education tuition reimbursementOutstanding 401k – up to 9% matching!Time-Off Packages – Vacation 15+ days, 10 Paid Sick Days, and 10 Paid HolidaysCommunity Impact – United Way Angel Day, Volunteer Day and Associate Directed ContributionAssociate Resource Groups – creating a culture of diversity and inclusionRecognize a fellow associate with “GEM” awards, including a monetary valueRemote day(s) availableOn-site Fitness Center and CafeECO transportation pass provided to every Denver associateJob Description:At CoBank, our Senior Software Engineer will analyze, design, develop, configure, test and implement changes to our enterprise Salesforce environment. They will also provide technical direction and guidance to other technical staff.Essential Duties and Responsibilities:Analyze and recommend design changes for complex problems and opportunities. Collaborate with groups throughout the Bank to determine the appropriate design to meet objectives or requirements. Responsible for implementing approved architecture design.Perform complex programming/configuration assignments requiring an advanced aptitude of Salesforce programming/configuration standards, methods, and best practices.Guide the team in translating requirements into configuration, identifying where custom development/integration may need to occur.Administer and maintain applications within the portfolio; make approved changes and amend or create appropriate documentation.Perform code releases, environment refreshes and monitor the overall health and performance of the platform.Maintain thorough knowledge of Salesforce and related systems. This includes best practices and processes having an impact on the applicationAssists in implementing Salesforce best practices (System Architecture, Workflow, Reporting, Maintenance, Change Management Process)This role will be part of the team’s on call rotation and will occasionally require after hours and weekend work.Basic QualificationsBachelor’s degree in Computer Science, MIS, Engineering or related field, or relevant work experience6+ years Software Development Lifecycle experience. Developing with tools such as Visual Force, Javascript, Apex controllers, Apex Classes/Triggers Configurations, Workflow, Batch Jobs and standard Salesforce componentsPreferred QualificationsAdvanced Salesforce Administrator / Developer Certification(s)Experience working within an Agile team using a process framework such as ScrumHigh aptitude in building queries using SOQL or SOSL.High aptitude using data models and understanding how and when to create custom objects vs. using out-of-the-box functionality.High aptitude with Service Cloud and CommunitiesHigh aptitude with Salesforce Object design.High aptitude with data migration and updates through App Exchange Data Loader.High aptitude working with customers to build and formulate business requirements.Excellent problem solving, troubleshooting, oral and written communication skillsAbility to work independently and as part of a teamAbility to provide first level of advice/assistance on procedures and work methods for software engineers and application developers.Ability to define and implement new technical direction and to identify and participate in issue resolution and process refinementWillingness to broaden technical, functional, and industry skill base and to keep current with industry information and technical knowledge databasesExperience in the financial services industry.Compensation InformationEstimated Base Salary Range:$100,000-$125,000Target short-term incentive opportunity:15%About CoBank:CoBank stands strong as a $135 billion enterprise dedicated to the financial needs of rural America. As a national cooperative bank and a proud member of the Farm Credit System it is our mission to serve as a relevant and dependable provider of credit and other value-added financial services. From our headquarters in Denver, Colorado and our regional banking centers across the US, CoBank provides loans, leases, export financing and other financial services to agribusinesses and rural power, water and communications providers in all 50 states.CoBank will not sponsor a work visa (e.g. H1B, etc.) to fill this position.CoBank is an Equal Opportunity Employer.",co,de
4,Columbia Care,Biotech & Pharmaceuticals,3.5,SR. Solutions Engineer,"Denver, CO",$84K - $108K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b5b9d106&cb=1618793341738&jobListingId=4006030651,"Reports to: Data Services ManagerPosition Overview:The Solutions Engineer will be responsible for design, development, implementation, documentation, and operational support of the company’s Seed to Sale solutions. Working well as a collaborative member of the team is imperative to success in the role, as is the ability to deliver results in a fast-paced environment where systems and processes are still being developed and maturing.Major Areas of Responsibility include:Collaboratively compose, edit, and revise process knowledge base documentation for new and updated solution releasesMonitor and respond to Seed-to-Sale help desk tickets, provide technical assistance for questions and problemsFollow up with customers to ensure full resolution of issues and provide notification of software updates related to submitted ticketsSupport training efforts on solution, general troubleshooting and diagnosing problemsSupport IT departmentRole will require occasional, planned off-hour supportMinimum Qualifications (Skills, Knowledge & Abilities):All applicants must be at least 21 years of age2+ years’ experience with cannabis software, software migrations or implementations, and Seed-to-Sale business operationsKnowledge of relevant regulations and strong understanding and usage of industry terminologyKnowledge of cannabis integrations, including but not limited to menu integrations (Leafly, Weedmaps, Dutchie, I Heart Jane), and marketing/CRM integrations (Headset, Springbig, HubSpot, BDS Analytics)Significant people and process skills, allowing for complex subjects to be communicated effectively to different types of audiences by adjusting the delivery of the informationEffective organizational, presentation, documentation, and analytical skills with demonstrated ability to follow through tasks to an effective resolutionExcellent organization skills with ability to handle multiple tasks to meet deadlinesStrong project management experience/skillsTravel %: 25-50FLSA status: ExemptAdditional Abilities Required:This job operates in an office setting and is largely sedentary, requiring the routine use of a computer and other standard office equipment. The ability to lift or move up to 5 pounds, bend, reach, and perform manual tasks may also be required.Note: Nothing in this job description restricts the company’s right to assign or reassign duties and responsibilities to this position at any time. Reasonable accommodations may be made in appropriate circumstances to enable individuals to perform the essential functions of the position.About Columbia CareColumbia Care is one of the largest and most experienced cultivators, manufacturers and providers of medical and adult use cannabis products and related services with licenses in 18 US jurisdictions and the EU. Columbia Care currently operates 107 facilities1 including 80 dispensaries and 27 cultivation and manufacturing facilities. Columbia Care is one of the original providers of medical cannabis in the United States, and continues to deliver an industry-leading, patient-centered medicinal cannabis operation that has quickly expanded into the adult use market as a premier operator. The company currently offers products spanning flower, edibles, oils, and tablets, and manufactures popular brands including Seed & Strain, Amber and Platinum Label CBD. With more than four million sales transactions since its inception in 2012, Columbia Care is known for setting the standard for compassion, professionalism, quality, care, and innovation in the rapidly expanding cannabis industry. For more information on Columbia Care, please visit www.col-care.com#indhp",co,de
5,"Douglas County, CO",Education,3.9,Engineer III (Capital Improvement Projects),"Castle Rock, CO",$45K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_92d15d80&cb=1618793341739&jobListingId=4060264119,"Engineer III (Capital Improvement Projects)Employment Type: 0 - Full-time RegularPay Range: $76,830.00 - 115,246.00Location: Castle Rock, COOvertime Exempt: YesElected Office / Department: DEPT OF PW- ENGINEERINGThis is complex technical engineering work within the Public Works Engineering Department. Duties and responsibilities are with an emphasis on civil engineering and construction practices. This position will manage and coordinate various phases of project development, with an emphasis on assisting in coordinating utility relocations, preparing construction bid documents and overseeing construction activities that are being performed by both consultants and contractors. Position requires a broad range of supervisory skills including but not limited to the responsibilities of managing contractors, consultants, and other professionals associated with the design and construction phases of a variety of transportation and drainage projects.The anticipated hiring range will be around the midpoint of the pay range, based on experience.ESSENTIAL DUTIES AND RESPONSIBILITIES: (The following examples are illustrative only and are not intended to be all inclusive.)Develops, analyzes and reviews engineering plans, survey documents and plans, engineering and environmental studies and reports, design and construction documents (plans and specifications) for correctness, compliance and constructability. Examples of those plans, would include: review of plats, roadway plan and profiles, bridges, box culverts, retaining walls and other transportation and drainage related structures, storm drainage improvements, water quality and detention improvements, grading, erosion and sediment control, construction phasing and method of handling traffic during construction, traffic signing and striping plans, traffic control, traffic signal plans and signal timing. Examples of studies, reports, design and construction documents would include: drainage reports, storm water management report, pavement design and geotechnical reports, traffic studies, alternative road standards, bid documents, roadway and structural calculations, NEPA and other applicable environmental clearance and permit documents, service plans, subdivision improvement agreements, intergovernmental agreements, improvement agreements, easement documents and right-of-way documents. All items listed, must be in conformance with applicable, federal, state and Douglas County criteria.Acts as the project engineer or design engineer on all projects assigned by supervisor. As project / design engineer, may be responsible for various phases of the project development from initial conceptual design through completion of construction of assigned projects.Familiar with the use of computer assisted engineering programs and design software to prepare or evaluate engineering design documents. Such programs and software include AutoCAD Infrastructure Design Suites (or equal) or Microstation InRoads (or OpenRoads).Coordinates project design and construction activities with other Douglas County Divisions and other local agencies such as adjacent City, Town, and County Governments, Tri County Health Department, Mile High Flood District, U.S. Army Corps. of Engineers (USACE), CDOT, FHWA, CDPHE, and applicable metropolitan districts.Prepares written technical correspondence based on review of project related design and construction documents. The correspondence evaluates project conformance with County, State and Federal design and construction criteria and offers solutions acceptable to County criteria or other applicable agency’s requirements for State Highway projects.Meets and coordinates with developers, engineers, architects, contractors and other County staff to discuss project conflicts and agree on acceptable solutions in order to form a consensus that satisfy the majority of entities involved, while meeting County criteria. Conducts pre-submittals, pre-bids, bid openings, pre-construction, etc.Prepares reports, specifications, plans, construction schedules, traffic analysis, and project designs and construction details relative to individual projects. Prepares and calculates quantities and cost estimates for all assigned projects. Determines project feasibility based on analysis of collected data, recommend construction sequencing and implementing an appropriate construction phasing plan for assigned projects during both design and construction.Ensure that construction or reconstruction activities are being completed in accordance with approved plans and contract specifications. Researches, interprets, and makes recommendations related to construction methodology, enforces codes and specifications, including (when applicable) adherence to Federal, State requirements related to Davis-Bacon wage rates, certified payroll, and other regulatory documentation requirements pertaining to construction labor requirements.Construction Management responsibilities include: assist in the review and evaluation of selecting contractors for assigned projects in order to ensure that recommendations of award of construction contracts are made to responsive and responsible contractors, overseeing and tracking contractor daily activities, review contractor request for information (RFIs) and preparing responses, negotiate, make recommendations to supervisor and execute Contract Modifications (Change Orders), prepare independent records of contractor daily progress and review contractor daily logs, material certifications, shop drawings, review inspections and material test results, review of construction phasing plans, review traffic control plans, review and analyze contractors construction schedules, (including project milestones, critical path and float). Assist in the preparation, evaluation and negotiations of contract amendments. Review and recommend approval of progress payments application for contractors and consultants.Conducts site inspections. Monitors, oversees, and ensures conformance of construction in compliance with the engineering plans, specifications, and safety standards on assigned projects. Responsible to resolve or coordinate the resolution when the construction of the improvements is not in accordance with the accepted plans; and make recommendations to supervisor on desired course of action to resolve project issues.Responsible for the review of individual contractor’s quality control plans and implementing the appropriate quality assurance program for individual projects, including scheduling and overseeing all necessary inspections and material testing for assigned construction projects, in accordance with Douglas County, other local entities / special districts, State and Federal requirements (as applicable).Responsible for assisting various contractors with the coordination of weekly project progress meetings, review of the contractor’s base line and all updated construction schedules submitted, identifying and tracking progress on critical path items throughout the project duration, including resolving utility conflicts and coordinating utility relocations both in advance of and during construction. Determine the status of construction work and verify adherence to contractual obligations. Investigate complaints and recommend corrective action as necessary to resolve complaints. Negotiate and resolve construction disputes; assist legal department and participate in construction claim defense.Assists in identifying utility locates and coordinating utility relocation for assigned projects. Coordinate utility work with contractors, utility companies and other project stakeholders, assist in developing the appropriate public outreach plan to keep the general traveling public, the local businesses and property owners informed and engaged during all phases of project development, especially keeping these groups well informed that are impacted by the project and appropriately informed about the project upcoming construction work and delays. Answer questions and provide information to the public and other interested parties regarding design and construction activities. Responsible for daily correspondence related to each project assigned.When required, attend and make presentations to the Planning Commission and Board of County Commissioners for assigned projects. Attend and assists in conducting neighborhood and other public meetings to discuss projects with interested and affected property owners and homeowner groups. Provides information and assistance to the public as needed. Provides public information and assistance by evaluating existing problems and making recommendations for the appropriate corrective actions to property owners, homeowners and their consultants.Performs other duties as assigned.SUPERVISION RECEIVED: Assignments are made in terms of broad practice, precedents, policies, and goals. Work may be reviewed for fulfillment of program objectives and conformance with departmental policy and practice.SUPERVISORY RESPONSIBILITIES: This position does not directly supervise other County employees.INDEPENDENT JUDGMENT: Work is performed independently within general policy guidelines. This position requires the ability to use given criteria, guidelines, theories, concepts, principles, specific information, in addition to independent judgment, in order to arrive at valid recommendations.MINIMUM QUALIFICATIONS:EDUCATION and/or EXPERIENCE: Requires a bachelor’s degree in Civil Engineering, Construction Management or a degree in another related field and a minimum of five (5) years of progressively responsible engineering experience in design or construction OR any equivalent combination.KNOWLEDGE, SKILLS AND ABILITIES:Considerable knowledge is required in civil engineering and traffic engineering design, principles, practices, techniques, methodologies and construction. Knowledge of Federal, State, and County regulations pertaining to design or construction of roads, bridges, retaining walls, drainage facilities. Knowledge of surveying methods and instruments. Negotiating and problem-solving skills in order to complete work. Knowledge and experience related to coordinating utility relocations, oversight of outside consultants and contractors is essential as well as the ability to check and verify legal land boundary descriptions for easements and right-of-way parcels, read or compile field survey notes and read and understand various construction staking practices.Ability to read, analyze, and interpret County Engineering Criteria, professional journals, technical procedures, and governmental regulations. Ability to respond to inquiries and/or complaints from applicants, regulatory agencies, or the public. Ability to effectively present information both orally and in writing to professionals, contractors, utility company representatives, County management, Board of County Commissioners, general public and other agencies. Ability to establish and maintain effective work relationships.Ability to perform complex math calculations using algebra, coordinate geometry, trigonometry, physics, related to the design and construction of capital improvement projects. Ability to apply mathematical operations to such tasks as frequency distribution, determination of test reliability and validity, analysis of variance, correlation techniques, sampling theory, and factor analysis.Ability to define problems, collect data, establish facts, and draw valid conclusions. Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.CERTIFICATIONS, LICENSES, & REGISTRATIONS:Registration in the Fundamentals of Engineering (FE\EIT) by the Colorado State Board of Registration for Professional Engineers and Land Surveyors, or any equivalent combination education and experience. Must have a valid Colorado Driver’s License at hire date.WORK ENVIRONMENT:Work is generally performed in a typical office environment or typical County construction site. The employee frequently works in outside weather conditions. However, depending on the assigned projects, the employee may spend as much as 50% to 90% of the time outside the office for extended periods of time.TOOLS AND EQUIPMENT USE:Personal computer, word processing software, various other types of computer software, preparing complex Excel spreadsheets, reviewing and comprehending complex Microsoft Project Schedule or Primavera software documents, copy machine, fax machine, telephone, various other office equipment, automobile and light trucks.PHYSICAL DEMANDS:While performing the duties of this job, the employee is regularly required to sit, stand, walk, talk, use hands, fingers, handle, feel or operate objects, and stoop, kneel, crouch, or crawl. The employee is occasionally required to reach with hands and arms.Employee must communicate clearly and effectively, both verbally and in writing; and must understand and be understood; and have experience in establishing and maintaining effective working relationship.Specific vision abilities required by this job include close and distance vision acuity and the ability to adjust his or her focus, allowing a broad field of vision.It is essential that the employee be physically able to operate a variety of computer and office equipment successfully in order to fulfill the essential functions of this position.AVAILABILITY/ACCESSIBILITY: This position requires the incumbent to remain available via mobile cellular device/email access during and after normally scheduled business hours.ADDITIONAL INFORMATION:This position is open until filled, review of applications will begin immediately and continue until a suitable candidate is selected.The job details outlined in this posting represent a modified summary of the full job description. A full copy of the job description may be requested by emailing HumanResources@douglas.co.us.In the event of an emergency/disaster in or near the County, all County employees are expected to make every effort to be available to assist the County Manager, Elected/Appointed Officials and Department Directors to ensure the continued operation of any and all necessary County functions. This may mean being available to perform additional duties and hours beyond what is normally required. In the event that an exempt employee does work more than 40 hours a week in support of County operations during an emergency, such employee may receive overtime or other appropriate wage compensation in accordance with existing County policies or at the discretion of the County.",co,de
6,Blue Margin,Information Technology,5,ETL Engineer I,"Fort Collins, CO",$37K - $62K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_1f85bc76&cb=1618793341740&jobListingId=4061589654,"Blue Margin, Inc. helps companies Thrive Through Data™. We create data warehousing and dashboard reporting tools that improve business outcomes for all of our clients. We're a high-performing team of experts, and the result of our work is more efficient and productive operations, a healthier culture, and stronger job-ownership by employees. We believe in working hard, volunteering in our community, and enjoying life to the fullest.Blue Margin Inc. is a Microsoft Gold partner in Data Analytics, Data Platform, Application Development, and Cloud Platform.Why are we looking?We are expanding our Microsoft Power BI team, and are looking for clever, creative, data-savvy people who are flexible and capable of putting themselves in the shoes of the client. Our growth means we are looking for people with great attitudes, who are fun to work with. It also means we provide an excellent opportunity for someone who is serious about learning and advancing their career.The ETL Engineer’s role exists to develop and maintain reporting databases using the Microsoft stack, primarily in Azure, ensuring high levels of data availability. They will also evaluate and advise on database technology components, such as software, hardware, and networking. Finally, the engineer will assist in implementing and maintaining reporting dashboards across the organization.We are seeking a candidate to work as a full-time employee in our local office in Fort Collins.Blue Margin has, and will continue, to take a conservative approach to keep our employees safe during the COVID-19 pandemic.Please note that we are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.Responsibilities:Maintain data warehouses.Design and deploy data table structures, reports, and queries.Diagnose and resolve database access and performance issues.Assure security of data from external parties and for management of row-level-security within the organization.Plan and coordinate backup and disaster recovery setup.Develop, implement, and maintain change control and testing processes for modifications to databases.Develop and maintain database stored procedures, views, and functions that support reporting data models.Develop and maintain ETL processes.Produce ad-hoc queries that develop reports to support business needs.Create reports and data models using Power BI that meet business requirements.Provide data management support to users.Create and maintain technical documentation.Candidates MUST possess the following qualifications:Up to 2 years of experience in development within the Microsoft/SQL stack.T-SQL experienceExcellent verbal and written communication skillsAbility to coordinate and work cohesively with a development team (no ‘code-loners’)Experience creating charts, graphs, dashboards in one or more of the following programs: Excel, SSRS, Power BI, Tableau, Qlik and/or similar programs.Familiarity with cloud services (AWS, Azure (preferred), Google Cloud)Experience creating databases from the ground upIn-depth understanding of data management (e.g., permissions, recovery, security, and monitoring)Comprehensive grasp of data visualization methods and data modeling for effective report creationAbility to design, construct, and maintain data warehousesBasic to intermediate experience with SSMS and SSISIdeal candidates would possess these additional qualifications:Experience with SSAS, Tabular-based reporting, and Tabular Data ModelsA broad understanding of data visualization methods and techniquesPower Query (""M"" language), and DAX language experienceProfessional presentation skills and the ability to present to audiences of 10-15 people.Broad business experience with proficient ability to talk to executives in business termsWillingness to creatively engage with customers to come up with custom solutionsFamiliarity with Kimball methodologies of data warehousingUnderstanding of the difference between application database design and reporting database designOur Culture:Company Core Values: Commit to Quality, Embrace Transparency, Choose to Be Positive, Be Efficient/Systematize, Pursue Learning, Be GenerousWeekly personal and professional development programs for allTeamwork—we maintain company-wide interaction and communicationEntrepreneurism – we want everyone on our team to be eager to adapt and evolve with our advancing business. We are looking for someone who is comfortable wearing more than one hat.Work Environment and Physical Requirements:This job may require moderate physical effort including lifting materials and equipment of less than 10 pounds and involves viewing a computer screen more than 80 percent of the time. The job will take place in a normal office environment with controlled temperature and lighting conditions. This position requires standing or sitting for long durations.This position may require occasional weekends and evenings and some occasional travel for off-site functions.Salary and Benefits:This is a full-time position with a starting salary range of $60-70K and is commensurate with experience and qualifications.Benefits include health, dental and vision insurance, short- and long-term disability, 401K matching, health club stipend, paid vacation, sick leave, and an annual profit-sharing plan.",co,de
7,Ping Identity,Information Technology,4.5,Sr. Data Engineer,"Denver, CO",$101K - $187K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_6c100817&cb=1618793341740&jobListingId=4058970598,"At Ping Identity, we're changing the way people think about enterprise security technology. With our innovative Identity Defined Security platform, we're helping to build a borderless world where people have total freedom to work wherever and however they want. Without friction. Without fear.We call this digital freedom. And it's not just something we provide our customers. It's something that drives our company. People don't come here to join a culture that's built on digital freedom. They come to cultivate it.We're headquartered in Denver, Colorado, and we have offices and employees around the globe. And we serve the largest, most demanding enterprises worldwide, including over half of the Fortune 100. Because even in the most complex enterprise environments, security shouldn't be a source of anxiety. It should be one of your greatest competitive advantages.You will work with product management and operations on extracting, housing, managing, and connecting product data to data warehouses and visualization tools. Additionally, you will create standard and ad hoc product usage reports and support us in continuing to understand our product usage/behavior, especially for cloud products. You will report to Product Operations. This job is remote-friendlyYou Will:Manage and build new data job flows between cloud products and data visualization toolsImprove data extraction and storage methodologiesPartner with product managers to determine new product data needs and trouble shoot any issuesAssess and analyze extracted dataCreate product usage data reports on a recurring and ad hoc basisYou Have:7+ years data engineering and/or data science experienceUnderstanding of Python, Pentaho, Airflow, Tableau, and SplunkOur Benefits:Open PTOParental LeaveFree Healthcare Option401(k) MatchGenerous Holiday ScheduleCommuter OffsetEducation ReimbursementPing Identity is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.Salary offers will be based on the candidate's qualifications",co,de
8,IP Automation,Manufacturing,-1,Design Engineer,"Colorado Springs, CO",$41K - $66K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044077&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5278b93a&cb=1618793341744&jobListingId=4063533378,"Summary: The Design Engineer will interface with IP Automation customers, conceptualize and quote concepts that meet customer expectations, complete engineering designs and work as project manager to have designs manufactured.E*ssential Duties and Responsibilities*:Create sketches, concepts and Engineering ideas and translate them into Solid Works drawingsMaintain file systems for work in progress, completed and conceptional drawingsMaintain the engineering change notice procedureCreate drawings in Solid Works, construct 3-D modeling and perform force analysis studiesCreates designs for DFM and DFA and collaborate with Manufacturing Engineers for improvement to designConceptualize and design for customer projects. Select materials and purchased materials to be used in the design.Prepare quotation packages for submittal to customer to comply with RFQ documentsEstablish easy to access and use of drawing files on the company directory, which will be shared with Engineering and Administrative staff.Define and sustain security systems to keep design data secure.Implement design by managing the resources required to develop the design into a working unit.Qualifications: Proficient at Solid Works drawing protocols.BS in mechanical engineering.Working knowledge of fasteners, transfer devices, mechanical motion components and power drive systems.Working knowledge of materials and their applications.Ability to communicate effectively across different levels of a manufacturing company and with customers.Good attendance requiredEffective project management skillsMinimum 3 years of experience in mechanical engineeringJob Type: Full-time",co,de
9,Perspecta,Aerospace & Defense,3.6,Enterprise Architect / MBSE engineer,"Colorado Springs, CO",$74K - $126K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_9189c1a2&cb=1618793341742&jobListingId=4059228474,"Business Group HighlightsDefenseThe Defense group supports the Department of Defense (DoD) mission to keep our homeland and its citizens safe. We provide solutions to improve the Nation's defense by providing software, systems engineering, IT, training and logistics and fleet management solutions.ResponsibilitiesSupport customer’s transformation efforts to move information technology systems from traditional server based architecture to a cloud-based architecture though the development of Model Based Systems Engineer (MBSE) tools and practices.Develop and maintain Enterprise Architecture artifacts across entire system utilizing architecture modeling tools.Collaborate with operational / technical SMEs and Standards personnel to identify architecture gaps, overlaps and inefficiencies, and develop recommendations for changes to improve enterprise architecture.Define and demonstrate the appropriate data standards, data structures, and supporting COTS, GOTS, and Open Source technologies required to manage the data needs.Integrate enterprise tools and develop MBSE-based processes to support requirements engineering, the customer's ERB process, CONOPS and architecture development, Risk, Issues and Opportunity Management boards, schedule management, test and verification strategy development, and system integration of new initiatives in support of expanded mission capabilities.Facilitate collaborative meetings between the MBSE users and the tool development team to communicate modeling needs and help innovate potential solutions.Provides technical advice and guidance to senior managers regarding the creation and implementation of MBSE methods and techniques.QualificationsA Bachelor’s degree in Computer Science, Electrical Engineering, Systems Engineering, or a related discipline and at least 15 years of systems engineering experience.Individuals in this position must have at least five years of demonstrated experience developing and maintaining Enterprise Architectures.Knowledge of modeling approaches: Unified Modeling Language (UML), Business Process Modeling, Data ModelingDeep understanding of data architecture approaches (e.g., DODAF, Zachman, UAF, TOGAF, JARM, etc.), industry standards and best practices (e.g., DMBOK)Basic knowledge of architecture, requirements engineering, CONOPS development, verification, test and system integration to accommodate End to End Systems Engineering.Experience in MBSE implementation ranging from conceptual to physical implementations; including Data Modeling, Data Ingest, and model query.Position requires a TS/SCI clearance with polygraphRequires 12 to 15 years with BS/BA or 10 to 13 years with MS/MA or 7 to 9 years with Ph.D.Desired:Excellent oral and written communications skills.3 or more years of experience as a lead systems engineer on complex or large projects.Experience in identifying, architecting, and recommending analytic technologies and solutions in a Big Data and Cloud environment, especially those required for implementation leveraging AWSFamiliarity with Intelligence Community acquisition lifecycles, software development methodologies, information security engineering concepts, cloud computing methodologies and/or SOA-enabling technologies.Familiarity with System Architect, Magic Draw, Cameo, Rhapsody, or Power Designer Architecture Tool Suites.Familiarity with DoDAF, UPDM, Joint Architecture Reference Model (JARM), Zachman Architecture Framework, Federal Enterprise Architectural Framework (FEAF), British Ministry of Defense Architecture Framework (MODAF), The Open Group Architecture Framework (TOGAF), FEA CRM, DoD JCA, UJTL, or IEAIntelligence Collection, Processing or Analysis; Information Assurance, or IT Infrastructure domain experience.INCOSE, ITIL, PMP, SAFe, Security+, Lean Six Sigma, OMG SysML, or similar certifications.Colorado Salary Minimum: $100,484.80 Colorado Salary Maximum:$214,822.40 The estimate displayed represents the typical salary range for this position, and is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees.About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
10,Ping Identity,Information Technology,4.5,Software Engineer - DevOps,"Denver, CO",$58K - $121K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_4e64ab75&cb=1618793341742&jobListingId=4058970657,"At Ping Identity, we're changing the way people think about enterprise security technology. With our innovative Identity Defined Security platform, we're helping to build a borderless world where people have total freedom to work wherever and however they want. Without friction. Without fear.We call this digital freedom. And it's not just something we provide our customers. It's something that drives our company. People don't come here to join a culture that's built on digital freedom. They come to cultivate it.We're headquartered in Denver, Colorado, and we have offices and employees around the globe. And we serve the largest, most demanding enterprises worldwide, including over half of the Fortune 100. Because even in the most complex enterprise environments, security shouldn't be a source of anxiety. It should be one of your greatest competitive advantages.As a Ping Identity Software Engineer - DevOps, you will be involved in every facet of our Cloud Based services. You will establish solutions for building, deploying, and maintaining the infrastructure of one of the largest identity platforms in the world. We follow a DevOps model: Development and Operations teams are integrated, running continuous deployments daily, and the teams collaborate in the solution's development, deployment, and operations.You Will:Develop solutions for automated deployment of our software and services on our production infrastructure hosted on AWS.Establish solutions for virtualized platforms.Develop management solutions for managing services across multiple cloud platforms and data centers.Perform technology evaluation and selectionReport to the Software Development Manager for PingCloudYou Have:2+ years of experience in Java programming1+ years of experience with Cloud Platforms including AWS1+ years experience of scripting using command line scripting, python or javascript1+ years experience with containerization technologies, including Docker1+ years experience with orchestration technologies, including KubernetesExperience with best practices for deployment automationExperience using Git in a team environment (merge requests, branching, push, and pullsCS Degree or equivalent experienceYou will have an advantage if:You understand networking, including routing, naming and securityYou understand the HTTP protocolYou have experience developing in a DevOps environmentYou have experience resolving customer deployment issuesYou have worked with distributed teamsOur Benefits:Open PTOParental LeaveFree Healthcare Option401(k) MatchGenerous Holiday ScheduleCommuter OffsetEducation ReimbursementPing Identity is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.Salary offers will be based on the candidate's qualifications.",co,de
11,HelloFresh,Consumer Services,3.7,Data Engineer,"Boulder, CO",$51K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c7029251&cb=1618793341742&jobListingId=4037693769,"Come see what's cookin' at HelloFresh!At HelloFresh, we want to revolutionize the way we eat by making it more convenient and exciting to cook meals from scratch. We have offices all over the world and we deliver delicious meals to millions of people.We are the industry leader in meal-kit subscription services and we're growing all the time. We have distinct meal-kit services that cater to everyone with the most menu variety in the market, which allows us to reach an incredibly wide population of people.The HelloFresh team is diverse, high-performing, and international, and our work environment is an inspiring space where you can thrive as a result.Job Description:We are growing our Data Engineering team to take our data modeling and automation to the next level. The Data Engineering team is part of the broader Growth Organization (Data Science, Digital Product, Marketing) and works closely with Data Scientists to build and maintain best-in-class data products to improve HelloFresh's user-experience and marketing effectiveness. The Data Engineering department is focused on designing scalable and automated data flows using a variety of big data tools and platforms (AWS Glue, Airflow, Spark, Databricks Cloud etc..)We are hiring a Data Engineer to play a key role in HelloFresh's Data Infrastructure & Automation workstreams within the Data Engineering team.Our vision is to maintain a best-in-class automated data platform directing our marketing initiatives on delivering the right food box at the desired price point to the front door of all our customers. We are looking for someone who can help us with some of our key engineering projects.You will do ...Design and deploy cloud-based Data infrastructure (AWS, Databricks)Implement ETLs monitoring automationHelp design, update and extend HelloFresh's data model (create new schemas, fact tables, mat views, joins, etc.)Data cleaning/enrichment: keeping data clean and consistent with production systems (e.g. bug fixes, backfills …)Design and implement end-to-end data products and marketing automation flows: from data ingestions for data science modeling to creation of automated pipelines to external software (Salesforce, etc.)Data Transformations: implement the logic of the data pipeline (aggregations, projections, selections, etc …)You are ...An active, solution-oriented member of autonomous, cross-functional agile teams collaborating with Product Owners, Data Scientists, and Business Intelligence teamsAble to develop an in-depth understanding of HelloFresh's core product and architecture, and act as an ambassador for state of the art software solutions and industry best practicesAt a minimum, you have ...BSc in a STEM discipline2+ years' data engineering experience is requiredProficient in Python (with knowledge of OOP) and SQL (DDL, DML, CTEs, query optimization, ...).Past experience working with Apache Spark requiredExperience with end-to-end testing and general DevOps practices for data pipelinesThe ability to design, implement and deliver maintainable and high-quality code using best practices (e.g. git/github, secrets, configurations, yaml/json)Knowledge of data structures (DataFrames, RDDs, Dataclasses) and data formats (CSV, JSON, Parquet, Avro, ORC)Experience with software design patterns, and building highly scalable solutions preferredExperience with job orchestration tools like Airflow, Luigi or similar preferredYou'll get …Competitive Salary & 401k company match that vests immediately upon participationGenerous parental leave of 16 weeks & PTO policy$0 monthly premium and other flexible health plans effective first day of employment75% discount on your subscription to HelloFresh (as well as other product initiatives)Snacks, cold brew on tap & monthly catered lunchesCompany sponsored outings & Employee Resource GroupsCollaborative, dynamic work environment within a fast-paced, mission-driven companyIt is the policy of HelloFresh not to discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because they are a protected veteran. #zrSalary: $95,000-$105,000",co,de
12,Computer Services Incorporated,Finance,4.1,Software Engineer - .Net Core,"Fort Collins, CO",$59K - $85K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_99d9ea14&cb=1618793341743&jobListingId=4062453151,"Software Engineers at CSI work in a team environment to research, design, code, test and maintain software solutions. You will work cross functionally to ensure end user requirements are met and CSI’s goal of providing innovative technology solutions to our customers is accomplished.In this role the Software Engineer will be a key contributor in the continuing evolution and expansion of our core applications to highly scalable, distributed, and resilient to four 9’s. She/He will be responsible for delivery of high value code that is maintainable, testable, operable, and secure. We are looking for a contributor comfortable at multiple levels - hands on coding, troubleshooting, and innovation.Ideal candidates have a background building and operating SAAS platforms using the Microsoft technology stack with modern services-based architectures.CSI builds and runs software in a sane, repeatable way - everyone contributes.Responsibilities:Participate in all phases of our Agile/SCRUM SDLC - working in concert with our Product, QA, and DevOps teamsCode, test and maintain applications for our customers and internal teamsStay up-to-date on emerging technologies and how they might be used to meet goalsBring new ideas to the team, teach best practices, pitch and lead adoption of changeDocuments and demonstrates solutions by developing documentation, flowcharts, layouts, diagrams, charts, proofs of conceptContribute to feature delivery from technical design through execution and release within our iterative cycleIdentify root cause, propose solutions, and assist in the resolution of production issuesBe involved in the maintenance and updating of legacy codeDesired Skills and ExperienceCore technologies:Current .NET technologies with a focus in WCF, Web.API, ASP.net.NET Core, C#, , Node, Containers, SQL, NoSQL (Couchbase, Mongo, Cassandra, Cosmos), Javascript (Angular, Bootstrap, KO, JQuery)Comfort with working in an Agile/SCRUM environmentExperience with cloud technologies such as Azure or AWSExperience developing microservice-based architecturesExperience with Event Driven ArchitectureMicrosoft stack - IIS, MSMQ, SQL ServerKnowledge of relational database design and stored procedure development using Microsoft SQL Server 2008 and upStrong understanding of object-oriented software designExtensive use of APIs and understanding of HTTP and REST architectureStrong understanding of design patternsProven ability to work in a rapid release production environmentExperience with developing scalable software systemsExperience with Unit Testing frameworks (NUnit, XUnit, MSTest)TDD or BDDNice to have:Experience with big dataMVC, TPL and latest async/await coding standardsAutomationMachine Learning",co,de
13,Perspecta,Aerospace & Defense,3.6,Systems Engineer,"Aurora, CO",$68K - $93K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_0dc528ce&cb=1618793341743&jobListingId=4035307327,"Business Group HighlightsIntelligenceThe Intelligence group provides high-end systems engineering and integration products and services, data analytics and software development to national and military intelligence customers. Serving federal agencies and the Intelligence Community for more than 50 years, the Intelligence group helps our clients meet their mission needs by providing trusted advisors, leading-edge technologies, and innovative solutions.ResponsibilitiesPerspecta is a company founded on a diverse set of capabilities and skills, bound together by a single promise: we never stop solving our nation’s most complex challenges. Our team of engineers, analysts, and developers work tirelessly to create innovative solutions. We continually push ourselves—to respond, to adapt, to go further.When you join Perspecta, you ally yourself with some of the smartest, most dedicated people in the industry. From mission domain experts with decades of experience, to engineers and developers using the latest agile techniques, you will find a team of people you’ll be proud to learn from and work with.Our high-caliber employees are rewarded in many ways—not only through highly competitive salaries and benefits packages, but also with the opportunity to create a meaningful impact on projects that matter. We will provide you the flexibility to shape a role that helps develop the career you want.ResponsibilitiesPerspecta is looking for a SYSTEMS ENGINEER to join a skilled, highly respected and long-standing team supporting operational systems and environments. The successful applicant will generate and execute testing procedures to verify the operational performance of end-to-end systems. They will also review test plans to ensure they meet operational objectives and will participate in the testing process to validate the satisfaction of mission requirements. They will collect and analyze data, produce metrics and trending information, and engage in end-to-end monitoring of complex intelligence systems. Activities include:Support monitoring of enterprise data processing, and the associated infrastructure, to provide timely detection of potential errors and system issuesConduct first-level analysis of testing results, coordinate and/or perform detailed in-depth analysis of the resultsIdentify any degradations in system performance. Support notifications to the government and associated personnel. Perform and/or support root cause analysis of observed issuesCreate and manage discrepancy reports, trouble tickets, or other forms of notification; Track through to resolution; Verify fixes are satisfactorySupport routine and ad-hoc scheduling of enterprise engineering testsMonitor planned outages and other activities which may impact system performance and data accuracy and report findings or issues to the governmentPlan, coordinate, and execute engineering tests following outages and events that may have impacted system performance or data accuracyAuthor Engineering Test Support Requests (ETSR) and design, plan, and conduct engineering evaluation test in support of enterprise operation and system deliveriesPrepare engineering test reports and findingsEnsure approaches to analysis are based on accepted scientific and mathematical practiceQualificationsRequired:Active TS/SCI Clearance with PolygraphRequires 8 to 10 years with BS/BA or 6 to 8 years with MS/MA or 3 to 5 years with PhD.Strong analytical skills, intelligence community domain knowledge, and demonstrated understanding of user needs and operational environmentsDemonstrated success in team environments; good presentation and communication skillsDemonstrated ability to clearly explain technical issues to both technical and non-technical audiencesDesired:Experience in the National Intelligence CommunityPreference for degrees in a technical field (e.g. physics, electrical/systems engineering, math)Colorado Salary Minimum: $82,992.00 Colorado Salary Maximum:$177,424.00 The estimate displayed represents the typical salary range for this position, and is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees.About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
14,BlueHalo,N/A,4.8,Data Engineer,"Colorado Springs, CO",$93K - $135K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_58030773&cb=1618793341744&jobListingId=4059540506,"Responsibilities:BlueHalo is looking for a Data Engineer to support the Missile Defense Agency (MDA) Modeling and Simulation Enterprise Engineering Directorate (MDA/DES - Enterprise Engineering). This position is located at Schriever, AFB.Qualifications:Key Responsibilities:Design, create, build and maintain data pipelines.Aggregate and transform raw data coming from a variety of data sources to fulfill the functional and non-functional business needs.Performance optimization: Automating processes, optimizing data delivery and re-designing the complete architecture to improve performance.Handling, transforming and managing Big Data using Big Data Frameworks and NoSQL databases.Job Qualifications:•Bachelor's Degree or equivalent in Science or Engineering•5+ years' practical experience with ETL/ELT processes•As a minimum, must have an Active Secret Clearance•Proficiency with ETL/ELT methodologies",co,de
15,Perspecta,Aerospace & Defense,3.6,Ground Systems Requirements Engineer,"Colorado Springs, CO",$44K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_68f7ac78&cb=1618793341744&jobListingId=4035460722,"Business Group HighlightsIntelligenceThe Intelligence group provides high-end systems engineering and integration products and services, data analytics and software development to national and military intelligence customers. Serving federal agencies and the Intelligence Community for more than 50 years, the Intelligence group helps our clients meet their mission needs by providing trusted advisors, leading-edge technologies, and innovative solutions.ResponsibilitiesThe Ground Systems Requirements Engineer will support the Ground Segment Team on a new program at Perspecta, focused on systems engineering and integration of a new Space Domain architecture. The Ground Systems Requirements Engineer supports the requirements development, decomposition, flow down, verification and validation across the entire lifecycle from concept to disposal for the ground system. The Ground System will consist of hardware and software architecture as well as all internal and external system interfaces, including operator displays and controls. The Requirements Engineer shall support trade studies that provide recommendation on the potential use of Commercial Cloud Services in the Ground’s Infrastructure, Platform, and Software as a service (IaaS, PaaS, SaaS) to meet security, scalability, redundancy, and resilience requirements. The Ground System requirements are iteratively matured through the systems engineering lifecycle. Specific responsibilities include:Support system requirements verification, validation, and traceability activities.Use Model-Based Systems Engineering approach from design through production.Support the preparation of all lifecycle readiness reviews including entry and exit criteria. , action items and liens issued at the reviews, and the production of review briefing materials. Reviews include system and various segment SRRs, SFRs, PDRs, CDRs, and other reviews as required, requiring the preparation and update of baseline requirements.The Ground System Requirements Engineer designs, develops, evaluates and modifies end-to-end systems and systems-oriented products through their entire life cycle, generates quantifiable requirements based on customer description, system planning and design, and acquisition logistics, and ensures requirements comply with client requirements and government standards through formal verification methods.QualificationsRequires 10 to 12 years with BS/BA or 8 to 10 years with MS/MA or 5 to 7 years with PhD.Required skills:Hold an active Top Secret ClearanceExperience with satellite and satellite ground systems (requirements, acquisition, development, or operation)Understanding of all aspects of the requirements formulation and validation and ability to assess program requirement risk areas and to programs design baseline cost and acquisition schedules.Possess a strong Ground Systems Engineering background across the TCPEDExperience with system design, development, integration, and testingExperience with System Integration, identifying key integration pointsAbility to represent key decisions and identify risks to the customerDesired Qualifications:Bachelors of Science Degree in Science, Technology, Engineering or Mathematics (STEM)Ability to organize and prioritize numerous customer requests in a fast pace deadline driven environmentExperience supporting IC or DoD in Systems Engineering and Systems IntegrationPossess SAFE Agile certification and ability to apply agile practices to deliveryPossess AWS certificationThe Colorado Equal Pay for Equal Work Act requires employers in the state of Colorado to disclose the following information. If the position applied to is not located in Colorado, the following information may not apply. Salary Minimum: $93,870.40 Salary Maximum:$200,678.40 The base salary range above represents the low and high end of the Perspecta salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and paid time off (PTO).About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
16,"Torch Technologies, Inc.",Aerospace & Defense,4.6,Data Engineer,"Colorado Springs, CO",$97K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_e3242958&cb=1618793341744&jobListingId=4063091106,"Job Description:Torch Technologies, a 100% employee-owned company is seeking a mid-level Data Engineer to become a key member of the Missile Defense Agency (MDA), Engineering team, providing data engineering expertise, while conducting research and development for artificial Intelligence and data science projects. This includes working with many of the following technologies: data pipelines, data services, operational data stores, data warehouses, data marts, big data stores, data mining, big data visualization and experiment designs. The right individual will display both a passion for data science and leading a cultural change in how data is used throughout the organization regarding these efforts.Duties and Responsibilities:Design, create, build & maintain data pipelinesAggregate & Transform raw data coming from a variety of data sources to fulfill the functional & non-functional business needsPerformance optimization: Automating processes, optimizing data delivery & re-designing the complete architecture to improve performance.Handling, transforming & managing Big Data using Big Data Frameworks & NoSQL databases.Building complete infrastructure to ingest, transform & store data for further analysis & business requirement.Work in a collaborative, multi-discipline team contributing to projects spanning Big Data, ML/AI, Cloud Architectures and Orchestration, Cyber, and Systems and Software Engineering.Job Requirements:A Bachelor of Science degree in Science or Engineering plus five (5) or more years’ practical experience with ETL processes, or a Master of Science degree plus four (4) or more years’ experience in a technical environment is required.Required Skills:Proficiency with ETL/ELT methodologies.Balanced knowledge of commercial data engineering tools, as well as open-source tool - including the relevant tuning, configuration and automation aspects to handle data pipelines at scale.Understanding of data models and formats to streamline ML/AI effortsHigh level data literacyProficiency in SQL and query tuningPython developerShell Scripting experience.Implemented DevSecOps controls (DoD CIO & AF CSO)Proficient in data security managementPrefer experience with open platform (Kubernetes/Istio), microservice/service mesh architectures, and leverage event-driven behavior across the entire portfolio Desired Skills:Experience with CI/CDExperience developing end-to-end pipelineCompetency in in Agile DevelopmentUnderstanding and experience with distributed execution technologies.Required Clearance:Current Department of Defense SECRET clearance.",co,de
17,Prove,Information Technology,4.2,Data Engineer,"Denver, CO",$72K - $97K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=148364&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_6329f41d&cb=1618793341744&jobListingId=4062521537,"About Prove Prove is the modern platform for continuous identity authentication and is used by over 1,000 enterprises and 500 financial institutions including 9 of the top 10 U.S. banks. Prove’s cloud solutions and mobile intelligence -driven APIs can be easily orchestrated to increase Approve Rates to over 90%, enabling companies to authenticate customer identities accurately, effortlessly, and privately, while mitigating fraud. Prove’s solutions are available in 195 countries. For the latest updates from Prove, follow us on LinkedIn. As we continue to scale our company, we are looking for people who know how to make an impact. We’re talking self-starting professionals who thrive in a fast-paced environment, process information quickly and make intelligent decisions. The work is challenging and requires not only smarts, but natural curiosity and tenacity. Teamwork is also important to us – we work together and play together. Prove has big plans; we’re excited and optimistic about the future. If this sounds like a career for you – come check us out.The Data Engineer will be responsible for building and optimizing our data and data pipeline architecture as well as building automated processes for production jobs. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.What You Are Accountable ForCreate and maintain optimal data pipeline architecture,Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Non-SQL technologiesWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.Work with data and analytics experts to strive for greater functionality in our data systems.Promote, maintain and enhance our cultural values of humility, passion, inclusion and leadership.Exhibit a strong passion for learning our products and markets through in-house and external training.What We RequireCS degree in Computer Science of Software engineering, or relevant experience2 to 5 years experience including:Leveraging advanced SQL knowledge and experience working with relational databases Automation frameworks like Pentaho, Luigi, etcPython, Java, C++, or ScalaExperience with stream-processing systems like Kafka, Storm, Spark-Streaming, etc is a plusExperience with enabling and supporting a data science and product teamThe salary range for this role based in Denver, Colorado is $130,000-180,000. Offered salary will be determined by the applicant’s education, experience, knowledge, skills, and abilities, as well as internal equity and alignment with market data.This position is eligible to participate in the annual incentive program. Prove’s Benefits include but are not limited to:-Excellent health, dental, and vision insurance that begins on your first day of employment-401(k) plan with company match-Unlimited vacation time -Stock option grants for each full-time new hireThis position description should not be considered the final description of the position. It should be assumed that we would, to some extent, structure responsibilities in accordance with the successful candidate’s capabilities and changing business conditions. Prove is an equal opportunity employer committed to providing equal employment opportunity for all people regardless of race, color, religion, gender or sexual orientation, age, marital status, national origin, citizenship status, disability, veteran status or other personal characteristics.",co,de
18,Semtech,Manufacturing,4,Quality Management Systems Engineer,"Colorado Springs, CO",$54K - $77K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1044077&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_427ebc78&cb=1618793341745&jobListingId=4062895091,"Location: Colorado Springs, Colorado- Federal Dr. / Elkton Dr.Job Summary:The Quality Management Systems Engineer will be responsible of managing the QMS and ISO9001 and IATF 16949 compliance across multiple design centers. He/she will lead and undertake audits across all areas of the business as well as across the supply chain when needed. He/she will follow up on resolution of internal audits, Corrective Actions Preventive Actions (CAPA), Non Conformance Material Report (NCMR) and Product Change Notification (PCN), End of Life (EOL) Notification; and participate in root cause analysis. Finally, he/she will drive and participate on the continual quality projects.Responsibilities:Lead internal and 2nd party audits according to latest QMS standards (ISO 9001, ISO14001, ISO45001, IATF16949 automotive. etc.)Plan and conduct process audits within design sites across USA, UK and Canada. Assist in training/guidance to other auditors or new employees.Report audit results to management. Follow up all non-conformities detected during audits and ensure closure of findings.Maintain the Quality Manuals and Quality Procedures and ensure contents are appropriate for business.Manage and drive our internal Change Control Board (CCB) as part of the PCN, EOL, Waivers or ECR requests.Manage and supervise the Calibration process for our lab facilities.Coordinate and drive the review of continuous improvement initiatives.Qualifications:Bachelor's Degree in Mechanical, Electrical, or Industrial Engineering preferred; other technical degrees will also be considered.A minimum of 5 years of relevant work experience; an ISO9001 semiconductor environment facility in a quality assurance role.Lead ISO9001 Certified, IATF 16945 Certified.Demonstrated mastery in quality methods, procedures, and processes.Displays strong interpersonal skills and is accessible and approachable.Effective communicator with the ability to interface at all levels within the organization, possessing a thorough written and verbal command of the English language.Other Desired AttributesISO 26262 Certified Auditor, ISO14001 & ISO45001 Auditor Certification. ASQ or SQA certification desirableProven ability to solve problems, analyze data using statistical concepts and toolsExposure to ISO Audits, Lean Manufacturing and Six Sigma methodologies, ideally Green/Black Belt certifiedCareer Growth Philosophy: At Semtech, we seek innovation and leadership from each and every member of our team. Our goal is to ensure that our talented professionals are equipped with support, resources, and the opportunity to excel. The career development program is an important part of our recruiting strategy. Our pay-for-performance philosophy provides recognition and prestige coupled with a competitive compensation package.The intent of this job description is to describe the major duties and responsibilities performed by incumbents of this job. Incumbents may be required to perform job-related tasks other than those specifically included in this description.All duties and responsibilities are essential job functions and requirements and are subjected to possible modification to reasonably accommodate individuals with disabilities.We are proud to be an EEO employer M/F/D/V. We maintain a drug-free workplace.Career progression notification for Quality Management Systems Engineer positions: Quality Management Systems Engineers are hired at the level commiserate with their education/skills/work experience and eligible to be promoted from a Quality Management System Engineer II to a Quality Management System Engineer III in their career progression. Such promotions are non-competitive, subject to the discretion of the Company, and may occur at any time. An employee must have the title of Quality Management Systems Engineer II to be promoted to a Quality Management System Engineer III. The Company does not accept applications for these promotions.The starting salary ranges corresponding to these roles are as follows:Quality Management Systems Engineer II $55,999 - $76,043, Quality Management Systems Engineer III $75,752-$111,719A description of benefits available to Quality Management System Engineers may be accessed at Semtech Benefits. Quality Management System Engineers are eligible for 15% annual bonuses and exempt.Job Type: Full-timePay: $55,000.00 - $111,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offReferral programRetirement planVision insuranceSchedule:8 hour shiftSupplemental Pay:Bonus payEducation:Bachelor's (Preferred)Experience:Quality assurance: 5 years (Required)License/Certification:ISO9001 certification (Preferred)Work Location:One locationCompany's website:https://semtech.wd1.myworkdayjobs.com/en-US/SemtechCareers/job/US---Colorado---Federal/Quality-Management-Systems-Engineer_REQ850Work Remotely:NoCOVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",co,de
19,Trihydro Corporation,"Oil, Gas, Energy & Utilities",4.1,Senior Civil Engineer/Project Manager,"Fort Collins, CO",$110K - $227K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1044077&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4215280a&cb=1618793341745&jobListingId=4038220866,"Civil Engineer - Project Manager/Senior Engineer – Cheyenne, WYTrihydro, a mid-sized engineering and environmental consulting firm with a national footprint, is seeking a dynamic, talented engineer to join our team. This position will focus on developing civil engineering and infrastructure work for regional public and private sectors. If you’re a civil engineer interested in career-growth opportunities and joining a growing team, we encourage you to apply!Improving our communities and the environment is at the heart of Trihydro’s mission. We achieve our mission by empowering our employees to develop solutions that exceed our clients’ expectations. We understand our employees are our number one asset; treating them as such has fostered a strong company culture that has spurred our growth and diversification over the past 35 years. We need experienced civil engineers who are willing to play key roles in our continued pursuit of our mission and continued growth and diversification.Position OverviewAs a member of our team, you will develop civil infrastructure solutions, supporting sustainable growth for generations to come. Work sectors may include water and wastewater systems and treatment, stormwater, transportation, and grading solutions. You will interact with existing clients and develop relationships with new clients. Through your work, you will be integrated into a thriving team environment, developing projects and client relationships, and fostering employee growth.ResponsibilitiesIn this role you will have responsibilities such as business development, client-relationship management, project and task management; overseeing the successful delivery of work scope, schedule, budgets; developing design calculations and detailed construction plan sets; permitting; data review; construction observation and administration; technical report and proposal writing; performing quality control/quality assurance reviews; and mentoring staff.LocationYou will be based in Cheyenne, Wyoming. Cheyenne is a great community that provides ready access to multiple recreational opportunities, opportunities associated with a state and community college, and Mountain West Living.We encourage you to apply if you: Have 10-15+ years relevant engineering design experience. Relevant experience includes designing civil infrastructure and water and/or wastewater systems, including but not limited to dams and reservoirs, water storage tanks, water distribution, transmission, storage, pump stations, sanitary sewer systems, water and wastewater treatment systems, stormwater drainage, rural and urban roads, and other civil projectsAre a strong communicator, both orally and written, with the ability to communicate effectively with clients and team membersAre a Professional Engineer (P.E.)Have experience with AutoCAD and Civil 3D, OpenRoads Designer and/or related CAD programsHave experience with hydrologic and hydraulic modeling and various structure designPossess strong technical and problem-solving skills, including attention to detail, accuracy and completeness, as well as a commitment to producing high-quality deliverablesHave an interest in maintaining existing client relationships, as well as developing new client relationshipsHave an interest and ability to travel to client locations and other Trihydro officesUnderstand the importance of time management and possess excellent organization skillsHave a strong driving record and a commitment to safe operationsThis job is for you if you: Desire career-growth opportunities and are interested in playing an integral role in a growing team and companyWant to be part of a dynamic company that treats its team members like familyValue working with others to achieve goals that make a difference to our clients and our communitiesAssume ownership of your work and take pride in producing high-quality deliverables.BenefitsAt Trihydro, our approach to work is honest and hard-working. You’ll find a company culture that is dedicated to excellence, nurtures collaboration and growth, and still finds plenty of time for fun! Some of the benefits of joining our team include:Robust health insurance (medical, dental, vision, and prescription)Industry-leading 401(k) retirement plan, including a 6% discretionary match by TrihydroComprehensive paid time off including vacation, comp/flex, sick, and holiday payWellness program, including reimbursement for gym membership, park passes, or related expensesStaff mentoring and opportunities for professional/career advancementBest-in-class safety culture built to protect our employees – the mothers, fathers, sons, and daughters who deserve to go home safely each nightThis is a full-time position averaging 40-45 hours per week. Interested candidates should apply at https://www.trihydro.com/about-us/careers with their application, resume, and cover letter addressed to Trihydro’s Recruiting Team. Call Jessica at 307-745-7474 today to schedule a virtual Q&A session. Trihydro is an Equal Opportunity, Affirmative Action employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because he or she is a protected Veteran.Job Type: Full-timePay: $80,000.00 - $110,000.00 per yearBenefits:401(k) matchingDental insuranceDisability insuranceHealth insuranceHealth savings accountLife insurancePaid time offParental leaveProfessional development assistanceReferral programVision insuranceSchedule:Day shiftMonday to FridayEducation:Bachelor's (Preferred)Experience:AutoCAD & Civil 3D: 10 years (Preferred)Hydrologic & Hydraulic Modeling: 10 years (Preferred)Civil Infrastructure Design: 10 years (Preferred)Water and/or Wastewater Systems: 10 years (Preferred)Business development: 10 years (Preferred)Project and Task Management: 10 years (Preferred)Staff Mentoring: 10 years (Preferred)License/Certification:Professional Engineer (Preferred)Work Location:One locationCompany's website:https://www.trihydro.com/about-us/careersCompany's Facebook page:https://www.facebook.com/TrihydroBenefit Conditions:Only full-time employees eligibleWork Remotely:NoCOVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",co,de
20,DISH,Telecommunications,3.3,Big Data Software Engineer II,"Littleton, CO",$77K - $93K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=132977&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_6aaed84c&cb=1618793341745&jobListingId=3802532098,"DISH Wireless is building a next-gen 5G network to disrupt the wireless industry and fuel innovation in transportation, health care, education, sustainability, city management, and agriculture.We’re driven by curiosity, pride, adventure, and a desire to win – and we’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve. Join us as we embark on our greatest adventure of all.Opportunity is here. We are DISH Wireless.DISH Wireless is looking for a Big Data Software Engineer II to work on our Wireless Analytics & Orchestration team based in Littleton, Colorado. The Big Data Software Engineer II will provide solutions to various big data use cases, and drive the development of data models that provide insights to optimize operations. The individual will be involved with the development of automation frameworks and applications in Dish Wireless Data Lake that integrate intelligence from multiple network functions and organizations.Primary Responsibilities:Apply big data technologies such as AWS S3, VMWare, GCP, Azure, Spark, Hadoop, HDFS, Druid, Kafka, Scala, Python, Java, Spark SQL, PostgreSQL, NoSQL, Oracle, Jenkins, Eclipse to solve operational problems like PaaS/NFVI, RAN, Core and Transport network capacity planning, performance optimization and lifetime user experience management.Access multiple sources and engineer datasets used for machine learning and real-time analytics to assist network automation and orchestration functions. Drive initiatives that ensure optimal network operation under various usage patterns and network slice instances.Analyze, recommend and implement solutions for large-scale distributed analytics and visualization frameworks used by both internal and external clients. Define the frequency, format, cleansing and streaming requirements for datasets publishing.Automate multi-channel data pipelines for AI model development and production systems using DevOps – CI/CD process.Using Gitlab for LCM, develop, integrate and test code and complete applications along with associated documentation from proof of concept to production readinessWork with other data engineers, scientists and subject matter experts to generate datasets used to rank features, and predict operations metrics like radio network demand, performance degradation, transport SLA failure and subscriber churn.Work with vendors to interpret various FM/PM data streams and make optimal use of systems features and configuration parameters.The ideal Big Data Software Engineer will have:BSCS/BSEE / MSCS/MSEE degree or BS/MS in Statistics/Mathematics/Physics and 3-5 years overall Data Engineering experience.Experience working in Hadoop, Hive, & Data Clusters.Experience applying statistical analysis to datasets to solve business problems.Experience with visualization framework/dashboard design and implementation.Experience with commercial and open source software frameworks like AWS EMR manipulating large datasets and developing data visualization applications.#LI-JS3Compensation: $64,800.00/Yr. - $89,400.00/Yr.From versatile health perks to new career opportunities, check out our benefits on our careers website.Employment is contingent on Successful completion of a pre-employment screen, which may include a drug test.",co,de
21,Anark,Information Technology,5,3D Data Software Engineer,"Boulder, CO",$88K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=8095&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_56e50067&cb=1618793341745&jobListingId=4060756521,"At Anark our 3D Data Software Engineer is responsible for the development of critical integrations with 3D CAD systems. This position works with a team of motivated engineers to plan software releases that adhere to customer requirements within business-acceptable timeframes.

The ideal candidate will have extensive experience developing 3D software on the Windows platform. Additional CAD specific knowledge/experience is very helpful.

Required Knowledge and Skills


3+ years experience with 3D data.
Strong C++ programming experience and one or more of C, C#, C++/CLI, or similar languages such as Java.
Strong understanding of BREP and polygonal mesh data, scene graphs, DAGs, and transformation matrices.
BS in Computer Science

Desired Skills (Which combo do you bring?)


Experience integrating with CAD software libraries.
Experience with 3D and 2D graphics-oriented development.
Experience using best-practices design/architectural patterns and loosely coupled component-based programming.
Experience with agile development methodologies including Test Driven Development, and a propensity for refactoring code.
Experience developing graphical authoring software tools.
Experience using Microsoft Visual Studio and TFS.
Basic knowledge of automated testing, such as writing unit tests.
Experience with cloud technologies such as Azure or AWS.
Experience in RabbitMQ or other messaging platforms.

Company

Anark is a leading provider of intelligent information management (IIM) software and solutions for technical industry, enabling engineering, procurement, manufacturing, and field service organizations to publish and manage technical content, for access and collaboration workflows across the extended enterpriseyielding faster iterations, reduced material waste, and higher-quality products and services with substantial cost savings.

Anark helps market leaders such as GE, Boeing, Lockheed Martin, Allison Transmission, Johnson & Johnson, Cisco, Ericsson, and TE Connectivity with their Digital Transformation, leveraging smart technical content to streamline procurement, manufacturing, and field service operations.

Culture, Compensation, Citizenship and more

Come work in a cutting-edge, exciting, fun, energetic, friendly, and supportive work environment. Anark Corporation strives to be a ""change the world"" innovator. Anark offers a competitive salary, performance bonus plan, stock options, 401(k) retirement program with employer match, and a comprehensive and generous benefits program. This position requires either US citizenship or US permanent resident legal status. A background check will be performed on all qualified applicants prior to an offer for employment.

Anark is a small but mighty locally owned Boulder, Colorado business. 15+ years in business with 15 years of F100 great clients! Within our inclusive environment, engineers ""have a say"" and the ability to work on a variety of challenging projects. We are building out our NextGen products in the enterprise, cloud-enabled and SaaS space. A great place to learn and grow as we offer a very open and collaborative atmosphere. Anark offers very competitive pay, our engineers starting base salary is 90,000 - 140,000 depending on skills, experience and the specific role. We also offer equity, bonus, 100% employer paid full medical benefits, learning and fitness perks and much more. Consider joining Anark if you are looking for a long-term career home where you can become a significant contributor.",co,de
22,Sovrn Holdings,Media,3.7,Data Scientist I Boulder,"Boulder, CO",$78K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_90d152a6&cb=1618793341745&jobListingId=3802746560,"Data Scientist Iat SovrnBoulder OfficeAbout the TeamThe Data Intelligence team is a subgroup of Sovrn’s larger Data Science team that generates data-based intelligence and machine learning solutions for internal stakeholders. The team processes data from over 40 billion HTTP requests and half a million affiliated marketing transactions daily, resulting in several petabytes of data on a monthly basis. The team then uses this information to produce data products that inform decision-making across the company, and to build optimization tools and new features that directly affect Sovrn and its publishers.About the JobIn this role of Data Scientist I, you will be responsible for learning in detail about a broad portion of the Sovrn business. You will apply your skills in data analysis to identify business opportunities to optimize our products and operations. You will partner with business leaders to guide decisions based on analysis of large datasets, rigorous testing, and a deep understanding of the technical workings of our Commerce, Exchange, and Signal product lines. Projects may include designing business performance reporting, developing optimization systems for the exchange, building simulations of product changes, and building prototypes of new features to increase the performance of our business. You will partner with other data scientists and engineers to develop your big data skills and use powerful tools to develop insights and optimization in Sovrn’s high performance real-time ad exchange and other business segments.What you will be doing:Develop detailed expertise in the technical workings of Sovrn’s various business unitsDevelop expertise in each data resource, and methods to extract and process data (SQL, Hive, Spark, Python, etc...)Develop expertise in the business drivers in a specific area of the Sovrn businessPartner with business leaders in that area to drive performance improvements through rigorous analysis and decision supportDrive business initiatives in that area through modeling, automating, and driving product design and testing.Analyze and solve problems at their root, stepping back to understand the broader contextCollaborate with fellow data scientists, product managers, engineers, and data platform teams to further develop Sovrn’s products and data resources.About YouYou are a storyteller who interprets results from complex datasets and turns them into clear and concise narratives to guide the direction of your company. You are eager to be a leader and mentor for more junior members of your team, as well as for groups of embedded analysts in other teams around the company. You enjoy using written and oral communication to evangelize data literacy throughout the company.The successful candidate will have:Expertise in SQL and relational databasesExperience in Python or other scripting languagesExperience with data modeling and machine learning algorithmsComfort with version-controlled codebase (Git)Strong communication skillsAbility to convert business problems into structured analysis and back to business solutionsA passion for helping teammates expand their data skill setAbility to quickly formulate solutions to difficult problemsExperience analyzing data to extract business recommendationsComfortable in fast-paced, start-up environmentsBonus Points:Bachelor's degree in Computer Science, Software Engineering, or equivalentExperience with AWS and/or GCPExperience with Java or ScalaPosition Reports to: Manager, Data IntelligenceLocation: Boulder, COWe understand that no candidate is perfectly qualified for any job. Experience comes in different forms; many skills are transferable; and passion goes a long way. Even more important than your resume is a clear demonstration of accountability impact, and the ability to thrive in a fluid and collaborative environment. We expect you to learn new things in this role, and we encourage you to apply if your experience is close to what we're looking for.",co,de
23,DCP Midstream,"Oil, Gas, Energy & Utilities",3.4,Business Intelligence Data Engineer,"Denver, CO",$82K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_6a7ee579&cb=1618793341745&jobListingId=4033283121,"DCP Midstream is a Fortune 500 natural gas company dedicated to meeting the energy and consumer needs of our society. With a focus on technology and innovation, we safely and reliably operate a strong and diversified portfolio of logistics, marketing, gathering, and processing assets across nine states.Benefits & Additional CompensationDCP builds connections to enable better lives and is dedicated to supporting our employees with opportunities for internal mobility, continual growth, and ongoing training. We believe all employees contribute to the success of the company and should be able to share in that success, which is why all jobs are eligible for the short-term incentive program with any payouts being subject to individual and company performance. Depending on the position and level, some jobs are also eligible to participate in the long-term incentive programs with any payouts also being subject to performances. We offer a comprehensive benefit program that includes medical, dental, vision, disability, life, a competitive 401(k) match, a retirement contribution, and several other unique benefits offerings. We make health and wellness a priority and offer a generous paid time off policy including parental leave, sick time, and vacation time.Job SummaryThis role serves as a subject matter expert in Data & Analytics focused on Business Intelligence, Datamining, Statistical Modelling and Data domain areas, serves as the lead for medium to large complex activities and who understands company goals and objectives. Enables collaboration with cross-functional teams. Translates strategies into roadmaps and requirements ensuring resolution with the utmost effectiveness and efficiency. Responsible for the research and development of business cases, designs, configurations, implementation plans and overall management of project related activities. Strong communication and analytical skills are required as part of this agile team. Provides support to team members as needed. Work in a collaborative way with Business and IT resources to research, troubleshoot, resolve and implement Data & Analytic services to our business.What you will be responsible forLeads and can drive medium to large size projects - as PM and SME to design and architect solutions, build test cases and script development and ensures projects meet business and IT objectivesPerform as the Data & Analytics expert for all business needs.Analyzes data and makes analytical recommendations for IT management to consider as components of enterprise architecture and the roadmap development for BI tools and technologiesWork autonomously with IT and Business groups to understand issues and come up with solutions to complex business challengesIdentify business requirements and map them to the Services and Applications within the Data & Analytic application landscape.Identify functionality gaps and develop solutions for themResearch and resolve questions, issues, and service opportunities. Provide recommendations, alternatives, and guidance to the business.Advise on options, risks, and any impacts on other processes or systemsConfigure, Review and Implement changes within Data & Analytic application landscape.Provides strong technical and functional business supportWork at the highest technical level of most phases of systems analysis while considering the business implications of the application technology to the current and future business environmentQualificationsMust have a minimum of 5 years’ experience (preferably 7-12 years) in similar roles managing or supporting Data & Analytics platforms and Statistical Models.Must have experience with Master Data Management Strategies and Applications; Talend, SnowFlake, Python, Microsoft Power BI, Microsoft Development StackBS/MS degree in Data Management, Data Engineering, Computer Science, Mathematics, Statistics is preferredMust have a functional and technical IT background with strong analytical skills with ability to write scripts, database queries, along with understanding the software development lifecycle and business acumenMust have strong communication and collaboration skills articulating in clear concise messagesStrong written/verbal communications skills. Understands importance and frequency of status updates or documentation capture and can present information or ideas openlyAbility to work independently in a highly complex and challenging environmentAbility to translate between functional requirements and technical designsAbility to work on all project phases: project preview, fit/gap analysis, configuration, design, testing and deploymentSpecial DemandsThis job primarily operates in a professional office environment and routinely requires the use of standard office equipment such as computers, phones, copy machines, etc. Noise level is typically low. Frequently in a stationary, sitting position for prolonged periods of time. Regularly moves about inside the office to complete tasks, attend meetings or to access the copy machine or file cabinets. Periodically pulls/pushes doors open to move around the office. Occasionally may lift and carry objects up to 20 pounds. Occasional travel may be required.Salary RangeThe salary range for this job is $80,300 - 132,500It has been and will continue to be the policy of DCP Midstream not to discriminate against any employee or applicant for employment because of their race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender expression, veteran status, disability, or other legally protected status.Primary Location: US-CO-DenverJob: Information Technology / Full-timeJob Posting: Feb 27, 2021, 1:00:00 AMRecommended SkillsData Management Systems Analysis Business Requirements Documentation Functional Requirement Software Development Life Cycle",co,de
24,"Ascend Analytics, LLC",Information Technology,3.9,Backend Software / Data Engineer,"Boulder, CO",$70K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_eddf0058&cb=1618793341746&jobListingId=4064293219,"We are seeking an experienced Backend Software / Data Engineer to join our development team. As a Backend Software / Data Engineer at Ascend Analytics, you will be responsible for the design, development, documentation, and deployment packaging of new cloud-based and hosted software applications, as well as maintaining existing code.Ascend Analytics is an innovative ""green tech"" software service company focused on energy analytics that are transforming the electric grid to renewables. Ascend's solutions provide the critical intelligence to support power supply decisions from operating strategies over the next hour, to hedging and budgeting decisions over the next five years, to long-term investment and resource planning decisions over the next thirty years.If you want to help shape a new future of a cleaner and most cost-effective energy supply and work with an industry-leading software company with dedicated and talented people who are passionate about our future, this could be a great fit.Job DescriptionAs an Backend Software / Database Engineer, you will be part of a collaborative team for advancing software solutions and analytics to support the clean-tech power revolution. Your strong software engineering skills will support mission critical decision analytics for renewable and battery storage power providers around the globe. Responsibilities include database development, business layer and data models, some UI/UX, documentation, test design and deployment scripting, developing data pipelines, ETL support, and refactoring code for improved performance and scalability.Job ResponsibilitiesSupport and advance software applications byWriting clean, scalable, production code for internal and external clientsMaintaining existing applications and creating new applications throughout our technology stackFocusing on back-end/database/ETL with some additional front-end UI work (web-based and WinForms)This position involves working collaboratively within your own software team as well as with our front-end software engineers, mathematical modelers, and technical sales team. The software development team follows an agile scrum process, and all team members are expected to contribute to technical design reviews, implementation strategies, and sprint planning.Required Skills & KnowledgeFor success in this position, you must have the following skills and experience:3-5+ years of hands-on experience in a similar positionExcellent knowledge of software technologies and architecturesSkills in database and data warehouse technology (Oracle / PostgreSQL / Analysis Services)Experience with DevOps best practices and version controlExperience with Windows-based environmentsConsidered a Plus:The following skills & qualities are considered a plus:Experience developing production-quality, client-facing applicationsUnjaded and positive attitudeOracle PL/SQL, .NET, Azure, Python, SAS, CI/CD and source control experienceRequired EducationBS required in Computer Science, Physics, Engineering, Math, or related fieldCompensationNegotiable based on qualifications and experience. Ascend highly values our employees and often pays above industry average.We offer flexible work hours with a relaxed environment and opportunities for domestic and international travel. Excellent benefits are available, including medical, dental, vision, and a 401k plan. Ascend values their employees' overall well-being and we contribute a monthly stipend to any gym membership our employees choose. Ascend Analytics is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.Please submit your resume and cover letter telling us why you'll be a great fit for this position! Contact us at: recruiting@ascendanalytics.com",co,de
25,Decentrix,Information Technology,4.4,DATA ENGINEER,"Denver, CO",$62K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_911f9a90&cb=1618793341746&jobListingId=3662324140,"Decentrix is offering an exciting opportunity to an individual with the right skill set and background to join our elite team and work with the most advanced Media Advertising Enhancement/Optimization Technologies. You would be using your business, technical & development skills in an extremely fast paced environment providing services to forward thinking media corporations. See www.bianalytix.com for more information.Position Responsibilities:Design, Develop and Maintain Data Storage, Data Analytics and Data Processing Product Applications, Systems and Solutions supporting clients in the Media IndustryDevelop, Enhance & Configure data transformation and storage solutions in support of our product offeringsWork closely with other internal engineering teams focused on front-end and back-end APIs development and configuration in direct support of various productsWork closely with internal product and project management teams to design and prioritize features and their associated delivery timelinesDiagnose and correct system and product faults, designing & implementing solutions to correctTechnical ProficienciesScala Language development with experience in full stack testingApache Spark and distributed data processing methodologiesT-SQL / PL SQL DevelopmentComplex data processing methodologiesMassive scale data processing methodologiesAmazon AWS technologies and products (ECS, EC2, EMR, S3, etc.)LinuxDocker image development & container executionAdvanced knowledge of RDBMS systems and associated storage optimization techniquesAnalytic data structure knowledge and experienceWorking knowledge of software engineering and applying database methodologies, techniques, and toolsPersonalThe experience in the design of data storage and data transformation processes to leverage and analyze complex data relationshipsThe skills to quickly diagnose and solve technical problems associated to large data solutions and the associated technologiesInterest and ability to work at the technical installation level with major media corporationsMaturity to manage task associated to products and/or services to an installation contractExcellent communication skills, including good verbal and written abilities",co,de
26,Fluid Truck,N/A,5,Data Engineer Solutions Architect,"Denver, CO",$85K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=4323&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_b17f2fcb&cb=1618793341746&jobListingId=4062760606,"Fluid is a peer-to-peer community truck sharing platform offering businesses and individuals a better way to rent vehicles. Fluid is rapidly scaling across the US with a proven technology platform that provides a more efficient way of connecting businesses & consumers with trucks.

Fluid allows people and businesses to connect their vehicles to our platform via Fluid Connect (a piece of hardware) that enables Fluid's mobile app to lock/unlock, track fuel/mileage, and mobilize the engine, making any vehicle easily rentable by other businesses and individuals. We enable businesses to dynamically scale up and down without having to take on more overhead, and we enable owners to generate cash from their existing assets and vehicles purchased for investment. We're facilitating more efficient utilization of vehicles around the country.

Lead Data Engineer/Solutions Architect

We are looking for an experienced Data Engineer to help develop and manage data resources, implement new technologies and tooling to further enable reporting and analytics, as well as help drive scalable data sharing practices. You will own data environments, integrate with new technologies, and oversee the development of new processes that support teams across the organization. In this role you will work on high impact business insights projects with high visibility and used by executives. You will gather requirements through direct interaction with business, operations, as well as software development teams. You will track the performance of our resources and related capabilities, constantly evolving our offering in order to scale our capability set with the growth of the business and needs of our customers.
The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. He/she will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment. In addition, you will often be required to address and solve ad-hoc/unstructured problems in a highly fast paced environment.
RequirementsBasic Qualifications

A desire to work in a collaborative, intellectually curious environment

Bachelors degree in Computer Science, Engineering, Mathematics, or a related field 5+ Years of Data Warehouse Experience with BigQuery, Redshift, PostgreSQL, etc Demonstrated strength in SQL, data modeling, ETL development, and data warehousing Experience in maintaining data warehouse systems and working on large scale data

transformation using Dataproc, Dataflow, EMR, or equivalent Big Data technologies Strong knowledge of database performance concepts like indices, segmentation, <span style=""font-size: 10.5pt; font-family: Roboto, sans-serif; color: rgb(0, 0, 0); background-color: rgb(255, 255, 255); font-weight:",co,de
27,"SMS Data Products Group, Inc.",Information Technology,4.7,Mid-Level Systems Engineer,"Colorado Springs, CO",$94K - $126K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1044077&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_6252c99b&cb=1618793341746&jobListingId=4063471713,"The EITSM System Engineer I assists with the engineering and maintenance of the organization's systems infrastructure, including supporting the design and implementation of hardware and software while monitoring the performance of deployed systems. The position administers and maintains Remedy foundation data, the F5 Global and Local Traffic Managers, Oracle database Real-Time Application Cluster and Grid Control, while maintaining and configuring the BMC Remedy AR System server and supporting systems. Individuals in this role also perform regularly scheduled security and maintenance patching, quarterly audits of EITSM configurations, modify/build workflow, while supporting the integration and test of system upgrades, added capabilities, and integration of third-party applications as needed. As a dynamic systems integrator, SMS offers proven solutions in engineering, operations, cybersecurity, and digital transformation. With expertise in modernizing and optimizing legacy infrastructure and systems, ensuring operational efficiency, and designing, implementing, and managing secure environments, SMS supports business and mission goals with proficiency, quality, and integrity.SMS has been serving the advanced information technology needs of the federal government since 1976, delivering talented teams and innovative, cost-effective solutions and services to support our customers’ missions for more than 40 years. SMS is headquartered in McLean, Virginia, with offices and on-site operations at customer locations throughout the United States.ResponsibilitiesAdminister and maintain Remedy foundation data.Administer and maintain the F5 Global and Local Traffic Managers.Administer and maintain Oracle database Real-Time Application Cluster (RAC) and Grid Control.Maintain and configure the BMC Remedy AR System server and supporting systems.Perform regularly scheduled security and maintenance patching.Perform quarterly security audits of EITSM configuration.Modify existing workflow or build additional workflow on an as needed basis.Support integration and test of EITSM system upgrades and added capability.Support integration and test of EITSM with third-party applications as needed under change management processes.Maintain and support EITSM systems and applications in the HNI integrated test facility.Requirements3 – 5 years of progressively responsible Windows Server and/or Remedy support with experience in mid-to-large data center environments.Minimum of 3 years of hands-on experience in:Advanced networking concepts, VLAN, trunking and port channelDemonstrated advanced diagnostics and troubleshooting abilitiesDisaster Recovery - expertise in risk reduction, Hot/Warm site DR architecture, high availability, planning for disaster situationsKnowledge of data communications, local-area networking, wide-area networking, routers, and switchesNetwork (Layer 2, 3) LAN/WAN knowledge and switches/routersThorough understanding of Internet Protocol (IP) routing, switching, and the OSI model.Possess refined critical thinking skills, should be a self-starter, and multi-task capable.Approach work as diplomatic, adaptive to a dynamic environment, dependable and reliable.Education: Bachelor’s degree in related technical discipline, or MIS related field is preferred but not mandatory.Required Certifications: Security+ or equivalent, ability to obtain MCSA 2012 or equivalent within 60 days of hire.Desired Certifications: MCSA 2016 or equivalentClearance: Active DoD Secret required with ability to upgrade to Top Secret clearance preferred.SMS is an Equal Opportunity Employer. Job Type: Full-timePay: $1.00 per hourBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programFlexible scheduleFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offParental leaveProfessional development assistanceReferral programRelocation assistanceRetirement planTuition reimbursementVision insuranceSchedule:Monday to FridayAbility to Commute/Relocate:Colorado Springs, CO (Required)Experience:Windows Server and/or Remedy: 3 years (Required)License/Certification:CompTIA Security+ (Required)Security Clearance:Secret (Required)Work Location:One locationCompany's website:https://www.sms.com/Work Remotely:NoCOVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredPlastic shield at work stationsTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",co,de
28,Splunk,Information Technology,4.1,"Data Engineer, DevOps - Remote OK","Denver, CO",$108K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=4128&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_58f39443&cb=1618793341746&jobListingId=4063567499,"As a Data DevOps Engineer in the Enterprise DataWarehouse team you will work closely with a team of Data, Business Intelligence and Dev/Prod Ops engineers to help automate CI/CD deployment in a consistent and reliable way to non-production and production data infrastructure, at scale. As part this team, you will build CI/CD automation across GitLab/Github/Bitbucket, Airflow, Python ETL/ELT, Database scripts, containerization (Docker) and container-orchestration systems such as Kubernetes. You will work towards supporting deployment, data flow architecture and automation to deliver the highly available, performant and secure environments of Splunk’s Enterprise Data Warehouse.

Responsibilities

Iterate on release management methodologies to increase the quality & velocity of data warehouse deployments. Deploy and maintain CI/CD pipelines across multiple environmentsYou will collaborate with Production Engineering team’s on-call responsibilities in rotation.Experience working with Python based ETL/ELT, API and Cloud Data Warehouse databases. Data warehousing, Data Engineering experience, particularly with Snowflake is a plus.Design, develop and operate terabyte-scale data pipelines and services that meet goals of low latency, high availability, resiliency, security and quality .Define best practices, work with data engineering teams on best practices and ensure they are followed. Teach others how to do the right things. Automate everything. Enable self-service as much as possible via automation so that application teams can do what they need without you, focus on the engineering aspect primarily Automate schema updates/migration via common pipelines and pattern to be used by application teams in their deployment processes

Requirements:

8+ years of relevant work experience surrounding CI/CD, Test Automation and data infrastructure operations. Demonstrated ability to develop advanced CI/CD pipelines in GitLab, Python, Airflow (e.g. using dynamic data pipelines, automated unit testing, performance testing, etc.)Experience in writing and troubleshooting ETL jobs (Python, Airflow) and complex database SQL scripts.You have a strong python programming background in writing clean, testable code. Develop monitors and build alerts around error conditions and performance. Experience in data technologies server administration, SLA/incident management, RBAC automation and controls, user communication and support. Strong problem solving skills and ability to work independently or in team settings on complex production issues. Participate in On-Call support as needed.
",co,de
29,Philips,Health Care,3.8,"Senior Product Industrialization Engineer / Technical Project Leader, Philips Healthcare, (Colorado Springs, CO.)","Colorado Springs, CO",$125K - $141K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1044074&s=58&guid=00000178e79a20f289ebe99e656074ac&src=GD_JOB_AD&t=SR&vt=w&cs=1_78327d21&cb=1618793341746&jobListingId=4003745175,"Job TitleSenior Product Industrialization Engineer / Technical Project Leader, Philips Healthcare, (Colorado Springs, CO.)Job DescriptionIn this role, you have the opportunity to: This position works in Philips Healthcare, IGTD Division as a part of the Product Industrialization department in the Colorado Springs, Colorado location.The PI TPL manages a PI Engineering Team through the delivery of new or existing projects, and works cross functionally with R&D, Service, and other business groups ensuring completion of the project on schedule and within project constraints.This person will drive process development of new products, ensuring that manufacturing processes meet requirements, and identifying and recommending solutions for complex technical issues. Activities include process technology development, pilot line development, prototyping, knowledge transfer from other sites and contributing to technical team meetings regarding these topics.You are responsible forLeading the PI Engineering Team through all phases of a PDLM (Product Design & Lifecyle Management) project.Initiating and executing on product industrialization activities including equipment selection, process development, process characterization and process validation, in support of new product development as well as design changes.Design for lean manufacturing – applying tools such as value stream mapping, standard work and design for flowManufacturing input focusing on Design for Manufacturability, Reliability, ServiceabilityDriving key performance indicators such as Cost of Goods, Yield, Output, Quality throughout projects and into commercializationProviding in-depth knowledge for problem solving linked to Manufacturing processes and equipmentCollaborating with cross-functional team members throughout product development phases to ensure program successSupporting internal manufacturing, external manufacturing, and manufacturing transfer projects.Coaching and mentorship to other engineersMaking data driven decisions using appropriate analytical methodologiesEmploying equipment, processes and procedures which promote a healthy, safe, and secure work environmentTo succeed in this role, you should have the following skills and experienceBS in Mechanical, Electrical, Industrial, Manufacturing, Computer Engineering, or closely related field and PMP preferred.5 plus years’ experience in product development in the medical device industrySuccessful record of accomplishment executing complex manufacturing or new product development projects / programs / improvement opportunities (timelines, quality, capacity, capability, cost, productivity some key metrics).Demonstrated ability in Lean and Six Sigma methodologies within FDA-regulated medical device manufacturing (certification(s) preferred)Strong understanding of NPI project, design transfer processes, and global Supply Chain operations processesCompetent in the creation, execution, and delivery in areas of process characterization, ATMV’s, VTMV’s, OQ, PQ, and PPQThorough knowledge of manufacturing production processes. Understanding of how new products and changes to existing products impact the product in the areas of cost, performance, quality, and throughput.Passionate about driving innovative technical solutions in the manufacturing operation. Eager to partner with Philips Global Manufacturing Engineering teams.Demonstrated leadership skills in areas of coaching, communication, facilitation, team leadership and business management.Demonstrated success in working complex issues with cross-function team members to effective resolution.Effectively communicates to numerous stakeholders including senior management, other Business Groups, internal and/or external customers and staff.Experience working with suppliers to resolve technical issues preferredSelf-motivated and able to learn quickly from others, recognize problems and take corrective action when appropriateA team player who proactively seeks out expertise and advice from othersThe salary range for this position is ____________. The bonus target is 10%. Our benefits can be found here: https://www.careers.philips.com/na/en/total-rewards-at-philips.Why should you join Philips?Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.It is the policy of Philips to provide equal employment and advancement opportunities to all colleagues and applicants for employment without regard to race, color, ethnicity, religion, gender, pregnancy/childbirth, age, national origin, sexual orientation, gender identity or expression, disability or perceived disability, genetic information, citizenship, veteran or military status or a person’s relationship or association with a protected veteran, including spouses and other family members, marital or domestic partner status, or any other category protected by federal, state and/or local laws.As an equal opportunity employer, Philips is committed to a diverse workforce. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants that require accommodation in the job application process may contact 888-367-7223, option 5, for assistance. Equal Employment and Opportunity Employer/Disabled/VeteranUS work authorization is a precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa.#LI-PH1ContactIf you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.",co,de
72,West Metro Fire Rescue,Aerospace & Defense,4.7,Data Engineer/ Analyst,"Lakewood, CO",$73K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044077&s=58&guid=00000178e79c1b019a40ccf61198b42c&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ffc2bac1&cb=1618793471222&jobListingId=4062448364,"Business Group HighlightsIntelligenceThe Intelligence group provides high-end systems engineering and integration products and services, data analytics and software development to national and military intelligence customers. Serving federal agencies and the Intelligence Community for more than 50 years, the Intelligence group helps our clients meet their mission needs by providing trusted advisors, leading-edge technologies, and innovative solutions.ResponsibilitiesPerspecta is a company founded on a diverse set of capabilities and skills, bound together by a single promise: we never stop solving our nation’s most complex challenges. Our team of engineers, analysts, and developers work tirelessly to create innovative solutions. We continually push ourselves—to respond, to adapt, to go further.When you join Perspecta, you ally yourself with some of the smartest, most dedicated people in the industry. From mission domain experts with decades of experience, to engineers and developers using the latest agile techniques, you will find a team of people you’ll be proud to learn from and work with.Our high-caliber employees are rewarded in many ways—not only through highly competitive salaries and benefits packages, but also with the opportunity to create a meaningful impact on projects that matter. We will provide you the flexibility to shape a role that helps develop the career you want.ResponsibilitiesPerspecta is looking for a SYSTEMS ENGINEER to join a skilled, highly respected and long-standing team supporting operational systems and environments. The successful applicant will generate and execute testing procedures to verify the operational performance of end-to-end systems. They will also review test plans to ensure they meet operational objectives and will participate in the testing process to validate the satisfaction of mission requirements. They will collect and analyze data, produce metrics and trending information, and engage in end-to-end monitoring of complex intelligence systems. Activities include:Support monitoring of enterprise data processing, and the associated infrastructure, to provide timely detection of potential errors and system issuesConduct first-level analysis of testing results, coordinate and/or perform detailed in-depth analysis of the resultsIdentify any degradations in system performance. Support notifications to the government and associated personnel. Perform and/or support root cause analysis of observed issuesCreate and manage discrepancy reports, trouble tickets, or other forms of notification; Track through to resolution; Verify fixes are satisfactorySupport routine and ad-hoc scheduling of enterprise engineering testsMonitor planned outages and other activities which may impact system performance and data accuracy and report findings or issues to the governmentPlan, coordinate, and execute engineering tests following outages and events that may have impacted system performance or data accuracyAuthor Engineering Test Support Requests (ETSR) and design, plan, and conduct engineering evaluation test in support of enterprise operation and system deliveriesPrepare engineering test reports and findingsEnsure approaches to analysis are based on accepted scientific and mathematical practiceQualificationsRequired:Active TS/SCI Clearance with PolygraphRequires 8 to 10 years with BS/BA or 6 to 8 years with MS/MA or 3 to 5 years with PhD.Strong analytical skills, intelligence community domain knowledge, and demonstrated understanding of user needs and operational environmentsDemonstrated success in team environments; good presentation and communication skillsDemonstrated ability to clearly explain technical issues to both technical and non-technical audiencesDesired:Experience in the National Intelligence CommunityPreference for degrees in a technical field (e.g. physics, electrical/systems engineering, math)Colorado Salary Minimum: $82,992.00 Colorado Salary Maximum:$177,424.00 The estimate displayed represents the typical salary range for this position, and is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees.About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
118,Slalom LLC.,Business Services,4.3,Senior Data Engineer,"Denver, CO",$93K - $103K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=4470&s=58&guid=00000178e79d0dd7ad29a4ce31d39b00&src=GD_JOB_AD&t=SR&vt=w&cs=1_fbdc25fd&cb=1618793533366&jobListingId=4061366991,"Slalom is a modern consulting firm focused on strategy, technology, and business transformation. We believe in what's possible and shape what's next.

At Slalom, personal connection meets global scale. We build deep relationships with our clients in 39 cities around the world while sharing insights across markets to bring the full breadth of Slalom's expertise to every engagement. Our regional Build Centers are hubs for innovation, attracting top talent to rapidly co-create the technology products of tomorrow. We also nurture strong partnerships with over 300 leading technology providers, including Amazon Web Services, Google Cloud, Microsoft, Salesforce, and Tableau.

Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 8,500 employees. We were named one of Fortune's 100 Best Companies to Work For from 2016-2021 and are regularly recognized by our employees as a 'Best Place to Work'. Learn more at slalom.com.

Denver consultants can build something locally while exercising their entrepreneurial muscles within the context of a proven and growing company. With our local delivery model, we live and work alongside our clients creating a different level of partnership and intimacy in our relationships. Slalom employees gain a wide breadth of experience across a diverse range of industries that thrive in Denver.

As a Senior Data Engineer, you’ll help deliver engaging, modern data solutions and strategies at one of the nation's top-rated consultancies. As a member of the Data & Analytics practice, you will analyze, design, and build cloud-based data solutions to address our clients' needs.

Role: Senior Data Engineer

What You'll Do:

Work alongside a best-in-class team to design and develop modern data solutionsGather technical requirements, assess client capabilities, and analyze findings to provide appropriate solution recommendations and adoption strategiesResearch, analyze, recommend, and select technical approaches for solving difficult and meaningful development and integration problemsLearn and embrace new tools and techniques to increase performance, automation, and scalabilityMentor other Slalom team membersUnderstand business goals and drivers and translate those into an appropriate technical solutionProvide technical direction and oversight to implementation teams

About You:

You bring 5+ years of data engineering and/or data warehousing experienceYou have 2+ years of deep experience building cloud data solutions (Azure, AWS, GCP, Snowflake)You're deeply experienced with designing and deploying end-to-end solutions with a cloud platform's analytic services including storage, permissions, private cloud, database services, virtual machines, and parallel processing technologiesExperienced with big data application development and/or with cloud data warehousing (e.g. Hadoop, Spark, Redshift, Snowflake, Azure SQL DW, BigQuery)You possess a working knowledge of agile development methodologies including DevOps conceptsYou're experienced with cloud SDKs and programmatic access servicesProficient in a relevant programming language for cloud platforms (e.g. Python, Java, C#, Unix), as well as SQLYou're well-versed in version control platforms like Git

About Us:

Slalom prides itself on helping team members thrive in their work and life. As a result, Slalom is proud it invest in benefits that include: meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability. We also offer additional benefits such as a yearly $350 reimbursement account for any well-being related expenses as well as discounted home, auto, and pet insurance.

Slalom is an equal opportunity employer that is committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veterans status, or any other characteristic protected by federal, state, or local laws. ",co,de
119,Proofpoint,Information Technology,3.9,Senior Data Engineer,"Broomfield, CO",$96K - $181K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=135088&s=58&guid=00000178e79d0dd7ad29a4ce31d39b00&src=GD_JOB_AD&t=SR&vt=w&cs=1_70a42a20&cb=1618793533366&jobListingId=3663587610,"It's fun to work in a company where people truly BELIEVE in what they're doing!We're committed to bringing passion and customer focus to the business.Proofpoint is a leader in the world of detecting and preventing email based fraud. We have built a cutting edge platform for collecting, processing and analyzing a massive amount of email data. The insight we provide helps our client base build a robust email infrastructure as well as informs clients of malicious use of their brand. We are looking for a Data Engineer to build a bridge between data systems and people. This role will be responsible for development and overall quality of data and related systems.Your day-to-dayBuild and maintain a data lake of email dataDevelop software systems to share data across ProofpointWork side by side with Data Scientists to enable research and development projectsBuild software prototypes to help determine feasibility and complexity of future workHelp measure Data quality and lead the effort to close on gapsParticipate in Data Classification and Privacy initiativesWhat you bring to the team5-10 years of experience in Software DevelopmentExpert level coding skills in Java, Go or similarExperience prototyping Data Science patterns in Python and/or ScalaExperience with Map Reduce, including AWS EMRExperience with Data tools like SparkExperience with deploying infrastructure in an AWS cloud environmentInterest or experience with containers and orchestration. Docker or Kubernetes experience is valued!Bachelor Degree or higher in Computer Science or relevant Engineering/Science disciplineWhy ProofpointAs a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint’s amazing culture!#LI-AN1If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",co,de
0,UCLA Health,Health Care,4.1,Senior Data Engineer,"Los Angeles, CA",$98K - $174K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178e7aaafcca755b28ea4109cab&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_c5905f2d&cb=1618794426891&jobListingId=4062957349,"ResponsibilitiesThe Senior Data Engineer reports to the Manager of Data Architecture, within the Data Architecture and Engineering team. You will be responsible for architecting, designing, developing and operating high Performance Big Data pipelines focused on genomics and precision health. This role will be at the intersection of computer sciences and biology.The role requires constant learning to remain up to date on the latest trends in the Big Data and Genomics world. You will contribute to the Data Architecture team’s efforts to develop cloud-based data infrastructure for data ingestion pipelines and analytics platforms to facilitate research activities and precision health initiatives and will help evolve our data infrastructure design to a next generation system that leverages Cloud and Big Data technologies.You will work directly with a wide variety of stakeholders, including clinicians, researchers, and students that develop, support and promote the usage of UCLA Health Data assets (Data Lake, Data Warehouse and Data Marts).Qualifications7 or more years of software development experience with multiple programming languages, technologies, and frameworksDemonstrated experience on the data processing side of the software development cycle and deep understanding of choosing the right Data Structures and right Algorithms for data processingHands on experience running bioinformatics pipelines on genomics and clinical dataGood understanding of Genomics tools and technologies like PLINK, VCF, FASTA, GATK and GenomicsDB; exposure to different genomics datasets like WGS, WES, and RNASeq highly desiredFamiliarity with Software Development Life Cycle, software unit testing and version control (preferably Git)Hands-on experience designing and delivering solutions involving computationally intensive steps using technologies such as Hadoop-Map reduce, Spark or HPCExpertise and working knowledge of Linux/Unix operating systems, command line tools and clustersStrong industry experience in programming languages such as Python, C# or Java, with the ability to pick up new languages and technologies quickly; understanding of cloud and distributed systems principles and experience with large-scale, big data methodsExperience designing, developing and consuming performant REST APIs for data abstractionsExperience working with Data Scientists, Researchers and DevOps engineers to build, deploy and operationalize code at scaleGood understanding of Object oriented and Functional programming paradigmsBachelor’s degree in Computer Science, Computer Engineering, Life sciences or related field from an accredited college or university; Master’s Degree in Computational Biology, BioInformatics preferredUCLA is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.",la,de
1,Tri-Search,Business Services,4.2,Data Engineer,"El Segundo, CA",$68K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044076&s=149&guid=00000178e7aaafcca755b28ea4109cab&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_1a18b2a1&cb=1618794426893&jobListingId=4062389539,"CPG company, position can be located in Denver or Los AngelesWHAT WE ARE LOOKING FOR:The Data Engineer reports to our Director, Enterprise Data and is responsible for designing, developing, testing, debugging, improving and supporting new and existing applications, reports and interfaces within the Microsoft technology stack. This individual will work closely with our Finance, Marketing, Operations and Sales teams to meet company objectives and improve customer productivity and efficiency. The Data Engineer will support and enhance our D365 ERP system through the creation of reports, interfaces and PowerApps, as well as assist the direct-to-consumer (DTC) business on Shopify through functionality enhancements and modifications as needed by the Ecommerce team.This individual should possess a problem-solution attitude and exceptional interpersonal + organizational skills to help understand the organization from the perspective of our teams. The Full Stack Applications Developer should thrive working in a multi-developer, multi-project environment with the ability to deliver clean and efficient code, as well as continuous best in class security practices.KEY RESPONSIBILITIES:Support the company's direct-to-consumer website hosted on Shopify and AmazonBuild Interfaces between applications, databases and servicesWork with project managers, business analysts, application support and QA to refine requirements and designsDevelop reports based upon team needs in various delivery methodsSupport and enhance the functionality of the company ERPDocument system requirements, designs and training materials, as neededPeer review IT team member work and enforce coding standardsIdentify opportunities for process improvement through the use of Microsoft Office 365 suite of tools and applicationsParticipate / Lead special projects and assignments, as requiredParticipate in all other miscellaneous SMPL and departmental tasks, as requiredAttend departmental/cross-functional meetingsSKILLS / KNOWLEDGE:Strong leadership and interpersonal skills to interact with Executives and team leads across the company,Architecture, design and development expertise within the languages stack and Microsoft Azure architectureRESTful service development; Database developments (normalization and warehousing)Thorough understanding of SDLC concepts; Knowledge of the following: Azure Data Lake, or related cloud-based storage, SQL Server Integration Services, Azure Data Factory, TFS, Git, Azure Devops version control and deployment, HTML5, CSS, JavaScript, jQuery, Microsoft Entity Framework and Responsive Design ConceptsAbility to manage projects simultaneously; Adjust to changing priorities; Drive strategic projects to successful deliveryBASIC QUALIFICATIONS:Bachelor’s degree and/or minimum 6 years relevant work experience, requiredMinimum 6 years relevant experience; CPG and in-house experience, strongly preferredFunctional understanding of MS SQL Server Database administrationCross functional experience, requiredExperience coding to Active Directory AuthenticationExperience supporting and developing Ecommerce platforms (i.e. Amazon and Shopify)ERP experience, a must ; D365 or Dynamics AX, preferredTechnical lead experience, preferredJob Type: Full-timePay: $100,000.00 - $120,000.00 per yearBenefits:401(k)Dental insuranceHealth insurancePaid time offTuition reimbursementVision insuranceSchedule:Monday to FridaySupplemental Pay:Bonus payApplication Question(s):What is the salary range you are targeting?Are you authorized to work in the US without sponsorship?Experience:ERP systems: 1 year (Preferred)Power BI: 2 years (Preferred)SSIS: 1 year (Preferred)Work Location:One locationWork Remotely:NoCOVID-19 Precaution(s):Remote interview process",la,de
2,Avanade,Information Technology,4,Azure Data Engineer,"Los Angeles, CA",$71K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_b0ff1b49&cb=1618794426894&jobListingId=4003695662,"Why Avanade:14-time winner of Microsoft Partner of the Year24,000+ certifications in Microsoft technology90+ Microsoft partner awards17 Gold Competencies3,500 analytics professionals worldwide1,000 data engineersImplemented analytics systems for more than 550 clients400 AI practitioners300 cognitive service expertsDo you enjoy making sure that information is accessible and easy to use? So do we.You’re a data designer who knows how to find, store and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.About You:You draw on your considerable experience in bringing data and statistics to life to solve sometimes complex problems, and you’re comfortable looking after several projects at once. You’re able to make your own decisions while at the same time supporting more junior team members.About the Role:As a Consultant, Data Engineering, you know the importance of data to the business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.How we support you:We believe in gender equity and an inclusive community. We offer a comprehensive benefits package: generous vacation allowance disability coverage, retirement plans, paid maternity and paternity leave, life insurance, extended benefits to cover items that support your well-being, health, dental and vision insurance, professional development and paid Microsoft certification opportunities.About you:You design data solutions that enable clients to see the whole picture and provide insightful and accurate analysis that helps to build successful businesses.Day-to-day, you will:Give colleagues and clients the tools to find and use data for routine and non-routine analysisUse your sound eye for business to translate business requirements into technical solutionsAnalyze current business practices, processes and procedures to spot future opportunitiesAssess client needs to build bespoke data design servicesBuild the building blocks for transforming enterprise data solutionsDesign and build modern data pipelines, data streams, and data service Application Programming Interfaces (APIs)Craft the architectures, data warehouses and databases that support access and Advanced Analytics, and bring them to life through modern visualization toolsImplement effective metrics and monitoringBe comfortable to make your own decisions and guide your colleaguesYour skills and business experience include:Transforming business needs into technical solutionsMapping data and analyticsData profiling, cataloguing and mapping to enable the design and build of technical data flowsUse proven methods to solve business problems using Azure Data and Analytics services in combination with building data pipelines, data streams and system integrationKnowledge of multiple Azure data applications including Azure DatabricksExperience in preparing data for and building pipelines and architectureYou probably have a Bachelors or Master’s degree in a quantitative field such as computer science, applied mathematics, statistics or machine learning - or an equivalent combination of education and experience. You’re likely to be a Microsoft Certified Solutions Associate, Microsoft Certified Solutions Expert, and/or Database Administrator already, and you have been in a similar professional position for around five to seven years.",la,de
3,IBM,Information Technology,3.9,Data Engineer,"Los Angeles, CA",$84K - $156K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_3d7f5947&cb=1618794426896&jobListingId=4059011172,"IntroductionHave you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.Your Role and ResponsibilitiesKey Responsibilities:Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical requirements and support their data infrastructure needs.Provide the ability to work within agile development methodology and collaborate effectively with multi-disciplinary teamsBuild modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements.Understand data architecture, build large-scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow.Have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Have expertise in data persistence solutions, experience with the latest (NoSQL) database technologies, and experience with building complex SQL queries using various (NoSQL or RDBMS) databases such as MongoDB or DB2Experience in software engineering with object-oriented design, coding and testing patterns on large-scale data infrastructuresUse DevOps best practices such as continuous integration, continuous delivery in the production implementation.GarageIBMReferred_NorthAmericaRequired Technical and Professional ExpertiseDevelop code using Python, Scala, R languagesExperience with relational SQL and NoSQL databases, including Postgres and Cassandra3+ years design & implementation experience with distributed applications3+ years of working experience in database architectures and data pipeline developmentDemonstrated knowledge of software development tools and methodologiesComputer Science with software engineering and Math background desiredPreferred Technical and Professional ExpertiseExperience with big data tools: Hadoop, Spark, Kafka, etc.Familiar with big data solutions with experience on Hadoop based technologies such as MapReduce, Hive MongoDB or Cassandra.Experience with stream-processing systems: Storm, Spark-Streaming, etc.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.Knowledge of cloud technologies such as Kubernetes, Cloud Foundry, PaaS, and IaaS (SoftLayer)NONEAbout Business UnitIBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.Impact. Inclusion. Infinite Experiences. Do your best work ever.About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.Location StatementIBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to:12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.Well-being programs to support mental and physical health.Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).Select educational reimbursement opportunities.Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.Giving and volunteer programs to benefit charitable organizations and local communities.Discounts on retail products, services, and experiences.This position is eligible for participation in an IBM sales incentive plan. Actual incentive opportunity will be based on performance and the eligible Target Incentive, as addressed in the applicable plan, all of which is subject to change.We consider qualified applicants with criminal histories, consistent with applicable law.IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",la,de
4,Mt. San Antonio College,Education,4.5,Data Engineer,"Walnut, CA",$83K - $115K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_f453e0a7&cb=1618794426897&jobListingId=4060794220,"Complete application packets will be accepted until the position is filled; however, those submitted by 11:59 p.m. (PST) on May 10, 2021 (Initial Screening Date) are assured consideration.Applicants must submit all of the following materials online unless otherwise noted at Mt.SAC Employment Website to be considered for this position:1. A Mt. San Antonio College online application.2. A cover letter describing how the applicant meets the required education and experience.3. A detailed rsum that summarizes educational preparation and professional experience for the position.4. Two letters of recommendation that reflect relevant experience (do not use social media or professional networks as a means to provide letters of recommendation).5. If applicable, College and/or university transcripts showing the awarded/conferred degree are required and must be submitted with the online application by all applicants, including current or former employees of the college, to demonstrate that the required educational qualifications are met. Unofficial transcripts are acceptable at the time of application; however, copies of diplomas are not accepted in lieu of transcripts.Health & Welfare:The College contributes an annual premium up to the family coverage amount for Kaiser Permanente $15 office visit medical, DeltaCare HMO dental, VSP vision and life insurance plans. Lifetime retirement benefits provided for eligible retirees.The District participates in the Public Employees Retirement System (PERS), State Teachers Retirement System (STRS) retirement programs, and National Benefit Services.Note Salary and Health & Welfare Benefits are subject to changeBasic Function/Overview:DEFINITIONUnder general direction, leads and coordinates day-to-day operations of the Operational Data Store (ODS), Data Warehouse, and all related technologies; analyzes and transforms data into a format that can be easily used by different departments for reporting; collaborates with programmers, Business Analysts, and functional areas in gathering requirements and clarifying their needs for implementation, generation, optimization, and support of their data; provides complex professional staff assistance to the Director, Enterprise Application Systems in areas of expertise.Supervision Received and ExercisedReceives general direction from the assigned managerial personnel. Provides coordination and lead work direction to staff.CLASS CHARACTERISTICSThis is a highly specialized class in the Information Technology (IT) Department that leads a wide variety of technical duties pivotal to the College's Operational Data Store and Data Warehouse. Responsibilities include performing diverse, specialized, and complex work involving significant accountability and decision-making responsibility providing guidance, suggestions, and coordination to the College as it relates to data infrastructure, modeling, data refresh timelines, and operations. Successful performance of the work requires an extensive professional background, as well as skill in leading and coordinating departmental work with that of other College departments. This class is distinguished from Director, Enterprise Application Systems by the latter's management and supervisory authority in planning, organizing, and directing the full scope of enterprise operations within the department.Essential Duties/Major Responsibilities:1. Provides technical support, analysis, and programming to ensure complete and appropriate use of the Colleges Operational Data Store and Data Warehouse.2. Responds and evaluates ad hoc requests for data, statistical analysis, research projects and studies; prepare requests for processing; arrange and maintain project schedules and timelines; design strategies to complete assignments; analyze and compare a variety of data solutions; make team project recommendations to the manager.3. Assists manager to evaluate and respond to requests for complex or original support from within and outside the College; works independently with requestors to clarify their needs and optimize the utility of results.4. Reviews user needs and requests and develops proposed solution for usable data design or format for the users reporting and analysis needs; monitors and tunes report queries and views.5. Assists in implementing ways to improve data reliability, efficiency and quality.6. Develops, constructs, tests, and maintains Operational Data Store and Data Warehouse architecture.7. Discovers opportunities for data acquisition.8. Expands the existing schema design to handle new data formats.9. Develops and documents Operational Data Store and Data Warehouse standards, scripts, guidelines, and usage procedures; enforces standards for use, control, updates, and maintenance for the Operational Data Store and Data Warehouse environments.10. Interacts and coordinates with other IT areas and key end users.11. Ensures data models, design, and architecture that are in place support the requirements of the programmers, Business Analysts, researchers, and different functional areas.12. Provides guidance on reporting, query or data extraction design, development, and maintenance, including monitoring performance tuning and optimization in queries; Recommends selection of query or reporting tools, methodologies, and procedures for development of reports and views.13. Develops data set processes for data modeling, mining, and production; prepares data for use in predictive and prescriptive modeling.14. Leverages large volumes of data from internal and external sources to answer reporting needs.15. Participates on committees, task forces, and special assignments, including, but not limited to Screening and Selection Committees and affiliated trainings. Prepares and delivers oral presentations related to assigned areas if needed.16. Performs other related or lower classification duties as assigned.Other Duties:Performs other related duties as assigned.Knowledge Of:1. State-of-the-art information systems as applied to large, complex administrative, or educational organizational environments.2. Principles and techniques of computer systems and software architectures.3. Operating System (OS)-based platforms.4. Programming languages, including but not limited to PL/SQL, SQL, Python, and Shell Scripting.5. Database front-end programs such as Microsoft (MS) Access, Statistical Package for the Social Sciences (SPSS), and related products.6. Data warehousing and techniques.7. Principles and concepts of Relational Database Management System (RDBMS), Big Data, and Operational Data Store.8. Statistical tools and research methods.9. Principles, techniques, and methodologies in project management and leadership.10. Business letter writing and record-keeping principles and procedures.11. Use, capability, characteristics, and limitations of computer systems and databases12. Methods, techniques, and practices of data collection and report writing.13. Modern office practices, method, and computer equipment and applications related to the work, including word processing, database, and spreadsheet software.14. Techniques for effectively representing the College in contacts with governmental agencies, community groups, and various business, professional, educational, regulatory, and legislative organizations.Skills and Abilities:1. Analyze informational requirements and needs, identify problems, provide technical advice and consultation, and ensure efficient computer system utilization.2. Analyze data and develop logical solutions to problems.3. Experience with Source code management systems.4. Code Debugging and Performance troubleshooting.5. Master new technologies quickly; stays abreast of current trends and developments in Operational Data Store, Data Warehouse, and Big Data.6. Conduct complex research projects on a wide variety of information technology and database administration topics, evaluate alternatives, make sound recommendations, and prepare effective technical staff reports.7. Interpret, explain, and ensure compliance with College policies and procedures.8. Establish and maintain a variety of filing, record-keeping, and tracking systems.9. Organize and prioritize a variety of projects and multiple tasks in an effective and timely manner; organize own work, set priorities, and meet critical time deadlines.10. Use English effectively to communicate in person, over the telephone, and in writing at both technical and functional levels.11. Understand scope of authority in making independent decisions.12. Review situations accurately and determine appropriate course of action using judgment according to established policies and procedures.13. Establish, maintain, and foster positive and effective working relationships with those contacted in the course of work.14. Explores and examines data to find hidden patterns.15. Tell stories to key stakeholders based on the analysis.16. Learns and applies emerging technologies, as necessary, to perform duties in an efficient, organized, and timely manner.Minimum Qualifications/Education & Experience:Equivalent to graduation from a regionally accredited four-year college or university with major coursework in computer science, data science or a related field, and four (4) full time equivalent years of experience in database management including two (2) full time equivalent years of progressive experience as a data analyst, data engineer, or researcher.Equivalencies:Preferred Qualifications:License(s) & Other Requirements:Examination Requirements:Working Environment:Incumbents work in an office environment with moderate noise levels, controlled temperature conditions, and no direct exposure to hazardous physical substances. Incumbents may interact with staff and/or public and private representatives in interpreting and enforcing departmental policies and procedures.Physical Demands:Must possess mobility to work in a standard office setting and use standard office equipment, including a computer; to operate a motor vehicle to visit various College and meeting sites; vision to read printed materials and a computer screen; and hearing and speech to communicate in person and over the telephone. This is primarily a sedentary office classification although standing in and walking between work areas is frequently required. Finger dexterity is needed to access, enter, and retrieve data using a computer keyboard or calculator and to operate standard office equipment. Incumbents in this classification occasionally bend, stoop, kneel, reach, push, and pull drawers open and closed to retrieve and file information. Incumbents must possess the ability to lift, carry, push, and pull materials and objects up to 20 pounds.Hazards:Conditions of Employment:Official offers of employment are made by Mt. San Antonio College Human Resources and are made contingent upon Board approval. It is also required that a final offer of employment will only be made after the candidate has successfully been live-scanned and clearance for employment is authorized by Human Resources. Costs for live-scan services shall be borne by the candidate.Notice to all prospective employees The person holding this position is considered a mandated reporter under the California Child Abuse and Neglect Reporting Act and is required to comply with the requirements set forth in Administrative Procedure 3518, titled Child Abuse Reporting, as a condition of employment.As required by the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act, the Mt. San Antonio Community College Annual Security Report is available here: Mt. SAC Annual Security Report 2017The person holding this position is considered a Responsible Employee under Title IX of the Educational Amendments Act of 1972 and is required to report to the Colleges Title IX Coordinator all relevant details reported to him or her about an incident of alleged sexual misconduct including sexual harassment, sexual assault, dating and domestic violence and stalking.Typing Certificate Requirements:Special Notes:Please note: A confirmation number will be assigned when your application packet indicates the supplemental questions have been answered and a document has been attached to each required link. Assistance with the online application process is available through the Office of Human Resources at 1100 N. Grand Avenue, Walnut, CA 91789-1399. Human Resources: (909) 274-4225. E-mail: employment@mtsac.edu.DO NOT include photographs or any demographic information (e.g. D.O.B, place of birth, etc.) on your application or supporting documents.TRAVEL POLICY: Costs associated with travel in excess of 150 miles one way from residence for the purpose of an interview will be fully reimbursed (at the economy rate). Relocation costs will be borne by the successful candidate. Travel reimbursement claims (original receipts) must be submitted no later than 30 days following the interview date.Foreign Transcripts:Foreign Transcripts: Transcripts issued outside the United States require a course-by-course analysis with an equivalency statement from a certified transcript evaluation service verifying the degree equivalency to that of an accredited institution within the USA. This report must be attached with the application and submitted by the filing deadline.Inquiries/Contact:Human Resources at 1100 N. Grand Avenue, Walnut, CA 91789-1399. Human Resources: (909) 274-4225. E-mail: employment@mtsac.edu.Selection Procedure:A committee will evaluate applications, taking into account breadth and depth of relevant education, training, experience, skills, knowledge, and abilities. The screening committee reserves the right to limit the number of interviews granted. Meeting the minimum qualifications for a position does not assure the applicant of an interview.Interviews may include a writing sample, committee presentation, and/or performance test. The start date will be following Board approval and receipt of live scan clearance.Special Instructions to Applicants:To be guaranteed consideration, it is the applicants responsibility to ensure that all required materials are received before the initial screening date and time indicated on the job posting. Incomplete application packets will not be considered. All application materials will become College property, will not be returned, and will not be copied. Please visit our employment website at Mt. SAC Employment Website to complete and submit your application for this position.Letters of RecommendationConfidential letters of recommendation are not accepted for this position. All letters of recommendation must be uploaded to the application.EEO Policy:The College is an equal opportunity employer. The policy of the College is to encourage applications from ethnic and racial minorities, women, persons with disabilities, and Vietnam-era veterans. No person shall be denied employment because of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, marital status, sex (gender), age, sexual orientation, or the perception that a person has one or more of these characteristics.Conflict of Interest:Mt. San Antonio College employees and the Board of Trustees members shall not engage in any employment or activity that is inconsistent with, incompatible with, or in conflict with Mt. San Antonio Colleges Administrative Procedures (AP 2710 Conflict of Interest, AP 2712 Conflict of Interest Codes).Cancel RTF Policy:WE RESERVE THE RIGHT TO RE-OPEN, RE-ADVERTISE, DELAY OR CANCEL FILLING THIS POSITION.THIS RECRUITMENT MAY BE USED TO FILL FUTURE VACANCIES.",la,de
5,Splunk,Information Technology,4.1,Senior Data Engineer,"Los Angeles, CA",$151K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=4128&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_8bc13fe0&cb=1618794426897&jobListingId=4063567581,"Ready to shake things up? Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and strive to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun, and most significantly to each other’s success. We continue to be on a tear while enjoying incredible growth year over year.

As the Senior Data Engineer within the Data Technologies and engineering organization, you will own and be part of business analytics projects from Inception through Hypercare. As a data and reporting engineer you will drive transformational data and analytics initiatives for improving the effectiveness and efficiency for Enterprise business functions. Having the right blend of technological depth, Sales, Marketing, Finance process and systems expertise along with analytics skills is key to the success of the role. You will be expected to manage end to end delivery of small to medium scale projects in the data & analytics area through active leadership and partner management, both at strategic and tactical levels. Very Strong presentation skills and executive presence, with effective communication to create impact and influence both at the executive and mid-level management.

What you'll do: Yeah, I want to and can do that.

Deep understanding of Cloud Data Warehouse methodologies, Data Architecture, Data Modeling, and metadata.Ability to support the creation of single source of truth for Business Metrics leveraging agreed upon data definitions, create a common data foundation, and semantic layers to be consumed by business.Deliver highly available, reliable, innovative large-scale data warehousing solutions to facilitate data ingestion, build optimized aggregates and building reporting solutions.Deep knowledge and hands-on experience working with Cloud database technologies like Redshift, Snowflake and multiple BI platforms such as Tableau, Splunk and scripting language like Python.Solid grasp of operational processes, systems and data in multiple areas of Sales & operations; Forecasting, Quote to Cash, Pipeline management.Understanding of SaaS business applications and processes as in Salesforce, SAP, Eloqua, Anaplan, etc.Identify data patterns, attribute hierarchies and data relationships and organize into data dictionaries, create standardized definitions for metrics and critical metrics.Analytical and problem-solving experience, exposure to large-scale systems and some experience writing code.Strong business analysis skills - capturing and documenting requirements, understanding business impacts and tradeoffs, conducting interviews and workshops, proposing solutions, documentation and training, etc.

Requirements: I’ve already done that or have that!

8+ years of experience as a Data Warehouse Analyst, Data Engineer and/or Data ScientistSavviness with complex SQL queries and knowledge of database technologies including window and analytical functionsExperience with Python analytic libraries and Business Intelligence tools such as Tableau.An ability to provide technical guidance, direction and problem solving to data engineering team members.Confidence to offer consultation to business partners and team members within Sales, Partner, Marketing Operations.A familiarity working with an AGILE/SCRUM process management.

Preferred knowledge and experience: These are a huge plus.

Knowledge of Splunk productsAgile certifications

Education: Got it!

Bachelor’s degree preferably in Computer Science, Information Technology, Management Information Systems, or equivalent years of industry experience.

What We Offer You: Wow, I want that.

A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies.A set of extraordinarily hardworking, innovative, open, fun and dedicated peers, all the way from engineering and QA to product management and customer support.Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation.A stable, collaborative and supportive work environment.

We don't expect people to work 12 hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication and believe that balance helps cultivate an extraordinary environment

This isn’t a job – it’s a life changer – are you ready?

Splunk has been named one of San Francisco Bay Area’s “Best Places to Work” by the San Francisco Business Times, ten years in a row. We offer a highly competitive compensation package and a plethora of benefits.

Splunk is proud to be an equal opportunity workplace and is an affirmative action employer. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.",la,de
6,The Aerospace Corporation,Aerospace & Defense,4,Data Engineer,"El Segundo, CA",$123K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_1a083c7a&cb=1618794426897&jobListingId=3663177907,"In an era of dynamic change in space, Aerospace is addressing a generation of complex challenges. We operate the only federally funded research and development center (FFRDC) committed exclusively to the space enterprise. Our technical experts span every discipline of space-related science and engineering. Join our team and thrive in a career that matters to the world and you personally.ResponsibilitiesThe Analytics Software Department is seeking a Data Engineer to help design and develop Data Engineering Platforms for our civil and national security space customers. Do you want to develop data analytics pipelines and do innovative work on the data processing frameworks and architectures with the ability to intelligently scale? Join us on the Analytics Software Department team in The Aerospace Corporation!Key FunctionsIndependently evaluates, selects, and applies engineering techniques, procedures and criteria, using judgment in making adaptations and modifications. Assignments typically have specified objectives.Supports multiple space systems customers.Develops cloud native applications and microservices for scalable and distributed software systems.Quickly learns new technical skills to tackle technology's greatest challenges.Provides recommendations on data engineeringQualificationsRequiredBachelor's degree in Computer Science from a recognized institution with a minimum 3.0 GPATwo or more years of industry-related experienceDesign of highly scalable web services and distributed systems with cloud native microservicesProficiency in at least one of the following languages: Java, Python, JavaScript, ScalaBuild and optimize data sets, 'big data' data pipelines and architecturesPresent project updates to management in order to ensure that project development remains aligned with subdivision’s goals and visionLead projects and build data engineering platforms for customers’ data challengesGood interpersonal skills and the ability to work in interdisciplinary teamsThis position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.PreferredMaster’s degree, further education or experience in engineering, computer science or other technical related fieldsExperience in leading software development teamsExperience with data visualization frameworks or developmentExperience with cloud deployment and management toolsActive Secret security clearanceEqual Opportunity CommitmentThe Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, age, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender, gender identity or expression, color, religion, genetic information, marital status, ancestry, national origin, protected veteran status, physical disability, medical condition, mental disability, or disability status and any other characteristic protected by state or federal law. If you’re an individual with a disability or a disabled veteran who needs assistance using our online job search and application tools or need reasonable accommodation to complete the job application process, please contact us by phone at 310.336.5432 or by email at ieo.mailbox@aero.org . You can also review The Equal Employment Opportunity is the Law poster and the supplement , as well as the Pay Transparency Policy Statement .",la,de
7,Foursquare,Information Technology,3.2,"Software Engineer, Data Engineering - Data Platform","Los Angeles, CA",$98K - $176K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=8095&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_8f897a76&cb=1618794426898&jobListingId=4035276328,"Foursquare is the leading independent location technology company, powered by our deep understanding of how people move throughout the world. Our solutions help businesses make smarter decisions, developers create more engaging experiences, and brands build more effective marketing strategies.

Foursquare's platform includes Attribution, Audience, Pinpoint, Proximity, Places, Pilgrim SDK and Visits. As the industry's first and only accredited company for location data from the Media Rating Council (MRC), this foundation powers all our solutions — those that exist today and those we have yet to build. Over 14 billion consumer-verified place visit confirmations help us keep our map and models fresh and up-to-date, building a phone's-eye-view of the world with 105 million unique places of interest worldwide.
About team


The data engineering team owns critical pieces of the machine learning and analytics platforms. This team helps to build data processing infrastructure to derive insights from billions of location data points every day. Help us build and collaborate with Product, Engineering, and Data Science teams to create tools and processes to bring research and machine learning models to production.


Responsibilities



Work with the Data Science team to bring machine learning models into production.
Build and run Big Data processing pipelines.
Write, deploy, and monitor services for data access by systems across our infrastructure.
Focus on performance, throughput, and latency throughout our architecture.
Write test automation, conduct code reviews, and take end-to-end ownership of deployments to production.

Qualifications

BS/BA in a technical field such as Computer Science or equivalent experience.
1-4 years of software development experience
Professional experience in at least one of Python, Java, Scala, or Ruby
Professional experience with at least one of Hadoop MapReduce and/or Spark data processing pipelines, analytics systems (e.g. OLAP, BI tools), or machine learning technologies.
Strong algorithms and data structures knowledge.

Nice to haves

Comfort with Unix/Linux and the command line.
Experience with CI/CD systems such as Jenkins, Travis, TeamCity, and CircleCI.
Experience with containerization and orchestration systems like Docker and Kubernetes.
Startup experience or experience at marketing or ad-tech data companies: RTB / real-time bidding. DSP / demand-side platform.


Foursquare is proud to foster an inclusive environment that is free from discrimination. We strongly believe in order to build the best products, we need a diversity of perspectives and backgrounds. This leads to a more delightful experience for our users and team members. We value listening to every voice and we encourage everyone to come be a part of building a company and products we love.

Foursquare is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by law.",la,de
8,FanDuel,"Arts, Entertainment & Recreation",4.1,Data Engineer - All Levels,"Los Angeles, CA",$97K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=8095&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a40aa498&cb=1618794426898&jobListingId=3666691324,"ABOUT FANDUEL GROUP

FanDuel Group is a world-class team of brands and products all built with one goal in mind — to give fans new and innovative ways to interact with their favorite games, sports, teams, and leagues. That's no easy task, which is why we're so dedicated to building a winning team. And make no mistake, we are here to win, but we believe in winning right. That means we'll never compromise when it comes to looking out for our teammates. From our many opportunities for professional development to our generous insurance and paid leave policies, we're committed to making sure our employees get as much out of FanDuel as we ask them to give.

FanDuel Group is based in New York, with offices in California, New Jersey, Florida, Oregon and Scotland. Our brands include:


FanDuel — A game-changing real-money fantasy sports app
FanDuel Sportsbook — America's #1 sports betting app
TVG — The best-in-class horse racing TV/media network and betting platform
FanDuel Racing — A horse racing app built for the average sports fan
FanDuel Casino & Betfair Casino — Fan-favorite online casino apps
FOXBet — A world-class betting platform and an affiliate of FanDuel Group
PokerStars — The premier online poker product and an affiliate of FanDuel Group

THE POSITION

Our roster has an opening with your name on it

Our competitive edge comes from making decisions based on accurate and timely data. As a Data Engineer, you will help us build scalable systems to provide access to that data across the company.

THE GAME PLAN

Everyone on our team has a part to play

Data is a key component of the business used by almost every facet of the company including product development, marketing, operations and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability. We operate a rigorous code review process, so you need to be able to continuously give and take feedback and act on it.

THE STATS

What we're looking for in our next teammate

We are looking for an experienced Data Engineer, ideally well versed in Python, with a deep understanding of large scale data handling and processing best practices in a cloud environment. You should be comfortable building complex yet performant SQL queries on large data sets. Our current stack is built on AWS with Spark and Hive on Amazon EMR for batch processing and Redshift for the data warehouse. Experience working with and tuning these for large scale workloads would be a plus.

As our data is always growing it is important that we have a cost effective data warehouse with data that is modelled to suit our users needs.

Looking ahead to the next phase of our data platform we are keen to do more more with real time data processing and working with our data scientists to create machine learning pipelines. We would love to hear how you have tackled these before.

What you get in return

Beyond working with such a great team?

An exciting environment with real growth
Contribute to exciting products used by a highly passionate user base
Personal learning and development opportunities
Flexible holiday allowance
401K plan with company match
Attractive health insurance premiums

There's more, but we don't want to go on and on.

FanDuel is an equal opportunities employer. Diversity and inclusion in FanDuel means that we respect and value everyone as individuals. We don't tolerate bias, judgment or harassment. Our focus is on developing employees so that they reach their full potential.",la,de
9,Intuit,Information Technology,4.5,"Staff Software Engineer, Big Data","Los Angeles, CA",$110K - $202K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_2dfc8570&cb=1618794426899&jobListingId=4037611697,"OverviewThe Intuit Data Engineering team is looking for a Senior Software Engineer, Big Data with a winning track record in Big Data and Distributed Systems. We’re using data in groundbreaking ways to uncover customer insights, personalize customer experiences through AI/ML, and provide a unified customer view across all Intuit products.Note: By applying to this position, your application is automatically submitted to the following locations: Mountain View, Los Angeles, San Diego and the following teams at Intuit.What you'll bringBS in Computer Science. MS Preferred.Strong CS fundamentals including data structures, algorithms and distributed systems.Strong database fundamentals including SQL, performance and schema design.8+ years of strong Object Oriented Programming (Java, Scala, or Python)8+ years of hands-on Software Engineering experience.8+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.Strong project leadership experience, including being a technical lead for multiple complex software development projects using agile methodologies.Experience in people management or interest in people management is a plus.Experience with Hadoop, Hive, HBase, Spark, Kafka, Storm, Druid, Cassandra, Columnar Databases and Graph Databases.2+ years working with Cloud Technologies.Experience with various offerings from AWS, including S3, EMR, Redshift, Data Pipeline, Athena and Kinesis is a plus.History of contributing to open source projects is a plus.5+ years DevOps experience including configuration, optimization, backup, high reliability, monitoring and systems version control.Track record working with data from multiple sources – willingness to dig-in and understand the data and to leverage creative thinking and problem-solving.Excellent interpersonal and communication skills, including business writing and presentations. Ability to communicate objectives, plans, status and results clearly, focusing on critical few key points. Demonstrated ability to work in a matrix environment, ability to influence at all levels, and build strong relationships.Knowledge of enacting service level agreements and the appropriate escalation and communication plans to maintain them.How you will leadDesign and develop big data and real-time analytics solutions using industry standard technologies.Develop web services that make big data available in real-time for in-product applications.Work with data architects to ensure that Big Data solutions are aligned with company-wide technology directions.Lead fast moving development teams using agile methodologies.Lead by example, demonstrating best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting, and incident response.Communicate progress across organizations and levels from individual contributor to senior executive. Identify and clarify the critical few issues that need action and drive appropriate decisions and actions. Communicate results clearly and in actionable form.Serve as technical “go to” person for our core technologies – Hadoop, Spark, AWS, Vertica, Tableau, Cassandra, Graph Databases and others.Demonstrate strong implementation aptitude to translate objectives into a scalable solution to meet the needs of the end customer while meeting deadlines.Demonstrate commitment to your professional development by attending conferences, taking classes, giving technical presentations, and participating in developer communities inside and outside of Intuit.",la,de
10,Glassdoor,Information Technology,3.8,Senior Data Engineer (Remote),"Los Angeles, CA",$122K - $152K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=132937&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_925d6a9e&cb=1618794426899&jobListingId=4037695799,"Senior Data Engineer

Looking for your next challenge? How about helping us disrupt a $90B+ talent acquisition market! Glassdoor is the world's fastest growing career community with more than 25M members and thousands of business customers and our mission is helping people everywhere find jobs and companies they love.

Our mission is to help people everywhere find a job and company they love. We're transforming an entire industry through the power of transparency. As the worldwide leader in employer branding and insights, our vision is for a world where transparency holds companies accountable to strive to become better employers.

Please note this role is open to remote hiring. Our main office locations are in San Francisco, CA, Chicago, IL and Uniontown, OH.

We are looking for a talented Senior Data Engineer to join our growing Data Engineering team. The ideal candidate has significant experience in building scalable data platforms that enable analytics, data science and data products. You must have strong, hands-on technical expertise in a variety of technologies and the proven ability to fashion robust, scalable solutions. You should have a passion for continuous quality improvement.

We embrace a wide variety of technologies and work very closely with data scientists and business stakeholders to deliver end to end solutions. Although this is an individual contributor role, we are a tightly knit team who widely collaborate with one another. If you are interested in a fast paced environment, the latest technologies, and fun data problems, come join us!

Responsibilities

Design and develop big data applications using a variety of different technologies.
Develop logical and physical data models for big data platforms.
Automate workflows using Apache Airflow.
Write data pipelines using Apache Hive, Apache Spark.
Create solutions on AWS using services such as Lambda, API Gateway, Kinesis etc.
Participate in rotational on-call support.
Provide ongoing maintenance and enhancements to existing systems.
Learn our business domain and technology infrastructure quickly.
Document, share your knowledge freely and proactively with others in the team.

Key Qualifications

5+ years of hands-on experience with developing data warehouse solutions and data products.
2+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive, Spark, Airflow, Kafka, etc.
2-3 years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.
2+ years of experience using Python as a programming language.
Experience with scripting languages: Perl, Shell, etc.
Practice working with, processing, and managing large data sets (multi TB/PB scale).
Exposure to test driven development and automated testing frameworks.
Background in Scrum/Agile development methodologies.
Capable of delivering on multiple competing priorities with little supervision.
Excellent verbal and written communication skills.
Bachelor's Degree in computer science or equivalent experience.

Nice To Have

Experience building customer facing products, machine learning pipelines or data products.
Experience working with Tableau, Looker or other data visualization software.
Familiarity with AWS or GCS technologies.
Ability to program in multiple programming/scripting languages: Python, Java, JS, Scala, etc
Be passionate about or have contributed to open sourced engineering projects in the past.

Why Glassdoor?

Work with purpose join us in creating transparency for job seekers everywhere
100% company paid medical/dental/vision/life coverage, with 80% dependent coverage
Long Term Incentive Plan
401(k) Plan with a Company Match to prepare for your future
Generous paid holidays and open paid time off

Our Commitments

A values-based culture: Our values are Transparency, Innovation, Good People and Grit. We look for talented, passionate people who embody these values in how they show up to work every day.
Pay transparency: We believe that with more salary transparency, you hold the information to ensure fair pay now and in the future as your career changes and grows. Pay bands and our compensation philosophy are shared publicly to ensure that everyone is paid fairly. Our annual Pay Gap Study found no gender or race/ethnicity pay gap at Glassdoor.
Diversity & Inclusion transparency: We are committed to building a company that is more diverse and representative of society at large. Glassdoor externally publishes our Diversity & Inclusion report and information about our employee population to hold ourselves accountable to our commitment. We also provide programs and resources to create a greater sense of belonging for our employees.
Employee feedback transparency: We believe in providing you with greater insight into what it is really like to work with us. In addition to our Glassdoor Reviews, we publicly publish our employee feedback survey responses to ensure everyone has a complete picture of what it's like to work here.
Company performance transparency: We believe you should know how your work contributes to moving the company forward. That's why we share detailed business performance updates in our monthly All Hands and deeper financial results every quarter. For more insight into the performance of our parent company, you can explore the financial results of Recruit Holdings, and its HR Technology segment in particular, each quarter. Operating transparently at Glassdoor is fundamental as we advocate for transparency in the broader workforce. The ultimate goal is not just to change how we operate at Glassdoor, but for every employer to follow our lead!

Glassdoor is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to race, color, religion, national origin, ethnicity, age, sex, marital status, physical or mental disability, gender identity, sexual orientation, veteran or military status, or any other category protected under the law. Glassdoor is an equal opportunity employer; committed to creating a community of inclusion, and an environment free from discrimination, harassment, and retaliation.",la,de
11,Perspecta,Aerospace & Defense,3.6,Magnetics Components Engineer,"Pasadena, CA",$66K - $104K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_c8faf84e&cb=1618794426899&jobListingId=4006748573,"Business Group HighlightsCivilian, State and LocalPerspecta’s Civilian, State and Local segment partners with the U.S. Federal Civilian State and Local governments to provide infrastructure services, business solutions, and digital transformation services that help them achieve policy objectives and integrate citizen-centric services.ResponsibilitiesPerspecta has an immediate need for a Magnetics Components Engineer in Pasadena, CA. This position can be worked remotely.The magnetic components engineer will be a member of JPL's Electronic Parts Reliability Engineering Group, responsible for reviewing all Electrical, Electronic and Electromechanical Parts (EEE) parts for reliability related performance and advises the projects on part selection, conducts scientific experiments or theoretical analysis to determine the physical behavior of parts in a space-like radiation environment.Oversees part procurement to ensure compliance with engineering requirements and maintains part inventories. Deep understanding and substantial use of common computer tools. Excellent written and oral communication skills.QualificationsA Bachelor’s degree in Electrical Engineering, Physics, Materials Science/ Engineering, Applied Mathematics or related technical discipline with a minimum of 12 to 15 years of related experience or a Master’s degree in similar disciplines with 10 to 13 years of related experience; or a PhD in similar disciplines with a minimum of 10+ years related experience.As a Magnetics Component Engineer, you will:Evaluate, select and approve magnetics components from design, construction, quality and reliability perspectives for use in space missions.Advise project management on highly complex electronic part selections that maximize reliability while considering schedule and cost constraints.Develop part engineering specifications and drawings.Interface with Mission Assurance Managers, Cognizant Engineers, and part manufacturers.Work with manufacturers on new component development and lead resolution of technical issues in order to support project flight build.Support technical surveys and audits of magnetics part suppliers.Perform statistical data analysis and risk assessments.Disposition test and inspection failures, including those during screening, destructive physical analysis (DPA), lot qualification and receiving inspection.Develop screening methods that effectively reduce risk in space and during manufacturing of magnetics components.Understand potential failure mechanisms affecting magnetics components and participate in failure investigations and reliability assessments.Utilize the Part Acquisition and Review System (PARS) to review project parts lists and assess part compliance to project requirements.Serve as an essential team member within the Group, ensuring part reviews, screening and testing, and procurement meet project schedule.Additional Requirements:Extensive understanding and experience in the selection, procurement, manufacture, use and testing/screening of high reliability magnetics components for space-flight applications.Strong working knowledge of magnetic properties, wire and core technology, and assembly and encapsulation engineering.Knowledge of MIL-STD-981, MIL-STD-1580, MIL-PRF-27and relevant JEDEC specifications and requirements related to magnetics components.Ability to multi-task with an established track record of meeting schedule milestones.Ability to work well with cross-functional teams with design engineers, line management, and project management.Preferred Qualifications:Relevant experience in magnetics technology including high voltage magnetics manufacturing or design.Knowledge of NASA parts requirements including EEE-INST-002Contract Technical Management experience.Demonstrated leadership skills.Colorado Salary Minimum: $102,315.20 Colorado Salary Maximum:$218,712.00 The estimate displayed represents the typical salary range for this position, and is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees.About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",la,de
12,Jobot,Business Services,4.8,Data Engineer,"Los Angeles, CA",$105K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=798489&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_86841184&cb=1618794426899&jobListingId=4059798767,"We are the first platform to merge AI/ML, Big Data and VR/AR to help companies visualize and understand their data and are looking to grow our team!!This Jobot Job is hosted by: Jason SiegelAre you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.Salary: $150,000 - $180,000 per yearA bit about us:We are the first platform to merge AI/ML, Big Data, and VR/AR to help companies visualize and understand their data. We are a small but rapidly growing team and just raised a big round of funding last week. Our team has published hundreds of papers in AI and data visualization and we have an advanced, patented technology. Our goal is to shape a better world by allowing for smarter data-driven decisions through AI.Why join us? Competitive Salary  Equity Bonus Unlimited PTO Flexible Work Schedule Full Benefits including Medical, Dental Vision 401K The chance to work with a very smart and collaborative teamJob DetailsYou will: Build innovative data analytics and ML pipelines  Develop our products for predictive maintenance (PMX) and digital signals processing (DSP) Meet with domain experts and present to stakeholdersWe would love to speak with you if you have any combination of the following: Degree in Computer Science/EE/Applied Math/Statistics/Bioinformatics Experience integrating applications with Spark, Dask, or Kafka 1-4 years of writing production ready code in Python Experience with AWS or other cloud computing frameworks Experience with SQL/NoSQL or other database system Experience with Git or similar tool Authorized to work in the US without sponsorship and be able to obtain a security clearanceBig Plus if: Experience with Docker, KubernetesExperience with Celery, Flask, Django Experience developing ML models and other data science techniquesInterested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",la,de
13,Square,Information Technology,4.3,Data Engineer,"Los Angeles, CA",$136K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=4134&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_f6824a68&cb=1618794426899&jobListingId=4060075969,"Company Description

Square builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We’re working to find new and better ways to help businesses succeed on their own terms—and we’re looking for people like you to help shape tomorrow at Square.

Job DescriptionAs a Business Intelligence Data Engineer, you will be responsible for defining, developing and managing curated datasets, key business metrics and reporting across functional units at Square. You will architect, implement and manage data models and ETLs that will enable product and business teams access consistent metrics across Square ecosystem. You are a self-starter and you are comfortable working cross-functionally with other teams across Square.

You will:

Partner with business stakeholders, upstream infrastructure platform engineering teams and downstream data consumers to understand data and translate business requirements into technical design of building scalable data pipelines. Develop and take ownership of BI data pipelines and centralized data warehouse with trustworthy curated datasets and standardized metrics and business definitions to empower data access and self-servicePerform data analysis and troubleshoot technical issues with platforms, performance, data discrepancies, production issues


QualificationsYou have:

5+ years of data engineer experience in a successful data engineering or business intelligence team with expert knowledge of data warehouse architecture and hands on experience of data modeling design, ETL pipeline implementation using SQL and Python, and building reports with Looker or similar BI visualization tools.Hands on experience on cloud-based computing services and data warehouses like Snowflake, Redshift, Azure, or similarExcellent communication skills with strong business intuition and ability to understand complex business systems; versatility and willingness to learn new technologies on the job.

Additional Information

At Square, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.

Perks

At Square, we want you to be well and thrive. Our global benefits package includes:


Healthcare coverageRetirement PlansEmployee Stock Purchase ProgramWellness perksPaid parental leavePaid time offLearning and Development resources
",la,de
14,Thermo Fisher Scientific,Biotech & Pharmaceuticals,3.8,Data Engineer II,"Los Angeles, CA",$55K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=133879&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_46725a6c&cb=1618794426899&jobListingId=4002201231,"In this role, you will be a key member of the Data Engineering Team within the Pharma Services Group (PSG) Technical Operations team. This Data Engineering Team owns connectivity and data modeling of shop floor, laboratory, and business systems such as ERPs, Laboratory Information Systems (LIMS), Manufacturing Execution Systems (MES), and data historians in support of advanced process modeling, visualization, and client data sharing initiatives across the entire PSG manufacturing network. The Data Engineering team is also responsible for the development of process configurations within the Discoverant Software system. Discoverant is a global network application enabling Continued Process Verification (CPV), investigation analysis, continuous improvement, operational dash-boarding, process monitoring, and other operational functions.What will you do?Collaborate with technical staff on the Discoverant implementation roll-out at PSG’s global manufacturing sites as well as projects focused on advanced process modeling and visualizations.Work with global manufacturing sites to define data needs of the organization.Understand and use knowledge of systems and technologies in the manufacturing network that are directly and indirectly related to Discoverant to ensure the global Discoverant implementation is effective in its function and is leveraged for best impact.Work with global and local teams to develop best practices and make recommendations for best impact.Will likely include recommendations and initiatives for additional third-party work, connectivity to other manufacturing, lab, and business systems, and establishing relevant tools, guidelines, and systems when needed.Work closely with other global functions and sites on initiatives or efforts related to data modeling and Discoverant hierarchy development (ex: Global Process Validation, Automation, Quality, Continuous Process Verification leaders, Operational Excellence, others).How will you get there?EducationBachelor’s degree in Computer Science, Engineering, Chemistry, Statistics or similar field requiredExperience1 -3 years of data engineering experience is required.Experience in SQL, Oracle, Object-Oriented coding, or HTML development.Working knowledge of basic statistics including control charts, process capability, and statistical process control.Understanding of the software development life cycle and GAMP 5 software validation practices.Basic understanding of pharmaceutical processing. The PSG network manufactures compressed tablets, capsules, soft gels, steriles, biologics, API, and viral vectors.High energy with strong self-motivation. Must be able to work independently with guidance from leadership and mentorship from senior team members.Good organization is required as this roll will be contributing to complex projects with many deliverables across multiple manufacturing sites.Strong communication skills. This role will be required to communicate across several roles and manufacturing sites across the network.A strong problem solver with solid analysis skills.Ability to travel up to 25% annually.",la,de
15,Amgen,Biotech & Pharmaceuticals,4,Specialist Data Engineer – Data Quality,"Los Angeles, CA",$98K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=133096&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_73140995&cb=1618794426900&jobListingId=4037605974,"Career CategoryInformation SystemsJob DescriptionDescription:In this role, you will be part of a high performing team formed by Data Management experts responsible for improving and maintaining the quality and integrity of the data captured in core business systems (e.g. Salesforce.com, SAP, etc.), purchased data (e.g. IQVIA) and the connected data stored in the Enterprise Data Fabric (EDF). You will play a vital role in establishing and maintaining a set of processes and controls aimed at proactively identifying data quality and integrity issues to be surfaced and addressed on an ongoing basis.You will define and maintain data related KPIs that will be shared in the Data Governance forums, where data anomalies and remediation plans are discussed and tracked.Responsibilities· Collaborate with functional Data Management, Data & Analytics and Enterprise Data Fabric teams to facilitate the adoption of Enterprise Data Quality frameworks· Support business data owners and data custodians in utilizing the enterprise Data Quality tool to certify the quality of the data captured in their internal systems based on Amgen’s data quality dimensions: Accuracy, Completeness, Conformity, Validity, Integrity, Consistency and Uniqueness.· Align with Data Stewards to determine data quality scope· Assist Data Stewards with data problem resolution when requested· Identify areas for data quality improvements and help to resolve data quality problems through the appropriate choice of error detection and correction, process control and improvement, or process design strategies.· Define and maintain Data Quality rules to proactively identify and monitor data quality issues in the Consolidation and Semantic layer of the EDF.· Define data quality KPIs in partnership with internal data providers Business Owners and EDF Data Domain Owners.· Support root-cause analysis for data quality issues and collaborate with Business Data Stewards to identify corrective actions· Lead or execute data remediation and impact assessment efforts· Assess and facilitate impact analysis of data providers system changes· Perform data profiling activities on key systems to identify Data Quality issuesBasic QualificationsDoctorate degreeORMaster’s degree and 3 years of Information Systems experienceORBachelor’s degree and 5 years of Information Systems experienceORAssociate degree and 10 years of Information Systems experienceORHigh school diploma / GED and 12 years of Information Systems experiencePreferred Qualifications:· Ability to profile against data standards· Advanced knowledge in Amgen-selected Data Quality tools (e.g. Enterprise Data Lake and Informatica IDQ)· Ability to document Data Quality Business Rules for data elements· Proficient in Data Governance tool integration with Data Quality packages and tools· Ability to create Data Quality dashboards and report results to Business Data Stewards and Data Owners· Strong understanding of relevant data standards and industry trends· Knowledge of relevant external regulations that impact master data and data management processes· Ability to understand new business requirements and prioritize them for delivery· Proficient in one of the coding languages (Python, Java, Scala)· Hands on experience writing SQL using any RDBMS (Redshift, Postgres, MySQL, Teradata, Oracle, etc.).· Experience with Schema Design & Dimensional data modeling.· Experience with AWS Services like EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway.· Experience with software DevOps CI/CD tools, such Git, Jenkins, Linux, and Shell Script· Experience with Spark, Hive, Kafka, Kinesis, Spark Streaming, and Airflow.· Hands on experience using Databricks/Jupyter or similar notebook environment.· Experience working in an agile environment (i.e. user stories, iterative development, etc.)· Experience working with test-driven development and software test automation· Experience working in a Product environmentAmgen is committed to unlocking the potential of biology for patients suffering from serious illnesses bydiscovering, developing, manufacturing and delivering innovative human therapeutics. Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people’s lives. A biotechnology pioneer since1980, Amgen has grown to be one of the world’s leading independent biotechnology companies, hasreached millions of patients around the world and is developing a pipeline of medicines with breakawaypotential.This position is open to remote workers within United States..",la,de
16,Oxford Global Resources,Business Services,3.6,Data Migration Engineer,"Cypress, CA",$43K - $85K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044076&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4ba0247a&cb=1618794426900&jobListingId=4062855512,"JOB SUMMARYThe Software Engineer II – Data Migrations will be an integral member of the Technical Solutions (RTS) Data Integration team and will beexpected to develop scalable technical solutions to be utilized in the data migration effort for ERP implementations. The Software Engineer II will collect and curate data fromdisparate sources, utilize data integration tool suite to perform data interrogation, Cleansing, prepare & optimize data to be loaded into ERP systems. The Software Engineer II will communicate with stakeholders and conduct research to develop a comprehensive understanding of relevant business needs and requirements.ESSENTIAL FUNCTIONSTechnical Design- Able to identify, analyze, specify, design, and translate functional design to technical design. Create and document technical designs for medium to high complexity solutions that may include integration with external systems.· Create and document technical designs for low to high complexity solutions that may include integrations with external systems· Participate in peer technical design review· Design systems that span multiple technologies/platforms· Create and apply design standards across all applications· Design solutions to meet performance requirements and scalability expectations· Design complex systems utilizing multiple technologies (may have a special area of expertise), including integrations with external systems.· Ensure the application operates according to functional and technical specificationsRequirements Elicitation – Ability to identify a desired future state that addresses a business problem.· Effectively uses interviewing skills to elicit, identify, and document business requirements· Precisely and consistently captures business problems· Prioritize requirements to identify the most critical needs· Uncover needs and value drivers that business partners and end users would not be able to articulate on their own· Articulate and incorporate extensive business knowledge into requirements· Obtain agreement and confirm understanding by clearly interpreting business requirements to business stakeholder· Drive consensus for a desired future state that meets the business problem and enterprise objectives· Influence stakeholders by clearly interpreting the future ""to be"" stateApplication Development - Able to write, test, debug, and maintain applications for end-user adoption, productivity improvement and efficiency.· Research, analyze, and produce high quality source code for low to high complexity solutions· Modify and enhance low to high complexity programs· Enable integration with third party applications using Microsoft Dynamics AX tools· Troubleshoot and resolve technical issues· Develop knowledge of the company's applications· Collaborate with cross functional teams to identify and solve software defects· Anticipate risks and implement contingency plans to resolve issues impacting applications· Proactively enhances systems for stability, efficiency, scalability and robustnessUnit Testing and Validation - Ensures developed code meets the technical and functional specifications.· Participate in the installation and configuration of development/test/production Dynamics AX 2012 environments as required· Provide assistance in ERP upgrades as required· Develop and document effective unit test cases to test solution and validate results are as expected· Ensure the application operates according to functional and technical specifications· Troubleshooting and resolve software bugs, data, and system configuration issuesProvide Accurate Project Effort Estimates - Ability to quantify and meet individual and project phase level efforts.· Manage ambiguity, meet and create accurate project effort estimates for their assigned tasks· Understand, consider and communicate interdependencies for project estimates· Adhere to RTS project methodology throughout project lifecycle· Accurately identifies project-specific risks through the software development lifecycleAdherence to Standards - Ability to create solutions that adhere to and incorporate RTS standards.· Apply and use information and technology standards in solution design· Adhere to project management methodology· Identify opportunities for creating reusable enterprise services· Obtain key inputs from Enterprise Architecture to ensure compliance and exception management· Identify commonalities and suggest a consistent approach across projects· Analyze, recognize, and recommend data handling standards and data governance policiesSUPPLEMENTAL DUTIES & RESPONSIBILITIES· Pursues training and development opportunities; Strives to continuously build knowledge and skills· Assist personnel in other RTS departments to resolve technical and/or application issues· Other duties as requested· Occasionally may require an adjusted work schedule - evening/weekend hours in order to meet project deadlines or to access the computer system to support 2nd/3rd shift usersREQUIRED & PREFERRED QUALIFICATIONS· Bachelor’s Degree in Computer Science, Information Science or equivalent work experience in a related field required.· 3+ years’ of relevant experience in Data Migration, Data Quality domain, and the use of data analysis techniques and Integration tools in designing solutions required.· Any ERP or Microsoft Dynamics AX/D365 F & O Data import export tool experience preferred.· Experience work with tools such as Atlas, D365 AOT Table access preferred· Experience with relational SQL databases required.· Working knowledge of programming methodologies, structures, and concepts .Net framework, UML, XML.· Must be self-motivated and able to work independently, with minimal supervision and as part of a team· Detail oriented with excellent interpersonal communication skills (verbal and written), with the ability to interact with all levels of an organization· Excellent customer service skills· Advanced experience in data wrangling, blending, cleansing, and standardization required· Experience implementing and executing data migration, integration, and quality development using Integration tools preferred.· Strong project management and organizational skills. Experience using a version control system is a plus.· Proven track record of delivering analytic solutions to solve complex problems using a data-driven approach and technical innovation.CORE COMPETENCIESProblem Solving - Ability to problem solve through problem identification (what is the problem), solution assessment (what can be done), problem documentation (document for future) and problem response (implementing a solution).Able to:Frame problems before trying to solve themBreak down highly complexity problems and identify all of their componentsProvide insight into the root-causes of problemsSeek advice from those who have solved similar problemsAnticipate problems and is proactive in addressing themFollow up to ensure that the problem has been resolvedAsk perceptive questions to seek optimal solutionsExplore various sources for answers, and think ""outside the box"" to find optionsBe open to others' ideas to help develop solutionsGenerate a range of solutions and courses of action with benefits, costs, and risks associated with eachEvaluate the chosen course of action to determine its worth and impactsInvolves the team in problem solvingProvide innovative and creative solutionsConsider proposed solutions against the reality of likely effects before going forward; looks beyond the obvious and does not stop at the first answerDecision making - Makes sound, well-informed, and objective decisions; perceives the impact and implications of decisions; commits to action, even in uncertain situations, to accomplish organizational goals.Able to:Gather data and others' input when making decisionsEscalate decisions when appropriateWeigh pros and cons of each option before making a decision and moving forwardBalance analysis, insight, experience, and perspective when making decisionsExplain the rationale for a decisionFind solutions that are acceptable to diverse groups with conflicting interests and needsMake decisions in difficult situations in a timely manner even when information is limited or unclearFollow up to ensure decision was implementedConsider lessons learned from experience, differing needs, and the impact of the decision on othersLead when it is necessary to facilitate change, overcome an impasse, face issues or ensure that decisions are made.Customer Service - Ability to develop and maintain strong relationships with others by listening, understanding and responding to their needs.Able to:Provide service to internal and external customers to satisfy their needs and expectationsListen to concerns and resolve reported issues effectively and promptlyEnsure and comply to customer response timeline (SLAs) based on the severity of reported issues including documenting concise and accurate status information in the ServiceNow ticketing systemDeliver high quality products and servicesCommit to continuous improvementDevelop to meet functional design/requirementsAnticipate others’ needs and move to effectively address issuesEstablish proactive relationship with others and provide education to clients as appropriateElicit feedback from othersDeliver high quality solutions that meet the organization’s needsCreate strategies to help the organization serve others more effectivelyConsider both short and long-term interests of the customer in making service decisionsCompany Business Knowledge - Understands the company, its products and the business processes.Able to:Apply broad (two or more areas) Reliance business knowledge to technology solutionsHelp guide and influence business decisions on technology solutionsAccountability - Holds self-accountable for measurable high-quality, timely, and cost-effective results.Able to:Proactively collaborate between own functional area and areas below or above in the project stream as neededSet well-defined and realistic personal goalsComply with established policies and proceduresAccept responsibility for mistakesDisplay a high level of initiative, effort, and commitment towards completing assignmentsMinimize re-workSeek out learning opportunitiesIdentify training needs and take action to obtain knowledgeAnticipate and adjust for problems and roadblocksBe enthusiastic for the things he/she sees as challengingBe proactive throughout work assignments /projectsPersistently push self and others for resultsHelp others learnMake good decisions on behalf of the company (profitability, compliance)Provide consistency between projectsMitigate issues within work scope to keep the workflow moving smoothly to a conclusionConsistently seize opportunitiesRecommend work allocationsLimit risk and exposureManage costCommunication - Communicates effectively across all levels to support departmental and organizational objectives.Able to:Establish rapport with co-workers easilyClearly express information taking into account audience and nature of the information (for example, non-technical, sensitive, and controversial)Ask questions and summarize what was heard to prevent miscommunicationPresent information in a concise and focused mannerListen to othersCommunicate written information (for example, facts, ideas, or messages) in a succinct and organized mannerProduce written information, which may include technical material that is appropriate for the intended audienceShare ideas and perspectives and encourage others to do the sameInform others involved in a project of new developmentsEnsure written messages have the desired effect on the target audienceEffectively uses multiple channels to communicate important messagesBuilding Collaborative Relationships - Develops, maintains, and strengthens partnerships with others inside and/or outside the organization.Able to:Establish rapport with co-workers easilyEncourage and facilitate cooperation, pride, trust and group identityFoster commitment and team spiritWork with others to achieve goalsListen and respond constructively to other team members' ideasOffer support for others' ideas and proposalsBe open with other team members about his/her concernsShare his/her expertise with othersSeek to resolve confrontations and disagreements constructivelyAcknowledge team members for their contributionsProvide assistance to others when they need itWork for solutions that all team members can supportEffectively collaborate with geographically distributed teamsFacilitate cooperation and motivate team members to accomplish group goalsRecognize the business concerns and perspectives of othersFocus on the situation, issues, or behaviors, rather than the peopleLeadership – Displays effort and commitment in carrying out the department’s goals and objectives.Able to:Act in a proactive and achievement-oriented mannerTreat co-workers in a fair and equitable mannerEmpower others by sharing informationActively listen and clarify information as neededFoster an atmosphere of open communicationBehave in a tactful, compassionate, and sensitive mannerConsider and respond appropriately to the needs, feelings, and capabilities of different people in different situationsRecognize the differences in people and what motivates themJob Types: Full-time, ContractPay: $85,000.00 - $111,000.00 per yearBenefits:401(k)Dental insuranceHealth insurancePaid time offVision insuranceSchedule:8 hour shiftEducation:Bachelor's (Preferred)Full Time Opportunity:YesWork Location:One locationWork Remotely:NoCOVID-19 Precaution(s):Remote interview process",la,de
17,Mattel,Manufacturing,3.9,Data Engineer,"El Segundo, CA",$74K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=4134&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_8d4e2e6a&cb=1618794426900&jobListingId=4062446036,"Company DescriptionCREATIVITY IS OUR SUPERPOWER. It’s our heritage and it’s also our future. Because we don’t just make toys. We create innovative products and experiences that inspire, entertain and develop children through play. Mattel is at its best when every member of our team feels respected, included, and heard—when everyone can show up as themselves and do their best work every day. We value and share an infinite range of ideas and voices that evolve and broaden our perspectives with a reach that extends into all our brands, partners, and suppliers.Job DescriptionThe Opportunity:

We are looking for a Data Engineer to join our growing team of analytics experts. As a data engineer, you are responsible for designing and implementing our data pipeline architecture and optimizing data flow and collection for cross-functional groups, considering scalability in mind. Data engineering is about building the underlying infrastructure, and so being able to pass the limelight to someone else is imperative. We want to see from you with mechanical tendencies and a desire to know how things work and to improve them. Furthermore, being able to listen to your colleagues is essential. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. You might be the right fit if you are excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.

What Your Impact Will Be:

Create and maintain optimal data pipeline architecture.Assemble large, complex data sets that meet functional / non-functional business requirementsIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from various data sources using SQL and Cloud technologies in GCP. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members to build and optimize our product into an innovative industry leader.Work with data and analytics experts to strive for greater functionality in our data systems.


QualificationsWhat We’re Looking For:

You should be familiar with Git, trunk-based development, GitHub/GitLab workflow, scrum, and agile development.Advanced working SQL knowledge and experience working with relational databases and working familiarity with a variety of databases.Strong analytic skills related to working with unstructured datasets.Experience building a serverless data warehouse in GCP or AWSExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify improvement opportunities.Build processes supporting data transformation, data structures, metadata, dependency, and workload management in large-scale environmentsWorking knowledge of message queuing, stream processing, and highly scalable big data data-stores.Strong project management and organizational skills.Experience supporting and working with cross-functional teams in a dynamic environment.6+ years of experience in a Data Engineer role, who has attained a Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field. Master’s degree preferred.Experience with big data tools: Hadoop, Spark, Kafka.Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.Experience with data pipeline and workflow management tools: Luigi, Airflow.Experience with GCP cloud services: BigQuery, Dataproc, CloudSQL, PubSub, GKE, Cloud ComposerExperience with stream-processing systems: Apache Flink, Apache Beam, Spark-Streaming.Experience with object-oriented/object function scripting languages: Python, Java, ScalaWorking knowledge of Terraform and Ansible is a plus.Experience with Kubernetes is a plus.Experience with MLFlow, Kubeflow, and DVC is a plus.Experience with Tensorflow, Keras, Sklearn is a plus.Experience with GitLab CI/CD pipeline is a plus


Additional InformationWhat It’s Like to Work Here:

We are a purpose driven company aiming to empower the next generation to explore the wonder of childhood and reach their full potential. We live up to our purpose employing the following behaviors:

We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower.We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization, you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking.We execute: We are a performance driven company. We strive for excellence and are focused on pursuing best in class outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results.

Who We Are:

Mattel is a leading global toy company and owner of one of the strongest catalogs of children’s and family entertainment franchises in the world. We create innovative products and experiences that inspire, entertain and develop children through play. We engage consumers through our portfolio of iconic brands, including Barbie, Hot Wheels, Fisher-Price, American Girl, Thomas & Friends, UNO and MEGA, as well as other popular intellectual properties that we own or license in partnership with global entertainment companies. Our offerings include film and television content, gaming, music and live events. We operate in 35 locations and our products are available in more than 150 countries in collaboration with the world’s leading retail and ecommerce companies. Since its founding in 1945, Mattel is proud to be a trusted partner in empowering children to explore the wonder of childhood and reach their full potential.

Visit us at https://jobs.mattel.com/ and www.instagram.com/MattelCareers.

Mattel is an Affirmative Action/Equal Opportunity Employer where we want you to bring your authentic self to work every day. We welcome all job seekers including minorities, females, veterans, individuals with disabilities, and those of all sexual orientations and gender identities.",la,de
18,J.S. Held,Business Services,4.1,Mechanical Engineer,"Los Angeles, CA",$74K - $180K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1044074&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_8750b62e&cb=1618794426900&jobListingId=4033886654,"J.S. Held is a global professional services/consulting firm specializing in construction, forensic architecture & engineering, environmental, health & safety services, equipment, water and fire restoration, and forensic accounting services.Mechanical Engineer Job Description:We are seeking Mechanical Engineers (PEs) to enhance our team of professionals in supporting our clients throughout the United States and adjacent territories. Our engineers routinely:Perform MEP & industrial system & equipment damage forensic cause & origin analysisAnalyze construction defect claimsPrepare technical reports of our findingsConduct property loss assessmentsDevelop repair scopesAnalyze applicable codes & standardsServe as expert witnessesOur areas of practice include residential, commercial and industrial building systems; analysis of the cause of damage, assessment of loss event and resulting damage; design and construction defect evaluation. Travel required in support of assignments. Active involvement in professional associations and societies is encouraged and supported.Job Responsibilities:Conduct field inspections and loss analysis, testing, and data collectionPrepare technical reports detailing cause of damage / failure, damage observed, and test resultsPerform desk reviews and field assessments of property loss to develop repair scopeWork with insured and contractors to reach agreement on scope of repairsReview and analyze building codes and industry standards, working with code officials as needed, to identify system requirementsPresent analysis and assessment findings to colleagues and clientsConduct research and develop technical topics for publicationManage multiple project assignments and execute them on time and within budget.Support in retention and development of client relationships.Attributes & Background:Bachelor’s degree in Mechanical Engineering (from an ABET accredited school required)PE license (required)15 or more years of mechanical equipment / system design or production / construction experienceForensic, failure analysis, or troubleshooting experience (required)Analytical and problem-solving skillsStrong verbal, writing, and interpersonal skillsComputer skills (including Word, Excel and PowerPoint)Ambitious, self-motivated, hands-on, and team orientedA desire to learn, excel and grow with us and within the professionAble to travel to sites when necessaryJ.S. Held is dedicated to becoming the global leader in providing multi-disciplinary consulting services to the insurance, construction, and legal communities. We specialize in forensic engineering, property damage consulting, construction claims consulting, program & project management and dispute resolution services. J.S. Held is committed to recruiting and cultivating top industry talent to build a collaborative and diverse team of experts. We leverage this experience to provide local and cost-efficient solutions and an unrivaled client experience.Some of the Benefits We Have IncludeJ.S. Held not only cares about being the best in our industry, we care about our team. We’re a business that understands life can be fluid and so we flex to ensure we provide the environment to suit that.Our flexible work environment allows you to work remotely when neededGenerous PTO policyMedical, Dental, and Vision Insurance401k MatchCommuter BenefitsEEO StatementJ.S. Held LLC provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, J.S. Held LLC complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.J.S. Held LLC expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of J.S. Held LLC employees to perform their job duties may result in discipline up to and including discharge.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.Please explore what we’re all about at www.jsheld.com. We are proud to be an EEO/AA employer.#LI-JB1#HP-123",la,de
19,Terray Therapeutics,N/A,-1,Data Engineer,"Pasadena, CA",$100K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_b080399a&cb=1618794426900&jobListingId=3753103078,"Company Overview: Terray Therapeutics is a venture-backed biotechnology company that is pioneering an automated, closed-loop, low latency, wet lab discovery platform and powerful AI capabilities to accelerate the discovery and development of small molecule therapeutics. Our internal development programs are focused on oncology and immunology. In addition to these programs we also work with leading pharmaceutical companies. Our platform is based on fluorescent imaging of ultra-dense microarrays such that, via thousands to millions of images, we can measure billions of target/molecule interactions in a day, generating hundreds of millions of dose-response binding curves.Position Summary: Terray Therapeutics is seeking a motivated, creative, and experienced Data Engineer. As an integral member of our data team, the candidate will be responsible for building a reliable, distributed data pipeline to handle millions of raw fluorescence microscopy images and their extracted features, allowing our machine learning engineers and data scientists to fully leverage our data to accelerate internal drug discovery efforts. The position will report to the Head of Computational and Data Sciences.The core responsibilities of this job will be:Manage and improve our data lake of millions of fluorescence microscopy imagesWork with our data scientists to incorporate our image processing workflow into the data pipelineBuild and manage our databases of billions to trillions of chemical structures, intensities, affinities, and data from other biological assaysDesign and architect a data warehouse to support downstream analyticsExperience and Qualifications: Given the company’s size, anticipated growth and fast-paced environment, the organization requires a data engineer who is thoughtful, high energy and can partner with the broader organization to further enhance our next generation drug discovery capabilities.Part of Terray Therapeutics’ success is nurtured by a hands-on work environment where everyone is accountable, everyone is vested in a vision of excellence, and everyone actively takes part in the success of the business. Terray Therapeutics supports a positive work environment comprised of engaged employees who feel appreciated, recognized and free to be creative.Qualifications include:Expert in engineering big data pipelines using modern technologies and cloud infrastructuresExpert in building and managing scalable relational databases, preferably in the life sciences spaceExperience with cloud computing services, preferably AWS (EMR, Redshift)Experience with high-end distributed data processing environments (Spark, Hadoop, etc.)Proficiency in Linux environment, experience with database languages (e.g., SQL) and experience with version control practices and tools (Git)Experience with pipeline/workflow managers (Luigi, Airflow, Nextflow, etc.)Highly proficient in Python and the PyData stack (numpy, pandas, scipy, dask, etc.)She/he will exhibit the ability to work well under pressure to provide results in a short timeframe. The company is looking for a highly responsive, goal-oriented individual who will bring significant energy and drive to solve complex technical problems and help us achieve our mission to advance human health.",la,de
20,Evolvinc,Information Technology,4.7,Senior Data Engineer,"Burbank, CA",$119K - $139K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=4341&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_bd95b352&cb=1618794426900&jobListingId=3231031059,"Our entertainment company is seeking a Senior Data Engineer to join our team! This is a Contract/Contract-to-Hire role that will work with other multi-disciplined engineers on developing net generation video consumption platforms.

We utilize and develop cutting-edge technology to deliver high-end and creative content on a global scale. We work across multiple platforms to transform how we see media. The ideal candidate will be up to date on the latest trends in the data community and possess a passion for coding. The Senior Data Engineer will be involved in system design and web-tailored solutions to create optimal design patterns.

Please, only apply if you are able to work directly for a U.S. company for the next three years. We are not currently able to work with C2C, H1, or OPT for this position.

Duties & Responsibilities:

Build and optimize performance of Hadoop and Spark batch jobs (Spark, Kafka, Cassandra, etc.).
Construct and improve ElasticSearch performance.
Build data pipelines orchestration.
Create the design and architecture for data-lake, data-marts, data-models, and data-warehouse.
Ensure efficiency of data science workflows and advanced machine learning algorithms.
Contribute to open source solutions and communities.
Stay current on emerging tools and technologies.
Collaborate cross-functionally with other software engineers and their teams.
Establish and demonstrate technologies, solutions, and leading practices.
Balance resources, requirements, and complexity.

Qualifications:

5+ years of experience.
Bachelors degree in Computer Science or similar field.
Possess a passion for coding. (Github profile? Thats awesome! -or- We will ask you to code before or during the interview.)
Strong knowledge of distributed systems and distributed computation.
Strong knowledge of Scala, Java, Python, or Go-Lang.
Demonstrated knowledge of Apache Hadoop / Spark ecosystem (Spark, Hive, Presto, Oozie, Pig, Hue, Zeppelin).
Demonstrated knowledge of data modeling.
Excellent communication and collaboration skills.
Experience with Unit, Integration, and Load testing, developing REST APIs, Git, Ant, Maven, SBT, and/or Gradle, Unix/Linux, and Docker containers building and deployment.

Experience with the following preferred:

GraphQL, Kubernetes, Apache Spark MLlib, Apache Spark GraphX, R, Amazon AWS or other cloud Services, Jenkins.

Powered by JazzHR",la,de
21,Splunk,Information Technology,4.1,"Data Engineer, DevOps - Remote OK","Los Angeles, CA",$114K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=4128&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_919be49e&cb=1618794426900&jobListingId=4063567589,"As a Data DevOps Engineer in the Enterprise DataWarehouse team you will work closely with a team of Data, Business Intelligence and Dev/Prod Ops engineers to help automate CI/CD deployment in a consistent and reliable way to non-production and production data infrastructure, at scale. As part this team, you will build CI/CD automation across GitLab/Github/Bitbucket, Airflow, Python ETL/ELT, Database scripts, containerization (Docker) and container-orchestration systems such as Kubernetes. You will work towards supporting deployment, data flow architecture and automation to deliver the highly available, performant and secure environments of Splunk’s Enterprise Data Warehouse.

Responsibilities

Iterate on release management methodologies to increase the quality & velocity of data warehouse deployments. Deploy and maintain CI/CD pipelines across multiple environmentsYou will collaborate with Production Engineering team’s on-call responsibilities in rotation.Experience working with Python based ETL/ELT, API and Cloud Data Warehouse databases. Data warehousing, Data Engineering experience, particularly with Snowflake is a plus.Design, develop and operate terabyte-scale data pipelines and services that meet goals of low latency, high availability, resiliency, security and quality .Define best practices, work with data engineering teams on best practices and ensure they are followed. Teach others how to do the right things. Automate everything. Enable self-service as much as possible via automation so that application teams can do what they need without you, focus on the engineering aspect primarily Automate schema updates/migration via common pipelines and pattern to be used by application teams in their deployment processes

Requirements:

8+ years of relevant work experience surrounding CI/CD, Test Automation and data infrastructure operations. Demonstrated ability to develop advanced CI/CD pipelines in GitLab, Python, Airflow (e.g. using dynamic data pipelines, automated unit testing, performance testing, etc.)Experience in writing and troubleshooting ETL jobs (Python, Airflow) and complex database SQL scripts.You have a strong python programming background in writing clean, testable code. Develop monitors and build alerts around error conditions and performance. Experience in data technologies server administration, SLA/incident management, RBAC automation and controls, user communication and support. Strong problem solving skills and ability to work independently or in team settings on complex production issues. Participate in On-Call support as needed.
",la,de
22,Finn Partners,Business Services,3.7,Marketing Data Engineer,"Los Angeles, CA",$73K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=4341&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_d0a32423&cb=1618794426900&jobListingId=4059320299,"FINN Partners Company has an opportunity for an Marketing Data Engineer. This role develops and maintains scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of FINNs research initiatives. Support and collaborate with data scientists, analysts and planners by developing advanced machine learning and statistical models to uncover audience or competitive insights for our clients. Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions. Deliver efficient data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery. Publish performance metrics to dynamic dashboards and other reporting systems. The position reports to the data science leader in the rapidly growing Global Intelligence unit.

Responsibilities:

We are looking for someone with a Bachelor's or Master's degree in the field of: Computer Science, Computer or Data Engineering or a related field. Strong problem-solving skills paired with extensive experience programming (R, Python, Java, C++, etc). Experience with Azure services and cloud applications environment.Strong data wrangling and cleaning skills. Software engineering skill (full cycle of specification, design, implementation, and maintain of software system). Experience with analytics publishing platforms such as Power BI, Tableau, Google Data Studio and Datorama.Modeling of complex data from heterogeneous sources, and hands on experience with relational databases and the use of SQL to extract and manipulate data.

Requirements:

Strong interpersonal communication and collaboration skills. History of working independently and effectively multi-tasking. Familiarity with RESTful APIs, containers and microservices. Familiarity with data privacy and data governance. Experience with SQL and NoSQL databases. Experience with Analytical Tools/Applications.Big Data Ecosystems: Hadoop, Spark, MapReduce, SQL, Hive, Databricks High-Performance Parallel and Distributing Computing. 3+ years of experience in a marketing, advertising, public relations, digital marketing, social media company, or management consultancy firm.Strong working knowledge of advertising, search engine, social media, text, and demographics data formats.

0-6 MonthsProgrammatically adding review data to analysis for brands, partners, products, scraping and purchased structured data.Exporting data from current platforms and analyzing/synthesizing with external data sets.Deployment in PowerBI and/or web.Google trend, Twitter trend and other trending data index to help track financial movement in industries coming out of lockdowns.Measurement framework design and concepting.

7-12 MonthsMachine learning capabilities. Automated and tailorable topic identification and segmentation.Better sentiment analysis for less consumer-focused topic areas (B2B, PR, PA).Predictive analytics - identify trends and extrapolate for near term and long-term consequences.Automated measurement framework deployment.

Powered by JazzHR",la,de
23,NBCUniversal,Media,4.1,DreamWorks Technology - Data Science Engineer,"Glendale, CA",$112K - $124K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_3fd0dadc&cb=1618794426900&jobListingId=4061982325,"60084BRTechnology & EngineeringFilmed Entertainment GroupResponsibilitiesThe Data Science and Engineering team at DreamWorks Animation is a cross-functional Data Science/Operations/Engineering team with involvement in all phases of application design, rollout and implementation. The Machine Learning / Data Science Engineer is responsible for using available data to engineer Machine Learning components, build APIs, and optimize systems. In this role you will be tasked to help build Machine Learning Systems used throughout the studio and solve interesting Data Scientific problems. You will play a key role in applying algorithms to generate predictions, in building Machine Learning Models and in working with Data used throughout the studio.SPECIFIC RESPONSIBILITIESUnderstand and contribute to current ML and Engineering solutionsIdentify, extract, clean and curate data from various sources. Develop best practices in data aggregation, cleansing and reportingBuild REST APIs to aid in the schema definition and definition of ingestion specifications to automate data ingres and processingWork on Machine Learning operationsBuild Predictive and Machine learning/Deep Learning models using CPU/GPUsDevelop and Deploy ML models on Azure and do Machine Learning InferenceHelp support business decisions with data and partner with the business to implement new and innovative solutions and analytics that drive valueWork closely with operations and software engineering teams to design and implement scalable high performance Big Data, ML systems and integration componentsQualifications/RequirementsAt least 3 years of relevant experienceB.S. in Computer Science or equivalent experienceProficient with PythonGood Unix/Linux experience requiredSound knowledge of SQL & NoSQL databases, Git and AzureSound knowledge of Math, Probability, Statistics and AlgorithmsData modeling and data architecture skillsBackground in machine learning frameworks and NLP projectsStrong written and verbal communicationsKafka, Spark, ElasticSearch a plusDesired CharacteristicsM.S. in Computer Science or relevant fieldHands-on - completes tasks quickly and thoroughly, follows-through and is highly dependableUnderstands the bigger picture and can make architectural decisions towards a common goalHighly responsible, self-motivated, and able to thrive in an energetic, fast paced, high growth environment. Exhibits ownership of projects and tasks assignedExcellent organizational skills required to adapt to a constantly changing technical environmentStrong team player with a customer service orientation with the ability to forge relationships at all levels of the company and across diverse culturesHave excellent communication skills – written, verbal and interpersonalSub-BusinessDreamWorks Animation TechnologyCareer LevelExperiencedCityGlendaleState/ProvinceCaliforniaCountryUnited StatesAbout UsFrom the award-winning storytellers, artist and innovators at DreamWorks Animation and DreamWorks Animation Television come the beloved characters and stories that come alive on the big and small screens. From films like Shrek, How to Train Your Dragon and Trolls to original TV series including Trollhunters, Voltron and Home: Adventures with Tip & Oh, DreamWorks Animation continues to bring home the laughter, fun and courage to dream.Visit www.dreamworksanimation.com to see our latest animated film and television productions.DreamWorks is a division of NBCUniversal. At NBCUniversal, we believe in the talent of our people. It’s our passion and commitment to excellence that drives NBCU’s vast portfolio of brands to succeed. From broadcast and cable networks, news and sports platforms, to film, world-renowned theme parks and a diverse suite of digital properties, we take pride in all that we do and all that we represent. It’s what makes us uniquely NBCU. Here you can create the extraordinary. Join us.NoticesNBCUniversal’s policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.",la,de
24,Amazon.com Services LLC,Information Technology,3.8,"Data Engineer, Marketing Measurement","Santa Monica, CA",$95K - $142K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=133043&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_690218cd&cb=1618794426901&jobListingId=3804190582,"4+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQLMS/BS in Computer Science, Systems Engineering or Electrical Engineering or Applied Mathematics or equivalent.4+ years of broad software engineering experience including infrastructure and application developmentProven track record of leading the delivery of large-scale, high-quality systemsExperience using at least one of Python, Java, Scala, Spark Hands-on experience working with R/Matlab/Python or any other statistical language/package is requiredKnowledge of statistical modeling techniques, e.g., logistic regression, decision trees, SVMs, neural networksExperience with Agile Management, OO Modeling, UNIX, and database related projectsAre you passionate about Amazon scale Big Data, Machine Learning and the ever growing Amazon's advertising & marketing landscape? If yes, this is the team for you!In this role, you will be owning first-of-its-kind data-management solution integrating Amazon 1P data with 3P data from advertising entities in privacy & security compliant manner to optimize Amazon's advertising and marketing dollars.The Consumer Behavior Analytics Cross channel optimization team (CBA-XO) organization is strategically and uniquely organized with SDEs, DEs, Product managers, Data/Applied Scientists and Economists to solve challenging predictive analytics problems at Amazon scale by providing data driven actionable insights.As a Data Engineer, you will be tasked with leading internal and external data acquisition and processing to building innovative machine learning products to optimize delivery of relevant and performant advertising experiences to customers. As a trusted engineering leader you will be given some of the most difficult data management, processing and intelligence generation problems to solve. You will need to develop and/or invent elegant mechanisms and cutting edge infrastructure processing capabilities that drive big data algorithms.You will operate as a mix of hands-on builder, and influencer. You will work closely with engineers and scientists contributing to the ongoing development and evolution of the underlying machine learning systems and algorithms. While you will spend the bulk of the time spent as a builder for delivering your own data processing solutions but will be expected to review, influence and support similar development in other areas.As a mentor, you will be a strong partner with science, product and engineering managers, supporting the skill and career development of junior scientists and engineers and educating the broader tech community strategic role of scientific innovations in furthering the advertising business.You’ll be expected to:Design data processing systems and algorithms for optimizing marketing spend across Amazon and its Subsidiaries.Build systems that extract and process volumes of disparate data using a variety of econometric and machine learning approaches. These systems should be designed to scale with exponential growth in data and run continuously.Leverage knowledge of big data technologies, advanced software systems, business intelligence reporting and algorithm development to build our measurement and optimization engines.Serve as a technical lead on our most demanding, cross-functional projects and mentor a team of data engineers and junior machine learning scientists to deliver solutions to internal stakeholders including other modeling teams at Amazon.Contribute intellectual property through patent generation.Functionally decompose complex problems into simple, straight-forward solutions.Understand system inter-dependencies and limitations as well as analytic inter-dependencies to build efficient solutions.Experience working in a complex, service oriented software developmentExperience working on automated marketing technologiesFour years' experience working on advertising measurement and optimization. Three years' experience working on analytics softwareExperience working with AWS Services, consuming, managing large scale datasets.Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",la,de
25,System1,Information Technology,4,Senior Data Engineer,"Los Angeles, CA",$130K - $185K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=148364&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_ae3460c4&cb=1618794426901&jobListingId=4060037780,"System1 is looking for engineers with production data experience to join the Data Engineering team. This team is the horizontal layer that supports business intelligence, optimization, machine learning, and external & internal reporting. We process and report on hundreds of millions of events and user attributes per day, gathered from an extremely heterogeneous and large set of data streams. Our bread and butter is Python and SQL. We utilize a range of technologies including AWS SNS, SQS, EC2, S3, Secrets Manager, Redis, Apache Airflow, Docker, as well as PostgreSQL and Snowflake for our data warehousing.The Role You Will HaveArchitect new components and improve on a coherent and performant data architecturePrototype, develop, deploy, and debug data ingestions and data management servicesEvaluate, recommend, and perform proof-of-concepts for new data toolsets and systemsDesign databases and construct queries and reports for a data driven business: guiding architectural design, business decisions, and optimizationsParticipate in peer code reviews and produce high quality documentationTake projects through the full engineering lifecycle: designing, ticketing, building, testing, deploying, and debugging tools and productsHelp grow a team and work with a tight knit group of engineers and data stakeholdersFlexibility in working with different teams, products, and their data needsWhat You Will BringBachelor’s in Computer Science or equivalent professional experience6+ years of experience with Python development6+ years of experience working and reasoning with large SQL datasets (Experience with PostgreSQL and Snowflake a plus)Understanding of NoSQL datastores like DynamoDB and RedisExperience with Linux and the AWS ecosystemExperience with Docker a plusExperience with Airflow a plusWhat We Have to OfferCompetitive PTO10 Company HolidaysUntracked sick timeMedical, Dental, Vision coverage401k w/matchProfessional development reimbursementLeadership & growth opportunitiesCommuter benefits#BI-Remote#LI-Remote",la,de
26,Qool Media Holdings,N/A,4,Senior Data Engineer,"Los Angeles, CA",$126K - $161K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_fca4efcc&cb=1618794426901&jobListingId=4059978166,"System1 is looking for engineers with production data experience to join the Data Engineering team. This team is the horizontal layer that supports business intelligence, optimization, machine learning, and external & internal reporting. We process and report on hundreds of millions of events and user attributes per day, gathered from an extremely heterogeneous and large set of data streams.Our bread and butter is Python and SQL. We utilize a range of technologies including AWS SNS, SQS, EC2, S3, Secrets Manager, Redis, Apache Airflow, Docker, as well as PostgreSQL and Snowflake for our data warehousing.The Role You Will HaveArchitect new components and improve on a coherent and performant data architecturePrototype, develop, deploy, and debug data ingestions and data management servicesEvaluate, recommend, and perform proof-of-concepts for new data toolsets and systemsDesign databases and construct queries and reports for a data driven business: guiding architectural design, business decisions, and optimizationsParticipate in peer code reviews and produce high quality documentationTake projects through the full engineering lifecycle: designing, ticketing, building, testing, deploying, and debugging tools and productsHelp grow a team and work with a tight knit group of engineers and data stakeholdersFlexibility in working with different teams, products, and their data needsWhat You Will BringBachelor’s in Computer Science or equivalent professional experience6+ years of experience with Python development6+ years of experience working and reasoning with large SQL datasets (Experience with PostgreSQL and Snowflake a plus)Understanding of NoSQL datastores like DynamoDB and RedisExperience with Linux and the AWS ecosystemExperience with Docker a plusExperience with Airflow a plusWhat We Have to OfferCompetitive PTO10 Company HolidaysUntracked sick timeMedical, Dental, Vision coverage401k w/matchProfessional development reimbursementLeadership & growth opportunitiesCommuter benefits#BI-Remote#LI-Remote",la,de
27,Centerfield Media,Business Services,3.7,Sr. Data Engineer,"Los Angeles, CA",$93K - $166K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=148364&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_62a762b5&cb=1618794426901&jobListingId=4036660542,"Hi, We're Centerfield. Centerfield is a cutting-edge digital marketing and sales technology company headquartered in the heart of Silicon Beach with additional offices in New York, Boston, Florida, and Jamaica. Our growing organization continues to impact the AdTech space by providing end-to-end customer acquisition services and analytics for our high-profile clients, while also successfully tailoring every step of the customer's shopping experience.  How do we do this? Centerfield develops intelligent Big Data driven marketing and sales technology which drives more than two million sales each year for brands such as AT&T, Sprint, ADT, Spectrum, and CenturyLink. Our technology platform, Dugout, combined with our leading consumer guides and 1500 person sales and retention center deliver new customers at scale to top residential services, business services, and telecommunications brands worldwide.  We’re always interested in expanding our team with top talent. Our creative work environment allows for innovative ideas and encourages a collaborative team culture... make sure to check out our perks below! The Opportunity...We’re looking for a talented Senior Data Engineer to join our LA team in building innovative advertising technology. We’re looking for someone who is highly motivated, web-focused, and has experience with the full data life cycle. You will help design the data collection infrastructure in support of Centerfield’s Data Architecture. You must have practical experience working with large data sets in the website lead generation & search engine marketing, SaaS, or cloud computing domains. How You'll Contribute...Help to implement maintenance strategy for all datasetsWork with relevant stakeholders to deliver appropriate BI, data warehousing, reporting, and analytical infrastructure required to support Centerfield’s assetsOwn problems from end-to-end, so that you can best collect, extract, and clean the dataWhat We're Looking For...5+ years working in a Data Engineer, BI Engineer, or Data Warehousing Engineer roleStrong experience with any ETL tool like Talend or SSIS or Informatica, etc.Experience with Google BigQuery and Google AnalyticsAbility to lead projects individually and deliver them on timeStrong experience in performance tuning techniquesExperience with real-time streaming implementation and architectureExperience building reports and data visualization with any BI tools like Tableau, Power BI, etc.Strong foundation in SQL coding and experience with ETL processesBonus Points… BI tools like Tableau, PowerBI, or Microstrategy, etc.Experience with NoSQL databases like MongoDB, DynamoDB, Druid, etc.Amazon Web Services (S3, SQS, Redshift, DocumentDB, etc.) Experience with PythonLife at Centerfield...Competitive salary + quarterly bonusUnlimited PTO – take a break when you need it!Industry leading medical, dental, and vision plans + generous parental leave401(k) company match plan – fully vested day 1Outside patio overlooking Playa Vista + cabanas, fire pits & working grillsMonthly happy hours, catered lunches + daily food trucksAward winning culture & unprecedented team spirit (featured in LA Business Journal & Built In LA)Fully stocked kitchens with snacks & drinksBreak room fully stocked with games, workout equipment + weekly in-office exercise classes (yoga, kickboxing & circuit training)Free onsite gym + locker roomsPaid charity and volunteer days (local mentor programs, adopt a pet, beach cleanup, etc.)Monthly team outings (ball games, casino night, hikes, etc.)Career growth – we enjoy promoting from within!To learn more, visit us Here. Interviews will take place after resumes have been screened for minimum requirements. Please note that this position is not restricted solely to the responsibilities listed above and that the job scope and responsibilities are subject to change. For more information about our collection, use, and disclosure of your personal information in connection with our evaluating your candidacy, please visit our Privacy Policy at https://www.centerfield.com/privacy-policy/. Centerfield Media is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected under federal, state or local law. ",la,de
28,Amgen,Biotech & Pharmaceuticals,4,Principal Data Engineer – Data Governance,"Los Angeles, CA",$170K - $285K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=133096&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_e51bd725&cb=1618794426901&jobListingId=4037605948,"Career CategoryInformation SystemsJob DescriptionAs a key member of the Enterprise Data Management organization, you will be part of the team responsible for delivering strategic and tactical data governance and stewardship services to capture data in a way that makes it easier to connect, share and consume across the enterprise. This is a vital role to ensure Amgen’s data ecosystem conforms with business needs, dynamic Data Privacy rules and regulations and Compliance requirements.You will interact with Amgen’s Data Management leaders worldwide by leading the Data Governance forums, where data related KPIs are discussed and remediation plans are approved and tracked.ResponsibilitiesDevelop and maintain data governance policies, processes and data standardsSupport business data owners, data stewards and data custodians to adopt the common enterprise Data Governance frameworkIdentify areas for data governance improvements and help to resolve data quality problems through the appropriate choice of error detection and correction, process control and improvement, or process design changesDefine data governance KPIs in partnership with internal data providers Business Owners and EDF Data Domain Owners.Support root-cause analysis for data quality issues and collaborate with Business Data Stewards to identify corrective actionsLead or execute data remediation and impact assessment effortsAssess and facilitate impact analysis of data providers system changesLead cross-functional Data Governance ForumsProvide metadata management capabilities (e.g. Data Dictionaries and business glossary)Lead efforts to adhere to Data Privacy and compliance requirementsAssist Data Stewards with data problem resolution when requestedBasic QualificationsDoctorate degree and 2 years of Information Systems experienceORMaster’s degree and 6 years of Information Systems experienceORBachelor’s degree and 8 years of Information Systems experienceORAssociate degree and 10 years of Information Systems experienceOrHigh school diploma / GED and 12 years of Information Systems experiencePreferred Qualifications:Proficient in metadata managementAbility to work with metadata tools to upload various metadata assetsSolid grasp of DQ tools and integrationsAbility to work with MDM and Transaction data teams continuously and effectively to identify assets to be governedAbility to work with the business stewards to capture glossary definitions and all other related metadataAbility to work with Data Privacy, Legal and Compliance to understand the various rules and regulations, compliance policies tied to the glossary elementsSolid understanding of system landscape, data flows, source system functionality and data standardsSolid understanding of relevant data standards and industry trendsKnowledge of relevant external regulations that impact master data and data management processesAbility to understand new business requirements and prioritize them for deliveryProficient in one of the coding languages (Python, Java, Scala)Has hands on experience writing SQL using any RDBMS (Redshift, Postgres, MySQL, Teradata, Oracle, etc.).Experience with Schema Design & Dimensional data modeling.Experience with AWS Services like EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway.Experience with software DevOps CI/CD tools, such Git, Jenkins, Linux, and Shell ScriptExperience with Spark, Hive, Kafka, Kinesis, Spark Streaming, and Airflow.Hands on experience using Databricks/Jupyter or similar notebook environment.Experience working in an agile environment (i.e. user stories, iterative development, etc.)Experience working with test-driven development and software test automationExperience working in Product teams environmentAmgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people’s lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world’s leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.We understand that to successfully sustain and grow as a global enterprise and deliver for patients — we must ensure a diverse and inclusive work environment.Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.This position is open to remote workers within United States..",la,de
29,Bridg,Information Technology,2.1,Sr. Data Engineer | Big Data SaaS Pipeline,"Los Angeles, CA",$91K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136006&s=58&guid=00000178e7aaafccbbec1cd0f8b7ca5b&src=GD_JOB_AD&t=SR&vt=w&cs=1_a8ca8d93&cb=1618794426901&jobListingId=3663239334,"Sr. Data EngineerWe are growing!!Bridg is seeking a Senior Data Engineer who will be architecting highly scalable data integration and transformation platform processing high volume of data under defined SLA. You will be creating and building the platform that includes ingestion and transformation of data, data governance, machine learning, analytics and consumer insights.We’re a rapidly-growing start-up in the heart of Sawtelle Japantown, just blocks away from the 405 and the 10. Our loft-style office houses a passionate, hard-working team of ramen-slurpers, beachcombers, and LA-daydreamers. At our core, we’re a tech company, yes, but our people make the magic happen.At Bridg, you will be solving complex problems with a business that celebrates innovation and values your contributions. We want you to wake up each day excited to use cutting edge tools/technologies and software development practices. Our platform is a combination of a large scale near-real time data pipeline (10s of billions of data points of sale transaction data from major retailers) and over 100 microservices.Our current tech stack includes Flink, Kafka, Cassandra, ElasticSearch, AWS Athena, Glue, Redshift, EMR, DynamoDB, and Java Spring Boot based microservices.A collaborative and innovative culture, Bridg offers highly advanced technology to identify and track purchasers in a physical retail store. Bridg's technology relies on data science and probabilistic modeling to identify and track the purchasers. The Bridg platform gives retail chains the same level of customer insight (and revenue growth) as data-savvy online retailers like Amazon, leveraging hundreds of millions of daily data points.Qualifications3+ years working in Big Data and related technologies5+ years Java and Spring Boot experienceExperience building high-performance, and scalable distributed systemsAWS cloud experience (EC2, S3, Lambda, EMR, RDS, Redshift)Experience in a variety of relevant technologies including Cassandra, AWS DynamoDB, Kafka, AWS Kinesis, Elasticsearch, Machine Learning, Spark, Hadoop, Hive, PrestoExperience in ETL and ELT workflow managementFamiliarity with AWS Data and Analytics technologies such as Glue, Athena, Redshift, Spectrum, Data PipelineMS preferred, or BA/BS degree in computer science, related field, or equivalent practical experienceExperience with Agile methodologies preferredExperience at start-ups a plusExperience in a fast paced development environment idealMust pass background checkMust be able to work in the office full time.Must be able to reliably commute to the office daily.What we offerA fantastic opportunity to be part of a growing start-up. A chance to work with a passionate, driven and fun team.An incredible work environment - fun, casual and fast-pacedMonthly team activities and outingsLoft-style office with plenty of break-out spaceFully stocked company snack area complete with every drink and snack your heart desiresGreat benefits - Health, Dental, Vision, and VacationSecurity, Availability and Confidentiality RequirementsYou are responsible for protecting the credentials provided to you to access S3’s (and customer, where applicable) networks, systems and dataYou are responsible for maintaining the confidentiality of all S3’s customer data to which you are granted access.Any suspected compromises of S3’s proprietary data or customer data must be reported to Management immediately.You will adhere to the S3 Information Security Policy and Procedures and supporting standard operating procedures to protect Company systems and data.Respond to and resolve customer help desk requests [varies based on role]You will alert management immediately with any expected system or data compromises and/or system failure impacting the security, confidentiality, availability and integrity of S3 and customer dataAbout Bridg:Bridg is a marketing software company that provides a CRM solution, email and SMS marketing, insights and analytics, mobile app and loyalty program development for restaurants and retailers. Powered by transaction data, Bridg builds unique 360º customer profiles to understand individualized behavior patterns, providing clients with deep data science used to create wide-reaching, effective personalized marketing campaigns that drive traffic and sales in a measurable way.Our headquarters is located in West LA / Santa Monica, and we offer competitive salaries, great benefits, and a high-energy environment with lots of room for personal and professional growth.",la,de
33,SCAN Group,Insurance,4.1,Data Analyst-HEDIS & Star,"Long Beach, CA",$81K - $91K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178e7abc2588ab41f577d425f9d&src=GD_JOB_AD&t=SR&vt=w&cs=1_215f99b5&cb=1618794497122&jobListingId=4004773667,"Data Analyst – HEDIS & StarLong Beach, CAFull-timeAbout SCANAs one of the nation’s largest not-for-profit Medicare Advantage plans, serving more than 200,000 members in California, SCAN Health Plan has been a mission-driven organization dedicated to keeping seniors healthy and independent for over 40 years. SCAN employees are passionate about what they do, and understand that success is based on achieving the mission. Employees are afforded with the training and tools necessary to do their jobs and are rewarded for their efforts and recognized as experts in their fields. To learn more, visit scanhealthplan.com or follow us on social media: LinkedIn; Facebook; and Twitter.The OpportunityDevelops, documents, and programs in support of 5-Star projects and in-house initiatives. In pursuit of high 5-Star ratings, conducts in-depth data analysis and interpretation, HEDIS reporting, and other related tasks.You WillDesigns and produces timely and meaningful analysis and data interpretation regarding large health care related datasets, related to 5-Star ratings, HEDIS, , state specific programs (such as QIP/PIP), programs issued by state agencies (such as DHCS or HSAG) and other associated company initiatives.Utilizes software programs such as SAS, SQL, Excel and/or other business intelligence tools to extract needed data. Writes original code and modifies existing code, as needed, to execute projects to specifications, and assists in the development of these specifications.Interprets data accurately and produces clear and comprehensive written analyses, graphics, tables, etc. for diverse internal and external audiences.Plans, organizes, and prioritizes assigned projects, creating and managing work plans that reflect the tasks, timeframes, and processes required to successfully complete each.Assists with development, implementation, and documentation of quality assurance (QA)processes to ensure that reported data is accurate and reliable.Documents data collection processes with other teams in Healthcare Informatics to transition data collection from one team to another.Contributes to and advances group knowledge about the Medicare population.Demonstrates a commitment to customer service through timely, accurate, and supportable deliverables.Ensures understanding of customer needs by proactively clarifying scope and requirements and keeping customers apprised of project status through effective communication.Supports customer understanding of analytical findings through effective presentation of results to individuals and groups.Achieves high-quality deliverables by assuring accuracy and thoroughness in executing projects.Manages multiple projects by effectively prioritizing work and communicating workload issues to management.Contributes to team effort by accomplishing related results as needed.RequirementsYour QualificationsBachelor’s or above degree in Math, Statistics, Biostatistics, Computer Science, or other quantitative disciplines required.Master's Degree preferred.2+ years of related analytical experience required.1+ years of experience with AI, ML preferred.Strong analytical skills required.Ability to effectively interact with, and present findings to customers at various levels of the organization.Advanced SAS data step, SAS macro language, and other SAS procedures required.Ability to document processes and analyses for reference/re-use required.Excellent technical, interpersonal, written and oral communication skills required.Proficient in MS Office.Your preferred qualificationsProficiency with MS SQL (queries) preferred.Clinical code knowledge related to claims/utilization preferred.Experience with managed care contract terms/analysis preferred.Experience in a Medicare Advantage environment preferred.What's in it for you?A competitive compensation and benefits programAn annual employee bonus programGenerous paid-time-off (PTO)Ten paid holidays per yearExcellent 403(b) Saving Plan, providing up to 4% match and vesting after three yearsCasual attireA work-life balance and much more!We're always looking for talented people to join our team! Qualified applicants are encouraged to apply now!SCAN is an equal opportunity employer and it is our policy to abide by all federal, state and local laws prohibiting employment discrimination. All qualified applicants will receive consideration for employment.Equal Opportunity Employer/Protected Veterans/Individuals with DisabilitiesThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor???s legal duty to furnish information. 41 CFR 60-1.35(c)",la,de
59,REVOLVE,Retail,3.2,Data Scientist,"Cerritos, CA",$101K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=926135&s=58&guid=00000178e7abc2588ab41f577d425f9d&src=GD_JOB_AD&t=SR&vt=w&cs=1_ea074e06&cb=1618794497127&jobListingId=4006402430,"
Data Scientist

Meet REVOLVE: 

REVOLVE is the next-generation fashion retailer for Millennial and Generation Z consumers. As a trusted, premium lifestyle brand, and a go-to online source for discovery and inspiration, we deliver an engaging customer experience from a vast yet curated offering totaling over 45,000 apparel, footwear, accessories and beauty styles. Our dynamic platform connects a deeply engaged community of millions of consumers, thousands of global fashion influencers, and more than 500 emerging, established and owned brands. Through 16 years of continued investment in technology, data analytics, and innovative marketing and merchandising strategies, we have built a powerful platform and brand that we believe is connecting with the next generation of consumers and is redefining fashion retail for the 21st century. For more information please visit www.revolve.com.

At REVOLVE the most successful team members have a thirst and the creativity to make this the top e-commerce brand in the world. With a team of 1,000+ based out of Cerritos, California we are a dynamic bunch that are motivated by getting the company to the next level. It’s our goal to hire high-energy, diverse, bright, creative, and flexible individuals who thrive in a fast-paced work environment. In return, we promise to keep REVOLVE a company where inspired people will always thrive.

Some of the sweetest perks we offer aren’t in a typical benefit package like hefty discount on items we carry – as in 50% or more off retail prices.

To take a behind the scenes look at the REVOLVE “corporate” lifestyle check out our Instagram @REVOLVEcareers or #lifeatrevolve.

Are you ready to set the standard for Premium apparel?

Main purpose of the Data Scientist role:

This is a full time role for a candidate who has diverse skill sets across math and computer science, and is dedicated to solving complex and analytically challenging problems here at Revolve.

Major Responsibilities:

Essential Duties and Responsibilities include the following. Other duties may be assigned.

Partner closely with business leaders in Marketing, Product, Operations, Buying team to plan out valuable data science projectsConduct complex analysis and build models to uncover key learning form data, leading to appropriate strategy recommendations.Work closely with the DBA to improve BI’s infrastructure, architect the reporting system, and invest in time for technical proof of concept. Serve as an algorithm and engineering lead to build advanced quantitative solutions.Work closely with the business intelligence and tech team to define, automate and validate the extraction of new metrics from various data sources for use in future analysisWork alongside business stakeholders to apply our findings and models in website personalization, product recommendations, marketing optimization, to fraud detection, demand forecast, CLV prediction.

Required Competencies:

To perform the job successfully, an individual should demonstrate the following competencies:

Outstanding analytical skills, with strong academic background in statistics, math, science or technology.High comfort level with programming, ability to learn and adopt new technology with short turn-around time.Knowledge of quantitative methods in statistics and machine learningIntense intellectual curiosity – strong desire to always be learningProven business acumen and results oriented.Ability to demonstrate logical thinking and problem solving skillsStrong attention to detail

Minimum Qualifications:

Master Degree is required3+ years of DS and ML experience in a strong analytical environment.Proficient in Python, NumPy and other packages with experience deploying end to end ML modelsFamiliar with statistical and ML methodology: causal inference, logistic regression, tree-based models, clustering, model validation and interpretations.Experience with AB Testing and pseudo-A/B test setup and evaluations, familiar with Propensity score matching and synthetic controlAdvanced SQL experience, query optimization, Data extractAbility to build, validate, and productionize models



Preferred Qualifications:

PhD in a quantitative field Strong business acumen5+ years of DS and ML experience preferredAdvanced SQL and Python, with query and coding optimization experienceExperience with E-commerce marketing and product analytics is a plusFamiliarity with Docker, Flask, Google Analytics API, GIT

A successful candidate works well in a dynamic environment with minimal supervision. At REVOLVE we all roll up our sleeves to pitch-in and do whatever it takes to get the job done. Each day is a little different, it’s what keeps us on our toes and excited to come to work every day.

ATTENTION:

After submitting your application, please check your spam folder for emails on your application status. Emails are sent from an ADP email address.",la,de
0,Cognizant Technology Solutions,Business Services,3.7,Hire and Train Data Scientist/ Engineer,"San Francisco, CA",$96K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178e7d573cb8ae5b6523635b7a9&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_0a054c78&cb=1618797229673&jobListingId=4063118844,"Please note, this role is not able to offer visa transfer or sponsorship now or in the future*After completing a comprehensive training program, you will join our AI&A practice as an Data Engineer supporting an enterprise client.About AI & Analytics: Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data, and provides businesses a clear way to transform how they source, interpret and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence.Data Engineer/Scientist is responsible for creating and supporting data processing solutions in cloud for our clients. In this role you will use Open Source technologies like Spark , Scala/Python/Java in AWS cloud environment to design and develop data processing applications to provide our clients with faster insight into their business. You will develop, test and deploy the solutions for warehousing systems. In addition, you will be responsible for resolving any issues with the systems as well as creating user documentation outlining the design, troubleshooting and repair steps.Day-to-Day ResponsibilitiesParticipate in Agile ceremonies like standup , grooming and retrospectivesDesign and develop solutions , which includes Preparation of design documents , unit testing , code version control and other relevant operational duties.Manage data related requests, analyze issues and provide efficient resolution Design all program specifications and perform required tests.Prepare codes for all modules according to require specification.Monitor all production issues and inquiries and provide efficient resolutionEvaluate all functional requirements and map documents and perform fix on all development processes.Collaborate with application groups to prepare effective solutions for all programs.Documents all technical specifications and associate project work you're doing.Cognizant is committed to veteran and military communities. Cognizant has been often recognized as a military friendly employer and is a coalition member of the Veteran Jobs Mission. Our business resource group Veterans Network assists our military associates in building and growing a career at Cognizant that allows them to demonstrate the leadership, loyalty, integrity, and commitment to excellence.Cognizant (NASDAQ: CTSH) is a leading provider of information technology, consulting, and business process outsourcing services, dedicated to helping the world's leading companies build stronger businesses. Headquartered in Teaneck, New Jersey (U.S.). Cognizant is a member of the NASDAQ-100, the S&P 500, the Forbes Global 1000, and the Fortune 500 and we are among the top performing and fastest growing companies in the world.Our strength is built on our ability to work together. Our diverse backgrounds offer different perspectives and new ways of thinking. It encourages lively discussions, inspires thought leadership, and helps us build better solutions for our clients. We want someone who thrives in this setting and is inspired to craft significant solutions through true teamwork.Ind123#LI-PS1#CBmsjaEmployee Status : Full Time EmployeeShift : Day JobTravel : NoJob Posting : Apr 16 2021About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",sf,de
1,Salesforce,Information Technology,4.5,"Senior Business Intelligence Engineer, Data Experience & Enablement","San Francisco, CA",$145K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000178e7d573cb8ae5b6523635b7a9&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_ef0ba18d&cb=1618797229673&jobListingId=4059467280,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.Job CategoryProducts and TechnologyJob DetailsThe Data Intelligence (Di) team is made up of data scientists, engineers, and analysts who are dedicated to driving product strategy with data-driven insights. The Di team works with executives, product managers, designers, developers, user researchers, marketers, and sales strategy team members across all Cloud businesses to discover new opportunities for growth and optimization, drive data-informed product strategy and create data product experiences and actionable insights that enable our stakeholders to maximize product adoption and revenue. This role will be reporting directly to the Director of Business Intelligence.The Senior Business Intelligence Engineer, Data Experience & Enablement (DxE) position will be responsible for evangelizing Business Intelligence solutions throughout the organization by providing actionable insights at the right context in the right time in the form of right visualization. This person will play the role of a senior data analyst on driving strategy to the finishing line and help support product and business growth. They are also responsible for designing, developing & maintaining visual display of all the mission critical data sets generated by the DxE team for statistical and machine learning computational requirements. Hence donning the role of “Data Artist”, making an impact by storytelling with data in summarizing, profiling, sampling, visualizing and analyzing terabytes of data. So if you are passionate about data and its analysis using Visualizations then you will love working in this team.The Senior Business Intelligence Engineer will work closely with various functional groups on projects involving data discovery, assessing data samples, massaging and preparing data for hypothesis testing and machine learning algorithms.This role has the overall responsibility for establishing and evangelizing Business Intelligence and data visualization services in support of analyst and data scientists with Data Intelligence. The Senior Business Intelligence Engineer plays a critical role in enabling the ability to bring order and insight to the data.ResponsibilitiesBuild adoption, churn, growth reports, and dashboards to deliver self-service insights.Design, build and maintain dashboards and interactive reports in Tableau and Salesforce Einstein Analytics.Acquire, clean, and structure data from multiple sources including applog data from Hadoop, dimensional from Oracle databases, AWS, Salesforce objects, and external data sources.Independently analyse and provide recommendations to data analysts, data engineers and data scientists on data design and data structures to build a sustainable model.Ability to trigger responses from the stakeholders/end users to build compelling visuals.Partner with product analysts, product engineering and other stakeholders to understand product instrumentation needs for insights & analytics.Translate numbers, trends and data to consumable insights - both explanatory and exploratory.Architect, develop, validate and communicate BI solutions such as reports, dashboards, KPIs and alerts.Understand modeling constraints and create elegant solutions to both present and deliver information for easy consumption.Define standards and procedures for best practices for business intelligence design & development.Lead reengineering efforts for existing applications to align them with new standards and guidelines.Develop and maintain thorough system documentation and training materials.Able to identify incomplete data, improve quality of data and integrate data from several data sources.Collaborate with Analysts and developers on the efficient use of Tableau and other visualization tools and how those technologies can be applied to effective data visualization applications.Engage with Tableau, Einstein analytics and other product owners to provide timely updates on product bugs/ issues and limitations. Also driving features and functions requests back into the vendor for inclusion in the product(s).Endorse open source tools & techniques in development, management and release process. Utilize in house software effectively.Create compelling custom visualizations using ElasticSearch/Solr and Open source JavaScript libraries.Job RequirementsBS/MS degree in Computer Science, Information Technology, Engineering , Statistics, Mathematics, Physics, Operations Research, Econometrics or equivalent/related degree.6 to 9 years of Data Visualization experience using Tableau, Einstein Analytics and other BI tools.Advanced expert in SQL, strong Python or R user, and familiar with tools like Splunk to wrangle, analyse data, and develop reports.Actively uses big-data infrastructure (Hive/Hadoop/AWS).Proficiency in at least one business intelligence tool such as Tableau or Einstein Analytics is required.Preferred Qualifications:Ability to quickly learn and gain a deep understanding of Salesforce business processes.Ability to perform thorough analysis of complex data, draw sound conclusions, and devise actionable strategies.Experience in architecting, designing dimensional sets and caching methods.Expert in the visual representation of complex information for driving business impact.Subject Matter Expert and Evangelist on enterprise data, visualization, data analysis, data modeling, SQL constructs and workload management.Expert in Dimensional Data Modeling and presentation layer design.Experience with Elasticsearch/Solr and open source JavaScript libraries like D3.Js and Highcharts is a plus.Ability to prioritize and execute multiple tasks in a highly dynamic environment with a result oriented mindset.Detail oriented with proven analytical, problem identification and resolution skills.Ability to work effectively in an unstructured and fast-paced environment, and have a high degree of self-management with clear communication and commitment to delivery timelines.Proven interpersonal, communication and presentation skills – must be able to explain technical concepts and analysis implications clearly to a wide audience.Above average capabilities with basic analysis tools of Microsoft Office suite.Experience in the use of open source software.Accommodations - If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.Posting StatementAt Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at Salesforce and explore our benefits.Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay any third-party agency or company that does not have a signed agreement with Salesfore.com or Salesforce.org.Salesforce welcomes all.Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.",sf,de
2,Stealth Mode Startup,N/A,4.1,Reliability Engineer (Hardware),"San Francisco, CA",$112K - $136K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044077&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f8107a69&cb=1618797229674&jobListingId=4062943195,"Join a rapidly growing startup that is developing exciting new life sciences technology. Play an important role in the development and commercialization of technology and products that will have a major impact on the medical and life sciences fields! Engineer solutions by working on a wide range of topics including mechatronics, robotics, controls systems, optics, and fluidics.Overview: As a Reliability Engineer you should be ready to contribute to a fast-paced multidisciplinary group focused on creating next generation analytical equipment. You will be focused on analyzing failure modes, failed components, and stress tests in order to mitigate issues and increase key reliability statistics set out in our company goals. You should look at design goals and decisions by weighing risks based on data, best practices, failures, and potential failure modes.Responsibilities: Identifying and validating potential risks related to performance, lifetime, and safety in electrical, mechanical, fluidic and/or optical sub-systems.Analysis of failure data from reliability test benches, beta instruments, in-field instrumentsLead and participate in DFMEA and PFMEA, including ranking of failure modes.Write technical documentation, including ECOs, work instructions, corrective actions, and tech notes for field service.Define and create reliability metrics and lifetime predictions for components and systems under development and in field.Owning the system reliability model that partitions an overall system level reliability budget to various sub-systems and sub-assemblies.Reviewing and approving the subsystem and sub-assembly lifetime testing plans according to the HALT principles.Qualifications: BS or MS in Engineering, Physics, or applied sciences>4 years’ experience in working with complex systems is preferred.Solid critical thinking skills: ability to deep dive into cause-effect to understand why something may fail.Engineering experience with one or more; fluidics, optics, mechatronic or robotics a plusData analysis using Python is a plus.Weibull, Weibull++, or statistical analysis preferred.Job Type: Full-timePay: Up to $115,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceHealth insurancePaid time offVision insuranceSchedule:8 hour shiftMonday to FridaySupplemental Pay:Bonus payAbility to Commute/Relocate:Newark, CA 94560 (Preferred)Education:Bachelor's (Required)Work Location:One locationBenefit Conditions:Waiting period may applyWork Remotely:NoCOVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredPlastic shield at work stationsTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",sf,de
3,"Association For Energy Affordability, Inc.",Transportation & Logistics,2.8,Energy Research Engineer,"Emeryville, CA",$56K - $100K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044077&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_7f7b5ba0&cb=1618797229674&jobListingId=4037589436,"Overview:  Association for Energy Affordability (AEA) is a rapidly growing nonprofit energy services and training organization dedicated to achieving energy efficiency in buildings in order to foster and maintain affordable and healthy housing and communities. Energy consulting services are completed through AEA’s participation in a variety of federal, state, and local energy efficiency initiatives. For more information about AEA, see http://www.aea.us.org.Position Summary:  AEA West is seeking an Energy Research Engineer to join our tight-knit, talented team of “Energy Geeks”. The candidate will perform field research, in-depth data collection and analysis related to high performance, zero carbon buildings. If you are passionate about decarbonizing the built environment, you love data, and you’re seeking to learn from an experienced team in a hands-on environment, then this is the perfect opportunity for you.The Energy Research Engineer engages in federal, state and local government and utility funded research and demonstration projects and engages in building and building system monitoring, measurement and verification, data analysis and visualization, energy modeling and report production as needed to complete a range of research project types. They are expected to be a self-starter, an independent problem solver, and a strong team-player.Responsibilities:  The Energy Research Engineer may be responsible for:· Developing measurement and verification (M&V) plans· Selecting and costing M&V equipment packages· Configuring, testing, and deploying monitoring and data collection equipment in the field· Instituting the use of and/or developing appropriate software tools for data collection and cleaning· Analyzing and creating visualizations of large data sets for both trending and energy savings calculations purposes· Manage energy performance analysis including data collection from various software tools and validating performance· Coordinating with other organizations as a member of research teams to define and implement M&V· Perform complex research and data analysis on a wide range of topics and share findings· Performing energy modeling and building simulations· Working with building owners, architects, and other decision makers to successfully manage advanced technology demonstration projects· Working with plumbing, mechanical and electrical contractors on site during construction projects to implement M&V installationsThese job responsibilities may be revised over time to ensure the functional responsiveness of the Energy Research Engineer to AEA and Federal and California State program requirements.Minimum Qualifications: · Bachelor’s Degree in engineering, architecture, environmental science, construction management or other sustainability related focus, with a demonstrated interest in energy conservation and building science preferred· Minimum of two years’ experience in building energy engineering· Experience working with large datasets and associated data collection, analysis, and visualization tools· Knowledge of building systems including lighting technologies, building envelope, mechanical systems and combustion scienceAdditional Qualifications Desired: · Familiarity with Python, including specific experience working with pandas, Plotly, and/or other libraries to perform data analysis and visualization tasks· Strong background in building science and mechanical/electrical engineering principles related to building systems· Knowledge and understanding of Title 24 and other building codes· Sound technical writing skills and experience· Ability to communicate complex technical information in an accessible manner· Experience with the use of energy modeling software a plus, i.e., EnergyPro, EneryPlus, OpenStudio, eQUEST, DOE2 programs· Proficiency in Microsoft Office Suite (Excel, Word, Outlook, and PowerPoint)EEO Non-Discrimination and ADA Reasonable Accommodation Statement: Applicants are considered for all positions without regard to race, color, creed, religion, age, national origin, alienage or citizenship status, gender, sexual orientation, gender identity, marital or partnership status, disability, military status, veteran status, or predisposing genetic characteristics. AEA does not discriminate on the basis of physical or mental disability where the essential functions of the job can be reasonably accommodated. Determinations on requests for reasonable accommodation will be made on a case-by-case basis. For more information on the physical requirements of this position and/or if you need reasonable accommodation for any part of the application and hiring process, please notify the agency at 212-279-3902 Ext-8265.TO APPLY: Please submit a resume with cover letter.~ Minorities and women are encouraged to apply ~Job Type: Full-timeBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programHealth insuranceLife insurancePaid time offProfessional development assistanceVision insuranceSchedule:Monday to FridayEducation:Bachelor's (Preferred)Experience:Building Energy Engineering: 2 years (Preferred)Work Location:One locationCompany's website:http://www.aea.us.org/Benefit Conditions:Waiting period may applyWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",sf,de
4,Pariveda Solutions,Information Technology,4.7,Software Engineer,"San Francisco, CA",$93K - $120K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_b013854d&cb=1618797229675&jobListingId=4063022483,"Overview:If you are into programming, working in small teams, and solving complex problems using the latest in Cloud, Mobile, and Web technologies, Pariveda Solutions is the company for you. Our San Francisco team is growing and looking for software developers who want to design, develop, and deliver enterprise-level applications. This is an opportunity to expand your knowledge of full life cycle development, gain direct client exposure, and grow yourself and team members.We Look For:Passionate coders with internship or application development experienceThe complete package- We design, code, and deliverSkilled problem solvers with the desire and proven ability to create innovative solutionsFlexible and adaptable attitude- Client, teams and technologies will change with each new challengeFuture technology leaders- Dynamic individuals energized by fast paced personal and professional growthPhenomenal communicators who can explain and present concepts to technical and non-technical audiences alikeBachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable experienceLegally authorized to work for any company in the United States without sponsorshipYou Can Expect To:Grow your career- eligible for promotion every 12 months and a clearly defined career path with the tools, support and mentors to get thereInteresting work with interesting people- Work on small teams with other Pariveda employees and clientsChallenge your brain- Think through complex problems and work with a team to implement real-world solutionsEmbark on new adventures- Shorter-term engagements mean the client and type of project change oftenTry new things- Learn to estimate, gather requirements, develop, test, manage projects, architect and deliver. We do it all!Explore different technologies- Develop applications in languages including…Java, .NET, Python, JavaScript/TypeScript, and SQLWeb - React, Redux, Angular, VueMobile - iOS and AndroidCloud – AWS, Azure, Google CloudData Driven solutions, IoT, Machine Learning, CI/CD in DevOps, and moreSharpen your communication skills- Create and present findings, solutions, and demos to audiences including senior executives and stakeholdersBecome a part of something bigger- Actively engage in our culture of continuous learning, community service, social gatherings, and personal and professional developmentPariveda BenefitsThe salary range for this position is $87,400 - $96,200 annually. Actual salaries may vary based on factors including but not limited to location, experience, and performance.Exceptional 401k – 4% company matchPlenty of Paid Time Off - 4 weeks of vacation time plus 10 holidaysPaid sabbatical after 5 years of service for Principal levels and abovePaid parental leaveCompany Ownership through Employee Stock Ownership Plan (ESOP) from your very first day at ParivedaExcellent Healthcare and Wellness100% company paid premiums for you and your family (medical, dental, vision)Life InsuranceShort Term and Long Term DisabilityIn 2003, we asked one simple question. Can a technology consulting firm be successful by focusing first on growing the individual to their fullest potential? We believed that through an unwavering commitment to developing people we could create a different kind of company. We created Pariveda. It is through this belief in helping the individual, counter to industry norms, we have grown revenue each and every year since 2003. We are passionate about creating interesting solutions to the unknown/unmet needs of our clients and to grow, both our people and our clients, through those experiences.We believe in the efficiency of small teams working together to solve complex problems leveraging strategy and technology. At Pariveda, we integrate information technology into the fabric of businesses across the breadth and depth of their value chains. We call this the Business of IT®. We believe in growing deep relationships with our people, our clients and others in our networks. Trusted relationships are integral to everything we do - from relationships with the people with whom we work, the people we partner with at our clients, or the people we interact with in our communities. We believe trusted relationships are built through challenging and exhilarating experiences that make a difference to clients and communities. You will discover people here are passionate about their work. You will discover our openness in developing you and growing as our expectations are openly communicated to you and provide opportunities for you to evidence your readiness to move to the next level. And together we seek to be difference-makers in our industry and the communities where we live by always learning, coaching more, and giving back.We serve clients ranging from Fortune 100 to Global 2000 to startup companies and spanning multiple industries. We provide company ownership through our Employee Stock Ownership Plan (ESOP) from your very first day of work with us. Our people live and work in local communities within the thriving cities of Atlanta, Chicago, Dallas, Houston, Los Angeles, New York, Philadelphia, San Francisco, Seattle, Toronto and Washington DC.If you are inspired by our mission and our beliefs and want to join us in developing yourself and others as Consultant in our San Francicso office, apply today.The Business of IT® is a registered trademark of Pariveda Solutions, Inc. describing where IT departments need to act more like the businesses they serve given the ubiquitous integration of information technology into the world of business.",sf,de
5,Nielsen,Information Technology,3.8,Data Engineer,"Emeryville, CA",$71K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_4b86977a&cb=1618797229675&jobListingId=4008057850,"Data Engineer - 78162Gracenote - USA Emeryville, CaliforniaGracenote, a Nielsen Media Company is presently looking for an experienced Data Engineer.Our teams are passionate about building high-quality robust software. We are looking for people who are as passionate as we are about technology, writing code, building cool, customer driven solutions, and who can demonstrate that to us with personal projects or contributions to the open source community (by writing code, participating in discussions, or evangelizing their favorite tools and languages).FOR THIS ROLE WE WILL BE LOOKING FOR INDIVIDUALS THAT HAVE:Minimum Bachelor’s Degree in Computer Science2+ years of software development experienceExperience coding in : Java, SQL, NoSQL, Kafka, Scala,Team experience with Agile methodologies, such as Scrum and test-driven developmentExperience developing service oriented architectures and an understanding of design for scalability, performance and reliabilityBuilt applications using relational databases such as MySQL, Postgres, or SQL ServerAbility and passion for learning new technologyBONUS SKILLS:DevOps experience deploying and tuning the applications you’ve builtConfiguration management tools such as Ansible, Chef, or DockerExperience designing and deploy applications in AWSExperience with MapForce#LI-DG1ABOUT NIELSEN GLOBAL MEDIAAs the arbiter of truth, Nielsen Global Media fuels the media industry with unbiased, reliable data about what people watch and listen to. To discover what’s true, we measure across all channels and platforms⁠—from podcasts to streaming TV to social media. And when companies and advertisers are armed with the truth, they have a deeper understanding of their audiences and can accelerate growth.Do you want to move the industry forward with Nielsen? Our people are the driving force. Your thoughts, ideas and expertise can propel us forward. Whether you have fresh thinking around maximizing a new technology or you see a gap in the market, we are here to listen and take action. Our team is made strong by a diversity of thoughts, experiences, skills, and backgrounds. You’ll enjoy working with smart, fun, curious colleagues, who are passionate about their work. Come be part of a team that motivates you to do your best work!Nielsen is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.Job Type: RegularPrimary Location: Emeryville,California",sf,de
6,Salesforce,Information Technology,4.5,Data Engineer (Experienced),"San Francisco, CA",$115K - $203K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=242900&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_391d9649&cb=1618797229675&jobListingId=4035244206,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.***** If you are currently in college/ grad school or have less than a year of experience - please check out FutureForce job opportunities at Salesforce:https://www.salesforce.com/company/careers/university-recruiting/The team is made up of data scientists, engineers, growth analysts, and information management experts who are dedicated to driving product strategy with data-driven insights. The team works with executives, product managers, designers, developers, user researchers, marketers, and sales strategy team members across all Cloud businesses to discover new opportunities for growth and optimization, experiment with data, drive adoption, and provide actionable insights that impact product strategy.Role Description:The Data Engineer position will be responsible for designing, developing & maintaining all parts of the data pipeline to build interactive and curated data needed to drive insights through data science, reporting & analytics. The role requires to partner with Data Scientists, Software Engineers, Data Analysts, and Information Management experts within Salesforce. This role involves making an impact by driving continuous improvements in moving, aggregating, profiling, sampling, testing and analyzing terabytes of data.Responsibilities:Own the technical solution design, lead the technical architecture and implementation of data acquisition and integration projects, both batch and real time. Define the overall solution architecture needed to implement a layered data stack that ensures a high level of data quality and timely insights.Communicate with product owners and analysts to clarify requirements. Craft technical solutions and assemble design artifacts (functional design documents, data flow diagrams, data models, etc.).Build data pipelines data processing tools and technologies in open source and proprietary products.Serve the team as a subject matter expert & mentor for ETL design, and other related big data and programming technologies.Identify incomplete data, improve quality of data, and integrate data from several data sources.Proactively identify performance & data quality problems and drive the team to remediate them. Advocate architectural and code improvements to the team to improve execution speed and reliability.Design and develop tailored data structures in database and Hadoop.Quickly create functioning ETL prototypes to address quickly changing business needs. Revamp prototypes to create production-ready data flows. Support Data Science research by designing, developing, and maintaining all parts of the Big Data pipeline for reporting, statistical and machine learning, and computational requirements.Perform data profiling, complex sampling, statistical testing, and testing of reliability on data.Clearly articulate pros and cons of various technologies and platforms in open source and proprietary products. Execute proof of concept on new technology and tools to help the organization pick the best tools and solutions.Harness operational excellence & continuous improvement with a can do leadership attitude.Job Requirements:BS/MS degree in Computer Science, Engineering, Mathematics, Physics, or equivalent/related degree.5+ years of experience working with ETL tools, specifically creating data driven orchestration and transformation jobs and user and project administration. A strong Python scripting knowledge including hands-on experience in building packages for ETL is required. Advanced Matillion developer is a plus. 4+ years of experience with Data Warehouse including knowledge of Stored Procedures, tasks and streams. Must be an expert in writing complex SQL queries and understand the methodologies to tune/improve query performance.Previous projects should display technical leadership with an emphasis on data lake, data warehouse solutions, business intelligence, big data analytics, enterprise-scale custom data products.Familiarity with new big data management techniques of schema on read, search analytics, graph analytics, semantic data lakes, linked data, etc.Knowledge of data modeling techniques and high-volume ETL/ELT design. Strong SQL optimization and performance tuning experience in a high volume data environment that utilizes parallel processing. Hadoop, Spark, Teradata platform experience a plus.Experience with version control systems (Github, Subversion) and deployment tools (e.g. continuous integration) required.Experience with programming languages like Java, Scala & scripting in Python, Perl, Bash.Experience working with Public Cloud platforms like GPC, AWS, or Azure. Familiarity with scrum/agile project management methodologies and SDLC stages required.Hands-on on Salesforce.com knowledge of product and functionality a plus.Ability to work effectively in an unstructured and fast-paced environment both independently and in a team setting, with a high degree of self-management with clear communication and commitment to delivery timelines.Strong problem solving with acute attention to detail and ability to meet tight deadlines and project plans.Ability to research, analyze, interpret, and produce accurate results within reasonable turnaround times with an iterative mindset with rapid prototyping designs.Accommodations - If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.Posting StatementAt Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at Salesforce and explore our benefits.Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay any third-party agency or company that does not have a signed agreement with Salesfore.com or Salesforce.org.Salesforce welcomes all.Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.",sf,de
7,Twitch,Information Technology,3.9,Data Engineer - Community,"San Francisco, CA",$98K - $171K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=8095&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_79f90ab7&cb=1618797229676&jobListingId=3723902027,"About UsLaunched in 2011, Twitch is a global community that comes together each day to create multiplayer entertainment: unique, live, unpredictable experiences created by the interactions of millions. We bring the joy of co-op to everything, from casual gaming to world-class esports to anime marathons, music, and art streams. Twitch also hosts TwitchCon, where we bring everyone together to celebrate, learn, and grow their personal interests and passions. We're always live at Twitch. Stay up to date on all things Twitch on LinkedIn, Twitter and on our Blog.About the RoleData is central to Twitch Community team's decision-making process, and building the infrastructure to support this is critical to enable data-driven decision making in our product operations. As a Data Engineer at Twitch, you will be responsible for leveling up the capabilities of stakeholders across your team and cross-functional teams, enabling them to make better decisions using trusted data.

As part of the Community team at Twitch, you will be on the ground floor with the product data team, defining the way we collect and operationalize data, building coherent Logical Data Models that drive physical design and influencing future data roadmaps and strategy. In a typical week or month, your responsibilities may range from optimizing operational data storage to processing semi-structured data streams to building self-service business intelligence infrastructure for analysts. Whether you specialize in one functional area or work across all of them, your end product is always usable datasets that provide business value. Your work will pave the way for high-quality, high-velocity decision-making that will lead to safer, more rewarding community interactions across the platform

The ideal candidate is proficient in a broad range of data design approaches, has experience working with cross-functional product development teams, and has a passion for shaping the future of community-driven entertainment.You Will:

Design, build and maintain a set of trusted data assets for a product or a group of products.
Act as our team's thought leader for defining data telemetry, storage and ETL processes.
Partner with the Central Data Platform & Analytics teams to standardize data storage, decrease redundancies and evangelize finalized data assets.
Partner with Analytics, Product and Engineering teams to understand data needs.
Write software code and data solutions that are high quality and comprehensible.
Have rigor around data architecture best practices:
Create coherent logical data models that drive physical design.
Balance customer requirements with technology requirements.
Be proficient in a broad range of data design approaches.
Be judicious about introducing dependencies.
Create flexible data solutions without over-engineering.
Understand how to be efficient with resource usage (e.g., system hardware, data storage, query optimization, AWS infrastructure etc.)
Have knowledge of engineering and operational excellence best practices. Be able to make enhancements that improve data processes (e.g., data auditing solutions, management of manually maintained tables, automating, ad-hoc or manual operation steps).

You Have:



3+ years of industry experience as a data engineer or in a related role, preferably in the consumer internet or gaming space, or working with a high-velocity, high-growth product / business.
3+ years experience in custom ETL design, implementation and maintenance.
Proficient in SQL -- comfortable working with complex joins, window functions and writing SQL for aggregations.
Experience working with Amazon Webservices, S3, EMR, Redshift etc.
Experience building aggregates, optimizing data workstreams and maintaining data pipelines
Comfort working independently, prioritizing projects, and managing stakeholder expectations across teams.
Strong written and verbal communication skills.
Eager to shape the development of a growing team and contribute to the design of novel products that shape the community experience for millions of viewers and creators.
Obsessed with data quality and a strong belief in test driven development

Bonus Points

Strong familiarity with Twitch, our creators, and our community.
Masters degree (preferred, but not required).
Fluency in statistical analysis and programming using Python, R, or similar tools.
Prior experience building end-to-end pipelines for supporting experimentation with machine-learning systems (e.g. recommendations, spam & fraud detection, notifications).
Experience with a data orchestration framework such as Airflow, AWS Step etc.
Experience with big data processing tech such as Spark, Hadoop etc.

Perks

Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",sf,de
8,Accenture,Business Services,4,Data Engineer,"San Francisco, CA",$84K - $156K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=37049&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_2cf71bf8&cb=1618797229676&jobListingId=4006684659,"We are:

Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence.

You Are:

A Data Engineering pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.

The Work:

Lead a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.
Design and build Big Data and real-time analytics solutions using industry standard technologies and work with data architects to make sure Big Data solutions align with technology direction.
Lead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.
Keep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.
Pinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.
Show a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers’ needs within deadlines.
Collaborate with research teams working on a variety of deep learning and NLP problems.

Here's what you need:

Bachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.
Minimum of 1 years of expertise in designing, implementing large scale data pipelines for data curation using Spark/Data Bricks in combination with Scala.
Minimum of 1 year experience with cloud platforms-Azure,AWS,or GCP
Minimum of 1 year of experience with using SQL in relational database management

Bonus points if:

Minimum 1 year working with Machine Learning technologies.
Cloud platform certification

Important Information:

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. Our rich diversity makes us more innovative, more competitive and more creative, which helps us better serve our clients and our communities.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.

Unless expressly indicated, this role is not open in the state of Colorado.",sf,de
9,Surya Systems,Information Technology,3.9,Data Engineer,"San Francisco, CA",$88K - $90K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_82133a9d&cb=1618797229676&jobListingId=4063487391,"OverviewTitle: Senior Data EngineerLocation: RemoteDuration: Long TermRequired Skills:As a Data Engineer you will build curated datasets and make them accessible to our partner teams by writing at scale production data pipelines. Your work will enable the decision-makers across the service operations organization to bring together insights and support our operations strategy and customer experience. In every decision that you influence, you will see the product safety improve and be more valuable to Twitter users.In this role you will:Design, develop, and launch extremely efficient and reliable data pipelines to move data and to provide intuitive analytics to our partner teams.Make Twitter-scale data more discoverable and easy to use for Data Scientists and Analysts across the service operations organizationCollaborate with other engineers and Data Scientists to discover the best solutions.Diagnose and solve issues in our existing data pipelines and envision and build their successors.QualificationsQualifications:Good understanding of one or more of the following: Python, Scala, or JavaStrong understanding of SQLBroad knowledge of the data infrastructure ecosystemExperience with Hadoop or other MapReduce-based architecturesExperience working with large data volumesExperience in building Data Warehouses and data modeling.Experience with any of the following is a plus:BigQuery, Presto, or HiveScalding, Spark, DataFlow, or Airflow2:32Please let me know if this looks fine.",sf,de
10,Nisum,Information Technology,3.8,Data Engineer,"San Francisco, CA",$124K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=148364&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_bc13f1a3&cb=1618797229677&jobListingId=4061334766,"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “Building Success Together®,” Nisum has grown to over 1,400 professionals across the United States, Chile, India, and Pakistan. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels.What you will do:As a Big Data engineer, you need to be intimately familiar with assembling large, complex data sets to satisfy functional and technical business requirements. Analytical skills related to working with unstructured datasets Optimize data delivery, automate manual processes, re-design infrastructure for improved scalability and identify, design and implement data ingestion, data delivery process improvements.Collaborate with analytics, data scientists and product teams to assist in building and optimizing innovative products and services to marketDevelop analytics tools that utilize data pipeline to provide actionable insights into customer acquisition, operational efficiency and key business performance metrics.Build big data pipelines, data sets and conduct performance tuning Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.Keep data separated and secure across architectural boundaries through multiple data centres and AWS regions.What you know:5+ years of experience in a Data Engineer role preferably in AWS with PySpark and SQLExperience with big data tools: Hadoop, Spark,Experience with relational SQL and NoSQL databases such as Cassandra.Experience with AWS cloud services: EC2, EMR, Athena Experience with object-oriented/object function scripting languages: Python, Java,Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as familiarity with unstructured datasets.Experience supporting and working with cross-functional teams in a dynamic environmentEducation:Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.",sf,de
11,Glu Mobile,Information Technology,3.9,Data Engineer,"San Francisco, CA",$151K - $166K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_be02fd43&cb=1618797229678&jobListingId=3663508940,"Team OverviewThe Data Engineering team at Glu builds core data infrastructure and applications in support of all areas of our business, including our studio teams, user acquisition, monetization and finance. Glu is passionate about maximizing the value that data and analytics can provide to the business and is aggressively investing in new capabilities. Our team covers a lot of ground from data ingestion through to machine learning applications.Role OverviewWe leverage a cutting-edge tech stack to build both batch systems (YARN+Spark/Hive) and stream processing applications (Kinesis/Flink/Spark Streaming/Druid) that operate efficiently at high scale. The ideal candidate has a strong engineering background and has built robust data platforms and pipelines and takes complete ownership of their area of expertise. This is a fantastic opportunity to use your engineering skills to make a material impact on a highly valued analytics platform.You'll most often be:Taking ownership of and developing critical new features for our next-generation analytics platform, supporting Glu's worldwide studios and central functions such as marketing and financeBuilding scalable, accurate and extensible stream processing applications using cutting-edge technology such as Spark Streaming and Apache FlinkImplementing complex and highly scalable end-to-end data pipelines, using Elastic Beanstalk, Kinesis, EMR, Spark, Hive, Druid, CassandraBuilding data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applicationsAnd your skills and experience include:Bachelor's degree in computer science/mathematics/engineering, or other fields with proven engineering experienceMore than 3 years of software engineering experience, especially working on back-end data infrastructureProficiency with at least one of the following languages: Java, Python, ScalaExperience with distributed stream processing technologies such as Flink, Spark Streaming and/or Kafka StreamsExperience with AWS Ecosystem, especially Kinesis, EMR, Lambda, and GlueKnowledge of NoSQL application data stores i.e. Druid, HBase, Cassandra, DynamoDB, RedisBonus points:Experience with high-scale machine learning, i.e. Spark M/L, SageMaker, etcExperience with SQL and SQL-like languages, especially HiveExperience with CI/CD process, testing framework, and containerization technologyExperience building data-rich web applications, especially with technologies like Angular, Node.js, and Elastic BeanstalkAll qualified applicants will receive consideration for employment. Glu is an equal opportunity employer committed to diversity in the workplace. We welcome people of different backgrounds and experiences to ensure a diverse and inclusive workplace.”",sf,de
12,Project Ronin,Information Technology,4.9,Data Engineer,"San Mateo, CA",$106K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=148364&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_66251434&cb=1618797229678&jobListingId=3671990632,"About the Opportunity:Our data engineering team is at an exciting juncture where they are developing a data ecosystem that will work dynamically with hospital systems, research institutes and other cancer data systems. The data engineering team will be a partner to the data science team ensuring the data that is collected is curated for them to create the best predictive models in the cancer care industry. As an early engineer to join the Data Platform Team, you will develop complex distributed streaming systems that ingest and process data arriving from and delivered to our partner healthcare systems. Additionally you will develop a Data Insights Platform, that will power ML workloads, in partnership with the Data Science team. You will learn and build healthcare knowledge graphs that will be central to improving outcomes for cancer patients.We are looking for Sr. Data Engineers to join our dynamic team and bring their passion for data engineering with them! What You Will Do:Integrate with healthcare APIs such as HL7 & FHIR to build ELT/ETL pipelines that store, transform and aggregate data to power our data science workloads and fuel our provider- and patient-facing applications.Define the core data models abstracted from the Electronic Health Records (EHR)Assess the existing data ecosystem; leverage existing APIs & build new ones to consume structured and unstructured data sets.Partner, develop and own the cloud-based data management platform that will define and change the way we work with data.Be an active participant in: Architecture reviews, code reviews, general agile processes, the development and mentorship of engineers, and building a strong engineering culture while advocating practical sophistication.What We're Looking For:5+ years of big data and software engineering experienceSolid expertise and skills in object-oriented and functional programming paradigms and implementations using Scala, Python, Elixir or similar language.Microsoft Azure, Amazon Web Services, Google Cloud Platform or similar cloud platform architecture experience involving analytic systems.Hands-on experience with distributed data technologies: Kafka, Spark, Flink, etc.Experience with analytics applications using one or more of the database technologies, such as OLTP, OLAP, key-value, document-oriented, and graph.Experience building reliable, performant streaming & batch processing data pipelines.Strong communication skills, both written and verbal.Project Rōnin is filling one of the greatest gaps in patient care to date. Our mission is to increase the length and quality of every persons’ life who has been affected by cancer. This year alone there will be nearly 1.8 million new cancer diagnoses, and the tools oncologists are using haven’t been updated in 20 years. With our platform, communication between patients and their doctors is optimized through an individual care platform that is already having an immediate impact. Want to learn more?LinkedinMediumOur ValuesAvoid the confidence gap. If some of the above describes you, we’d love to chat and see where your skills can add to our team.We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status.",sf,de
13,Agama Solutions,Information Technology,3.9,Data Engineer,"San Francisco, CA",$70K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_90eca952&cb=1618797229678&jobListingId=4008041057,"Title: Data EngineerLocation: San Francisco, CAPosition Type: Long TermJob Description:Creating AWS infrastructure for Salesforce syncs to/from RedshiftManaging AWS infrastructure as code using TerraformUnderstanding of AWS IAM roles and VPC connectivity are important.Creating scripts to be run on said AWS infrastructure that performs the sync.Uploading script deployment packages to AWS and GitManaging code on a properly secured secret storage system so that passphrases/secrets are not committed directly in source code to AWS/GitGood understanding of Salesforce APIs and platform behaviorSkill set:Python (or Go Lang), AWS Lambda, AWS S3, AWS EC2, AWS Redshift, AWS Postgres, Informatica and SFDC config if not dev.",sf,de
14,Udemy,Education,4.8,Data Engineer,"San Francisco, CA",$126K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=148364&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_aa35c0f8&cb=1618797229678&jobListingId=4036643455,"As part of the Finance team, the Financial Data engineer will assist with designing and implementing a functional Financial Data warehouse to support the preparation/gathering of financial data, delivery of stakeholder reporting, month-end reporting, monthly financial reporting, and ad hoc analyses. In this role, you will be the technical lead of the Enterprise data team. You will support our Snowflake data warehouse, and develop and maintain pipelines to and from other data sources. You will represent the finance team in working with the Production Data and Engineering teams to develop a financial data warehouse. You will create and maintain reporting infrastructure for Finance, gather and drive execution of requirements from Finance and design processes and reports to meet those requirements.Here's what you'll be doing:Partner with the Finance team and other business areas to be the data expert on key initiatives at Udemy including projects focusing on revenue attribution models, understanding performance marketing, tax income classification, and other financial projectsAssist in the development and delivery of all reports in a streamlined, timely, and efficient manner in accordance with the agreed upon calendarDevelop and implement databases, data analytics, and other strategies that optimize reporting efficiency and qualityAcquire data from primary or secondary data sources and maintain databases/data systemsIdentify, analyze, and interpret trends or patterns in complex data setsFilter and “clean” data by reviewing queries / reports and performance indicators to locate and correct code problemsMaintain / create the financial accounting and reporting process documentation and ensure detailed work instructions are developed for the roleWork with the Finance teams and the broader business to gather reporting requirements from the Data Warehouse and identify future development requirements for changes in the data warehouseDevelop good working relationships with Reporting and Accounting customersEnsure adherence to Group accounting policiesProvide information to the external parties as required. Escalate issues to the Finance, Business Systems, and other leads as appropriateIdentify improvement opportunities, generate ideas, and implement solutionsWork with the Global management team to prioritize business and information needsWe're excited about you because you'll have:3-5+ years of full-time experience working in data engineering, data infrastructure, or equivalentExperience maintaining Snowflake infrastructure and Fivetran ETL pipelines. Experience with Tray.io a plusExcellent skills in SQL, Excel required and familiarity working with Netsuite, Workday, Salesforce, Redshift and Looker is advantageousProven ability to create and develop good working relationships to facilitate the accomplishment of work goals, coupled with the ability to gain commitment from othersExperience with infrastructure as code tools such as Terraform, Ansible and PackerCapable of working on own initiative and also part of a teamExcellent analytical skills and ability to identify and analyze problems and potential improvements, and propose and implement solutions#LI-UL1About UdemyWe believe anyone can build the life they imagine through online learning. Today, more than 40 million students around the world are advancing their careers and passions by exploring and mastering new skills on Udemy, and expert instructors are able to share their knowledge with the world. Through our global marketplace and our solutions for businesses and governments, we connect people everywhere with the skills they need for success in work and life. We’re a close-knit bunch that enjoys problem-solving and collaboration, and we share a serious belief in the power of learning and teaching to change lives. Udemy’s culture encourages innovation, creativity, passion, and teamwork. We also celebrate our milestones and support each other every day.Founded in 2010, Udemy is privately owned and headquartered in San Francisco’s SOMA neighborhood with offices in Denver (Colorado), Dublin (Ireland), Ankara (Turkey), Gurugram (India), and São Paulo (Brazil). Udemy in the NewsUdemy Adds More than $1 Billion To Its Valuation in New Funding RoundUdemy’s Workplace Learning Tool Just Surpassed $100M in ARRPaid Paternity Leave Should be the Norm in the U.S.Breakdown of Most In-Demand Skills for 2020—Finance, Marketing, Sales and EngineeringHow Investing in Yourself Today Will Set You Up for Career Success TomorrowFeedback Isn’t the Problem, but the Way That We Deliver It Is Broken",sf,de
15,Uber,Information Technology,4,Software Engineer (Data Platform) - Freight,"San Francisco, CA",$74K - $142K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_f57383d7&cb=1618797229679&jobListingId=4037083589,"About Uber FreightUber Freight connects shippers with truckers, much like the way Uber connects riders and drivers. The Freight team believes that empowering truck drivers will bring more open, efficient, and increasingly safer transportation to our roads. We are a team of sharp, entrepreneurial individuals bringing technologies, algorithms and lessons from Uber’s core business into the $700B U.S. Transportations & Logistics industry. Comprised of Uber veterans and newcomers, we are looking for candidates who share our enthusiasm for disrupting today’s toughest challenges in transportation. We are a Customer Obsessed team, and care deeply about our users, continually looking for opportunities to improve their lives.About the RoleData is the true differentiator for Uber Freight in the long run. We need your help to build out the data flywheel at Uber Freight. Better data will enable the team to build better products: understanding carrier preferences helps us surface the right shipment at the right time. In turn, better product offerings will attract more usage and generate more data for the team to leverage. You will work cross functionally with Data Scientists, Product Manager, Business Analyst and other Backend Engineers to make this happen.Basic QualificationsMinimum of 2+ years software development experienceExperience with large-scale distributed storage and database systems (SQL or NoSQL, e.g. MySQL, Cassandra, Hadoop)Experience in working on large-scale distributed systemsExperience developing backend micro-services (Golang, Java or Python)CS degree or equivalent experiencePreferred QualificationsDeep understanding on big data architecture and hands on building pipelines/frameworks/services (e.g. Hadoop, Hive, Hdfs, Kafka, Presto etc.)At least two (2) years of software engineering experienceDemonstrated experience working collaboratively in cross-functional teamsExperience working in organization of different data maturity. You not only know what a mature data organization looks like but you also have opinions on how to plot a path thereKnowledge of the logistics and freight industry a plus",sf,de
16,Amobee,Business Services,3.8,"Architect/Lead Software Engineer, Applications","Redwood City, CA",$86K - $172K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1021349&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_cbea9065&cb=1618797229680&jobListingId=4035342994," The Amobee Applications Engineering Team play a significant role in that we are the face of our technology platform to our customers, users, and partners. Our team maintain a constant focus on innovations across our technology stack in order to design and implement new and powerful features that make our platform more scalable, high performance, resilient, user friendly, and ultimately ready to deliver a better ROI to our customers. Our team build and maintain all client facing interfaces (e.g. web app, APIs,..etc) to enable our customers to build audience, plan and execute against various media types, act on cross-channel reporting and analytics available on the platform.We are mostly full stack engineers with exposure to everything – back-end, front-end, and everything in between. The collaborative nature of the team allows you to constantly learn new things. You’ll collaborate closely with other product and technology leaders to jointly chart the platform roadmap. You’ll work closely with other software engineers across the engineering organization to innovate on our platform architecture, and to continue building a world-class technology platform.  Responsibilities Serve as technical/development lead on major company initiatives Review architecture and technical design on key projects Collaborate with Product to validate use cases and requirements Lead integration testing across multiple engineering teams.  Provide technical mentorship to junior engineers Influence and evangelize new software technologies to other team members Work closely with other software architects to make engineering wide architecture recommendations and decisions Experimenting with new ways of visualizing large amounts of data Continuous usability improvements on complex workflows Ensure our technology stack stays current Passionate about building a World class Technology PlatformQualifications Degree in Computer Science or equivalent 4+ years of software development experience High degree of comfort in Java or other object-oriented language Experience with scalable, high performance, multi-tier, enterprise application development Familiarity with JavaScript frameworks such as Angular or React. Knowledge of application frameworks like Spring. Experience with data storage technologies Experience with queuing and messaging frameworks Experience with service oriented architecture Keen sense of information architecture and visual design Motivated by writing fast, scalable code with testability in mind Strong problem solving skillsExcited by working in a fast-paced environment#LI-AR1About Amobee The world’s leading independent advertising platform, Amobee unifies all advertising channels—including TV, programmatic and social—across all formats and devices. We provide marketers with streamlined, advanced media planning capabilities powered by in-depth analytics and proprietary audience data. Our platform and technology, provides the most advanced advertising solutions for the convergence of digital and advanced TV— including linear TV, over the top, connected TV, and premium digital video. Enabling advertisers to plan and activate across more than 150 integrated partners, including Facebook, Instagram, Pinterest, Snapchat and Twitter. Amobee has been named to Fortune’s Top 10 Best Workplaces in Advertising and Marketing. Amobee’s platforms have been widely recognized amongst our industry winning numerous awards in technology innovation, see all Amobee Awards. We are a wholly owned subsidiary of Singtel, one of the largest telco companies in the world, reaching over 700 million mobile subscribers in 21 countries. Amobee operates across North America, Europe, Middle East, Asia and Australia. For more information, visit amobee.com or follow @amobeeIn addition to our great environment, we offer a competitive base salary, employee development programs and other comprehensive benefits. Please send a cover letter along with your resume when applying to the position of interest located at Amobee.com. We are an Equal Opportunity Employer. No phone calls and no recruiting agencies, please.",sf,de
17,Varo Money,Finance,3.9,Senior BI Data Engineer,"San Francisco, CA",$117K - $209K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_db877fe9&cb=1618797229680&jobListingId=3804227200,"ABOUT VAROVaro is an entirely new kind of bank. All digital, mission driven, FDIC insured, and designed for the way our customers live their lives.We're on a mission to bring financial inclusion and opportunity to all hard-working Americans. Through our mobile app, we offer premium bank accounts that have no minimum balance requirement or monthly account fees, high-interest savings accounts, short term lending and solutions to help customers stretch their paycheck, build credit and start saving. Our tech-first products are designed to make money work for everyone and help customers and communities build greater financial resiliency.Varo is distinct from other fintechs: we've made history as the first and only consumer fintech to be granted a full national bank charter by the Office of the Comptroller of the Currency (OCC).Varo Bank represents the evolution of a new generation of banks that are born from innovation and built on technology to empower consumers and businesses.Our team combines the best of both consumer tech and banking, and we’re wildly passionate about helping our customers. Our teams are based in San Francisco and Salt Lake City. Privately held, we’ve raised over $482M to date, from leading institutional investors and strategic partners including Warburg Pincus, The Rise Fund, Gallatin Point Capital, Harbourvest Partners, Progressive Insurance, and Russell Westbrook Enterprises.Varo is entrepreneurial, collaborative, enthusiastic, customer-oriented, fast-paced, and multicultural. This is an open and relatively flat organization that puts an emphasis on collaboration, sharing ideas and information. For a relatively early stage company, Varo is grounded in a strong set of values and takes pride in the diversity of its employees and board.Varo. A bank for all of us.ABOUT THE ROLEAs a Senior BI Data Engineer, you will play a critical role in implementing a variety of solutions to ingest, process and provision data to/from Varo’s Data Lake. The Varo Lake enables Varo’s data capabilities in Tableau reporting, analytics and allowing scientists to explore data in automated and self-service models.As a technical contributor, you will take ownership of development for processing and analyzing data across the data platform.WHAT YOU'LL DODevelop integration between Data Lake and Tableau Online, automation processes, using Python and Tableau Rest APIsDesign, develop and maintain workflows and mappings, using the appropriate data load technique for storing dimensions and enterprise KPIs, using Python and AWS tools.Debug and tune data integration processes; process controls, troubleshoot and recommend improvements and alternate methodologies.Participate in code reviews and ensure that all solutions are aligned to pre-defined architectural and requirement specificationsProvide production support to ensure timely completion and availability of data for reporting use. Analyze, resolve problems and provide technical assistance as is necessary.Participate in design reviews and provide input to the design recommendations; provide input to information/data flow, understand and comply with Agile Methodology in all planning stepsWork closely with Product Analytics team in order to design the best solution to support Varo Enterprise ReportingPREVIOUS SKILLS AND EXPERIENCES THAT'LL HELP YOU BE GREAT Bachelor's degree in Computer Science, MIS, Engineering or related field, or relevant work experience5-7 years programming experience in Python with calling third party APIs5-7 years experience in SQL and database development5+ data modeling, data warehouse experienceAbility to drive to success in both independent and group projects.Ability to deliver results quickly in fast-paced environment.Experience working within the AWS (Glue and Athena) and Tableau is a plusPrevious role working in Banking or Lending is also a bonus!CULTURAL ALIGNMENTVaro is entrepreneurial, collaborative, enthusiastic, customer-oriented, fast-paced, and multicultural. This is an open and relatively flat organization that puts an emphasis on collaboration, sharing ideas and information. For a relatively early stage company, Varo is grounded in a strong set of values and takes pride in the diversity of its employees.OUR CORE VALUESCustomers First: Understand the problems our customers are trying to solve. Respond with a sense of urgency. Build relationships that result in loyalty. Be data and insights-driven. Test everything. Achieve results through strong execution. Build a product people love. Assess new initiatives with the customers’ interest in mind. Act with empathy.Take Ownership: Bias towards action. Have high standards. Be accountable for the results of your work, our product, our company. Trust others to own it.Respect: Treat others how you want to be treated. Listen first before being heard. Speak the truth even when it's not easy. Assume best intentions. Bring your full self to work.Stay Curious: Ask why. Dare to make things better. Learn something new each day (even from mistakes). Be open to growth. Develop creative solutions.Make it Better: Think big. Set high goals. Work towards long term value rather than short term wins. Create change. Be resilient.Varo is an equal opportunity employer. Varo embraces diversity and we are committed to building teams that represent a variety of backgrounds, perspectives, and skills. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",sf,de
18,iknowvate technologies,Information Technology,3.1,Data Engineer,"San Francisco, CA",$110K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_8b8f1177&cb=1618797229680&jobListingId=3663497084,"San Francisco, California - United States | Posted - 07/24/20OverviewData EngineerJob Description and Responsibilities.1.Experience in service management in Google Cloud Platform and exposure to GCP, AWS or Azure.2.Proficiency in web service design using RAML, YAML (with JSON) and ODATA.3.Experience in building common services framework for logging, error handling, auditing, policy management, authentication and authorization.4.Experience in building microservices using Springboot, GraphQL, Camel, etc.5.Good understanding of Microservice architecture with experience of server administration and physical deployment (On Cloud, On Premise and Hybrid).6.Experience in integration with CRM (Microsoft Dynamics and Salesforce), Cloud solutions (Adobe Campaign), Tibco EMS, Databases (Cassandra and RDBMS) and Streaming platforms (Kafka).7.Experience in source control management using GIT8.Experience in Continuous integration and Continuous deployment using Maven, Jenkins, Docker, Kubernetes and Springboot.9.Experience in other programming languages like python, scala, etc10.Experience in integration with logging and monitoring tools like Splunk, Prometheus, Grafana, etc.11.Perform IT resiliency experiments by injecting failures into distributed system to improve the systems resiliency12.UI experience is an added advantage.GCP, Kubernetes, Docker, Springboot, GraphQL, Istio, Spinnaker, Cassandra",sf,de
19,SADA,Information Technology,4.8,Senior Data Engineer,"San Francisco, CA",$86K - $160K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b59f5272&cb=1618797229680&jobListingId=3663496793,"Join SADA as a Sr. Data Engineer!Your MissionAs a Sr. Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes and data warehouses.You will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as lead client-facing technical discussions for established projects.Pathway to Success#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers, and the consultative polish you bring to customer interactions.As you continue to execute successfully, we will build a customized development plan together that leads you through the engineering or management growth tracks.ExpectationsRequired Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.Job RequirementsRequired Credentials:Google Professional Data Engineer Certified or able to complete within the first 45 days of employmentRequired Qualifications:Mastery in at least one of the following domain areas:Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.Experience writing software in one or more languages such as Python, Java, Scala, or GoExperience building production-grade data solutions (relational and NoSQL)Experience with systems monitoring/alerting, capacity planning and performance tuningExperience in technical consulting or customer-facing roleUseful Qualifications:Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)Experience with IoT architectures and building real-time data streaming pipelinesExperience operationalizing machine learning models on large datasetsDemonstrated leadership and self-direction - a willingness to teach others and learn new techniquesDemonstrated skills in selecting the right statistical tools given a data analysis problemAbout SADAValues: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.Make them raveBe data drivenBe one step aheadBe a change agentDo the right thingWork with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match, professional development reimbursement program as well as Google Certified training programs.Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",sf,de
20,Uber,Information Technology,4,Sr Software Engineer - Big Data | Capacity Engineering,"San Francisco, CA",$97K - $181K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_c594c168&cb=1618797229680&jobListingId=4036974108,"About the RoleUber is one of the fastest growing tech companies in history. Supporting this rapid business growth while developers add features creates a variety of reliability and efficiency challenges. We must ensure we have enough resources to operate the business and our software is stable and performant.Uber is on the lookout for an outstanding Software Engineer, with a specialization in Data Engineering, to join our Capacity Engineering team in San Francisco. As a Data Engineer, you will help define a holistic vision and build an Infra Data Warehouse solution across a wide variety of focus areas such as capacity planning / management, forecasting, fleet-wide usage monitoring, distributed tracing, benchmarking, budgeting and ordering of hardware. All to help grow Uber’s infrastructure while collaborating with shared platform teams, service owners, finance, data scientists and infra leaders.What You’ll DoDesign and develop large scale distributed systems such as data warehouses and big data pipelines.Build scalable, reliable, secure, efficient and highly performant platforms and infrastructure for a variety of analytics and business applications.Develop and maintain data tools and solutions (e.g., pipelines, models, tables) to acquire, process, and store data by ensuring the accessibility, reliability, and quality of data for end users.Apply techniques of capacity management, security, and optimization to store, maintain, modify, and output data.Applying data modeling techniques to organize and transform data into meaningful and valuable output.Profile large quantities of data to provide appropriate recommendations for products and/or processes.Design and implement automated monitoring for data quality issues that scales with a rapidly expanding warehouse.Basic QualificationsBS or MS in Computer Science or a related technical field, or equivalent experience.3+ years of experience building and managing distributed systems. Sound understanding of distributed system fundamentals.Proficient in one of the following programming languages: Go, Java, C/C++. Good scripting skills and the ability to pick up new ones.Experience with data engineering, data pipelines, big data systems, data science, SQL, analyticsPreferred QualificationsSystematic problem solving approach and knowledge of algorithms, data structures and complexity analysis.Familiarly with different types of data serialization formats such as Parquet, Avro and Protobuf.Understanding of big data infrastructure tools and software such as Kafka, HDFS and Hive.Experience with a relational database (MySQL, PostgreSQL)Grit, drive and a strong sense of ownership coupled with an appetite for collaboration.Bonus points if: You have experience with time-series forecasting or anomaly detection systems, Machine Learning and/or advanced statistical modeling experience.At Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 10,000 cities around the world.We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let’s move the world forward, together.Uber is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires accommodation, please let us know by completing this form.",sf,de
21,Crunchyroll,Information Technology,3.1,Data Scientist,"San Francisco, CA",$81K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_da76fb42&cb=1618797229681&jobListingId=4036911996,"Who We AreWe're a cast of characters working to shine a spotlight on anime. Crunchyroll is an international business focused on creating both online and offline experiences for fans through content (licensed, co-produced, originals, distribution), merchandise, events, gaming, news, and more. Visit our About Us pages for more information about our collection of brands.Crunchyroll COVID-19 Hiring StatusCrunchyroll employees are currently working from home, and we are still conducting remote interviews and hiring during this time. This role is expected to start remotely, and we'll work closely with you as we understand every person has unique circumstances.Location: San FranciscoOur headquarters is located in downtown San Francisco, where our group of cross-functional experts assemble to create experiences for our passionate communities.About the TeamAt Crunchyroll, our motto is simple - we champion the extraordinary by super-serving our super-fans. Say that 5 times fast! What better way to do so than by helping our millions of fans across the globe discover their next favorite show?We are a low ego team that takes on not-so-humble challenges. From supporting the reporting needs of a few partner teams way back in 2015, to building a widely used data platform that provides custom solutions to multiple downstream consumers today; our journey has been exciting, celebratory, and informative.With our data platform, we now power reporting, personalization, analytics and other cross-functional integrations.Join us in improving and building new personalization features for each of our superfans.Our values as a team - we love opensource, encourage collaboration, value opinions, and cultivate continuous learning.P.S. Check out this recent article for a peek into how we evolved our personalization efforts to get to where we are today.Location: San FranciscoOur headquarters is located in downtown San Francisco, where our group of cross-functional specialists assembles to create experiences for Crunchyroll and VRV's hardworking communities.A day in the life of our Data Scientist:Assist with building out Data Science and ML capabilities and help drive the execution of an extraordinary multi-year roadmap that impacts both our top line and bottom line. They will collaborate closely with other data scientists to deliver on these efforts.Will be responsible for owning and improving Crunchyroll's personalization algorithms and associated infrastructure.Will be responsible for improving the experimentation framework by building out a comprehensive A/B testing strategyWill collaborate with data engineers in building a cross-functional feature repositoryWill work closely with product teams in architecting, designing, and implementing features that scale.About You:Bachelor's Degree in computer science or equivalent experienceBasic understanding of computer science fundamentals3+ years of Statistics, Data Science, or Data Analysis backgroundComfortable with complex SQL queryingComfortable working with large datasets1+ years of experience in at least one programming language, preferably PythonBasic understanding of software architecture, object oriented design, and design patterns.Experienced in conducting experimentation (A/B testing)Basic understanding of some public cloud, preferably AWS. Additional familiarity of associated cloud resources (S3, EC2, RDS etc.) is a plusBasic knowledge of Data Engineering, Database technologies and distributed systemsExperience working in an agile environmentComfortable with using Github or similar tool for version controlBenefits: San Francisco Office:Competitive salary""Use What You Need"" time away from work policyMedical, dental, vision, STD, LTD, and life insuranceHealth care and dependent care FSA401(k) plan with employer matchEmployer paid commuter benefitOn-site gym, showers, yoga, and wellness classesCatered lunch and dinner 4 days per weekSkilled, passionate, and fun co-workersPet friendly environment - pet insurance and dog friendly officeQuestions about Crunchyroll's hiring process? Please check out our FAQPlease beware of recent scams to online job seekers. Those applying to our job openings will only be contacted directly from @crunchyroll.com and @ellation.com email accounts. If you have any questions of the authenticity of an Ellation or Crunchyroll job offer, please contact recruiting@crunchyroll.com before giving away any information.About CrunchyrollCrunchyroll connects anime and manga fans across 200+ countries and territories through the content they love. Best known as a top streaming service delivering AVOD and SVOD content, Crunchyroll also provides experiences to deepen fan engagement and community through social, events, games, consumer products, content distribution, content creation, and manga publishing.Fans have access to the largest collection of licensed anime through Crunchyroll, Anime Digital Network (in partnership with Citel, a subsidiary of Média-Participations), and Anime on Demand video streaming services, translated in multiple languages for viewers worldwide. Viewers can also access simulcasts — top series available immediately after Japanese broadcast. Crunchyroll's services also extend to licensing of theatrical, TV, home video, and consumer product rights.Fans engage further with events (including owned events Crunchyroll Expo, Anime Awards, Crunchyroll Movie Nights, KAZÉ Movie Nights), consumer products through eCommerce and retail partners (Crunchyroll, KAZÉ, AV Visionen), Crunchyroll Games, KAZÉ Games, and manga (KAZÉ Manga, Crunchyroll Manga app, Crunchyroll Manga Store).Crunchyroll was founded in 2006 and is headquartered in San Francisco, with offices in Los Angeles, Tokyo, Paris, Chisinau, Lausanne, and Berlin (AV Visionen). VRV (U.S.) and Eye See Movies (Germany) are also Crunchyroll brands.Our Company ValuesYou'll see these in action if we're lucky enough to have you:Embrace Originality - We've taken different paths to get here - but we're in it together to win in animeFuel Passion - Understanding fandom makes us better at what we doChampion Change - We're agile and see change as an opportunity to lead by exampleHustle Intentionally - As fans of our fans, we always want to do more - but we're deliberate in our pathElevate Anime - We're showing the world how special anime isWe are an equal opportunity employer and value diversity at Crunchyroll. Pursuant to applicable law, we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",sf,de
22,Acumen LLC,Government,3.5,Data Engineer I,"Burlingame, CA",$60K - $111K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a14b830d&cb=1618797229681&jobListingId=4037170254,"Are you someone who enjoys working with data? Are you a self-motivated thinker who wants to make an impact in the fast-growing healthcare data industry?We are looking for an entry-level Data Engineer who highly values research, wants to work with multifaceted datasets, and craves new challenges in programming. As a Data Engineer, you will have the opportunity to gain first-hand experience integrating and structuring the healthcare data that shapes policy on many key topics, such as the Affordable Care Act, Medicare, and Medicaid. You will also have the chance to work closely with seasoned programmers, developing the skills to work with data management tools and various programming languages. In addition, you will work alongside smart, vibrant people with a passion for the exciting future of healthcare research.The Data Engineer will:Extract, transform, and load (ETL) big data.Develop complex data processing algorithms that combine multiple data sources, while optimizing run-time efficiency.Develop data structures, databases, and querying programs which facilitate efficient data access.Develop data structures from claims and enrollment data which support research and analytic activities of in-house analysts as well as congressional and federal agencies.Ensure data inventory is complete and accurate through application design, including fault analysis and detection, quality control, and the development of tracking systems.Collaborate with other Data Engineers and in-house researchers to maintain systems, produce documentation, and educate internal and external users about company resources.Perform validation checks across multiple sources to verify data integrity as needed.Perform other duties and responsibilities as assigned.Qualifications RequiredA Bachelor’s in Computer Science, Statistics, Mathematics, Operations Research, Economics, Public Health, or related field with quantitative emphasisStrong organizational, planning, and problem solving skillsTeam player with strong interpersonal skillsExcellent written and oral communication skillsFamiliarity with one or more computer programming languagesQualifications DesiredMaster’s in Information Management Systems, Statistics, Mathematics, Operations Research, Economics, Public Health, a related field with quantitative emphasis, or 2+ years of work experience in a field with quantitative emphasisInterest in big dataInterest in making an impact in the field of healthcare policy researchPrevious experience in a Data Analyst/Data Engineer position1+ years of experience working with programming languages such as SAS, SQL, Python, or R1+ years of experience working with databases or data pipelining toolsPlease submit a cover letter and resume to be considered for this position.Due to the sensitive nature of much of our work, all Acumen employees must undergo a background check. Your employment will be contingent upon your completing, and Acumen reviewing to its satisfaction, a mandatory background check. Employees who work with particularly sensitive information may be asked to undergo an additional background check after starting work. Please note this additional background check requires a minimum of three years' residency within the United States.Required SkillsRequired Experience",sf,de
23,Evoke Technologies,Information Technology,4,Data Engineer/ Data Architect (Big Data),"San Francisco, CA",$115K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=4134&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_c19817a4&cb=1618797229681&jobListingId=4059024449,"Company DescriptionFrom our world-class culture to our generous benefits, to developing cutting edge technology solutions, Evoke Technologies constantly works towards its mission of creating a profitable growth company that is a great place to work. We encourage our employees to embrace collaboration, get creative and think outside the box when it comes to delivering some of the most advanced technology solutions for our customers.

At a glance, Evoke has over 18 years of rich industry experience and 700+ highly skilled technology consultants. Incorporated in 2003 and headquartered in Dayton, Ohio, Evoke is actively helping global corporations to transform and address critical business issues by applying innovative information technology solutions. Our global delivery and mature engagement models are designed to improve efficiency, governance, and bring predictability, making the sales team's confidence in the company an easy sell to prospective clients.Job Description


Working Exp in Big Data solutions and related technologies


Distributions - Cloudera, EMTRHadoop, SparkData Ingestion and streaming tools etc

Qualifications

Overall 12+ years of exp5+ years in Big Data solutionsStrong Exp in LinuxStrong Exp in JavaWorking Exp in Big Data solutions and related technologies


Distributions - Cloudera, EMTRHadoop, SparkData Ingestion and streaming tools etc.
Working Experience in technology companies and/or research environment - Distributed scalable Big Data store or NoSQL experience - Experience with Apache Hadoop and Hadoop Distributed File System (HDFS), S3 protocol, ObjectStore, and with processing large data stores.Ability to show flexibility, initiative, and innovation when dealing with ambiguous and fast–paced situations.Analytical skills to troubleshoot high-level, complex, and technical problems

Additional InformationThanks / Regards

M: (937) 533 - 4406

mkotipalliATevoketechnologies.com",sf,de
24,"Stefanini, Inc",Information Technology,3.6,Big Data Developer,"San Francisco, CA",$49K - $96K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_9b2137b9&cb=1618797229681&jobListingId=4037242006,"Stefanini is looking for Big Data Developer in CA.Description:Client is looking for a Big Data Engineer to join the Advanced Data and Analytics Capabilities Team.We are a team based out of San Francisco that partners with business lines across the client System to deliver big data and advanced analytics products and solutions.In this role, you will have the opportunity to contribute to several high-quality data solutions and enhance your technical skills across many disciplines.Key ResponsibilitiesDesign, develop, and maintain end to end data solutions using open source, modern data lake, and enterprise data warehouse technologies (Hadoop, Spark, Cloud, etc.)Contribute to multiple data solutions throughout their entire lifecycle (conception to launch)Partner with business stakeholders to understand and meet their data requirementsProvide ongoing maintenance and enhancements to existing data solutionsMaintain security in accordance with Bank security policiesParticipate in an Agile development environmentQualificationsBachelor""s degree in Computer Science, Engineering, or Information Management (or equivalent)5+ years of relevant work experienceProfessional experience designing, creating and maintaining scalable data pipelinesHands-on experience with a variety of big data (Hadoop / Cloudera, Cloud, etc.) and machine learning (Spark, AWS SageMaker, etc.)Experience with object-oriented scripting languages: Java (required), Python, etc.Advanced knowledge of SQL and experience with relational databasesExperience with UNIX shell scripts and commandsExperience with version control (git), issue tracking (jira), and code reviewsProficient in agile development practicesAbility to clearly document operational procedures and solution designsAbility to communicate effectively (both verbal and written)Ability to work collaboratively in a team environmentAbility to balance competing priorities and expectations",sf,de
25,Benchling,Information Technology,4.9,Security Data Engineer,"San Francisco, CA",$152K - $167K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_e34a6fdf&cb=1618797229681&jobListingId=4063777547,"Over the coming years, biotech will fundamentally rewrite the way we live. Gene editing and cell therapy are dramatically changing how we treat cancer and other major illnesses. Biofuels and biomaterials are transforming the cars we drive, the clothes we wear, and the makeup of everyday objects. Crop science and synthetic biology are producing sustainable and ethical food. Benchling’s mission is to accelerate the research that propels us towards this reality, and magnify its impact, through modern software.Every day, scientists around the world use Benchling’s applications, platform, & analytics in their efforts to solve humanity’s most pressing problems. For these scientists, Benchling is the central technology they use to conduct their research. Our customers include pharmaceutical giants, leading biotechs, and the world’s most renowned research institutes.ROLE OVERVIEWAs a Security Data Engineer at Benchling you’ll be joining a team responsible for building a best-in-class security program from the ground up. Our focus is on providing value to the organization by emphasizing real world security and embracing automation to keep up with the company as we experience hypergrowth. We’re looking for engineers who are excited to apply their expertise to our mission of securing some of society's most sensitive data.WHAT YOU WILL WORK ONDesigning, constructing, testing and maintaining a robust, reliable, and scalable security data pipeline infrastructure.Partnering with Security Incident Response Engineers on threat detection engineering (e.g alerts, searches, reports, etc.).Partnering with the multiple engineering teams on internal and customer facing security and privacy initiatives, ensuring that security data accessibility, quality, and reliability are taken into account.Employing an array of technological tools to integrate with 3rd-party data systems.Partnering with Security Engineering, Infrastructure Engineering, and Software Engineering on security feature roadmaps and security architecture.Researching new detection mechanisms for attack vectors and techniques relevant to our space and presenting findings to both internal and external audiences.Developing set processes for data mining, data modeling, and data production.Partnering with Security Incident Response Engineers during incident response and investigations.Evaluating external tooling, developing new automation and tooling.Helping to rapidly scale our team. As a member of the security team, you'll be an integral part of how we mature our own tooling, best practices, engineering processes, and hiring.ABOUT YOU5-10 years of working on backend infrastructure/data systems or with application/infrastructure logging pipelines4+ years of those years of experience in Security Engineering or related experienceExperience writing code, designing systems and data workflows, optimizing data processing algorithms, and systems to support security data analytics.In-Depth knowledge of AWS cloud infrastructure and its associated security suites (e.g., IAM, GuardDuty, Inspector, CloudTrail, CloudWatch, etc)Familiarity with modern infrastructure technologies such as: Docker, Kubernetes, Terraform, Cloudformation, Kinesis.Relevant development experience in at least one scripting language, preferably PythonStrong communicator with both words and data - you understand what it takes to go from raw Security data to something a human understandsComfortable with complexity in the short term but can build towards simplicity in the long termDetection and Response experience (Detection Engineering, Digital Forensics, Incident Response, and/or Threat Intelligence)Technical leadership skills (you enjoy being a tech lead, mentoring technologists, evangelizing security and privacy)Plus: Contributions to the security community via talks, papers, blogs, projects, CVEs, etc.Benchling welcomes everyone. We believe every member of our team enriches our diversity and inclusion by broadening our ways of problem-solving for future challenges. Even if you don't meet 100% of the qualifications for this job, we strongly encourage you to apply.LEADERSHIP PRINCIPLESAdmit mistakes and shortcomingsDeliver resultsDisagree and commitObsess over customersRely on work ethicShow empathyRecruit and develop the bestSweat the detailsThink and communicate clearlyUnite around the missionPERKS AND BENEFITSWork with a talented yet humble teamCompetitive compensation & equity packageQuarterly mental health daysWeekly virtual social events, and annual company retreats401k, Medical, dental, and vision insurance (US Employees Only)Monthly health & wellness stipend (Currently US Employees Only)Yearly educational stipend (Currently US Employees Only)To support remote work conditions, Benchling provides each employee a one-time stipend of $1,000(USD) upon commencing employment, and additional discounted employee purchase plans for home-office equipment.In following best practices and safety protocols, all Benchling employees are expected to work remotely until we are further advised that it is safe for employees to resume work in their respective office locations.",sf,de
26,Uber,Information Technology,4,Software Engineer - Machine Learning Platform,"San Francisco, CA",$105K - $174K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_a16eda04&cb=1618797229681&jobListingId=4037083826,"Uber is on the lookout for top-notch software engineers to join our Machine Learning Platform team. This role involves building and managing robust distributed systems, and solving infrastructure challenges to empower Uber’s product engineering and data science teams with the latest technologies in large scale Artificial Intelligence.The Machine Learning Platform team works on software and services that democratize and empower teams across Uber to use the technology. You will be part of a team of strong software and systems engineers executing in an exciting, dynamic environment. The Machine Learning Platform team is part of Michelangelo. For more information on the Michelangelo team as a whole, please visit our recent blog posts:Meet Michelangelo: Uber’s Machine Learning Platform: http://eng.uber.com/michelangelo/Productionizing Distributed XGBoost to Train Deep Tree Models with Large Data Sets at Uber: https://eng.uber.com/productionizing-distributed-xgboost/What You'll DoDesign and deliver software and tools as part of our state-of-the-art Machine Learning platformSystems architecture design, including management of upstream and downstream dependenciesProvide technical leadership, influence and partner with fellow engineers to architect, design and build infrastructure that can stand the test of scale and availability, while reducing operational overheadDrive efficiencies in systems and processes through automation: capacity planning, configuration management, performance tuning, monitoring and root cause analysisParticipate in periodic on-call rotations and be available for critical issuesCollaborate with platform, product and security engineering teams, and enable successful use of infrastructure and foundational servicesBasic QualificationsBS or MS in Computer Science or a related technical field, or equivalent experienceSound understanding of computer architecture and CS fundamentalsProficient in one of the following programming languages: Java, Go, Python, C/C++Good working knowledge of networking, Linux, Docker, databases, Hadoop, Hive, and/or SparkPreferred Qualifications5+ years of experience of systems software engineeringExperience building and managing distributed systems and high-throughput servicesSystematic problem solving approach and knowledge of algorithms, data structures and complexity analysisGrit, drive and a strong feeling of ownership coupled with collaboration and leadershipExperienced production user of Deep Learning frameworks such as Apache SparkML, XGBoost, Ray, Tensorflow, PyTorch, Keras, etc.Power-user Linux knowledge and willingness to explore Linux internalsExperience managing dependencies in data science packagesExperience in high performance computingAt Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 10,000 cities around the world.We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let’s move the world forward, together.Uber is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires accommodation, please let us know by completing this form.",sf,de
27,Uber,Information Technology,4,Software Engineer (Machine Learning) - Freight,"San Francisco, CA",$95K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_d4cb4309&cb=1618797229681&jobListingId=4037083759,"About Uber FreightUber Freight connects shippers with truckers, much like the way Uber connects riders and drivers. The Freight team believes that empowering truck drivers will bring more open, efficient, and increasingly safer transportation to our roads. We are a team of sharp, entrepreneurial individuals bringing technologies, algorithms and lessons from Uber's core business into the $700B U.S. Transportations & Logistics industry. Comprised of Uber veterans and newcomers, we are looking for candidates who share our enthusiasm for disrupting today's toughest challenges in transportation. We are a Customer Obsessed team, and care deeply about our users, continually looking for opportunities to improve their lives.About the teamsFreight Engineering is tasked with creating the algorithms, systems, applications that power our independent drivers, sales and operations teams, and shippers that need to transport freight across the country. For these different user segments, we create business portals, mobile applications, integrations with third-party systems, and self-learning models that adjust to market conditions in real-time. Most of our work is distributed via the Web and through mobile app stores, interfacing with Uber cores services and running on Uber's compute platform.Marketplace DynamicsThe Marketplace Dynamics team is responsible for building products, algorithms and services that drive pricing efficiencies within our network. The Marketplace Dynamics group works at the intersection of data science & engineering, and develops the decision-making systems to create a healthy central exchange. Alongside our Shipper and Carrier teams, this group optimizes the pricing, matching, and recommendation capabilities across our applications.Basic Qualificaitons3+ years of full-time engineering experienceExpertise in one or more object-oriented languages, including Python, Go, Scala or JavaExperience with distributed storage and database systems, including SQL or NoSQL, MySQL, Cassandra, Hive, Presto or SparkPreferred QualificationsMS/PhD in Computer Science, or related fieldsExperience using machine learning libraries or platforms, including Tensorflow/Pytorch, Caffe, Theanos, Scikit-Learn,or Spark MLLibExperience developing complex software systems scaling to millions of users with production quality deployment, monitoring and reliabilityExperience in stream processing: Storm, Spark, Flink etc.",sf,de
28,BlackBerry,Information Technology,3.4,Senior Application Software Engineer (Full Stack Developer),"San Ramon, CA",$121K - $200K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_daf46da9&cb=1618797229681&jobListingId=4007406875,"Worker Sub-Type:Regular Job Description:We are now accepting application for this opening in the following cities:San Ramon, CAMt. View, CASeattle, WAArlington, TXToday, BlackBerry® is a transformed company. We’re no longer about the smartphone, what we once did for smartphones is what we’re now doing for Enterprise of Things (EoT) – envisioning, enabling and securing new forms of communication that are connecting the business world in extraordinary new ways. We have the most complete and advanced end-to-end solutions to enable EoT, and our ideas lead the way in the hottest markets like cybersecurity, SaaS, neural networks and autonomous vehicles.We have made great strides in executing our business strategy. We are no longer in turnaround mode and focused on growth. With consecutive years of positive operating income and an enterprise cybersecurity software and services business delivering $219m & over 10% year on year growth. Building on the culture of quota achievement and success, you couldn’t consider joining us at a more exciting time.We are looking for a Senior Software Engineer to join our Engineering Team of the AtHoc division of BlackBerry.Working as part of our engineering team, this person will be responsible for full lifecycle development of the BlackBerry AtHoc crisis communication system on the latest .NET platform, from initiation to design, architecture, development, integration and deployment. The Senior Engineer will be working on a sophisticated, large-scale communication platform designed to send millions of notifications over a great range of devices including desktops, smartphones, voice telephony, and SMS.This is a Senior-level engineering role where the individual will be working with a team of Engineers to develop Web Applications, web services, and highly scalable software components. The candidate should have strong object-oriented design and development expertise as well as experience developing highly scalable web-based systems. The individual is responsible for developing enterprise level application involving large amounts of data and communication; undertaking research into new technologies to provide leading-edge solutions to complex problems is an inherent part of this job. This position will require you to work extensively in collaboration with internal teams and participate in cross-functional team meetings, requirements gathering, scoping, decision making, and technical documentation. Strong interpersonal and project management skills are a must.Responsibilities :Drive the development and evolution of our mass notification system platformParticipation in all phases of project life cycle: analysis, design, develop, test, debug, deploy, maintain and updateDevelop, Architect, Design and write high quality, high performance code in front end technologies React, Angular, Node.js, JavaScript, Typescript, Bootstrap, HTML and CSS.Collaborate with peers and seniors both within their team and across the organization.Participate in development life cycle activities like design, coding, testing and production release.Work with product owners using agile methodologies to deliver high quality solutions on time.Work with the other stream team to ensure your applications and services are highly available and reliable.Leading development work with geographically distributed teamsQualifications :BS/MS in Computer Science or related work experience equivalent5 - 8 years of developing scalable & secure enterprise web applications using Microsoft ASP.NET with C#/.NET application frameworkProficiency with C#/.NET Application Framework, ADO.Net, and Web API.3-4 years of UI Interface application design and development is mandatory.Expertise with React/Redux/Saga or Angular will be an added advantage.Database design and development skills with Microsoft SQL Server and T-SQL.Solid object-oriented design and development skills including solid knowledge of core libraries, design patterns.Architecture and design capability and ability to evaluate technology and finalize scalable options.Experience with large-scale distributed systems including performance, scalability, and security.Evaluate, define, recommend and expand scalable architectural solutions for our cloud and on-premise products.Experience with Designing ESRI GIS based Web application.Excellent verbal communication, analytical skill and critical thinking. Be able to communicate openly and frequently with all members of the team.#LI-CW1Job Family Group Name:Product DevelopmentScheduled Weekly Hours:40",sf,de
29,Uber,Information Technology,4,Machine Learning Engineer - Uber AI Recommendations,"San Francisco, CA",$105K - $174K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1044074&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&cs=1_134402f6&cb=1618797229681&jobListingId=4037083742,"Uber AI’s mission is to optimize and innovate Uber’s products and business using machine learning and AI. The group consists of Uber's machine learning platform team which enables machine learning at scale, AI building blocks which enable product teams to build unique experiences and engagements with product teams on their business problems.We are developing a platform around recommendation and personalization across Uber products. We strive to understand our riders, drivers, restaurants and build more personal experience across all users.The group consists of machine learning engineers, mobile engineers, backend engineers and research scientists and engineers.About the RoleUber AI Building Blocks establishes core, reusable ML systems that can be applied across problems. Through close collaboration we deliver innovative Machine Learning/AI solutions for core business problems.We focus on productionizing ML to improve end user experiences and drive the business. As a core offering, we are developing a platform around recommendation and personalization across Uber products. We strive to understand our riders, drivers, restaurants and build more personal experience across all users. As an engineer, you would be responsible for developing and deploying models that are high performant and can operate at high scale (imagine every Uber trip). You will deliver these solutions from inception to production.What You’ll DoDevelop innovative ML/AI solutions for challenging business problems that are fundamental for Uber.Partner with product teams to analyze key business problems.Collaborate with data science and engineering teams to integrate and validate machine learning solutions end-to-end.Deliver enduring value in terms of software and modeling artifactsHelp build a predictions engine that can support a wide variety of personalization and recommendations use cases.Basic Qualifications2+ years of industry experience in applied ML, or a Ph.D. with some industry experience obtained through e.g. internships.Proficiency in Python, JavaExperience running production engineering systemsExperience with ML frameworks such as PyTorch and TensorFlow.Preferred Qualifications4+ years of industry experience in applied ML, or a Ph.D. and 2+ years of industry experience.Experience building, deploying and maintaining models in production systemsExpertise in recommendation systems, or deep learning.Proficiency in one or more coding languages such as Java, Go, C, C++.Experience with any of the following: Spark, Hive, Kafka, Cassandra.Ability to innovate, as proven by a track record of software artifacts or publications.Ability to deliver end-to-end solutions, including data preparation, training, and deployment.Experience working with product teams.Ability to work with ambiguous problem definitions.Proven ability to communicate technical knowledge to a business audience.Collaborative attitude and constructive approach.",sf,de
30,Braintrust,Business Services,5,Data Engineer (NO C2C),"San Francisco, CA",$88K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136006&s=58&guid=00000178e7d573cb968a5ff529a02fdf&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_19abbcd9&cb=1618797229682&jobListingId=4059853680,"JOB TYPE: Freelance, Contract Position - No agencies (See notes below)LOCATION: Remote (TimeZone: BST, CST, EST)HOURLY RANGE: Our client is looking to pay $50 - $60 USD / HRESTIMATED DURATION: 40Hrs/Week - Long Term, 6-month projectHIGH-LEVEL QUALIFICATIONS:ABOUT US:Braintrust (usebraintrust.com) is a user-controlled talent network, where you keep 100% of what you earn and actually get to own the platform. We've been onboarding some big clients and specifically need a Data Engineer for our client.The Position:The primary skill set required would be writing SQL but BigQuery & Python would be also be a helpful skill. You will be working with our data analytics team (~10 people) to gather and execute requirements.Responsibilities:Designing and creating new tables/views in BigQuery to structure the data in a way that is easier to use for reportingAd-hoc data pulls for analysis and export to external partnersTroubleshooting data related issues with reports and finding data quality problems in our existing datasetsData discovery on new sources data being brought into data warehouse and creating data dictionariesExperience with Tableau or Workato are nice to havesABOUT THE HIRING PROCESS:Qualified candidates will be invited to do a screening interview with the Braintrust staff. We will answer your questions about the project, and our platform. If we determine it is the right fit for both parties, we'll invite you to join the platform and create a profile to apply directly for this project.C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.This is a remote position.",sf,de
