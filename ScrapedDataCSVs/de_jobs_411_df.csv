,company,industry,rank,job_title,location,salary_range,link,description,search_city,search_job
0,Deloitte,Accounting & Legal,3.9,"Junior Data Engineer - Austin, TX","Austin, TX",$70K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1008783&s=149&guid=00000178c1db790caf8013cc835522a7&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_95219572&cb=1618160090028&jobListingId=4030709477,"Junior Data Engineer – Austin, TXAre you an experienced, passionate pioneer in technology – a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel?Work you’ll doWe are looking for experienced Data Engineers to build and deliver innovative, game-changing mission-driven data pipelines. On this project, you will be responsible for leading the architecture and setup of hosted data lakes, as well as the ingestion pipeline and processing for large datasets, working closely with Agile software development team(s). This role includes responsibilities such as creating and managing schedules for data management (migration, integration, etc.) efforts, working with clients to validate migrated data, working with Agile development teams to understand changes and their impacts towards data migration efforts, among other tasks.The teamAnalytics & CognitiveIn this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence. Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the GPS marketplace.Analytics & Cognitive will work with our clients to:Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platformsLeverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actionsDrive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvementsQualificationsRequired:Ability to Obtain and Maintain a Government Security Clearance2+ years of experience with extract, transform, and load (ETL) methods and tools2+ years of experience with data modeling, data warehousing, and building ETL pipelines2+ years of experience with SQL queries and JSON objects1+ years of experience with both SQL and NoSQL databases, including PostgreSQL and MongoDBBachelor's degree in Computer Science, Engineering, Mathematics or other business-related fieldMust be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.Preferred:Familiarity with microservice architecturesInterest in event streaming architectures, such as Apache KafkaPrior professional services or federal consulting experienceKnowledge of data mining, machine learning, data visualization and statistical modelingAbility to thrive in a fast-paced work environment with multiple stakeholdersCreativity and innovation – desire to learn and apply new technologies, products, and librariesHigh-performing team playerHow you’ll growAt Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs at Deloitte University, our professionals have a variety of opportunities to continue to grow throughout their career. Explore Deloitte University, The Leadership Center.BenefitsAt Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.Deloitte’s cultureOur positive and supportive culture encourages our people to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them to be healthy, centered, confident, and aware. We offer well-being programs and are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives. Learn more about Life at Deloitte.Corporate citizenshipDeloitte is led by a purpose: to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our people and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. Learn more about Deloitte’s impact on the world.Recruiter tipsWe want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you’re applying to. Check out recruiting tips from Deloitte professionals.AIGPSDS&J",aus,de
1,Indeed,Information Technology,4.4,Staff Software Engineer - Data Infrastructure,"Austin, TX",$80K - $148K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000178c1db790caf8013cc835522a7&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_d4eee845&cb=1618160090028&jobListingId=4055237587,"Your JobIf you are an engineer who's passionate about building innovative products that scale to tens of millions of page views a day, Indeed is looking for you. Indeed offers smart developers like you a complex development ecosystem with short release cycles. Every week sees the new release of multiple products that meet the growing needs of millions of jobseekers worldwide.As a Staff Software Engineer at Indeed, you will be responsible for designing, developing, and maintaining pipelines that create search indexes out of data from large databases. You will design and implement efficient algorithms for ranking search results, increasing recall, filtering spam, personalization, etc. and extract, cluster or classify high-quality features from unstructured data and code innovative tools to support rapid experimentation and learning.The Data Infrastructure team is responsible for building and maintaining the pipelines and systems for ingesting data from all of Indeed’s applications and for processing it to gain insights into our employers and jobseekers. Data Infrastructure is at the core of Indeed’s data driven culture. Some examples of systems that we are responsible for include our event logging pipeline, our change data capture pipelines, our hadoop cluster, a proprietary petabyte scale distributed key value store, and a proprietary petabyte scale columnar olap query execution engine.Indeed’s job search engine serves billions of search queries every month connecting tens of millions of jobseekers to relevant job opportunities. As part of a small collaborative team from engineering, operations and product management, you will work on areas such as feature extraction, document indexing, retrieval, and relevancy scoring. We constantly dig into the data available at Indeed to analyze, inform and develop solutions to the right problems. If looking at data, slicing and dicing it in multiple ways and coming up with interesting insights is something you thrive upon, you will fit right in.Who You AreRequirements:BS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field with 8+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl;ORMS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field 5+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl.Minimum 5 years of experience building applications using at least one of the following: web application technologies including: HTML, CSS, or Javascript; OR Databases, for example: Mysql, Mongo, or a similar program; OR a collection of systems connected and communicating via a network connectionMinimum 3 years of experience mentoring more junior EngineersSignificant experience with large scale, high-performance systemsWe will consider for employment qualified applicants with arrest and conviction records in accordance with the San Francisco Fair Chance Ordinance.Who we areWe are a rapidly growing and highly-capable Engineering organization building the most popular job site on the planet. With engineering hubs in Seattle, San Francisco, Austin, Tokyo, Singapore, Hyderabad, Dublin, Aberdeen and Vancouver, we are improving people's lives all around the world, one job search at a time.Our MissionAs the world’s number 1 job site*, our mission is to help people get jobs. We strive to cultivate an inclusive and accessible workplace where all people feel comfortable being themselves. We're looking to grow our teams with more people who share our enthusiasm for innovation and creating the best experience for job seekers.(*comScore Total Visits, March 2020)Salary Range DisclaimerThe base salary range represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Restricted Stock Units (RSUs), an open Paid Time Off policy, and many region-specific benefits.Salary Range TransparencyUS Remote 138,000 - 174,000 USD per yearEqual Opportunities and Accommodations StatementIndeed is deeply committed to building a workplace and global community where inclusion is not only valued, but prioritized. We’re proud to be an equal opportunity employer, seeking to create a welcoming and diverse environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, family status, marital status, sexual orientation, national origin, genetics, neuro-diversity, disability, age, or veteran status, or any other non-merit based or legally protected grounds.Indeed is committed to providing reasonable accommodations to qualified individuals with disabilities in the employment application process. To request an accommodation, please contact Talent Attraction Help at 1-855-567-7767, or by email at TAhelp@indeed.com at least one week in advance of your interview.Privacy PolicyView Indeed's Applicant Privacy and Accessibility Policies - https://www.indeed.com/legal/indeed-jobs",aus,de
2,American Innovations,Information Technology,3.4,Senior Firmware Engineer,"Austin, TX",$98K - $137K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_e7f6a920&cb=1618160090029&jobListingId=3822542441,"Senior Firmware EngineerAmerican Innovations protects people and the environment by providing proven compliance solutions to oil and gas professionals from the field to the office. More than 30 years of experience drives innovative solutions that address the need for efficient data collection, reporting, and analysis – an integrated family of hardware, software and professional services backed by relentless customer service.Are you ready for the next chapter in your professional career? Are you looking to join a company that is the leader in our core market and are rolling out our next generation of products now? Join our R&D team and take our company to the next level!Position AlignmentWhat you can offer us:1. Planning and DesignUnderstand our product and service roadmap; with the team lead(s) and Development manager, help shape our roadmap and plan how we will execute it; help clarify what can be done technically.Design great products; ensure a common look and feel across product lines; define and advocate consistent coding practices and adhere to the common architecture.Understand the requirements you are responsible for delivering, make every reasonable effort to clearly know what “done” means before you start planning or coding; use requirements to drive the complete solution. Look for gaps and propose alternatives to address gaps.Design reusable code that is readable and discoverable; create reliable estimates; identify and communicate potential risk areas; follow coding standards; help other developers design & estimate.Improve your understanding of user needs & experiences by connecting to the outside world (thru NACE, user meeting, customer visits, etc.) & apply that in your planning & design.30%2. Execute and CreateDeliver on-time, on-budget, high quality code; communicate and help resolve any issues that arise. Be a positive and productive member of the team.Work with Hardware Development frequently to ensure your work is aligned and seamless; help Developers resolve issues of alignment and seeing the bigger picture of their workWork closely with Test Group to ensure no code is released without proper testing and review. Promptly address quality issues; help prioritize bugs – apply your experience to help explore possible short comings. Quality over delivery date.Demonstrate initiative and ownership – create great code with the whole solution in mind instead of just achieving the minimum required.25%3. Process and EfficiencyUnderstand the metrics for Software Development that drive performance; help managers design effective metrics; regularly and honestly report your results; challenge yourself and others to improve.Raise issues and concerns about the resources and time necessary to do the job correctly.Document how we do things so we can review and incrementally and systematically improve how we code and deliver outstanding products.Actively participate in project post-mortems; discover great practices we want to adopt and areas for improvement; remove inefficiency & barriers; communicate & implement improvements as agreed.25%4. DevelopmentDevelop skills to fill technical needs on the team; identify and develop personal growth opportunities.Stay abreast of current technology and incorporate that into your deliverables appropriately; paying close attention not to fall behind the technology curve.Help my team understand my strengths and where best I can be utilized.Grow and craft the career I want. Identify what motivates me.Support the 121 process, evolve my understanding and growth with the 121 process.Understand my strengths and weaknesses, develop a plan to get better. Improve my development skills, learn software best practices, be a resource to other developers.Support and strengthen the culture, clearly understand and communicate purpose and culture.10%What do you need to be successful?Minimum of 3 years of C/C++ development experience. More experienced candidates are also encouraged to apply.Bachelor or Masters in Electrical Engineering, Computer Engineering, Computer Science, or a related fieldDevelop embedded software in C/C++ for new productsHelp develop automated unit and system tests for your softwareOwn delivery of embedded software for new products, as an individual or team leadDevelop and review software architectures and system designsSupport hardware, software, and test engineers as they integrate with, deploy, and test our productsExperience in microcontroller or embedded software programming and debuggingExperience in RTOS and multithreaded programming using mutexes, queues, etc.Experience with at least one scripting language, Python preferredKnowledge of C and desire to learn modern C++, including C++14 constructs and STLExperience with continuous integration practices such as static analysis, automated unit test, and typical workflows built around Git feature branchingComfortable debugging hardware using DMM, Oscilloscope, logic analyzerWhat we can offer you:Competitive benefits focused on your physical well-being, including Medical, Dental, and Vision insurance and company provided Life and Disability.Programs to improve your financial well-being, including a 401(k) plan with an employer match up to 4% with immediate vesting and financial education courses.Opportunities to give back to the community, including paid volunteer hours.Supportive and collaborative environments, happy hours, and fun events.Assistance to further your learning and development.A rewarding culture, with a focus on positive business practices and protecting the environment.Successful applicants must be eligible to work in the US and must be able to pass a pre-employment background and drug test. American Innovations is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",aus,de
3,Army National Guard,Government,4.2,12Y Geospatial Engineer,"Austin, TX",$36K - $65K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_00b0ee44&cb=1618160090029&jobListingId=4055877016,"Job DescriptionYou can play an important part in disaster relief missions as a Geospatial Engineer for the Army National Guard. In this role, you will extract and supply geographic data that supports military operations of all kinds and help commanders visualize the battlefield during combat.As a Geospatial Engineer, your primary responsibility will be to collect and process military geographic information from decentralized sources (remote sensed imagery, digital data, intelligence data, existing topographic products, and other collateral data sources), present this information to leaders, and return decisions to the field.You may also:Supervise topographic surveying, cartography, and photolithography activitiesAssist in topographic planning and control activitiesAssist in determining requirements and providing technical supervision of geographic intelligence programsJob DutiesCreate geographic data and compile them into mapsCreate and maintain multiple geospatial databasesPrepare military-style briefs covering all aspects of the terrainSome of the Skills You’ll LearnBasic knowledge of Geographic Information SystemsImagery interpretation and exploitationHelpful SkillsInterest in geography, maps, and chartsAbility to demonstrate basic computer skills and work with drafting equipmentConceptualize ideas into computer-generated 2-D/3-D geospatial productsPreference for a technical career fieldThrough your training, you will develop the skills and experience to enjoy a civilian career with construction, engineering, and architectural firms, as well as with government agencies as a surveyor, mapmaker, cartographer, cartographic technician, or photogrammetrist.Earn While You LearnInstead of paying to learn these skills, get paid to train. In the Army National Guard, you will learn these valuable job skills while earning a regular paycheck and qualifying for tuition assistance.Job training for a Geospatial Engineer requires 10 weeks of Basic Training, where you'll learn basic Soldiering skills, and 20 weeks of Advanced Individual Training (AIT) and on-the-job instruction, including practical application of geographic information systems. Part of this time is spent in the classroom and part in the field.Benefits/RequirementsBenefitsPaid trainingA monthly paycheckMontgomery GI BillFederal and State tuition assistanceRetirement benefits for part-time serviceLow-cost life insurance (up to $400,000 in coverage)401(k)-type savings planStudent Loan Repayment Program (up to $50,000, for existing loans)Health care benefits availableVA home loansBonuses, if applicableMost non-prior service candidates will earn between $200 and $250 per drill weekend, subject to changeRequirementsMilitary enlistment in the Army National GuardMust be at least a junior in high school, or have a high school diploma or a GED certificateMust be between the ages of 17 and 35Must be able to pass a physical exam and meet legal and moral standardsMust meet citizenship requirements (see NATIONALGUARD.com for details)Requires military enlistment. Programs and benefits are subject to change. Ask your Army National Guard recruiter for the most up-to-date information. Actual MOS assignment may depend on MOS availability.Other Job InformationJob ID: 1368237ZIP Code: 786173647Job Category: EngineerAge Requirements: Must be between the ages of 17 and 35 administrator map reader aide",aus,de
4,Stamps.com,Information Technology,3.7,Senior Data Scientist,"Austin, TX",$94K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1187695&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_5162fbce&cb=1618160090030&jobListingId=3775647577,"Here at ShipStation, part of Auctane, we're passionate about helping online businesses become more productive. We save thousands of merchants hours every day by automating the fulfillment side of their business. We partner with top eCommerce and shipping companies to make a previously complicated and labor-intensive process simple and enjoyable.

As a Senior Data Scientist, you will solve challenging logistics and optimization problems to make our customers more successful. You will analyze large amounts of data from a variety of sources, discover and solve real world problems, and develop metrics and business cases that will enable us to continually delight ShipStation customers. The ideal candidate will be a self-starter, highly analytical, and intensely detailed with a strong customer focus.

Responsibilities:

Work with the Director of Data Science to plan, implement, and support machine learning projects to help our customers work and ship more efficiently

Communicate the results and methodology effectively within the team and to stakeholders across the business
Stay on top of innovations and technologies in the world of machine learning
Collaborate with people in our Product and Engineering teams to put your work in the hands of customers
Participate in regular project reviews
Provide feedback to other members of the team
Mentor junior members of the team

Use visualization, reporting and other tools to improve the ways in which our team accesses and interprets datasets.
Measure and continuously improve the accuracy of predictive models.
Effectively document and communicate methodologies and results.
Use data to inform and influence the direction of product roadmap.

Required Education and/or Experience:

Bachelor’s degree in Computer Science, Math or equivalent years of relevant work experience
Five plus (5+) years of quantitative experience with large data-sets, from prototyping to business impact
Two plus (2+) years’ experience with SQL and relational databases (e.g. PostgreSQL, MySQL, SQL Server)

Skills and Knowledge:

Solid understanding of machine learning and statistical methods with their underlying theory and math.
Demonstrated work in building, deploying, and demonstrating business value from predictive models and data products.
Solid software development experience, including translating ML models into production software.

Skills and Knowledge:

Strong and persuasive communication skills.
Knowledge of geospatial analysis
Knowledge of AWS/GCP/Azure
Working knowledge with NLP a strong plus

Computer/Software/Application Proficiency:


Python, R, Scala, Git Docker
SQL; (e.g. PostgreSQL, MySQL, SQL Server)

Equal Opportunity Employer/Veterans/Disabled

If you are based in California, we encourage you to read this important information about the ShipStation Privacy Policy for California residents linked here.

#LI-JF1",aus,de
5,Brinqa,Information Technology,2.7,Software Engineer - Deployment Services,"Austin, TX",$42K - $90K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044077&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_793e8663&cb=1618160090031&jobListingId=4001415166,"Brinqa is looking for an integration software engineer to join our team. In this role you will work as part of a small, dynamic and fast moving customer success team to deliver quality solutions to our customers. We are looking for a well-rounded developer who can think strategically and deliver tactical implementations. The ideal candidate must be self-directed and a fast learner, flexible enough to work with new technologies and deliver high quality solutions in a timely manner. You will also be responsible in coordinating with our Engineering team on various components of Brinqa, mainly revolving around customer requirements and issues, but also including issues and improvements based on manual testing conducted on specific components.End-to-End Design and ConfigurationDesign various data models (schema) using the Brinqa platform as dictated by the customer use case.Configure various data connectors based on analysis of customer data to be imported. This includes due diligence of data provided by customers and back-and-forth communication with them regarding the same, along with the rest of our CS team.Design various rules based on data and customer use case, keeping in mind the overall design flow for the specific implementation.Write Groovy scripts as required, as part of data model design, data connectors configuration and design of rules.Design views, dashboards and reports to efficiently reflect the customer use case.Communicate well with customers and internal teams alike to achieve efficient design implementation within designated timeframe.Product TestingManually test and validate specific customer use cases to ensure requirements are met.Create tickets for issues found and improvements desired (driven by key customer requirements, and determined in conjunction with the CS team).Follow-up on created tickets and test out resolved issues. Plan release of Brinqa builds with issue fixes and improvements to customers.QualificationsMust have:Bachelor’s degree in Computer Science/Information Science or equivalent work experience.Three or more years of relevant experience.Experience working with Java.Basic understanding and working knowledge of databases.Basic understanding of 3-tier architecture.Good listening skills coupled with good written and verbal communication skills.Teamwork and collaboration skills.Additional qualifications:Experience working with Groovy and Grails.Knowledge of NoSQL databases, specifically Neo4j.Familiarity with application deployment and AWS.Working knowledge of Linux and Linux command-line.Software: Nginx, Apache Tomcat, IntelliJ IDEA, JIRA, Sublime Text.Job Type: Full-timePay: From $83,095.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceHealth insuranceLife insurancePaid time offRetirement planVision insuranceSchedule:Monday to FridayCOVID-19 considerations:We are currently working from home to keep our employees safe. We do have an office in Austin and will return as soon as it is appropriate. Thank you.Ability to Commute/Relocate:Austin, TX 78731 (Preferred)Application Question(s):Have you worked for a tech software company before?Do you have at least three years of Java experience?Do you have at least 2 years of experience with the following scripting languages:JavascriptJSONCYPERGroovy and GrailsExperience:professional services: 3 years (Preferred)Work Location:One locationCompany's website:www.brinqa.comCompany's Facebook page:https://www.facebook.com/Brinqa-546883215350894/Benefit Conditions:Waiting period may applyOnly full-time employees eligibleWork Remotely:Temporarily due to COVID-19",aus,de
6,Stamps.com,Information Technology,3.7,Senior Security DevOps Engineer,"Austin, TX",$86K - $141K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044767&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_e8d452bc&cb=1618160090031&jobListingId=3796360143,"About Auctane:

Every day, the complex challenges of global shipping and logistics bring growing pains that fast-growing online brands struggle to negotiate. Getting products into the hands of customers quickly and affordably is a challenge for most. At Auctane, we serve and champion these merchants every day. Our software stack solves shipping and logistics problems that arise as merchants scale, so they can focus their time, energy, and resources on what matters most.

Auctane is a team of shipping and software experts with a passion for helping merchants move their ideas, dreams and innovations around the globe. The Auctane family includes ShipStation, ShipWorks, ShipEngine, and ShippingEasy. Our partners include Amazon, UPS, USPS, eBay, BigCommerce, Shopify, WooCommerce, and Walmart.

A wholly-owned subsidiary of Stamps.com (Nasdaq: STMP), Auctane is headquartered in Austin, TX, with offices in St. Louis, London, and Sydney.

The Team:

The Auctane DevOps team is responsible for finding the right tools and processes required to build an efficient and effective automated environment for the engineering team. In addition, a heavy emphasis is placed on automating infrastructure, CI/CD, and various other processes. The team is constantly looking at new technologies that will help us with faster delivery of features, enhance observability and improve the quality of life in the engineering organization.

The Role:

The Senior DevOps Engineer will also work closely with IT, Devops and Engineering to ensure best practices & compliance initiatives are being implemented and adhered to. This may include SOX, SOC2, OWASP, and potentially others. This team member will collaborate with various constituents across engineering and business functions to develop and sustain a secured infrastructure by means of reducing our external attack surface, enhancing and validating patch management, performing vulnerability scans, coordinating penetration testing as well as other security initiatives across all of our products.

Responsibilities:

Reduction of internal & external attack surfaces in our cloud environment.
Research attempted efforts to compromise security protocols.
Tracking and researching the latest attacks and how they might apply to our environments.
Ensure new changes in our CI flows do not present additional risk.
Performing vulnerability scans and remediate vulnerabilities in a timely manner.
Coordinate with 3rd party penetration testers & product engineering to determine risks and resolutions to any findings.
Work with engineering leads on developing security best practices for coding.
Streamline administrative processes for onboarding and offboarding engineers.
Administer security policies to control access to engineering systems.
Ensure data stores are handing data according to our policies.
Monitor for alerts/incidents/data leaks & act immediately on them.
Follow alerting support communication escalation procedures.
Ability to communicate honestly and directly while having the courage to own their convictions and adhere to strongly held principles and values.
Coordinate with Sales Teams in helping them answer security questions for prospects.
Work with the Security & Compliance team on compliance initiatives and issues.

Required Education and/or Experience:

BS or MS in Computer Science, Management of Information Systems, Information Security/Assurance, Internal Audit, or equivalent years’ experience.
Minimum of Seven plus (7+) years of professional experience with any combination of at least 2 technical disciplines, including the following: cloud security, network security, application security, threat modeling, threat intelligence, software development and coding, incident response, vulnerability management, and cryptography

Skills and Knowledge:

Hands on experience with AWS in a production environment.
Knowledge of Linux/Unix and Windows tools and architecture.
Knowledge of standard network protocols and multiple levels (TCP/IP, HTTP(S), IPSEC, etc)
Knowledge of various host and network telemetry data (e.g. process lists, application logs, netflow records) and how to relate them to each other.
Knowledge with common threat modeling approaches and enterprise attack surfaces.
Comfortable scripting, writing tools to automate repeatable tasks.
Excellent written and verbal communication skills.

Computer/Software/Application Proficiency:

Security or AWS certifications (CISSP, GCIA GCIH, GCFA, GCFE, AWS SA, etc.)
Experience with Security Operations, Incident Response, Threat Hunting and Assurance methodologies e.g. fuzzing, static and dynamic code analysis.
Experience with common attack patterns and exploitation techniques. Ability to write fully functional exploits for common vulnerabilities such as simple stack overflow, cross-site scripting, or SQL injection.

Travel Requirements (if applicable):

None

Equal Opportunity Employer/Veterans/Disabled

If you are based in California, we encourage you to read this important information about the ShipStation Privacy Policy for California residents linked here.

#LI-JF1",aus,de
7,Apple,Information Technology,4.3,"Data Engineer, Apple Media Products Data Science & Analytics - Austin","Austin, TX",$113K - $173K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_88bad06d&cb=1618160090032&jobListingId=4001611777,"SummaryPosted: Feb 12, 2021Role Number:200223347At Apple, great ideas have a way of becoming great products and services. If you are a self- motivated and energetic person who is not afraid of challenges, we are looking for you!Apple is seeking a Data Engineer to join the Data Science & Analytics Organization for Apple Media Products (AMP), covering the App Store, Apple Music, Apple TV, Apple Podcasts, and other services. This role will drive data engineering for large-scale data science and machine learning initiatives across numerous AMP products.AMP collaborates with executives and various partners across product, design, engineering, and business teams: Our mission is to drive innovation at Apple through in-depth quantitative research of the App Store, Apple Music, Apple TV and Apple Podcasts.Key QualificationsBackground in computer science, mathematics, or similar quantitative field with a minimum of 4-6 years professional experienceProficiency in at least one programming language (e.g., Python, Java, Scala) and rock-solid SQL skillsExperience with workflow scheduling / orchestration such as Airflow or OozieDemonstrated ability in Big Data Technologies (Hadoop, MapReduce, Hive etc...).Spark experience preferred.We seek the ability to design and implement effective testing and operations strategies for data pipelines and data productsData visualization experience with tools like Tableau a plusExperience on Kubernetes, Docker preferred.DescriptionTranslate business requirements by business team into data and engineering specificationsBuild scalable data sets based on engineering specifications from the available raw data and derive business metrics/insightsWork with engineering and business partners to define and implement the data engagement relationships required with partnersAnalyze complex data sets, identify and formulate correlational rules between heterogeneous sources for effective analyticsProcess, clean and validate the integrity of data used for analysisDevelop Python and Shell Scripts for data ingestion from external data sources for business insightsEducation & ExperienceMinimum of a Bachelor's degree in Computer Science, Statistics, Mathematics, Engineering, Economics or related field. Ideally, Masters or Ph.D. in a related field.",aus,de
8,PayPal,Information Technology,4.1,Data Engineer,"Austin, TX",$111K - $137K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_599684c2&cb=1618160090032&jobListingId=4054412702,"Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 375 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.Job Description Summary: Seeking data engineer candidate for PayPal's CTO business technology team that looks to optimize internal infrastructure and processes.Job Description:Position OverviewPayPal's mission to democratize financial services relies on platform & infrastructure that is fast, reliable and secure. That infrastructure must be managed thoughtfully, be able to handle organic and intermittent growth and stay within budget.The Technology Business Management (TBM) team is a small results-driven group that focuses on enterprise efficiency from assets and applications, to operations and processes and is part of a larger organization that reports directly to the CTO.The Efficiency-Showback program is one of key strategic programs for the org and is an expansion of the work we have done around efficiency in 2020. The program measures impact, provides accountability through cost transparency, and operational efficiencies of our physical technology infrastructure, thousands of applications used to run PayPal, and the processes that govern IT. The TBM team performs detailed analytics using data from multiple data sources / monitoring tools to identify inefficiencies and work within the organization to communicate / remediate them.The team is rapidly growing its area of responsibilities and is seeking a multi-disciplined engineer who is strong in database engineering as well as solid software development skills. This person will develop and enhance the current data pipeline used to perform efficiency analytics, write and maintain integrations with other systems of record and help the team scale to become an enterprise-wide product.We are looking for a candidate who is motivated to build solid, scalable platform capabilities, someone who likes to raise the bar with respect to code quality, testability and maintainability standards. Typical day to day involves working with your teammates on solution discussions, implement complex stored procedure logic, work on integration scripts as well as attend and actively participate in scrum ceremonies and have at least a little fun.Core DutiesWork with the DB architect to create and maintain optimal data pipeline architectureAssemble large, complex data sets that meet functional / non-functional business requirementsBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologiesBuild APIs that expose the data so customers can consume and integrate with our dataEvaluate large and complex queries / stored procedures and recommend changes to optimize performanceAssist with the expansion into public cloud cost transparencyLead automation efforts leveraging innersource interaction models with other teamsAssist data analysts on our team with query development, statistical analysis, and data visualization as neededMaintain technical documentation on stored procedures and ETL logic used to managed the databaseCore CompetenciesCore Behavioral CompetenciesStrong written and verbal communication skillsAbility to write clear and concise communicationsAbility to work effectively in a global team environmentRole Specific Behavioral CompetenciesAbility to translate complex problems into simpler termsAbility to work independentlyPrerequisite Knowledge & ProficienciesMust HaveExperience building and optimizing ETLs, data pipelines, architectures and data setsProficient in Microsoft SQL Server 2016 & 2019 Database Development (T-SQL), Data Analysis and Support.Thorough understanding of RDBMS concepts and ability to write complex SQL queries, Stored procedures, Functions & triggersProficiency with python scripting languageExperience with Splunk and splunk query languageExperience Google Big Query and AWS redshiftExperience with No SQL / HadoopDemonstrated experience working with large data sets and a love for working with dataUnderstand or be keen to learn about REST API development and designVery strong foundational knowledge in Object-Oriented Design Principles, Data Structures, Algorithms, and Software EngineeringWorking knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX)Experience with code repositories like Git/GitHubExperience writing and maintaining technical documentationBasic familiarity with MS Word, Excel & Visio knowledge neededA constant desire to grow, learn, and explore new thingsNice to HaveExperience with SignalFX analytics platformExperience with gimmel notebooksExperience with some visualization tool (e.g. tableau or power BI)Experience managing database upgrades / data migrationsExperience optimizing queriesBasic fundamentals of JAVAUnderstanding of Angular and/or ReactJSExperience & Education4-5 years working experience as a Data Engineer3+ years software development in front-end and/or back-end technologiesBS in computer science, Information systems or equivalent field, MS preferredExamples of Specific Job Tasks/AccountabilitiesWork with lead to define technical requirements and design for new tables, ETLs, integrations,Perform development of new stored procedures, integrations, views etc as part of bi-weekly agile sprintsMaintain scheduled jobs and debug when necessaryAttended technical meetings with customers of the IT efficiency product so they can integrate with us to consume dataAttend daily status calls to track sprint progressCreate, update, maintain documentation on stored procedures, ETL logic, db schema etc.Work with cross-functional teams to build and enhance automation workflowsBuild / optimize queries needed by team as neededProvide demos and code reviews when applicableTrack data quality / integrity issues with the db and report themWe're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",aus,de
9,The HT Group,Business Services,4.2,Ruby on Rails Engineer-Direct Hire,"Austin, TX",$57K - $116K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044072&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f5e0cac5&cb=1618160090033&jobListingId=4053308885,"Salary: Salary commiserates with experienceReference: 14023The HT Group is working with a well established Austin based company who is looking for a talented Ruby on Rails Engineer on a full time / direct hire basis. This is a great opportunity to work within a flat organization where you can bring your creative ideas and ability to write great code in a collaborative team environment.Responsibilities will include:Design and implement high performance, large-scale distributed services in an Agile environmentDrive success of projects from design to integrationWork on constant new solutions based project both with internal and external teamsKey Qualifications:4+ years of Ruby on Rails development experienceStrong understanding of relational databases such as PostgreSQL/MySQL and other data storage technologiesAbility to work across cross functional product, web and mobile teamsStrong TDD testing abilityPassion for writing great code that is maintainable and meets established standardsMust be a self starter and be able to manage own your workloadA ble to approach large, complex problems and solve them systematicallyKnowledgeable of Agile methodologyYou have a strong track record of putting Rails to work and bringing products to lifeBS degree preferredOur client offers a very competitive compensation plan, great benefits and flexible ""fun"" work environment. They are motivated to move fast to identify and hire the right person to join the team!Apply to this job posting or send your resume directly to scott.courville@thehtgroup.com.",aus,de
10,Expedia Group,Information Technology,4,Data Engineer,"Austin, TX",$75K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_f34cfb34&cb=1618160090034&jobListingId=3775810749,"We are looking for a Data Engineer to join our Commerce Data Engineering team, which is building data for use in real-time programmatic and batch use cases enabling product and business teams to achieve faster and bigger results! Join us as we consume a variety of data, consolidate that information and making it available, understandable and extensible for several business and product teams in the company. Success in this role comes from combining programming with data manipulation to provide data access patterns like batch and APIs to deliver scalable technical solutions that enable broad consumption and usage at Expedia Group.The Data Engineer will be responsible for building the data pipeline, storage patterns, and access methods for the Commerce Data used across the entire company. This will involve coding in several languages, using streaming technologies, working with multiple data storage platforms, and delivering information via multiple access patterns such as at rest for analytics and programmatically through APIs.What You’ll DoActively participate with our development team in all phases of the software development lifecycle, including requirements gathering, functional and technical design, development, testing and roll-out, and supportWrite automated unit, integration and acceptance tests to support our continuous integration pipelinesBuild performance and load tests written from scalability and resiliency standpointCollaborate with and learn from all members and levels of our teamParticipate in peer code reviewsInteract with technical and non-technical leaders and partners to collect feedback and present resultsWho You AreEnthusiastically seek out solutions for data engineering problemsFocused developer with a strong sense of ownershipAbility to independently drive individual stories to completion and production deploymentCapable of working closely with team members to ensure data solutions are well built and of high quality5+ years developing data and software solutions2+ years of experience in Java2+ years of experience in building data pipelines in the cloud with tools like S3, Hadoop, Hive; working with Petabytes of data2+ years of experience in Java and streaming technology such as KafkaExperience in classic and NoSQL databases system such as SQL Server, Elasticsearch, CassandraExperience with of all aspects of data systems including database design, ETL, aggregation strategy, performance optimizationExperience working with various tools, processes, and languages like Spark, Scala, Airflow, Splunk, Datadog, Docker, JenkinsWhy join us:Expedia Group recognizes our success is dependent on the success of our people. We are a global travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and bring the world within reach – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them the tools to do so.Whether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.If you have a hunger to make a difference with one of the most loved brands in the world and to work in the dynamic travel industry, this is the job for you.Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, Vrbo®, Orbitz®, Travelocity®, Wotif®, ebookers®, CheapTickets®, Hotwire®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia Cruises™ and SilverRail Technologies, Inc. For more information, visit www.expediagroup.comExpedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.",aus,de
11,Teacher Retirement System of Texas,Finance,3.8,Senior Business Intelligence and Data Analyst,"Austin, TX",$84K - $90K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_81bc874f&cb=1618160090034&jobListingId=4052793204,"WHO WE ARE:The Teacher Retirement System of Texas is the largest public retirement system in Texas, serving more than 1.5 million people. Innovation, technology, and collaboration make the difference as we strive to continue earning your trust every day. TRS improves the retirement security of Texas public education employees through our 'best in class' investment management and delivery of pension and health care benefits.Our Mission: Improving the retirement security of TRS members by prudently investing and managing the Trust assets and delivering benefits that make a positive difference in their lives.Teacher Retirement System of Texas (TRS) is developing groundbreaking solutions to manage retirement & healthcare services as well as maximizing investment returns for the state’s public education employees. Succeeding in life is about commitment and hard work—maybe a favorite school teacher imparted that idea to you along the way. At TRS, we take that to heart and believe life can also be a balance between giving back while excelling professionally.State Classification:0654/Data Analyst V/B26WHAT YOU WILL DO:Business Intelligence and Data Analysis Defines, develops, and implements automation of reports, processes, and interfaces. Designs and develops models to improve financial analysis and to project financial impact of business changes. Interprets and translates accounting and finance business needs into effective applications and operational requirements to assist IT staff with implementation of finance and accounting system solutions. Liaison between IT and Finance to facilitate testing and implementation of data warehouse. Identifies data gaps, errors, anomalies, inconsistencies, and redundancies by analyzing the content, structure, and relationships within data. Understands and compiles accurate data to present reports and assesses data quality. Applies a broad range of techniques and theories from business intelligence, data analysis and visualization, statistics, predictive analytics and machine learning to deliver actionable business insights based on large-scale data. Defines, captures, enriches, explores and preps data to support desired metrics monitoring and reports. Leverages mature data with variable/algorithm selection, predictive and behavioral analytics to identify emerging risks and issues beyond operational controls. Troubleshoots and resolves problems related to accounting and finance systems and applications.Reporting Provides thorough, visible, rigorous and transparent data reports and analysis. Tracks trends and provides recommendations for solutions based on findings. Interprets and communicates analytical insights to audiences with various analytical backgrounds using different but suitable communication methods for different audiences. Develops visually appealing and intuitive dashboards that provide visibility into key performance, risk, and control indicators across agency divisions and departments. Delivers quality results and presentations under short timelines.Training and Technical Guidance Serves as a central resource for reports interpretation and assists with developing specifications for reports. Provides training and technical assistance to agency staff on processes, applications, and reporting. Participates on finance related agency committees and special projects as assigned. Performs quality assurance and serves as a subject matter expert on data integrity, extraction, testing and compilation.Performs related work as assignedWHAT YOU WILL BRING:Education: Bachelor’s degree from an accredited four-year college or university in Information Technology, Data Analytics, Business Intelligence or a related field.Experience: Five (5) years of full-time experience in SQL development, data analytics, business intelligence or similar field. Experience and education may be substituted for one another. Experience with MS SQL Server (including SSRS, SSIS, and SSAS), MS PowerBI (or the equivalent), other business intelligence and visualization tools, and MS Office Suite. Experience may be concurrent.Registration, Certification, or Licensure: None.Preferred Qualifications Master’s degree from an accredited four-year college or university in Information Technology, Data Analytics, Business Intelligence or a related field. Experience with Workiva Wdesk/Wdata, MS Visual Studio, MS Visio, Jira, and Talend Data Fabric. Experience in data modeling and working with a star-schema data warehouse or other data analytic data structures.Knowledge, Skills and AbilitiesKnowledge of: Strong knowledge of business intelligence tools (i.e. MS PowerBI), databases, SQL and various job associated programming languages to support data analysis and predictive analytics. Database modeling and data warehousing principles. Generally Accepted Accounting Principles (GAAP) and/or Governmental Accounting Standards Board (GASB). Project management and system development life cycle concepts.Skill in: Experience using technical and statistical analysis skills to deliver clear, concise, and visually appealing management metrics and reports to inform decision making and actions. Analyzing detailed accounting system data, troubleshooting associated problems, and interpreting and applying applicable laws, policies, and procedures. Writing report queries, including an understanding of relational databases. Business process analysis and problem solving. Completing detailed work with a high degree of accuracy. Planning, organizing, and prioritizing work assignments to manage a high-volume workload in a fast-paced and changing environment. Using a computer in a Windows environment with Microsoft Office word processing, spreadsheet, and other business software. Effective written and verbal communications, including explaining complex information to others in an understandable manner, and writing clear and precise policies, procedures, and training or other materials. Proven track record to work in a team environment and influence a diverse group of stakeholders.Ability to: Operate effectively in a fast-paced environment with competing and shifting priorities. Continually learn new concepts and tools to support job needs and strive for ongoing professional development. Establish and maintain harmonious working relationships with co-workers, agency staff, and external contacts. Work effectively in a professional team environment.Military Occupational Specialty (MOS) Codes:Veterans, Reservists or Guardsmen with experience in the Military Occupational Specialty ( http://www.hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_AdministrativeSupport.pdf ) along with the minimum qualifications listed above may meet the minimum requirements and are highly encouraged to apply. Please contact Talent Acquisition at careers@trs.texas.gov with questions or for additional information.To view all job vacancies, visit www.trs.texas.gov/careers or www.trs.csod.com/careersite.For more information, visit www.trs.texas.gov.",aus,de
12,ConsumerTrack,Information Technology,3.2,Data Engineer,"Austin, TX",$71K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=14295&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_d9481b54&cb=1618160090035&jobListingId=3822698902,"ConsumerTrack™ is unique in the digital marketing and media industry - we combine marketing, digital, content and fintech. Our performance based approach increases brand awareness and generates targeted audience engagement on our internal web properties and partner sites.

Learn More About What We Do

The ConsumerTrack has big growth plans ahead and is looking for a rockstar Data Engineer experienced in Data warehousing and Python to join our Data Engineering team. The CTI Data Engineering team is responsible for designing and developing the Data lake, enterprise database, data warehouse, reporting solutions, and pipelines for data processing. If you are a critical thinker with a solid track record of developing data solutions and solving complex problems with SQL and Python, we want you to join our team! You will play a vital role in designing and developing our next generation data pipelines and data platform. Join the team and prototype new data product ideas and concepts!

Functions/Responsibilities

Build and maintain multiple data pipelines to ingest new data sources (API and file-based) and support products used by both external users and internal teams. Optimize by building tools to evaluate and automatically monitor data quality, develop automated scheduling, testing, and distribution of feeds. Work with our data science and product management teams to design, rapid prototype, and productize new data product ideas and capabilities.  Work with the data engineering team to migrate and enhance our existing Pentaho-based ETL pipeline to a new ELT-based/SaaS Integration system. Conquer complex problems by finding new ways to solve with simple, efficient approaches with a focus on reliability, scalability, quality, and cost of our platforms. Build processes supporting data transformation, data structures metadata, and workload management. Collaborate with the team to perform root cause analysis and audit internal and external data and processes to help answer specific business questions.

Requirements

Basic Qualifications:

Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field. 3+ years of professional Dimensional Data Warehousing/Data Modeling and ‘Big Data’ Experience. Strong skills to write complex, highly-optimized SQL queries across large volumes of data. Comfortable working directly with data analytics to bridge business requirements with data engineering. Experience with AWS infrastructure. Must have excellent troubleshooting and problem-solving skills. Ability to operate in an agile, entrepreneurial start-up environment, and prioritize. Excellent communication and teamwork, and a passion for learning. Curiosity and passion for data, visualization, and solving problems. Willingness to question the validity, accuracy of data and assumptions.

Preferred Qualifications:

Experience with Redshift, Snowflake, or other MPP databases is a plus. Knowledge for ETL/ELT tools like Informatica, IBM DataStage, or SaaS ETL tools is a plus. Experience with Tableau or other reporting tools is a plus.

Benefits

Competitive salary with excellent growth opportunity; we pride ourselves in having a team that exudes leadership, high initiative, creativity and passion. Awesome medical, dental and vision plans with heavy employer contribution. Paid maternity leave and paternity leave programs. Paid vacation, sick days and holidays. Company funding for outside classes and conferences to help you improve your skills. Contribution to student loan debt payments after the first year of employment. 401(k) -- employees can start contributing immediately. After the first year, CTI matches your contribution up to 4% of your salary.

A note about our response to COVID -19 and our new norm: The world has changed and we know it’s important to adapt and to do our part to take care of our teams in this global pandemic. Our number one priority is to have our ConsumerTrackers feel safe, balanced and connected. We’re committed to providing our teams with the best resources and tools to navigate this new virtual world that we’re living in. We've also reinvented the ways in which we recognize, celebrate, and engage with each other to keep our culture strong!

Here’s a peek into our world at ConsumerTrack -

Our teams are working remotely 100% for the foreseeable future and have flex time. We’re in the digital media space so we’re mobile and flexible!


*Option to work from an office (if you need to get away!)
Tools & resources are available to keep our team connected across North America. (JIRA, Trello, Airtable, Slack, Zoom and so much more!) To keep our community of ConsumerTrackers engaged and connected, virtual team building events are held weekly and monthly. For wellness and balance, weekly virtual fitness classes such as yoga are available. To care for the local communities that we’re a part of across the U.S our team members host socially distanced philanthropic events every quarter. And most importantly, we’ve committed to consistent and transparent communication to help us all stay informed, engaged and to keep us on our path to success and #greatness.

We are an equal-opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.",aus,de
13,Celsius,Accounting & Legal,3.9,Data Engineer,"Austin, TX",$71K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_85287a7f&cb=1618160090035&jobListingId=4055655485,"Celsius addresses the financial needs of today’s consumers worldwide through a democratized interest income and lending platform accessible via a mobile app. With a mission to put unparalleled economic freedom in the hands of the people, and a core belief that financial services should only do what is in the best interests of the community, Celsius is a modern platform where membership provides access to curated financial services that are not available through traditional financial institutions. Crypto holders can earn high-yield compounding interest by transferring coins to their Celsius Wallet and can borrow fiat currency against their crypto collateral at the lowest interest rates in the space.The Celsius team is committed to doing good and doing well. We believe in the power of disruption and the importance of decentralization to create a new system that acts in the best interest of everyone. Each member of our team brings something unique and innovative to the table, but the common thread that links us together is our passion for blockchain, equality, and leading the next financial revolution that changes the equation to bring power back to the people.Position: Data EngineerResponsibilities:Help pioneer data Lake and data Warehouse infrastructure from the ground up using latest technology and best practices.Constructing ETL processes both in batch and streaming using latest technologies and scalable and robust infrastructure configurations on AWS & SnowflakeDefine and build data lake and data warehousing infrastructure from the ground up.Develop datasets per the requirements of analysts and key stakeholdersHave a strong role in maintaining data Integrity, security, and governanceWorks closely with all business units and engineering teams to develop strategy for long term data platform architecture.Designs data integrations and data quality framework.Designs and evaluates open source and vendor tools for data lineage.Qualifications:Advanced and proven skill in designing and developing scalable and secure data infrastructureStrong knowledge and experience building data lake/warehouse with Snowflake as a foundation.Advanced SQL skills and strong experience with database administrationProven skill in using technologies such as Kinesis,, Postgres with RDS, Lambda/Nuclio, S3, Redshift, etc.Advanced Python experience and skill with a suite data processing and analysis librariesExcellent problem solving and troubleshooting skillsProcess oriented with great documentation skillsExcellent oral and written communication skills with a keen sense of customer serviceKnowledge of Blockchain and cryptocurrency is a big plus",aus,de
14,Zenoss,Information Technology,3.9,Data Engineer,"Austin, TX",$72K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=4128&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_446e81bf&cb=1618160090036&jobListingId=3747938725,"Zenoss is seeking an experienced Data Engineer to join a team of Engineers creating breakthrough ITOps and AIOps Platform. We are seeking an individual with knowledge and experience in handling and extracting value out of large volumes of data in Systems Management, Application Performance Management, Systems Monitoring and / or Financial Transaction Management and Monitoring domains.

At Zenoss, our culture encourages team members to ask questions, challenge assumptions, and dig in to address the problems posed with highly distributed cloud and SaaS software systems. As a Data Engineer, you will be responsible for analyzing, organizing, and extracting value from big data collected by Zenoss Cloud. You will also be responsible for implementation and delivery of data-intensive features and functionality for Zenoss Cloud. You will work alongside engineers, Principal Architects, and product managers, and together you will plan and deliver high-value product features with the support of the big data collected in the Zenoss Cloud.

Zenoss offers a healthy work/life balance, a positive work environment, and a host of amenities to enable our teams to do their best work.

We are all currently working from our home offices. Ideally, when we return the right candidate will work from our amazing Austin, Texas headquarters, but for the right candidate we will consider someone who wants to work remotely within the US.Responsibilities

Design and implement highly scalable, data-intensive, and reliable product features Work with cross-functional engineering teams and with Architecture and Product teams to analyze, organize and extract value from Zenoss Cloud big data Leverage data science to design and implement new features and functionalityLearn new technologies quickly and leverage 3rd party tools to speed delivery

Qualifications

MS/BS in Computer Science/Electrical Engineering or equivalent work experience in an enterprise software engineering organization with a focus on data science and/or data analytics3+ years of experience as a data engineer on a large distributed team building large scale enterprise and SaaS platforms with big data backendsExperience with AI/ML and its application to Big Data.Experience with data pipelines and CI/CD of big data solutionsExperience with Cloud (GCP or AWS, Azure) and other SaaS platforms is a plusHighly effective verbal and written communication skills Must be results-focused, team-oriented, and with a strong work ethic

Please no agencies or third parties.

At this time we are unable to sponsor candidates who are not able to work in the USA.",aus,de
15,W2O Group,Business Services,3.8,Data Engineer,"Austin, TX",$95K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_e24ebd2c&cb=1618160090036&jobListingId=4001188956,"Recently named Best Place to Work by MM&M, The Holmes Report, PR News, PRWeek, and AdAge, Real Chemistry is an integrated marketing and communications firm powered by analytics and specializing in healthcare. We are currently looking to add talented professionals to our growing team. This is a great opportunity to join a dynamic, fast-growing global agency.Role:As a Data Engineer with our technology team, you’ll be responsible for building and maintaining our data warehouse environment, maintaining our internal data processes, and implementing and supporting business intelligence capabilities across multiple business divisions. You will play a key role in helping design our enterprise data architecture to support overarching data governance and related initiatives such as data architecture management, data security management, and data quality management.This role will be that of an over-arching Data Engineering guru. The ideal candidate will connect and work closely with Data Warehousing, Data Analytics, SW Engineering and Data Sciences as well as Product and Project Management. They will be responsible for solving some of the most complex and high scale data Engineering challenges in our industry while impacting the lives of healthcare professionals and their patients. The ideal candidate must be technologically curious, driven to work with some of newest data engineering technologies on the marketplace today. They will be a visionary and a key driver in the rapid adoption and scalability of crucial data engineering, warehousing and cloud-based technologies.This Data Engineer will collaborate with executive level internal and external stakeholders. They will lead the development, delivery and implement of AI, IOT, data engineering and data analytics projects which will leverage data to develop industry leading business insights. This person will focus on solutions such as machine learning, IoT, batch/real-time data processing, data and business intelligence while ensuring enterprise wide data security and integrity.ResponsibilitiesExtensive, demonstrated expertise with PythonHands on experience with ApacheDemonstrated experience with distributed computingExpertise with AWS services such as Athena, Glue, Lambda, S3, DynamoDB, NoSQL, Relational Database Service (RDS), Amazon EMR and Amazon Redshift.Experience with R helpfulExpertise with GCP resources including BigQuery and GCSPlan and execute complex data analyses using SQL and other toolsDelivery of cloud architecture to support new distributed computing solutions that often span the full array of cloud services. This will include migration of existing applications and development of new applications using cloud services.Own the Insights gleaned by the creation of advanced technology roadmaps. Share real world implementations and recommend new capabilities that would simplify adoption and drive greater value.RequirementsBachelor’s degree is required, while a Masters or PhD in Computer Science, Physics, Engineering or Math, and/or with Advanced certifications are highly desirable.Hands on experience leading enterprise-wide data engineering, warehousing and analytics projectsAbility to think strategically about business, product, and technical challenges in an enterprise environmentAbility to collaborate effectively across organizationsUnderstanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, PostgreSQL, BI reporting and Dashboard developmentDemonstrated industry efficiency in the fields of database, data warehousing or data sciencesImplementing AWS services in a variety of distributed computing, enterprise environmentsCustomer facing skills with the ability to drive discussions with senior leadership regarding trade-offs, best practices and risk mitigationDesire and ability to interact with all levels of the organizationReal Chemistry offers a comprehensive benefit program and perks, including flexible PTO, expanded paid leave for new parents including Your 4th Trimester ® , a program that helps new parents transition back to work, and a five-week sabbatical program. Other perks include Income Protection, Retirement plans/401(k) match, and cell phone savings plans. Learn more about our great benefits and perks at: http://www.realchemistry.com/Real Chemistry is committed to being an Equal Opportunity employer. As such, we seek motivated and qualified applicants without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity/expression, ethnic or national origin, age, physical or mental disability, genetic information, marital information, or any other characteristic protected by federal, state, or local employment discrimination laws where Real Chemistry operates. We strive to employ, motivate, advance and reasonably accommodate any qualified employees and applicants. We believe diversity of persons and ideas forms the most comprehensive, forward-looking company.",aus,de
16,Affirma Consulting,N/A,-1,Data Engineer,"Austin, TX",$86K - $101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=4323&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_08ef31cb&cb=1618160090036&jobListingId=4057950067,"Ranked one of Puget Sound Business Journals Best Workplaces and Fastest Growing Companies, Affirma is expanding its presence and hiring many talented individuals. Affirma offers exciting projects, a relaxed culture, and a flexible work environment.
Affirma is a full service technology consultancy. We provide a breadth and depth of expertise while maintaining the personal touch of a boutique firm. Our teams specialize in helping organizations of all sizes solve their most challenging business pain points by creating custom in-house solutions. We offer services ranging from business intelligence, web design and creative consulting, infrastructure, and so much more. At Affirma we are extremely passionate and dedicated to our customer satisfaction. Our teams focus on ensuring we are delivering dependable and reliable solutions with every project we work on.
This individual will support Affirmas mission to provide exception value to our clients by planning, executing, and deploying data management solutions.
Qualifications:



• 2-4 years experience in dimensional data modeling, ETL development, and data warehousing in a professional capacity

• Bachelors degree or equivalent education and/or experience

• Hands-on experience with at least one, and exposure to a variety of leading ETL, database, or data warehousing technologies like Azure, SQL Server, AWS, SSIS, and Redshift

• Strong knowledge of relational databases including retrieving, manipulating, creating, updating, and deleting data and database objects

• Experience bringing together data from many disparate data sources to a unified source of truth

• Hands-on experience implementing data warehouses of any scale and understanding of data warehousing best practices

• Advanced knowledge of T-SQL in developing complex queries, stored procedures, functions, and database administration operations, and query optimization and tuning

• Ability to work in a dynamic environment with some level of ambiguity to implement customer and project requirements with minimal supervision

• Driven by analytics and naturally curious to ask why and what if

• Excellent written and verbal communication with stakeholders, team members, and in documentation
Responsibilities:



• Design, propose, and develop database and data warehousing solutions

• Collaborate with team members to refine and debug scripts and reports

• Write and maintain documentation to describe database development, logic, scripting, testing, changes, and corrections

• Support the release of solutions into production environments

• Balance shifting priorities, demands, and timelines while effectively communicating expectations to team members and stakeholders in a clear and timely fashion

• Provide technical to assistance to data consumers regarding errors, problems, or questions with databases and reports

• Provide thought leadership, best practices, and standards required to deliver effective, lasting, and easy-to-maintain solutions to clients

• Continuously grow depth and breadth of knowledge of leading data and analytics tools and principles
Preferred experience includes:



• Background in computer science or related technical field

• Knowledge of programming or scripting language like R, Python, or JavaScript

• Experience working with Big Data tools like Hadoop
Accountabilities and Measures:



• Keeping our clients happy

• Working and collaborating well with internal and external team members

• Staying within project budget targets

• Adhering to billable and un-billable policies
Why Affirma?

• One of Washington's Fastest Growing Private Companies & Top 100 Best Companies to Work For (According to Seattle Business Magazine and Puget Sound Business Journal)

• Casual environment, surrounded by incredibly intelligent and motivated co-workers, and a performance-driven culture

• Flexible Schedule

• Opportunity for growth

• Great location, great people, exciting projects, and tons of fun.
",aus,de
17,Flex,Manufacturing,3.8,Manufacturing Engineer / Controls Engineer,"Austin, TX",$55K - $87K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044074&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_0d2a0d15&cb=1618160090036&jobListingId=4053631598,"Job DescriptionThe Manufacturing Engineer / Controls Engineer will be based in Austin, TX . Will be responsible for a receiving, analyze, clean, and customize technical information/documentation from the customer related to his product, derived from a New Product Introduction (NPI) or a design change in order to establish all necessary processes to manufacture it by maintaining its design and performance integrity.We are looking for someone who demonstrates:Intense collaborationPassionate customer focusThoughtful, fast, disciplined executionTenacious commitment to continuous improvementRelentless drive to winHere is a glimpse of what you’ll do:Analyze Customer and machine requirements and provide support and input which enables Flex Manufacturing Systems and Customer Systems to communicate so Product can be manufactured in Flex IT Systems .Write functional and technical specificationsTroubleshoot issues with hardware and processes.Must function as part of a cross functional team to support assembly operations.Analyzes data and reports to determine if designs meet functional and performance specifications.Confers with other engineering personnel and prepares design modifications as required.Evaluates data to improve yields of existing builds.Uses computer assisted engineering and design software and equipment to perform engineering and design tasks.Coordinates engineering activities for the Customer Focus Team (CFT) and coordinates with the customer to resolve production problems.Develops and updates documentation to establish production methodology and requirements.Manages BOM loads and Engineering Change NoticesUnderstands and updates Shop Floor systems/routingsMust be self-motivated, able to set priorities and able to multi-taskHere is some of what you’ll need (required):Electrical, Industrial, Computer Science or Mechanical Engineering Degree.Computer skillsMust have strong oral and written communication skillsHere are a few of our preferred experiences:Medical Industry experienceOffice software to include, Microsoft OFFICE and Outlook S/Wations skillsFlex MES System knowledgeAgile and Baan knowledgeSQLHere are a few examples of what you’ll get for the great work you provide:Full range of medical benefits, dental, visionLife InsuranceMatching 401KPTOTuition ReimbursementEmployee discounts at local retailersPF38#LI-PF1Job CategoryOperationsRelocationNot eligibleIs Sponsorship Available?NoFlex does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. Flex is an Equal Opportunity Employer and employment selection decisions are based on merit, qualifications, and abilities. Flex does not discriminate in employment opportunities or practices based on: age, race, religion, color, sex, national origin, marital status, sexual orientation, gender identity, veteran status, disability, pregnancy status or any other status protected by law. Flex provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: accessibility@flex.com . Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within Flex will be reviewed at the e-mail address. Flex will contact you if it is determined that your background is a match to the required skills required for this position. Thank you for considering a career with Flex.The information we collect:We may collect personal information that you choose to submit to us through the Website or otherwise provide to us. This may include your contact details; information provided in online questionnaires, feedback forms, or applications for employment; and information you provide such as CV/Resume. Your details will be provided to the entity you are applying for a job with. We will use your information for legitimate business purposes such as responding to comments or queries or answering questions; progressing applications for employment; allowing you to choose to share web content with others or; where you represent one of our customers or suppliers, administering the business relationship with that customer or supplier. We will process your data in accordance with our Recruitment Privacy Notice .If you have any queries about the processing of your data, please contact:Global Data Privacy Officer:Email Address: dataprotection@flex.com",aus,de
18,Cisco Systems,Information Technology,4.2,Big Data Software Engineer (),"Austin, TX",$77K - $141K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_72993936&cb=1618160090036&jobListingId=3776304919,"Who We are:Cisco Tetration builds a hybrid-cloud workload protection platform. Cisco Tetration allows customers to collect a rich set of telemetry data on their deployments (across bare-metals, virtual machines, containers) and enables them to implement zero-trust policies in their environment. In addition, it provides outstanding insights around network traffic visibility, policy discovery and management, application discovery and software vulnerabilities to end users.About the Role:As an integral member of the big data pipeline team, you will be closely involved in product development cycle from conceptualization to deploying in production environments. You will be embedded within cross-functional teams that include big data engineers, data scientists and UX/UI engineers. The features you develop will enable data center network transparency and management at unprecedented scale.Mandatory Skills 5+ years of expertise in one or more of Go, Java, C++. 2+ year’s experience in Hadoop and other Big Data technologies. Strong Foundation in data structures, algorithms and software design. Strong analytical and debugging skills. Familiar with agile practices, and believes in test driven development. Bachelor's Degree in Computer Science or related field (MS preferred).Nice to Have: Full stack software engineer. Experience in Machine Learning.#WeAreCisco, where each person is outstanding, but we bring our talents to work as a team and make a difference powering an inclusive future for all.We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (36 years strong) and only about hardware, but we’re also a software company. And a security company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!But “Digital Transformation” is an empty buzz phrase without an environment that allows for innovation, creativity, and yes, even failure (if you learn from it.)Day to day, we focus on the give and take. We give our best, give our egos a break, and give of ourselves (because giving back is built into our DNA.) We take accountability, multifaceted steps, and take difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us!#LI-MF1",aus,de
19,Visa,Information Technology,4.1,Staff Data Engineer - Visa AI Platform,"Austin, TX",$75K - $143K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=4134&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_6fa590c4&cb=1618160090036&jobListingId=4056034592,"Company DescriptionAs the world's leader in digital payments technology, Visa's mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company's dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.

At Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.

You're an Individual. We're the team for you. Together, let's transform the way the world pays.Job DescriptionPayments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area. For a payment system to work well, the risk techniques, performance, and scalability are critical. These techniques and systems can benefit from big data, data mining, artificial intelligence, machine learning, cloud computing, & many other advance technologies and in VISA, we have all of these. If you want to be in the exciting payment space, learn fast, and make big impacts, Artificial Intelligence Platform team within Payment Security & Identity group @ VISA is an ideal place for you!

This position is for a Staff Software Engineer with solid development experience who will focus on creating new capabilities for AI Platform while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.

You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.

This position will be based in Austin, TX and reporting to Director of Software Engineering. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.

Essential Functions

Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions.Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards. Responsibilities span all phases of solution development.Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolvedPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.

Qualifications

Basic Qualifications:

8 years of relevant work experience with a Bachelor’s Degree or at least 4 years of relevant work experience with an Masters Degree, or a PhD.

Preferred Qualifications:
Bachelor degree in Computer Science or related field and 8 years of Software Development Experience or a Masters with 5 years of Software Development Experience or a PhD with 2 years of experience.Exposure to leading-edge areas such as Machine Learning, Deep Learning, Stream Computing, MLOps.Expert in at least one of the following: Golang, Java, or C/C++Experience with web service standards and related patterns (REST, gRPC)Experience developing large scale, enterprise class distributed system or subsystems that require high availability, low-latency, & strong data consistency computingExperience implementing solutions for low-latency, distributed services using open standard technologies.Experience with Big Data and analytics in general leveraging technologies like Hadoop, Spark, Flink and MapReduceExperience with distributed caching technologies like RedisExperience developing proper metrics instrumentation in software components, to help facilitate real-time and remote troubleshooting/performance monitoring.Experience architecting solutions with Continuous Integration and Continuous Delivery in mindStrong interpersonal and leadership skills with effective communication (both written and verbal) skills and the ability to present complex ideas in a clear & concise way, a team player with good work ethicsA background in the fraud detection domain is a plus.


Additional InformationWork Hours

This position requires the incumbent to be available during core business hours.

Travel Requirements

This position requires the incumbent to travel for work 0% of the time.

Mental/Physical Requirements

This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms.

EEO Statement

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Visa will consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",aus,de
20,Apple,Information Technology,4.3,Data Engineer - Ad Platforms Engineering,"Austin, TX",$94K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_dbebd11c&cb=1618160090036&jobListingId=3750026858,"SummaryPosted: Nov 20, 2020Role Number:200208761At Apple, we work every day to create products that enrich people’s lives. Our Ad Platforms group makes it possible for people around the world to easily access informational and imaginative content on their devices while helping publishers and developers promote and monetize their work.Our technology and services power Search Ads in the App Store and the advertising found in Apple News. Our platforms are highly performant, deployed at scale, and set new standards for enabling effective advertising while protecting user privacy!The Ad Platforms Data Insights Engineering team is seeking a data engineer to join in developing the next generation of analytical solutions built to empower Sales, Product, and Executive teams. This role plays as a key member of the team driving the strategy, development, execution, and continuous improvement of data products for Ad Platforms. You will be building the foundational data architectures and pipelines for our core analytical data products & science capabilities. A successful candidate will have experience using varied data storage such as Hadoop, Cassandra, and Oracle as well as analytical and processing technologies such as Spark and Hive.Key QualificationsBackground in computer science, mathematics, or similar quantitative field with a minimum of 4-6 years professional experienceExperience supporting and working with cross-functional teams in a dynamic environmentExtract Transform Load (ETL) experience using Spark, Kafka, Hadoop, or similar technologiesSQL expertise, data modeling, and relational database experience requiredExperience using one or more scripting languages (e.g., Python, bash, etc.)Presto, Hive, SparkSQL, Cassandra, Solr, or other big data query and transformation experienceExperience with AWS cloud services: EC2, EMR, RDS, Redshift, Athena, Glue, SagemakerUnix-based command line experience requiredExperience with workflow scheduling / orchestration such as Airflow or OozieExperience with applying data encryption and data security standardsAbility to design and implement effective testing and operations strategies for data pipelines and data productsExperience implementing machine learning and data science workloads a plusData visualization experience using R, Python, or Tableau a plusData visualization or web development skills a plusAbility to communicate technical concepts to a business-focused audienceMost importantly, a sense of humor and an eagerness to learnDescription- Solve tough problems across the technology spectrum including designing, creating, and extending data storage, processing, and analytic solutions- Partner with business and analytics teams to understand specific requirements, build, and deploy analytical pipelines and data science workloads- Use modern tools and technologies to build reliable and performant pipelines and data products- Automate and optimize existing analytic workloads by recognizing patterns of data and technology usage- Must be able to work in a rapidly changing environment and perform effectively in a sprint-based agile development environmentEducation & ExperienceBachelor’s degree or equivalent experience required, Master's Degree in Computer Science or other Engineering field strongly desired",aus,de
21,Blizzard Entertainment,Media,3.5,Senior Software Engineer (C++) - Game Services,"Austin, TX",$74K - $144K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1044074&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_cc30937a&cb=1618160090036&jobListingId=4057449971,"Job Title:Senior Software Engineer (C++) - Game ServicesRequisition ID:R002267Job Description:The Battle.net & Online Products organization is home to 300+ superpowered engineers, program managers, and designers focused on the technology that powers Blizzard Entertainment’s games. Whether you’re playing one of our titles, chatting with friends, or just shopping online, B&OP ensures that our players are immersed in engaging, exciting, and secure experiences.Blizzard Entertainment has an opening for a talented and enthusiastic Senior Software Server Engineer to join our Battle.net Game Services GroupThe Game Services Group develops the software, services and infrastructure that keeps millions of players online simultaneously worldwide, 24 hours a day, 365 days a year. When a player logs in, sends a friend request, a whisper, or a chat within one of our rich virtual worlds, Game Services powers these capabilities. When you use voice chat, check your profile statistics, or create a new social group, we are the team that makes those things possible. From Overwatch to Hearthstone, StarCraft 2 to Diablo 3, World of Warcraft to Heroes, regardless of the game, time zone, or scale, Game Services is ready to answer the call with effectiveness and professionalism, acting as the central pillar to supercharge all player engagement.Covid-19 Hiring Update: We’ve transitioned to a work-from-home model and we’re continuing to interview and hire during this time. This role is expected to begin as a remote position. We understand each person’s circumstances may be unique and will work with you to explore possible interim options.ResponsibilitiesWork with a small and talented team to develop scalable, highly performant platform servicesImplement new features and services to support the needs of multiple teamsCoordinate with embedded and external teams, create relationships and assist with shared initiativesParticipate in the ongoing effort to improve our platform infrastructure, with the goal of achieving ever increasing service availabilityPerform research to acquire new knowledge necessary to perform assigned tasks and maintain a process of technological evolutionDevelop unit and integration test code to validate service reliabilityMentor and educate more junior engineers on the teamRequirementsA degree in computer science, or a related fieldA minimum of 5 years of relevant work experienceAbility to work in a collaborative environmentExcellent communication skillsAdvanced understanding of C++Prior development work on distributed systems and client/server architecturesStrong data-structure, logic, and algorithm skillsKnowledge of network and server security issuesExperience with performance analysis and code optimizationExperience with protocol and API designDatabase development experience (MySQL, Oracle, Cassandra, etc.)Self-motivated and able to break down complex tasksA desire to help make the service the best that it can be for our playersPlusesProficient in at least one scripting language such as PythonLinux development experience (server applications, gdb debugging, etc.)Experience with cloud/virtualization/containerization technologies and infrastructureEnthusiastic about supporting a live serviceFamiliarity with Blizzard Entertainment games and features, at least at a casual player levelTeam Name:Battle.net & Online Products",aus,de
22,The HT Group,Business Services,4.2,Lead AdTech Engineer,"Austin, TX",$85K - $178K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1044072&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_6a4cc7ef&cb=1618160090037&jobListingId=4053929367,"Salary: Market relatedReference: 13944The Role:Working as a Lead Software Engineer, you will be involved with high level design and architecture decisions and hands-on coding to field our next generation of Supply Side and Demand Side Platform architecture for video ad transcoding. This role will intermarry state of the art video encoding technology with high availability, cloud-based APIs for interaction with SSPs, DSPs, and 3rd party video advertising servers. To fully contribute, you will need an understanding of IAB standards and industry practices both on conceptual and pragmatic levels. The role requires an ability to innovate new solutions and to communicate across all levels of the company.Responsibilities:Work with Business Development to extend our video ad transcoding architecture so it meets our customers' needs and grows revenue.Apply advertising technology domain knowledge to broaden and improve our ability to interact in the video ad tech ecosystem.Translate business needs and strategy into technical specifications & requirements.Direct software team members and provide hands on contributions to architecture, systems design, implementation, testing and deployment.Map out development pathways to meet current and future opportunities in the rapidly changing online and streaming video advertising space.Minimum QualificationsHigh level competency designing, implementing, and testing systems that interact using OpenRTB, VAST, VPAID, DSP, SSP for high availability ad serving and measurement.7+ years of experience in software development, ad system architecture, and digital ad technologies.Demonstrated experience and success architecting and directing teams to create fielded ad serving systems.Expert level fluency in JavaScript with strong competency with HTML, CSS, and DOMThe ability to diagnose issues and identify and implement solutions for 24x7 live, cloud based (AWS, Google Cloud, Azure) systems.Attention to detail and understanding of engineering best practices.Strong communication skills, being able to discuss complex technical topics using clear, understandable language in both written and spoken form.Bachelor's degree required. with a major in Computer and/or Data Science, Statistics, Mathematics, or Engineering. Advanced degree preferred.Desired Additional Qualifications- Familiarity and understanding of video and audio transcoding systems. - Working knowledge of Python, C++, Relational Databases.",aus,de
23,Dell Technologies,Information Technology,4.2,"Consultant, Data Archive Engineer","Austin, TX",$77K - $144K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_eba27e6f&cb=1618160090037&jobListingId=3771929600,"Consultant, Data Archive EngineerThe Data Archive Engineer will be part of a team that will be responsible for maturing Dell’s capabilities around programmatically archiving and purging data, to align with security and privacy requirements as well as opportunities to optimize business processes and infrastructure usage.ResponsibilitiesWork with application SMEs and business stakeholders to identify entities for archival and any dependencies to be considered when defining archive and purge rulesConfigure Informatica ILM to connect to legacy application databasesBuild retirement and reporting entities per requirements for each application databaseSet up corporate retention rules, per the security and privacy policies and application retention rules, per the business requirementsConfigure legal and audit holds in ILMWork with the application teams to create and manage schedule/calendar for archive and purge jobs, and work with those teams to execute the jobsCreate reports from Informatica ILM to provide visibility to application teams, business stakeholders, and executive leadership.Play a supportive role working with the Infrastructure team for general Informatica ILM administration activities, including to ensure environments are maintained, software upgrades are completed as required, and ILM application issues/tickets get resolved.SkillsCompetent to analyze diverse and complex problemsLeads large budget projectsExcellent analytical and problem-solving skills is a must haveStrong communication and presentation skillsAbility to communicate complex insights in a precise and actionable mannerMindset to think differently; alignment to Industry standards; awareness of emerging technologies and industry trendsRequirementsTools: Secure Data ArchiveDatabase Platform Experience: MySQL, SQLServer, Sybase, Oracle, etc.Database Scripting/Development: SQL, PL/SQLScheduling Tools: Autosys, DBMS_JOBSOS: UNIX/Linux shell scriptingReporting Tool Experience: Power BI, Crystal, Biz Obs, etc.Experience gathering/validating technical and functional requirements with customerExperience reviewing data/testing results with customerExperience with data modeling or reverse engineering data modelsUnderstand Dev and Test process E2EBI/Data Analytics ExperiencePreferencesBachelor of Engineering or Master of Computer ApplicationsExperience in working in Agile (SCRUM) MethodologyHere’s our story; now tell us yoursDell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life - while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.Application closing date: 31 December 2020Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.Job ID: R078195",aus,de
24,Apple,Information Technology,4.3,Big Data Engineer - Wallet & Apple Pay - Austin,"Austin, TX",$94K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_fefe9147&cb=1618160090037&jobListingId=4055514716,"SummaryPosted: Oct 5, 2020Role Number:200197422Looking for hardworking, passionate and results-oriented individuals to join our team to build data foundations and tools to craft the future of commerce and Apple Pay. You will design and implement scalable, extensible and highly-available data pipelines on large volume data sets, that will enable impactful insights & strategy for payment products. Our culture is about getting things done iteratively and rapidly, with open feedback and debate along the way; we believe analytics is a team sport, but we strive for independent decision-making and taking smart risks. Our team collaborates deeply with partners across product and design, engineering, and business teams: our mission is to drive innovation by providing the business and data scientist partners outstanding systems to make decisions that improve the customer experience of using our services. This will include using large and complex data sources, helping derive measurable insights, delivering dynamic and intuitive decision tools, and bringing our data to life via amazing visualizations.Collaborating with the head of Wallet Payments & Commerce Data Engineering & BI, this person will collaborate with various data analysts, instrumentation specialists and engineering teams to identify requirements that will derive the creation of data pipelines. You will work closely with the application server engineering team to understand the architecture and internal APIs involved in upcoming and ongoing projects related to Apple Pay. We are seeking an outstanding person to play a pivotal role in helping the analysts & business users make decisions using data and visualizations. You will partner with key players across the engineering, analytics & business teams as you design and build query friendly data structures.The ideal candidate is a self-motived teammate, skilled in a broad set of data processing techniques with the ability to adapt and learn quickly, provide results with limited direction, and choose the best possible data processing solution is a must.Key Qualifications5+ years of professional experience with Big Data systems, pipelines and data processingPractical hands-on experience with technologies like Apache Hadoop, Apache Pig, Apache Hive, Apache Sqoop & Apache SparkAbility to understand API Specs, identify relevant API calls , extract data and implement data pipelines & SQL-friendly data structuresIdentify Data Validation rules and alerts based on data publishing specifications for data integrity and anomaly detectionUnderstanding on various distributed file formats such as Apache AVRO, Apache Parquet and common methods in data transformationExpertise in Python, Unix Shell scripting and Dependency driven job schedulersExpertise in Core JAVA, Oracle, Teradata and ANSI SQLFamiliarity with rule based tools and APIs for multi stage data correlation on large data sets is a plusDescriptionTranslate business requirements by business team into data and engineering specificationsBuild scalable data sets based on engineering specifications from the available raw data and derive business metrics/insightsUnderstand and Identify server APIs that needs to be instrumented for data analytics and align the server events for execution in already established data pipelinesExplore and understand sophisticated data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reportingProcess, clean and validate the integrity of data used for analysisDevelop Python and Shell Scripts for data ingestion from external data sources for business insightsEducation & ExperienceMinimum of bachelor’s degree, preferably in Computer Science, Information Technology or EE, or relevant proven experience is preferred",aus,de
25,VMware,Information Technology,4.3,"Data Engineer - Opportunity for Working Remotely Austin, TX","Austin, TX",$86K - $159K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_8ae5e539&cb=1618160090037&jobListingId=4054831053,"The Elevator Pitch: Why will you enjoy this new opportunity?This Data Engineer position provides a unique opportunity to grow your career by deepening your Analytics expertise and learning more sophisticated data science techniques to deliver better insights while also providing customer facing exposure. You will have opportunities to participate in design, by presenting data and valuable points of consideration to resolve problems. This customer experience is critical for anyone with a passion in data and analytics looking to broaden their business acumen.Success in the Role: What are the performance outcomes over the first 6-12 months you will work toward completing?Work with data engineering team to learn the environment and start delivering on solutions within 90 days. During this time frame, identify critical design and test issues needed to ensure an on-time delivery. Within 180 days, person should be able to pick up subject area independently and deliver the solutions.The Work: What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis?Most of your time will be spent analyzing data and writing high-quality code with excellent test coverage using Informatica/Python/HIVE/HANA/Spark and BOBJ/Tableau. You can expect to be the owner and take accountability for the quality of your code.Collaborate in-person and through Slack/Zoom or e-mail with data engineering team to brainstorm solutions.Spend time learning VMware’s standard operations, products, and improving your engineering and professional skills. We want you to be curious, learning both from team members and individual study.What is the leadership like for this role? What is the structure and culture of the team like?The hiring manager for this role is Arvind Panwar, Manager, Data Engineering, Sales. His expertise has been built from the frontlines with roles in Analytics solutions, program management and most recently in management of a data engineering team for the past one year.Arvind’s management philosophy is about encouraging everyone on the team to be independent thinkers and helping other team members. Arvind looks for people who can think out-of-the-box and then execute on a good idea. Innovation = Creativity and Execution.The core team is made up of three data engineers and 3 BI engineers software developers and close partnership with a member of other data engineering team. The team works flexible hours, arranging schedules to fit their needs and taking consideration for phone calls with global colleagues and business stake holders, primarily in US, EMEA, India and Costa Rica.What are the benefits and perks of working at VMware?You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com.Employee Stock Purchase PlanMedical Coverage, Retirement, and Parental Leave Plans for All Family TypesGenerous Time Off Programs40 hours of paid time to volunteer in your communityRethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilitiesFinancial contributions to your ongoing development (conference participation, trainings, course work, etc.)Wellness reimbursement and online fitness and wellbeing classesThis job requisition is not eligible for employment-based immigration sponsored by VMware.#LI-REMOTECategory : Engineering and TechnologySubcategory: Software EngineeringExperience: Manager and ProfessionalFull Time/ Part Time: Full TimePosted Date: 2021-04-07Cloud Management: VMware’s Cloud Management team delivers vRealize Suite, a solution that’s essential to accelerating our customers’ journey to digital transformation. It’s our market-leading, state-of-the-art cloud management platform designed to deliver and manage IT services across private, public, and hybrid clouds. VRealize Suite is an integrated, comprehensive solution that meets the challenge of managing a cloud infrastructure from a single pane of glass. We’re changing the way users design, build, view, and manage public and private clouds, and enabling them to run with optimal performance, insightful analytics and automated delivery. Join our user-focused team of software engineers, data scientists, web designers, product managers, and marketers. You’ll gain valuable experience in the fast-growing field of cloud infrastructure management from a pioneer and industry leader.VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",aus,de
26,Amazon.com Services LLC,Information Technology,3.8,Software Development Data Engineer,"Austin, TX",$75K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=133043&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_b43d7fe5&cb=1618160090037&jobListingId=3822222485,"5+ years of experience with Linux operating systems including operations in a large-scale production environment.5+ years of Systems Engineering / Administration including experience in a large distributed environment.5+ years experience in shell, Perl and/or other scripting languages.3+ years of Amazon Web Services.3+ years of experience using system monitoring suites, understanding of and defining metrics collection, collector configuration and definition, and topology architecture within a large-scale environment.2+ years of Python scripting experience.2+ years experience in a DevOps environment supporting large scale production environment.1+ years of Network Engineering / Administration experience.2+ years of Data Administration, preferably DynamoDB.Ability to produce high quality technical and supporting documentation.Bachelor’s Degree in a technology related field or equivalent professional experienceDo you love big challenges and solutions that scale?Amazon Operations Technology is looking for an experienced Systems Development Engineer to join our Data Services team in Austin, TX. In this role you will be solving challenging problems and developing scalable, high-performing solutions that require minimal long-term sustaining and development support. Our team is responsible for all global core services and infrastructure within the Operations Technology space; our systems support over 100,000 Amazonians and hundreds of thousands of IP enabled devices.In this role, you will partner with Systems Engineers, Network Engineers and Software Engineers globally to develop simple and efficient technology that supports our Fulfillment Centers and Transportation Sites. You will work with a wide variety of technologies and projects that range from third party enterprise solutions to open source and proprietary inventions. Technicians and Engineers worldwide will look to you for mentorship, guidance and solutions to complex business problems that are truly unique to Amazon. We value performance, simplicity, and scalability in our designs. In your day-to-day work you will focus on automation of complex tasks to allow our business to scale with customer demand.5+ years of Amazon Web Services.5+ years of experience in a DevOps environment supporting large scale production environment.5+ years of Python scripting experience.Robust troubleshooting, problem-solving and analytical skills.Robust understanding of Information Security principles and mitigation techniques.Excellent communication, documentation and presentation skills for technical and business audiencesA degree in Computer Science, Electrical Engineering or equivalent technology discipline.Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",aus,de
27,Amazon Advertising LLC,Information Technology,3.8,Data Engineer - Amazon Advertising,"Austin, TX",$88K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=133043&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_9aa838a7&cb=1618160090037&jobListingId=4056914476,"3+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQL5+ years of experience as a Data Engineer or in a similar roleDemonstrated strength in data modeling, data warehousing, and building ETL pipelinesSQL proficiencyBachelor’s degree in Computer Science or related fieldExperience with MySQL or MS SQL or Oracle replication, clustering, and scalingExperience with database backups and remote disaster recoveryExperience dealing with large databasesExcellent interpersonal communication and strong verbal and written English skillsDo you want a unique, exciting opportunity to help start a new data engineering team within a rapidly growing organization within Amazon Advertising? Amazon’s Advertising Analytics and Insights (A&I) team is looking for an experienced data engineer who is passionate about developing scalable data solutions from the ground up and who is looking for opportunities where the work they do powers the growth of the business.This is a highly visible position with significant impact and growth. You will get an opportunity to build products from ground up at Amazon scale. You can shape the architecture, design and deliverables without being bogged down supporting legacy systems. We are looking for an engineer who can thrive in a startup environment, think big, and can move fast. In this role, you will be responsible for structuring and streamlining large sets of data regarding our insight decisioning processes, with the ultimate goal of building a solution that drives automation of insight decisioning via machine learning logic. The ideal candidate will be comfortable navigating ambiguity and recognizing patterns in order to drive automation of insight decisioning logic.As a data engineer on this team, you will:Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to design systems that meet business needs.You will analyze the business problems and design reliable, scalable data storage and analytics systems that enable the business and our products to scale.Play a leading role in building systems and datasets using software engineering best practices, data management fundamentals, data storage principles, and operational excellence best practices.Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specificationsEffectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflictsAdvanced degree in Engineering, Computer Science or related fieldDemonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.Understanding of Big Data technologies and solutions (Spark, EMR, Hive, S3, Redshift, etc.)Understanding of Amazon Web Services (AWS) technologiesExperience with multiple database platformsPassion for learning and using new technologiesThrives in a fast-paced, innovative environmentAmazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age",aus,de
28,Cisco Systems,Information Technology,4.2,Big Data Software Engineer,"Austin, TX",$77K - $141K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_22fb04e0&cb=1618160090037&jobListingId=3776304923,"Who We are:Cisco Tetration builds a hybrid-cloud workload protection platform. Cisco Tetration allows customers to collect a rich set of telemetry data on their deployments (across bare-metals, virtual machines, containers) and enables them to implement zero-trust policies in their environment. In addition, it provides unprecedented insights around network traffic visibility, policy discovery and management, application discovery and software vulnerabilities to end users.About the Role:As an integral member of the software agent team, you will be closely involved in product development cycle from conceptualization to deploying in production environments. You will be embedded within cross-functional teams that include big data engineers, data scientists and UX/UI engineers. The features you develop will enable data center network visibility and management at unprecedented scale.Mandatory Skills 5+ years of expertise in one or more of Go, Java, C++. Strong Foundation in data structures, algorithms and software design. Strong analytical and debugging skills. Familiar with agile practices, and believes in test driven development. Bachelor's Degree in Computer Science or related field (MS preferred). 2+ years’ experience in Druid and HBase preferred.Nice to Have: Full stack software engineer. Experience in Machine Learning.#WeAreCisco, where each person is outstanding, but we bring our talents to work as a team and make a difference powering an inclusive future for all.We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (36 years strong) and only about hardware, but we’re also a software company. And a security company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!But “Digital Transformation” is an empty buzz phrase without an environment that allows for innovation, creativity, and yes, even failure (if you learn from it.)Day to day, we focus on the give and take. We give our best, give our egos a break, and give of ourselves (because giving back is built into our DNA.) We take accountability, multifaceted steps, and take difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us!#LI-MF1",aus,de
29,Sense Corp,Business Services,4.1,Cloud Data Engineer,"Austin, TX",$72K - $135K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=14295&s=58&guid=00000178c1db790c855a302cbd767d55&src=GD_JOB_AD&t=SR&vt=w&cs=1_7c137b29&cb=1618160090038&jobListingId=3488895299,"Sense Corp is seeking a brilliant, creative, fun, and passionate Data Engineer, who is naturally curious. Our Data Engineers work with cross-functional teams, are passionate about data accuracy and reliability and are always looking for new and more efficient ways to extract, process and transform data, As part of our Technology division, you will collaborate with the team while individually contributing to project deliverables that meet our clients’ needs.

Deep expertise in ETL automation tools such as Azure Data Factory, Matillion, Talend, Mulesoft, Informatica Cloud Experience with Cloud Data Warehouse tools such as Snowflake, Amazon Redshift, Azure Synapse, Google BigQuery Experience with Data Lake technology such as Amazon S3, Azure Data Lake, Google Cloud Storage Experience with cloud-based platforms and tools, and migration paths from legacy systems Experience with DevOps tools and practices such as Git, Jenkins, JIRA, Azure DevOps Experience with integrating with both database systems and APIs Experience with documenting technical requirements, designs and systems Extensive experience building scalable and resilient data pipelines Extensive experience writing SQL Experience with procedural, functional or object-oriented programming language such as Python, Java, Scala, R

Additionally, candidates should be able to perform at a high level in at least two of the following technology categories:

Big Data tools such as Apache Hadoop, Spark, and Hive including managed solutions such as Databricks, Amazon EMR, Azure HD Insight, and Google Cloud Dataproc Message broker solutions such as Kafka, Google Pub/Sub, Amazon Kinesis Stream processing solutions such as Flume, Storm, Spark Streaming NoSQL Databases such as HBase, Cassandra, Redis

Requirements

Minimum 3 years of experience in a similar role Ideally previous experience as a Technical Consultant Entrepreneurial attitude with desire to foster and grow the Data Engineering team or in addition to fulfilling project responsibilities Growth minded and focused on personal improvement in addition to delivering successful projects Willing to travel to client Bachelor’s Degree in CS, MIS, CIS, or a comparable technical degree US Citizen or GC Holder

Benefits

Sense Corp has a proud history of ranking among both the Best Places to Work and Healthiest Employers in Austin, Dallas, Houston, and St. Louis. We offer a variety of ways to LEARN, SERVE, GIVE, RELATE, and GROW.

Extensive Training Opportunities Wellness Program Leadership & Professional Development Mindfulness Program Employee Driven Centers of Excellence Social & Educational Networks Enterprise Diversity & Belonging Program Community Outreach

About Sense Corp

Sense Corp is a leading professional services firm focused on transforming organizations and government agencies for the digital era. We deliver tailored solutions to help clients solve their most complex challenges and maximize potential. Founded in 1996, Sense Corp maintains operations in Austin, Columbus, Dallas, Houston, Minneapolis, and St. Louis and serves mid-market to Fortune 50 companies.

The Sense Corp Compass

We may be the only consulting firm in the country where being brilliant isn’t enough to land you a job. Sense Corp employees must be brilliant, creative, human, and fun all at once. In other words, we hire terrific, well-rounded people. It’s one reason clients love working with us. And it’s why we enjoy working with each other. Regularly recognized as a Best Place to Work and Healthiest Employer, Sense Corp is driven by a company culture that aims to help employees be the best version of themselves.

Visit us at www.sensecorp.com.",aus,de
58,Dun & Bradstreet,Information Technology,3.4,PenTesting Application Security Engineer -100% remote,"Austin, TX",$91K - $139K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1206940&s=58&guid=00000178c1dc967e99865611a77a7dd8&src=GD_JOB_AD&t=SR&vt=w&cs=1_5ddeeb07&cb=1618160163075&jobListingId=3745083277,"Why We Work at Dun & BradstreetWe are at a transformational moment in our company journey - and we’re so excited about it. Each day, we are finding new ways to strengthen our award-winning culture, and to accelerate creativity, innovation and growth. Our purpose is to help customers improve business performance with Dun & Bradstreet’s Data Cloud and Live Business Identity, and we’re wildly passionate and committed to this purpose. So, if you’re looking to make an immediate impact at a company that welcomes bold and diverse thinking, come join us!

​

The Role

The Application Security Engineer will be part of D&B’s Product Security team and will be part of a team that is responsible for ensuring secure software delivery of the D&B products.

In this role, the Application Security Engineer will perform vulnerability assessments, penetration testing, code reviews and implement DevSecOps practices to guide application teams and help them make their products more secure.

*This role can be 100% remote (US only) or located in our Austin, TX/Center Valley, PA or Short Hills, NJ offices (hybrid schedule)

Responsibilities

Conduct and perform vulnerability analyses on web and mobile applications. 

Perform dynamic application security testing (DAST) before applications are deployed in production.

Perform Static Scanning (SAST) and triage results to advise development teams on remediationsDevelop DevSecOps practices (configure SAST/DAST tools, Jenkins etc) by implementing key controls (SAST/DAST/SCA) in the SDLC

Perform manual code reviews (Java/C#.net) to identify business logic vulnerabilitiesIdentify and develop metrics/KPIs to show the progress of overall application security program and identify opportunities for improvement.Be able to pivot onto ad-hoc assignments as necessary

Qualifications

Bachelors Degree in Computer Science or other related fields of study5-7 years of working experience in technology, with 3+ years in cyber security (specifically PenTesting and vulnerability assessment)Proficiency in understanding of: Burp Suite, OWASP Top 10, OWASP ZAP, NVD, CVSS scoring, application assessmentsStrong proficiency in at least one programming language (Python preferred)Strong technical acumen, communication and influence skills to demonstrate effectiveness of different application security initiatives

Pluses:

Experience with project development, management, and tracking software (JIRA, Confluence, BitBucket, GitHub, etc)Experience security tools such as CheckMarx, Snyk etc

Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.

We are committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with Dun & Bradstreet and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to TalentAcquisitionTeam@dnb.com. Determination on requests for reasonable accommodation are made on a case-by-case basis.

Please note that all Dun & Bradstreet job postings can be found at https://dnb.wd1.myworkdayjobs.com/Careers and all communication from Dun & Bradstreet will come from an email address ending in @dnb.com.",aus,de
59,Indeed,Information Technology,4.4,Director of Software Engineering- Data Infrastructure,"Austin, TX",$108K - $171K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1044074&s=58&guid=00000178c1dc967e99865611a77a7dd8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_90f3a419&cb=1618160163075&jobListingId=4055237744,"Your JobAs the engineering leader for our data infrastructure team, you will be responsible for managing Indeed’s data lake, including many aspects of our cloud migration, our storage platform, and our compute platform. This team owns the data pipelines for replicating operational and transactional systems into our data lake. This team consists of experts on how to move data around, and are responsible for developing frameworks which allow employees to connect with and derive insights from this data. As our engineering organization grows, you will help build the team, ensure we keep the talent bar high, and grow the skills and capabilities of your team. All of Indeed’s products are built with performance, scalability, and data-driven decision-making in mind. You can read more about the kinds of technology challenges we tackle on the Indeed Engineering Blog at: http://engineering.indeed.com/blogWho You AreYou're someone who wants to see the impact of your work making a difference every day. You understand how to use data to make decisions. You are someone who finds passion in the craft, someone constantly seeking improvement and a better way to solve tough problems. You have a passion for producing the highest quality code as well as leading others to do the same. You are someone who either has built or is passionate about building scalable, reliable systems that span multiple data centers around the world and handle millions of requests every day.You understand that the best managers serve their teams, removing roadblocks and giving individual contributors autonomy and ownership. You are someone with high standards who will push us to be better, and who will take pride in Indeed like we do. You have delivered challenging technical solutions at scale. You have led engineering teams and earned the respect of talented software developers. You are equally happy talking algorithms and data structures as you are brainstorming about agile development process and technology career development. You want to be in the mix technically while providing leadership to your teams.What we are looking for7+ years of experience in leading software development with a consistent track record of on-time delivery for large, cross-functional projectsExtensive experience building data platforms using technologies like Hadoop, Apache Spark, and AWSSomeone who has led teams that manage large Hadoop clusters or who have built a large scale database or data lakeExtensive experience leading cross-team initiativesOur managers are still very technically involved in coaching and driving technical discussions and decisions, and we value the Lead by Example philosophy at Indeed in our engineering managers.The ability to guide a team to achieve important goals togetherThe desire to solve tough problems with quality software at scaleAn understanding of the value derived from shipping code rapidly to production and learning/iterating on the results.Strong ability to coach developers, helping them improve their skills and grow their careersStrong knowledge of databases, both SQL and NoSQLExperience building high-performance distributed systemsWho we areWe are a rapidly growing and highly-capable Engineering organization building the most popular job site on the planet. With engineering hubs in Seattle, San Francisco, Austin, Tokyo, Singapore, Hyderabad, Dublin, Aberdeen and Vancouver, we are improving people's lives all around the world, one job search at a time.Our MissionAs the world’s number 1 job site*, our mission is to help people get jobs. We strive to cultivate an inclusive and accessible workplace where all people feel comfortable being themselves. We're looking to grow our teams with more people who share our enthusiasm for innovation and creating the best experience for job seekers.(*comScore Total Visits, March 2020)Salary Range DisclaimerThe base salary range represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Restricted Stock Units (RSUs), an open Paid Time Off policy, and many region-specific benefits.Salary Range TransparencySeattle 241,000 - 315,000 USD per yearEqual Opportunities and Accommodations StatementIndeed is deeply committed to building a workplace and global community where inclusion is not only valued, but prioritized. We’re proud to be an equal opportunity employer, seeking to create a welcoming and diverse environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, family status, marital status, sexual orientation, national origin, genetics, neuro-diversity, disability, age, or veteran status, or any other non-merit based or legally protected grounds.Indeed is committed to providing reasonable accommodations to qualified individuals with disabilities in the employment application process. To request an accommodation, please contact Talent Attraction Help at 1-855-567-7767, or by email at TAhelp@indeed.com at least one week in advance of your interview.Privacy PolicyView Indeed's Applicant Privacy and Accessibility Policies - https://www.indeed.com/legal/indeed-jobs",aus,de
120,Lowe's Home Improvement,Retail,3.5,SR. DATA ENGINEER - BIG DATA PLATFORMS,United States,$86K - $197K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1110586&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_d6b2923e&cb=1618160368322&jobListingId=1006991146118&cpc=BCC169F53084E245&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-59a08035d5c2c7ab&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMUmUtN0t1VkxuSmhYQ3JKeUxucHdmbVdfN2Vic0ZKQWI4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlOUWlXakNYcEsxeExTaXd2Wk92UlNjUzZCUDJjNlZxSXZvaWVwaFhQNUQ3RFJraTJVdUdYMzEza0J4Q184b0laSllBMVhXTmFmQ19fQlBBcDZmejBhNTBkVjlDcTRyV2I0R1c5azFxWjdBR0M2VEtQb25jUUgxOU93NktxUWdYUmlNaGZjdnJtcF9UU0pPaTlrLWdvTVNKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSVElpc2RKYTN5aUhvRlBQTkxXQ2dXMnZzdk9FcC0yZjJ1WDJoRU02a3RuZzU5ck1oM2FPYVY4bVZCenV5MGlwRW5CRzhFYjZ6VHJSZmg1eklxTEx2eXhFRFVLY3RIVnNVdmNldTdaSjVmaEdQOUFobUV5Ylk3NlZZOGpKLWNGV2ZnLVBwUFNZbnhmeUkyb1VaenhWbzFPM3E2STVvVlM2bFQ0TDFabjFKcjQ5aHpVS2xjU2IydGJIa1NmOUw5UU9mQmpiY3Nzb0pqQ19hSnZzRERQVFBGbjh3dkJNZmlncFFaUlFZejc0YW5jemp6b05DSXhQZnFoS0c5ZC0zeW1GSmRfTFdja2QzZjlKaVVxQzdaT3NjZ3RYd2xYRWd3ejB5Z0dmLXR0ckpwOTNoSFlrQnZmd2hrMnFqalNKVWtWcTFScDVQdm90ak9lc2tPTk5OTzZMWUF3Tzd3RWtOdkhfcQ,"At Lowe’s – Data, Analytics and Computational Intelligence – we run large Big Data Platforms for Data Processing, ML, Data Analytics. If you are passionate about setting up Big Data Platforms on-prem and on cloud, working on debugging issues, platform triage, etc. this is for you. You will be challenged with managing multiple Big Data platforms on Hadoop, exploring new technologies, set up of data storage platforms involving Open Source technology, integrating data platforms with Catalog, BI Tools, setting up platform for ML model training, deployment, etc.This person needs to be motivated towards learning, exploring technologies, guiding team members, collaborating with users and be able to set up a modern platform for Data Processing, Storage, Data Preparation, Training and Deployment.JOB SUMMARY: The primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver modules, stable application systems, and Data or Platform solutions. This includes developing, configuring, or modifying complex integrated business and/or enterprise infrastructure or application solutions within various computing environments. This role facilitates the implementation and maintenance of complex business and enterprise Data or Platform solutions to ensure successful deployment of released applications.Key Responsibilities: Translates complex cross-functional business requirements and functional specifications into logical program designs, modules, stable application systems, and data solutions; partners with Product Team to understand business needs and functional specificationsCollaborates with cross-functional teams to ensure specifications are converted into flexible, scalable, and maintainable solution designs; evaluates project deliverables to ensure they meet specifications and architectural standardsGuides development teams in the design and build of complex Data or Platform solutions and ensures that teams are in alignment with the architecture blueprint, standards, target state architecture, and strategiesCoordinates, executes, and participates in component integration (CIT) scenarios, systems integration testing (SIT), and user acceptance testing (UAT) to identify application errors and to ensure quality software deploymentParticipates and coaches others in all software development end-to-end product lifecycle phases by applying and sharing an in-depth understanding of complex company and industry methodologies, policies, standards, and controlsHas solid grasp of software design patterns and approaches; understands application level software architecture; makes technical trade-off decisions at application levelAutomates and simplifies team development, test, and operations processes; develops detailed architecture plans for large scale enterprise architecture projects and drives the plans to fruitionSolves complex architecture/design and business problems; solutions are extensible; works to simplify, optimize, remove bottlenecks, etc.Provides mentoring and guidance to more junior level engineers; may provide feedback and direction on specific engineering tasksPlatform Engineering ResponsibilitiesAdministering crucial and complex Bigdata/Hadoop infrastructure to enable next generation analytics and data science capabilities.Adding immediate value by establishing big data environments based on Hadoop.Innovating and evolving our big data capabilities through research and hands-on practice.Operating a multi-tenant service, encompassing cluster management, security, resource and quota management, partitioning. monitoring chargeback, data governance, quality and lineage.Performance monitoring and Benchmarking experience to run various workloads. As needed participation in after-hours maintenance windows to update, change, and install various systems; Participation in the 24 x 7 On-Call Rotation.Hands-on experience in Hadoop cluster set up, performance fine-tuning, monitoring, and administration.Manage Bigdata application on On-prem and Public cloudMinimum QualificationsBachelor's Degree in Engineering, Computer Science, CIS, or related field (or equivalent work experience in a related field)5 years of experience in Data, BI or Platform Engineering, Data Warehousing/ETL, or Software Engineering4 years of experience working on project(s) involving the implementation of solutions applying development life cycles (SDLC)Platform Engineering Qualifications4-5 years of experience in Hadoop, NO-SQL, RDBMS or any Cloud Bigdata components, Teradata, MicroStrategyExpertise in Java/Scala/Python, SQL, Scripting, Teradata, MicroStrategy, Oracle, MySql, SQL Server, Hadoop (Sqoop, Hive, Pig, Map Reduce), Spark (Spark Streaming, MLib), Kafka or equivalent Cloud Bigdata componentsPreferred QualificationsIn most cases Lowe’s will not be able to provide sponsorship for roles located in the Tech HubMaster's Degree in Computer Science, CIS, or related field5 years of IT experience developing and implementing business systems within an organization5 years of experience working with defect or incident tracking software5 years of experience writing technical documentation in a software development environment3 years of experience working with an IT Infrastructure Library (ITIL) framework3 years of experience leading teams, with or without direct reports5 years of experience working with source code control systemsExperience working with Continuous Integration/Continuous Deployment tools5 years of experience in systems analysis, including defining technical requirements and performing high level design for complex solutionsAbout Lowe’s: Lowe’s Companies, Inc. (NYSE: LOW) is a FORTUNE® 50 home improvement company serving approximately 18 million customers a week in the United States and Canada. With fiscal year 2019 sales of $72.1 billion, Lowe’s and its related businesses operate or service more than 2,200 home improvement and hardware stores and employ approximately 300,000 associates. Based in Mooresville, N.C., Lowe’s supports its hometown Charlotte region and all communities it serves through programs focused on creating safe, affordable housing and helping to develop the next generation of skilled trade experts. For more information, visit Lowes.com.About Lowe’s in the Community: As a FORTUNE® 50 home improvement company, Lowe’s is committed to creating safe, affordable housing and helping to develop the next generation of skilled trade experts through nonprofit partnerships. Across every community we serve, Lowe’s associates donate their time and expertise through the Lowe’s Heroes volunteer program. For the latest news, visit Newsroom.Lowes.com or follow @LowesMedia on Twitter.Lowe’s is an equal opportunity affirmative action employer and administers all personnel practices without regard to race, color, religion, sex, age, national origin, disability, sexual orientation, gender identity or expression, marital status, veteran status, genetics or any other category protected under applicable law.Job Type: Full-timePay: $86,227.00 - $197,447.00 per yearBenefits:Health insurancePaid time offSchedule:Monday to FridayEducation:Bachelor's (Required)Experience:data: 5 years (Preferred)Work Location:Multiple locationsWork Remotely:Temporarily due to COVID-19",aus,de
121,Celsius,Accounting & Legal,3.9,Data Engineer,"Austin, TX",$86K - $197K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5fc09c1b&cb=1618160368323&jobListingId=1006990184515&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-68f9115ffcb3cf3f,"Celsius addresses the financial needs of today’s consumers worldwide through a democratized interest income and lending platform accessible via a mobile app. With a mission to put unparalleled economic freedom in the hands of the people, and a core belief that financial services should only do what is in the best interests of the community, Celsius is a modern platform where membership provides access to curated financial services that are not available through traditional financial institutions. Crypto holders can earn high-yield compounding interest by transferring coins to their Celsius Wallet and can borrow fiat currency against their crypto collateral at the lowest interest rates in the space.


The Celsius team is committed to doing good and doing well. We believe in the power of disruption and the importance of decentralization to create a new system that acts in the best interest of everyone. Each member of our team brings something unique and innovative to the table, but the common thread that links us together is our passion for blockchain, equality, and leading the next financial revolution that changes the equation to bring power back to the people.
Position: Data Engineer
Responsibilities:

Help pioneer data Lake and data Warehouse infrastructure from the ground up using latest technology and best practices.
Constructing ETL processes both in batch and streaming using latest technologies and scalable and robust infrastructure configurations on AWS & Snowflake
Define and build data lake and data warehousing infrastructure from the ground up.
Develop datasets per the requirements of analysts and key stakeholders
Have a strong role in maintaining data Integrity, security, and governance
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
Designs data integrations and data quality framework.
Designs and evaluates open source and vendor tools for data lineage.


Qualifications:

Advanced and proven skill in designing and developing scalable and secure data infrastructure
Strong knowledge and experience building data lake/warehouse with Snowflake as a foundation.
Advanced SQL skills and strong experience with database administration
Proven skill in using technologies such as Kinesis,, Postgres with RDS, Lambda/Nuclio, S3, Redshift, etc.
Advanced Python experience and skill with a suite data processing and analysis libraries
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
Knowledge of Blockchain and cryptocurrency is a big plus",aus,de
122,Blackstraw AI,Information Technology,3.8,Data Engineer,Texas,$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1110586&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a6bc00ac&cb=1618160368325&jobListingId=1006986281246&cpc=AC285F3A3ECA6BB0&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-23eb84151cb05c7f&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLam9OUHc2R3k4ZDA3c3d4MEVUUXdyMnc3WTNnTWhSaXI4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlPdG9nQ3V3ZnNQWWMyUWxTMlF4bUZ5QW9wUTY1VzlzMUtROFlqZ3JES2tEVXJmVmRoc2tWMjFWN3dfVGxxUENBSTVnaVBUQjBGeXBRVV9JRm85dXBhYk1jcDdLNDFybHN2NWcycUVIWDZRcXJiZ2NqVmI2MGxUMldzSV9vWW40Q2E0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVmYwZm95YkNyWEhJMVZpV1JpZHBLTExyZkdfSG5sX3lqY0dEM1d0QURTaWZMZzZiNlRTQktKR1ZZMGI0Y1BhR3NOX01LaV80a2NFRVk4MkJPNllDcDNMLTZBQVVURTBkSDBydFlrQ2xZUjN5dFhtdENQZGpmWmxsRGZpYkJrUzF4QVRWTGxFSnlvbkkyYmNqN2pyaV9XcTYxa01PMVNrN0ZwWUZpNmlocTB3T29DSWtHeF9pRFhGbHFnYm5waEYtdGRzaHJXVHVTQkphWjBVVy1qX0ZmT2RwdUV4c2c2QUlzazhqc3ZVdGRpWHctOFo4eHFoWlZPMVdnMXZvUjJpOEZTQnBSeXZmc0tQaUV6clEtR2lBNWZxMHNUNmhya19ITzlHdngyS084bHhFMzRWQWlBbE1xbjJKU29MdGs2eHlDMWZDVmNTRERQVElweGRaOHd5UVFJLUNnLVA4TFM1TFM,"Company Background: Blackstraw is an AI startup from Tampa Bay, FL. Utilizing a unique combination of our AI Platforms and Services backed by real world AI deployment experience, we deliver innovative solutions to our growing list of clients. This is the perfect opportunity for anyone who is looking to become a part of an innovative and energetic team that develops solutions that transform organizations.Key responsibilities for this position include: Be an expert in Python, with solid working knowledge of Python web framework such as Django, Flask, etc...Good familiarity with ORM (Object Relational Mapper) libraries.Ability to integrate multiple data sources and databases into one system.Understanding of the threading limitations of Python, and multi-process architecture.Good understanding of server-side templating languages such as Jinja 2, Mako, etcUnderstanding of accessibility and security compliance.Good knowledge of user authentication and authorization between multiple systems, servers, and environments.Understanding of fundamental design principles behind a scalable application.Familiarity with event-driven programming in Python.Understanding of the differences between multiple delivery platforms, such as mobile vs desktop, and optimizing output to match the specific platform.Able to create database schemas that represent and support business processes.Strong unit test and debugging skills.Proficient understanding of code versioning tools such as Git, Mercurial or SVN.Should follow good code quality standards.Follow/maintain an agile methodology for delivering on project milestones.Expertise in OOPS and design patternShould know http apis development in python (Flask, Tornado) and should also know how to package a code and create executables/binaries in python codePreferred Qualifications:Hands on work experience with: Python, Django, Flask, Elasticsearch, Azure, Docker.Good knowledge of caching technologies like Redis.Knowledge of Big Data, Hadoop would be a plus.Other details:OPT visa holders can apply only if you have previous relevant work experienceJob Type: Full-timePay: $70,000.00 - $100,000.00 per yearBenefits:Dental insuranceHealth insurancePaid time offVision insuranceSchedule:Day shiftMonday to FridaySupplemental Pay:Bonus payWork Location:Multiple locationsVisa Sponsorship Potentially Available:Yes: Other non-immigrant work authorization (e.g. L-1, TN, E-3, O-1, etc.)No: Not providing sponsorship for this jobCompany's website:www.blackstraw.aiBenefit Conditions:Only full-time employees eligibleWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview process",aus,de
123,PayPal,Information Technology,4.1,Data Engineer,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_124474c4&cb=1618160368323&jobListingId=1006987641132&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-7e1d1d6d7d6d18ac,"Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 375 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
Job Description Summary: Seeking data engineer candidate for PayPal's CTO business technology team that looks to optimize internal infrastructure and processes.
Job Description:
Position Overview
PayPal's mission to democratize financial services relies on platform & infrastructure that is fast, reliable and secure. That infrastructure must be managed thoughtfully, be able to handle organic and intermittent growth and stay within budget.
The Technology Business Management (TBM) team is a small results-driven group that focuses on enterprise efficiency from assets and applications, to operations and processes and is part of a larger organization that reports directly to the CTO.
The Efficiency-Showback program is one of key strategic programs for the org and is an expansion of the work we have done around efficiency in 2020. The program measures impact, provides accountability through cost transparency, and operational efficiencies of our physical technology infrastructure, thousands of applications used to run PayPal, and the processes that govern IT. The TBM team performs detailed analytics using data from multiple data sources / monitoring tools to identify inefficiencies and work within the organization to communicate / remediate them.
The team is rapidly growing its area of responsibilities and is seeking a multi-disciplined engineer who is strong in database engineering as well as solid software development skills. This person will develop and enhance the current data pipeline used to perform efficiency analytics, write and maintain integrations with other systems of record and help the team scale to become an enterprise-wide product.
We are looking for a candidate who is motivated to build solid, scalable platform capabilities, someone who likes to raise the bar with respect to code quality, testability and maintainability standards. Typical day to day involves working with your teammates on solution discussions, implement complex stored procedure logic, work on integration scripts as well as attend and actively participate in scrum ceremonies and have at least a little fun.
Core Duties
Work with the DB architect to create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies
Build APIs that expose the data so customers can consume and integrate with our data
Evaluate large and complex queries / stored procedures and recommend changes to optimize performance
Assist with the expansion into public cloud cost transparency
Lead automation efforts leveraging innersource interaction models with other teams
Assist data analysts on our team with query development, statistical analysis, and data visualization as needed
Maintain technical documentation on stored procedures and ETL logic used to managed the database
Core Competencies
Core Behavioral Competencies
Strong written and verbal communication skills
Ability to write clear and concise communications
Ability to work effectively in a global team environment
Role Specific Behavioral Competencies
Ability to translate complex problems into simpler terms
Ability to work independently
Prerequisite Knowledge & Proficiencies
Must Have
Experience building and optimizing ETLs, data pipelines, architectures and data sets
Proficient in Microsoft SQL Server 2016 & 2019 Database Development (T-SQL), Data Analysis and Support.
Thorough understanding of RDBMS concepts and ability to write complex SQL queries, Stored procedures, Functions & triggers
Proficiency with python scripting language
Experience with Splunk and splunk query language
Experience Google Big Query and AWS redshift
Experience with No SQL / Hadoop
Demonstrated experience working with large data sets and a love for working with data
Understand or be keen to learn about REST API development and design
Very strong foundational knowledge in Object-Oriented Design Principles, Data Structures, Algorithms, and Software Engineering
Working knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX)
Experience with code repositories like Git/GitHub
Experience writing and maintaining technical documentation
Basic familiarity with MS Word, Excel & Visio knowledge needed
A constant desire to grow, learn, and explore new things
Nice to Have
Experience with SignalFX analytics platform
Experience with gimmel notebooks
Experience with some visualization tool (e.g. tableau or power BI)
Experience managing database upgrades / data migrations
Experience optimizing queries
Basic fundamentals of JAVA
Understanding of Angular and/or ReactJS
Experience & Education
4-5 years working experience as a Data Engineer
3+ years software development in front-end and/or back-end technologies
BS in computer science, Information systems or equivalent field, MS preferred
Examples of Specific Job Tasks/Accountabilities
Work with lead to define technical requirements and design for new tables, ETLs, integrations,
Perform development of new stored procedures, integrations, views etc as part of bi-weekly agile sprints
Maintain scheduled jobs and debug when necessary
Attended technical meetings with customers of the IT efficiency product so they can integrate with us to consume data
Attend daily status calls to track sprint progress
Create, update, maintain documentation on stored procedures, ETL logic, db schema etc.
Work with cross-functional teams to build and enhance automation workflows
Build / optimize queries needed by team as needed
Provide demos and code reviews when applicable
Track data quality / integrity issues with the db and report them
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",aus,de
124,Visa,Information Technology,4.1,Staff Data Engineer - Visa AI Platform,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_0219ee1a&cb=1618160368323&jobListingId=1006992863994&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-a5d70921aaa50670,"Company Description
As the world's leader in digital payments technology, Visa's mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company's dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.
At Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.
You're an Individual. We're the team for you. Together, let's transform the way the world pays.

Job Description
Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area. For a payment system to work well, the risk techniques, performance, and scalability are critical. These techniques and systems can benefit from big data, data mining, artificial intelligence, machine learning, cloud computing, & many other advance technologies and in VISA, we have all of these. If you want to be in the exciting payment space, learn fast, and make big impacts, Artificial Intelligence Platform team within Payment Security & Identity group @ VISA is an ideal place for you!
This position is for a Staff Software Engineer with solid development experience who will focus on creating new capabilities for AI Platform while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.
You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.
This position will be based in Austin, TX and reporting to Director of Software Engineering. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.
Essential Functions
Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions.
Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards. Responsibilities span all phases of solution development.
Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.

Qualifications
Basic Qualifications:
8 years of relevant work experience with a Bachelor’s Degree or at least 4 years of relevant work experience with an Masters Degree, or a PhD.
Preferred Qualifications:
Bachelor degree in Computer Science or related field and 8 years of Software Development Experience or a Masters with 5 years of Software Development Experience or a PhD with 2 years of experience.
Exposure to leading-edge areas such as Machine Learning, Deep Learning, Stream Computing, MLOps.
Expert in at least one of the following: Golang, Java, or C/C++
Experience with web service standards and related patterns (REST, gRPC)
Experience developing large scale, enterprise class distributed system or subsystems that require high availability, low-latency, & strong data consistency computing
Experience implementing solutions for low-latency, distributed services using open standard technologies.
Experience with Big Data and analytics in general leveraging technologies like Hadoop, Spark, Flink and MapReduce
Experience with distributed caching technologies like Redis
Experience developing proper metrics instrumentation in software components, to help facilitate real-time and remote troubleshooting/performance monitoring.
Experience architecting solutions with Continuous Integration and Continuous Delivery in mind
Strong interpersonal and leadership skills with effective communication (both written and verbal) skills and the ability to present complex ideas in a clear & concise way, a team player with good work ethics
A background in the fraud detection domain is a plus.
Additional Information
Work Hours
This position requires the incumbent to be available during core business hours.
Travel Requirements
This position requires the incumbent to travel for work 0% of the time.
Mental/Physical Requirements
This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms.
EEO Statement
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",aus,de
125,VMware,Information Technology,4.3,"Data Engineer - Opportunity for Working Remotely Austin, TX","Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_b65bb9ef&cb=1618160368323&jobListingId=1006988759756&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-6477612882753299,"The Elevator Pitch: Why will you enjoy this new opportunity?
This Data Engineer position provides a unique opportunity to grow your career by deepening your Analytics expertise and learning more sophisticated data science techniques to deliver better insights while also providing customer facing exposure. You will have opportunities to participate in design, by presenting data and valuable points of consideration to resolve problems. This customer experience is critical for anyone with a passion in data and analytics looking to broaden their business acumen.
Success in the Role: What are the performance outcomes over the first 6-12 months you will work toward completing?
Work with data engineering team to learn the environment and start delivering on solutions within 90 days. During this time frame, identify critical design and test issues needed to ensure an on-time delivery. Within 180 days, person should be able to pick up subject area independently and deliver the solutions.
The Work: What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis?
Most of your time will be spent analyzing data and writing high-quality code with excellent test coverage using Informatica/Python/HIVE/HANA/Spark and BOBJ/Tableau. You can expect to be the owner and take accountability for the quality of your code.Collaborate in-person and through Slack/Zoom or e-mail with data engineering team to brainstorm solutions.Spend time learning VMware’s standard operations, products, and improving your engineering and professional skills. We want you to be curious, learning both from team members and individual study.
What is the leadership like for this role? What is the structure and culture of the team like?
The hiring manager for this role is Arvind Panwar, Manager, Data Engineering, Sales. His expertise has been built from the frontlines with roles in Analytics solutions, program management and most recently in management of a data engineering team for the past one year.
Arvind’s management philosophy is about encouraging everyone on the team to be independent thinkers and helping other team members. Arvind looks for people who can think out-of-the-box and then execute on a good idea. Innovation = Creativity and Execution.
The core team is made up of three data engineers and 3 BI engineers software developers and close partnership with a member of other data engineering team. The team works flexible hours, arranging schedules to fit their needs and taking consideration for phone calls with global colleagues and business stake holders, primarily in US, EMEA, India and Costa Rica.
What are the benefits and perks of working at VMware?
You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com.
Employee Stock Purchase Plan
Medical Coverage, Retirement, and Parental Leave Plans for All Family Types
Generous Time Off Programs
40 hours of paid time to volunteer in your community
Rethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilities
Financial contributions to your ongoing development (conference participation, trainings, course work, etc.)
Wellness reimbursement and online fitness and wellbeing classes
This job requisition is not eligible for employment-based immigration sponsored by VMware.
#LI-REMOTE
Category : Engineering and Technology
Subcategory: Software Engineering
Experience: Manager and Professional
Full Time/ Part Time: Full Time
Posted Date: 2021-04-07
Cloud Management: VMware’s Cloud Management team delivers vRealize Suite, a solution that’s essential to accelerating our customers’ journey to digital transformation. It’s our market-leading, state-of-the-art cloud management platform designed to deliver and manage IT services across private, public, and hybrid clouds. VRealize Suite is an integrated, comprehensive solution that meets the challenge of managing a cloud infrastructure from a single pane of glass. We’re changing the way users design, build, view, and manage public and private clouds, and enabling them to run with optimal performance, insightful analytics and automated delivery. Join our user-focused team of software engineers, data scientists, web designers, product managers, and marketers. You’ll gain valuable experience in the fast-growing field of cloud infrastructure management from a pioneer and industry leader.

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",aus,de
126,Iodine Software,Information Technology,4.8,Associate Data Engineer,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_7387c96c&cb=1618160368324&jobListingId=1006985295617&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-cc4ccdd7d4b04673,"Iodine Software is a healthcare AI company that has pioneered a new machine learning approach - Cognitive Emulation - to help healthcare finance leaders build resilient organizations. Cognitive Emulation uses proprietary AI technology and machine learning algorithms to think the way a clinician thinks and emulate clinical judgement. This allows us to help nearly 500 hospitals quickly and accurately identify areas of potential opportunity to accelerate productivity, data accuracy, and financial return.
What You'll Do

Iodine thrives on innovation. We are looking for an Associate Data Engineer that will help us discover the information hidden in vast amounts of data. You will be joining a small team that is tackling many interesting data engineering problems using cutting edge technology. Because we work on the cutting edge of a lot of technologies, we need someone who is a creative problem solver, resourceful in getting things done, and productive working independently or collaboratively. You will be accessing and shaping our enormous amount of data to help drive our future innovation.

Gather and process raw data at scale (including writing scripts, calling APIs, writing SQL queries, using ETL tools, etc.)
Work closely with our engineering team to integrate data science products and get them into users’ hands
Process structured and unstructured data into a form suitable for analysis
Enhance data collection procedures to include information that is relevant for building analytic systems
Implement ETL processes; Apache Airflow experience is a plus
Process, cleanse, and verify the integrity of data used for analysis
Do ad-hoc analysis and present results in a clear manner
ML Ops experience is a big plus


What You'll Need

Minimum Requirements (Education, certifications and experience):

Bachelor’s degree OR 2+ years’ experience extracting, cleaning and managing large pools of data
1 year experience processing large amounts of structured and unstructured data
Intermediate proficiency in SQL and relational databases
Experience with a scripting language such as Python
Great communication skills
Data-oriented personality

Preferred Requirements:

Programming experience, ideally in Python or Java, but we are open to other experience if you’re willing to learn the languages we use
Experience with MLOps tooling
Strong understanding of ETL best practices
Experience with Postgres and Kafka


See Something, Do Something

At Iodine, we are incredibly privileged to be entrusted with an enormous amount of Protected Health Information (PHI) amounting more than 90 million lives. Inherent to our culture is the need to live up to that trust in everything we do. Security is a primary responsibility shared by every Iodine employee and we expect everyone to honor that responsibility. That includes abiding by our security policies, being constantly-vigilant to possible risks to the privacy and safety of the information given to our care, and bringing forward any concerns about security
What You'll Get

This is a unique opportunity to join a close-knit, rapidly growing team and help us improve a key piece of the organization. You will have the opportunity to drive the strategy and direction of our product for our users. You will join a passionate and ambitious team, with a proven record of success building multiple companies. Learn more about us at www.iodinesoftware.com.

**You must be currently authorized to work full-time in the United States on a permanent basis.**",aus,de
127,Ascension,Health Care,3.5,Sr Data Engineer,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_e1b9fa6c&cb=1618160368324&jobListingId=1006994449867&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-1f134fd40efc1cc3,"We Are Hiring:

Ascension is a faith-based healthcare organization dedicated to transformation through innovation across the continuum of care. As one of the leading non-profit and Catholic health systems in the U.S., Ascension is committed to delivering compassionate, personalized care to all, with special attention to persons living in poverty and those most vulnerable. In FY2019, Ascension provided $2 billion in care of persons living in poverty and other community benefit programs.
Ascension includes more than 150,000 associates and 40,000 aligned providers. The national health system operates more than 2,600 sites of care – including 150 hospitals and more than 50 senior living facilities – in 20 states and the District of Columbia, while providing a variety of services including clinical and network services, venture capital investing, investment management, biomedical engineering, facilities management, risk management, and contracting through Ascension’s own group purchasing organization.
Ascension Information Services is one of the nation’s largest healthcare information technology services organizations.
We provide Ascension and its subsidiaries low-cost, high-value IT infrastructure and software application services that:
Support rapid and effective clinical decision makingImprove efficiency and care transitionsFoster information sharing across the continuum of careMake knowledge and data actionable, leading to improved patient outcomes
What You Will Do:

Responsible for construction and development of ""large-scale cloud data processing systems"" The Data Engineer must have considerable expertise in data warehousing and job requires proven coding expertise with Python, Java, SQL, and Spark languages. Must be able to implement enterprise cloud data architecture designs, and will work closely with the rest of the scrum team and internal business partners to identify, evaluate, design, and implement large scale data solutions, structured and unstructured, public and proprietary data. The Data Engineer will work iteratively on the cloud platform to design, develop and implement scalable, high performance solutions that offer measurable business value to customers.
Required Work Experience:
Four to seven years of experience required.
Some of the minimum experience requirement may be met with Masters or other advanced degreeCloud Experience Required
Coding experience with Python, Java, Spark, and SQL
Strong Linux/Unix background and hands on knowledge.
Past experience with big data technologies including HDFS, Spark, Impala, Hive,
Experience with Shell scripting and bash.
Experience with version control platform github
Experience unit testing code.
Experience with development ecosystem including Jenkins, Artifactory, CI/CD, and Terraform.
Works on problems of diverse scope and complexity ranging from moderate to substantial
Assists senior professionals in determining methods and procedures for new tasks
Leads basic or moderately complex projects/activities on semi-regular basis
Must possess excellent written and verbal communication skills
Ability to understand and analyze complex data sets
Exercises independent judgment on basic or moderately complex issues regarding job and related tasks
Makes recommendations to management on new processes, tools and techniques, or development of new products and services
Makes decisions regarding daily priorities for a work group; provides guidance to and/or assists staff on non-routine or escalated issues
Decisions have a moderate impact on operations within a department
Works under minimal supervision, uses independent judgment requiring analysis of variable factors
Requires little instruction on day-to-day work and general direction on more complex tasks and projects
Collaborates with senior professionals in the development of methods, techniques and analytical approach
Ability to advise management on approaches to optimize for data platform success.
Able to effectively communicate highly technical information to numerous audiences, including management, the user community, and less-experienced staff.
Consistently communicate on status of project deliverables
Consistently provide work effort estimates to management to assist in setting priorities
Deliver timely work in accordance with estimates
Solve problems as they arise and communicate potential roadblocks to manage expectations
Adhere strictly to all security policies
Desired Work Experience:
Proficient in multiple programming languages, frameworks, domains, and tools.
Coding skills in Scala
Experience with gcp platform development tools Pub/sub, cloud storage, big table, big query, data flow, data proc, and composer desired.
Strong Linux/Unix background and hands on knowledge.
Knowledge in Hadoop and cloud platforms and surrounding ecosystems.
Experience with web services and APIs as in RESTful and SOAP.
Ability to document designs and concepts
API Orchestration and Choreography for consumer apps
Well rounded technical expertise in Apache packages and Hybrid cloud architectures
Pipeline creation and automation for Data Acquisition
Metadata extraction pipeline design and creation between raw and finally transformed datasets
Quality control metrics data collection on data acquisition pipelines
Able to collaborate with scrum team including scrum master, product owner, data analysts, Quality Assurance, business owners, and data architecture to produce the best possible end products
Experience contributing to and leveraging jira and confluence.
Strong experience working with real time streaming applications and batch style large scale distributed computing applications using tools like Spark, Kafka, Flume, pubsub, and airflow.
Ability to work with different file formats like Avro, Parquet, and JSON.
Managing and scheduling batch jobs.
Hands on experience in Analysis, Design, Coding and Testing phases of Software Development Life Cycle (SDLC).
Qualifications and Education:
Master level technology degree preferred
Technology certifications preferred
Bachelor's in computer engineering or equivalent field or equivalent foreign degree required
What You Will Need:

Education:
High school diploma/GED with 2 years of experience, or Associate's degree, or Bachelor's degree required.
Work Experience:
1 year of experience required.4 years of experience preferred.2 years of leadership or management experience preferred.
Why Join Our Team:

Ascension is a faith-based healthcare organization dedicated to transformation through innovation across the continuum of care. As one of the leading non-profit and Catholic health systems in the U.S., Ascension is committed to delivering compassionate, personalized care to all. In FY2020, Ascension provided $2.4 billion in care of persons living in poverty and other community benefit programs. Ascension includes more than 160,000 associates and 40,000 aligned providers across a national network of ministries. We offer rewarding careers across more than 2,600 sites of care – including 146 hospitals and more than 50 senior living facilities – in 19 states and the District of Columbia.
Equal Employment Opportunity Employer:

Ascension Technologies is an equal opportunity employer (EEO) and affords equal opportunity to all associates and applicants without regard to race, color, religion, national origin, gender identity, sexual orientation, age, physical or mental disability, veteran status, genetic data, or other legally protected status. For further information regarding your EEO rights, click on the following link to the “EEO is the Law” poster:
http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf
EEO is the Law Poster Supplement
Please note that Ascension will make an offer of employment only to individuals who have applied for a position using our official application. Be on alert for possible fraudulent offers of employment. Ascension will not solicit money or banking information from applicants.",aus,de
128,Burnett Specialists,Business Services,4.3,Senior Data Engineer,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1110586&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_bcf00d48&cb=1618160368324&jobListingId=1006991093566&cpc=59DEFF8D475298C3&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-e4332f0bb062ce9d&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1hSWNSZ05QQTE1eTgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMYW9jTWtrcWpGUjV6Z05EcjVJblN3OWkySGdsLWs5bl84cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOGhTbUY5YlpBRVNybEZWaC1ZblktZG9mdHFLSHVEcXdrMDI1aTNKai1YSm8wTFBlTVhCSm93UGFGWV9JRW5XU2ZYMFpMUUFpdlNaSkt5SFJmdXJHcXBoZW9iNlFWS0FXbnV5MWo3eWV3d2FaWnAxS0R3cFhfNjhuVkhHQXJnMUtEU1p4NmlVZzJFaTJiaXlxQTVSZTVOckJGcHhteVNTcVl4dXFCS0pVTU5ZRDdUcDh3LVFTaUdfSUJpcmo0MFJZVHhXTGVjaDQ1aXMzNWlSN2pwczdRSS1ZTnFoQjEta0twVTZjcm9FUnZCa05sckNQNkdKLUFtdUxNNXdpcmY3ZkhfNU44bDBwYWc3YnZxT1JBSzBheHZ1R19VOTk4Q2hXdTZ1dzNUNTRQbUtJWWMzUHJWYlFxbFppb0xKQVJtLUhOR2g2b3VFMmZsb2FwNGtOLXJGV3d2dDJEZVR0UUlBTmZ1aVJGSDdiSldrbnU1M0ViWk8xVEhDemF2VXAtQml3N1JmR2VURUxrRzFReTg3eVpoOTNMREhtbGUxUms5LVI2dDctZnYxV3NKMWxITXFkY0RhTUFTTzNfNmxlZjJoV2JiVUN1S3NYQmRWb05yVjlwRVU3eU9NWjN6YWZkbTZuVVk4MkJPNllDcDNMLTZBQVVURTBkSHFVb2NjY0twZXpUNVBsMmxYSjV6VG4wM0FLbmFSM1MzQ0VRMTFHNzFMZDR3UEpsczBkVVdnckRhM05aZ21iMTZHV2NyRkxRYUhUd3JNUUJlSHoyZ0NkVVVaN3FQaWJVdnM2Z0VoS2g1NWlIN1FPMkVqbkhJUzN6WUVNTjNMbkFGTU5CSkpBVzdZbkJnRFlNNk44MmU4MnFqalNKVWtWcTFScDVQdm90ak9ldlFEUzhSMFY5STBNM2tHSk9HdnRXSGp0QkMyWTRVY0gtdnJmdFJLT2o5d0Q5VzJHbGliNkRTRW9iMTM3ZktZVW5qZERNNkJwOU1Fb2piVEtQN3VscUQ,"Senior Data Engineer
We are working with an AI SaaS company that is looking to hire a Senior Data Engineer. This company provides SaaS products to athletic retailors, their major brands, and the digital world to provide a turnkey e-Comm platform.
Responsibilities:
Initial work will involve building RESTful APIs and an event driven data pipeline to support the company's B2B services before moving into a more traditional data engineering role.
Take ownership of the company's data, setting up systems to support analytics as the first member of the data and BI team.
Work with tools such as Dataflow, Pub/Sub, Kafka, or Spark
Offer technical support where needed regarding data modeling, data warehousing, BI and analytics.
Stay current with industry trends and source new ways for our business to improve.
Requirements:
Proficiency modeling data for both analytical and transactional schemas.
In-depth knowledge with cloud offerings for data related systems. (GCP, Azure, or AWS)
Comfortable managing database clusters and working with cloud-managed databases.
Experience connecting to 3rd party APIs and data sources to import or export data.
Comfortable developing and writing applications outside the database
Proficiency with analytics and BI applications/platforms
Comfortable working on Linux based systems and using the command line (bash).
Understanding of data related to e-commerce, retail, or financial systems.
Ability to contribute to RESTful services written in Typescript and NodeJS
Strong analytical SQL skillset. (PostgreSQL, MySQL, and BigQuery)
Confidence building solutions that allow pushing medium-sized datasets to hundreds or thousands of recipients with high resiliency and low latency.
Experience:
4+ years of experience
Qualified candidates please send resumes
AUSDH40
Interested candidates please send resume in Word format Please reference job code 116908 when responding to this ad.",aus,de
129,"Advanced Micro Devices, Inc.",Information Technology,4.1,Data Fabric Front-End Design Engineer - 89924,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_8870219c&cb=1618160368324&jobListingId=1006987836468&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-a8b99f14d8872cab,"What you do at AMD changes everything
At AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies – building blocks for gaming, immersive platforms, and the data center.
Developing great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the “extra mile” to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.
Data Fabric Front-End Design Engineer
THE ROLE:
This is a front-end design engineering position on AMD’s Data Fabric IP. The Data Fabric is the high-bandwidth, high performance, fabric network logic that ties together all the IPs on an SOC. Every product that AMD sells has its own custom-designed Data Fabric, so this role gives an engineer the opportunity to work on a broad array of products that address a variety of markets, including traditional servers, high performance computing, client desktop and laptop PCs, machine intelligence, graphics, console gaming, embedded, and customer-specific applications. It is a challenging position that involves working at a fast pace of innovation on the cutting edge of technology. Come join the AMD team!
THE PERSON:
The candidate should be able to work cooperatively with a talented global team and use his or her engineering skills to solve novel problems and optimize designs and flows.
KEY RESPONSIBILITIES:
Work with the Data Fabric architects and the chip floorplanning team to develop a custom Data Fabric topology
Synthesize Data Fabric IP using Synopsys tools and work with the micro-architects to ensure the design components meet the project’s area, power, and performance goals
Provide feedback to RTL team to resolve timing, power, area, LINT, DFT, and cross-clock-domain issues.
Provide interface to integrate IP blocks into the SOC and resolve the same types of power, timing, area, and formal equivalence checking at the chip level.
Analyze design power and devise improvements through architectural or flow optimizations
PREFERRED EXPERIENCE:
Extensive working knowledge, gained through multiple tapeouts, of the latest generation of Synopsys design tools, including Design Compiler NXT, Formality, Power Compiler, PrimeTime, Fusion Compiler, and IC Compiler II
A proven understanding of computer architecture
Knowledge of high performance interconnection logic and networks is a plus
ACADEMIC CREDENTIALS:
MS degree in Computer Engineering preferred
LOCATION:
Austin, TX

#LI-LC1

Requisition Number: 89924
Country: United States State: Texas City: Austin
Job Function: Design

AMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.",aus,de
130,Spiceworks,Information Technology,3.9,Senior Data Engineer - Spiceworks,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_764a37fc&cb=1618160368325&jobListingId=1006992426613&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-c471b4ec9cafbd86,"Sr Data Engineer
Who you are:
You are detail oriented with a curious nature. You have experience in working to find trends in data sets and developing algorithms to help make raw data more useful. You have strong communication skills and understand the purpose behind the work that you do. You have experience with multiple programming languages and over 5 years of experience with data engineering as Senior level staff.
Ownership of data products, pipelines, and stakeholder integrations is our bread and butter and this thrills you! With your background in optimizing data retrieval and how to develop the outputs needed for stakeholders - reports, dashboards, or other visualizations. You are excited to build with us!
What you’ll do:
The typical Data Engineer's role at Spiceworks Ziff Davis is both fluid and challenging. You will work to run data through pipelines and augmentations and data science technology in order to score the leads and interest levels across multiple categories of interest. Each day, you will build small, reusable components in a large landscape of data, you’ll collaborate with business teams to improve data models that feed our business intelligence tools and increase data accessibility, write integration tests, and contribute to the internal engineering documents..
You’ll have nuanced relationships across teams and you’ll be a critical point of contact for the Data Engineering function. In this role, you will work across a data landscape with diverse technologies and potentially work in situations that are not clearly defined - as some tools do not have owners and you will need to go into the system that you’ve never coded in before, but you’ll be responsible for diagnosing issues and identifying solutions.
You will have the standard ELT (Extract, Load, Transform) responsibilities but as this is a Senior-level role, you’ll also be responsible for spearheading initiatives with other teams - ranging from assisting Data Science in developing and deploying microservices to be utilized to augment data to debugging a fluctuation in data being produced by intermediate proxy services.
You will be in close contact with teams across the business and will serve as a reliable, seasoned Engineering team member.
What will be your responsibilities?
Design, coordinate, and implement data integrations between other teams in the forms of databases, file payloads, microservices - using the appropriate technology for the use-case (SNS, S3, AuroraDB, K8s Background Job, etc)
Design, implement and maintain data pipelines for both loading disparate system's data into a Data Warehouse, as well as building out data products.
What does it take to do this job?
Experience working alongside Data Scientists to make use of the data that they collect
In-depth knowledge of distributed systems and computer science
A background in our primary technologies: AWS Components, Kubernetes, Docker, Snowflake (ANSI-SQL), Python, Matillion (Data Flow Orchestration), Data Dog
Familiarity with technologies and languages like HTML/CSS/Javascript, Make, Ruby on Rails, Golang, Scala
Demonstrated expertise with SQL (T-SQL and/or ANSI-SQL)
Expertise with some modern programming languages (Python, Ruby, etc)
High comfort level with Docker
Empathy Statement:
Spiceworks Ziff Davis is a safe, inclusive workplace for people of all backgrounds and walks of life. We strongly encourage you to apply if you are from a marginalized or underrepresented group, particularly in the technology industry. Some candidates may see a long list of job requirements and feel discouraged because they don't match every single bullet point - we suggest, please apply anyway.
Work from Anywhere:
We're flexible on location wherever possible - we are a Work From Anywhere company. We don't believe in a ""perfect"" candidate because we believe in our core value, ""Evolve and Adapt Quickly"". If you believe this is a role that you'll be excited to work in every day, want to be a part of a culture like ours, and will be relentless about pushing boundaries to succeed, please apply.
Who we are: Spiceworks Ziff Davis (SWZD) is a trusted global marketplace that connects technology buyers and sellers with the most actionable and precise intent data. We are uniquely positioned to offer tech brands unmatched visibility into accounts that are truly in-market, by leveraging our scale, quality and diversity of intent data. With unparalleled access to the world’s most influential technology buyers through a combination of first-party (Community, Tools, Editorial) and third-party intent data, SWZD is a leader in intent-backed, intelligent, omnichannel marketing.
-XXX-
About SWZD | Open Job Opportunities | The 2021 State Of IT",aus,de
131,Roku,Information Technology,4,Sr. Data Software Engineer,"Austin, TX",$70K - $100K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_83e6b6f2&cb=1618160368325&jobListingId=1006994775610&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-509609cac98b7c84,"Help us get more people excited about cutting the cord
Roku is changing how the world watches TV


Roku is the #1 TV streaming platform in the US, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.


From your first day at Roku, you'll make a valuable — and valued — contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers worldwide while gaining meaningful experience across various disciplines.

About the team
Our team's mission is to build a world-class big data platform to bring value out of data for us, for our partners, and for our customers. Our goal is to democratize data, support Roku's exploding ad business, provide reporting and analytics self-service tools, and fuel existing and new business critical initiatives.


About the role

Sr. Data Engineer

Roku pioneered TV streaming and continues to innovate and lead the industry. The Roku Channel has us well-positioned to help shape the future of streaming. Continued success relies on investing in Data Engineering.


The ideal candidate will have endless curiosity and can pair a global mindset with locally relevant execution. You should be a gritty problem solver and self-starter who can drive programs with the product and commercial teams within Roku and across external strategic partner organizations. The successful candidate will display a balance of hard and soft skills, including the ability to respond quickly to changing business needs.

What You Will Do:

Scratch-build a highly scalable, available, fault-tolerant data processing systems using AWS technologies, HDFS, YARN, Map-Reduce, Hive, Kafka, Spark, and other big data technologies. These systems should handle batch and real-time data processing over 10s of terabytes of data ingested every day and petabyte-sized data warehouse.
Low level systems debugging, performance measurement & optimization on large production clusters.
Participate in architecture discussions, influence product roadmap, and take ownership and responsibility over new projects.
Maintain and support existing platforms and evolve to newer technology stacks and architectures.

What you've done and what you bring:

Strong SQL skills.
Proficiency in at least one scripting language, DASH / Python Preferred.
Proficiency in at least one object-oriented language is desired, Java Preferred.
Experience with AWS is a plus.
Collaborate with cross-functional teams such as developers, analysts, and operations to execute deliverables.
5+ years professional experience as a data or software engineer.
BS in Computer Science; MS in Computer Science preferred.

The Roku culture


Roku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV.


We have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002.


#LI-JG1",aus,de
132,infolob,Information Technology,4.3,data engineer with Scala java 11,"Austin, TX",$67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1dffbaa7&cb=1618160368330&jobListingId=1006989486670&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-bb443d82947555e5,"* 12+ years of experience building scalable back end services* 3+ years as a tech lead* Expert knowledge of Java 11+, reactive Java, Scala, Netty and Nginx* Extensive experience designing distributed applications architecture and implementing it on code heavily relying on distributed messaging, storage and compute* Exceptional knowledge and hands-on experience in high volume events processing using both reactive streaming and batching for billions of events and multi-petabytes of data* In-depth knowledge of relational, NoSQL and Graph databases, HDFS, Kafka, multiple data centers replication strategies and disaster recovery* Strong understanding and experience with CI/CD pipelines, unit and integration testing, containerization, monitoring and alerting, production logs debugging* Strong collaboration skills, system thinking and ability to clearly explain complex conceptsSkill SetsNiche SkillExperiencePreferenceData EngineeringYes10+ yearsIs RequiredJava 11No2-5 yearsIs RequiredScalaYes2-5 yearsIs RequiredNginxNoAt least 1 yearIs RequiredDistributed SystemsYes5-10 yearsIs RequiredStream processingYes5-10 yearsIs RequiredNoSQLNo2-5 yearsIs RequiredKafkaNo2-5 yearsIs RequiredJob Types: Full-time, ContractPay: Up to $70.00 per hourBenefits:Dental insuranceHealth insuranceSchedule:8 hour shiftApplication Question(s):please do share your best number email and time to connectEducation:Bachelor's (Required)Experience:data engineering: 1 year (Required)building scalable back end services: 10 years (Required)Scala: 1 year (Preferred)java 11: 1 year (Preferred)Nginx: 1 year (Preferred)NoSQL: 1 year (Preferred)Kafka: 1 year (Preferred)Contract Length:More than 1 yearWork Location:Multiple locationsWork Remotely:Temporarily due to COVID-19",aus,de
133,Credible,Finance,4.5,Senior BI Data Engineer,"Austin, TX",$67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_326df53f&cb=1618160368326&jobListingId=1006992629612&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-7938c1622adf15d9,"Who is Credible?

We believe life's changes create financial needs for people and that the traditional financial system often puts up unnecessary obstacles. People celebrate major milestones like going to college, getting married, and buying a home. And most of the time, these milestones come with financial implications.

At Credible, we have built a company with the mission of bringing transparency, choice, simple processes and savings to accessing credit for life's important moments. What you see is what you get. We are committed to being upfront, honest, and clear about your options. There are no mysteries, no hidden fees, and no secret clauses.

Credible is a fast-growing Fintech company that has world class management, has raised multiple rounds of funding, is generating significant revenue and is disrupting the lending market and helping people save money and get out of debt faster.

About the Role:

Our Business Intelligence team is looking for a Senior BI Data Engineer who is passionate about data, analytics, and business strategy. You will help the team learn more about our business, teach others in the company about analytics, and improve the use of our data. You'll be an integral part of providing data-driven insights that inform significant company decisions.

Responsibilities:

Build data pipelines and python-based ETL tools for getting, processing, and delivering data
Develop data models and schemas in our data warehouse that enable performant, intuitive analysis
Partner with teams across the organization to understand their analytics needs and create dashboards and reporting that allow them to execute more effectively
Work with business leaders to define key metrics and build reporting to monitor and understand performance along those metrics
Conduct in-depth data analyses that lead to actionable insights, owning the entire process from ideation to execution to presentation of findings to stakeholders
Become an expert on all aspects of Credible's data and analytics infrastructure
Be the driving force behind the adoption and effective use of our BI tool within every team at Credible

Education and Experience:

BA/BS in a quantitative field
5+ years of work experience as a data engineer, or in a highly analytical role
Experience writing SQL queries and using a BI tool
Experience with programmatic scripting using Python to develop ETL pipelines and tooling
Experience using the command line and git
Strong grasp of statistics and experience conducting rigorous data analyses
Experience developing models and visualizations in Looker a plus
Experience at an e-commerce or fintech company a plus

 Nice to Have:

The capacity to juggle multiple priorities effectively within a fast-paced environment is critical
You're a highly motivated self-starter with the ability to work efficiently with minimal supervision
Anticipate business needs and think with a business owner mindset – think critically about analyses, don't just complete them
Passion for spreading the value of data throughout the company and communicating insights to a broad audience with varying levels of technical expertise

Why work at Credible?

We are a fast moving, fun-loving, seriously smart group of people who really care about impacting the lives of our customers. We empower our employees to make decisions, take risks, drive our business and make changes when we don't get it right. These are our values:

Exceed Customer Expectations: We provide an exceptional experience to each and every customer that compels them to share it with others.
Take Ownership: We are trusted to make decisions that are in the best interests of our customers and our business. We think and act like owners. We care – and that makes all the difference.
Be Curious: We are curious, ask questions, seek to understand and try new things.
Do the Right Thing: We earn trust by being transparent, respectful and honest with each person with whom we interact.
Get Results: Results fuel our excitement and we know how our personal accomplishments tie to the success of the company.
Be Bold: We are courageous and take risks that scare us. Our enthusiasm for experimenting is how we will find the next breakthrough.

Our benefits:

We offer competitive compensation, generous benefits, free food and a flexible vacation policy.

But mainly, you want to work at Credible because you believe in our mission and want to have a major role in delivering on it! We look forward to getting to know you.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",aus,de
134,"BOXX Technologies, LLC",Information Technology,3.7,Senior Data Center Engineer,"Austin, TX",$67 Per Hour(Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_66bd4633&cb=1618160368326&jobListingId=1006987800102&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-cc4affd66f0d2aa1,"Senior Data Center Engineer
An exciting opportunity now exists to join BOXX Technologies! We are searching for an enthusiastic, hard-working, and driven Senior Data Center Engineer to join our team in Austin, TX. This full-time position reports to the Vice President of Engineering and Operations.
Job Description
This job will require the qualified candidate to lead technical efforts to evaluate, test and deploy servers, virtual machines, networking, and software to support a high-performance workstation as a service business serving professional content creators in the Architecture, Media and Entertainment and Engineering sectors. You will be responsible for successfully completing the following:
 Installing and configuring operating systems, remote desktop applications, virtual machines, license servers, connection gateways, connection brokers and other software. Installing, configuring and test network hardware Testing hardware and software deployments for functionality and performance. Troubleshooting issues - find root causes and corrective actions. Managing support escalations and work with the team to find and implement resolutions. Working with product management team on new technologies and methods Documenting processes, settings and similar related information Providing pre sales technical support for Business Development and Sales teams on customer calls Owning the CRD (Customer Requirements Document) during the sales process and lead the team to implement the requirements when onboarding new customers.
Special Skills Remote Desktop Technologies: Teradici, RDP etc. Microsoft Windows and Windows Server Administration Virtualization with VMWare, Microsoft and Citrix NVIDIA GPU virtualization and GPU pass through technologies High Level Security Concepts including firewalls and secure network tunneling. LINUX - Various distributions Networking with Cisco (Meraki), pfSense, Juniper or Arista OS Cloud integration with Azure, AWS or Google
Other requirements
Bachelor of Science in Information Systems, Computer Science, or related field
 10+ years of experience as a Data Center Engineer, Systems Engineer, or equivalent Ability to lift 25lbs or more The ability to travel when needed The ability to work remotely
BOXX Technologies Offers
Fun collaborative working environment with the opportunity to grow and learn
Industry competitive base salary and quarterly bonus potential
Various group insurance choices, matching 401(k) plan, and paid vacation, personal and sick plans.
About Us
BOXX is the leading innovator of high-performance workstations and rendering systems for visual effects, animation, product design, engineering, architectural visualization, artificial intelligence, deep learning and more. Combining record-setting performance, speed, and reliability with unparalleled industry knowledge, BOXX is the trusted choice for creative professionals worldwide.
For immediate consideration, please Apply Now via this link.",aus,de
135,Synergy Sports,N/A,-1,Senior Systems Engineer | Data Center Operations,"Austin, TX",$105K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4ee53f87&cb=1618160368326&jobListingId=1006983939282&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-08d733e0d4cd559d,"Synergy Sports, the single source for computer vision, AI-driven video and data solutions for sports, seeks a fully Remote Senior Systems Engineer to help build out, grow and improve the data center operations and infrastructure within the business, with a focus on storage, automation and security.
This job offers tremendous opportunities to work with the only company that delivers on-demand professional-level basketball, baseball, and hockey analytics linked to supporting video to nearly 1500 pro teams, international, and college teams. Our systems are highly complex and contain petabytes of data and video requiring extremely talented engineers to maintain the scale and efficiency of its products.
Synergy’s work environment is geographically distributed, with employees working from home offices. The successful candidate must be comfortable working in a virtual office using online collaboration tools for all communication and interaction in English.
We are a globally distributed team and we work on an asynchronous model with flexibility of when and where you want to perform your job, while still being able to attend team calls and regular meetings. Personal initiative and a strong work ethic are highly encouraged and rewarded.
The company is deadline driven and provides a very transparent freedom and responsibilities culture to all our teams. We strongly believe striking the balance between work and family is very important and our culture is focused on the well-being of our team and their loved ones.
Objectives
An experienced, highly technical candidate joining the Synergy team is expected to successfully contribute to the ongoing development of Synergy’s online sports data and video delivery solutions supporting systems such as:
Linux/Windows Servers
PBs of storage including SAN/NAS/DAS
Automation using Puppet or Ansible
Monitoring tools (Opsview, Splunk, ELK, NewRelic)
Cloud Infrastructure AWS/Azure
Video capture and encoding equipment
Juniper, Pulse Secure and Sophos Networking Equipment
Asset Management (Netbox)
Other Responsibilities:
Management of multiple vendors & associated equipment, applications and operating systems with different contracts, warranties, process, licenses, patches and upgrade processes
Manage data center cost and reduced budget, where resources are procured based on ""best-cost""
Monitoring and visualization of the data center, the associated status, and the changes within and across all systems
Collection and analysis of power, space and capacity information to determine how to utilize the data center more efficiently to save energy and space or increase to the utilization of existing equipment
Automation of changes to the infrastructure while providing a single source of information and a consolidated view across all facility, IT hardware, networks, and applications
Use of the tools and insight to provide a resilient environment where risk is minimized, uptime is maximized, and services and applications can be delivered fast with minimal costs.
Requirements
Strong written and verbal communication skills
Excellent troubleshooting skills
Data center operations experience
8+ years of experience with Linux (Redhat or Debian), Windows Server, Networking (Switches/Firewalls) and Storage (Direct Attached or SAN)
Experience with cloud based identity solutions
Automation Puppet, Ansible or Scripting
Security Best Practices (Active Directory, Networking etc.)
Bonus Superpowers:
Distributed storage solutions (CEPH, Scality, EMC)
Windows and Linux Clustering
Logging and Monitoring (ELK/Splunk/Opsview/NewRelic)
Geo Load balancing or DR failover
Containers (Docker/Kubernetes)
Load balancing (F5 or NGINX or HA Proxy)
Benefits
Big problems, massive impact. We’re working on big scalability challenges and our flat structure means individuals have an incredible amount of impact on everything they touch.
A-players only. Join our team of best-in-class engineers to disrupt the sports industry and learn, share and grow with great peers on a daily basis.
A culture geared towards innovation and experimentation. From Deep learning and Computer vision to Kubernetes and the latest cloud technologies.
Medical, vision and dental.
401k
Life insurance
Paid sick leave
Remote work and flexible schedule",aus,de
136,Roku,Information Technology,4,Sr. Data Engineer (Technical Team Lead),"Austin, TX",$105K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_b1c64e68&cb=1618160368326&jobListingId=1006994775608&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-f398b22b53f757a7,"We're re-inventing the way the world watches TV, and that's a story we'd like your help telling.
Roku is changing how the world watches TV


Roku is the #1 TV streaming platform in the US, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.


From your first day at Roku, you'll make a valuable — and valued — contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers worldwide while gaining meaningful experience across various disciplines.

About the team

Our team's mission is to build a world class big data platform to bring value out of data for us, for our partners, and for our customers. Our goal is to democratize data, provide reporting and analytics self-service tools, and fuel existing and new business critical initiatives.

About the role


Roku pioneered TV streaming and continues to innovate and lead the industry. The Roku Channel has us well-positioned to help shape the future of streaming. Continued success relies on investing in Data Engineering.


The ideal candidate will have endless curiosity and can pair a global mindset with locally relevant execution. You should be a gritty problem solver and self-starter who can drive programs with the product and commercial teams within Roku and across external strategic partner organizations. The successful candidate will display a balance of hard and soft skills, including the ability to respond quickly to changing business needs.

Sr. Data Engineer (Technical Team Lead)

With tens of million players sold across many countries, thousands of streaming channels and billions of hours watched over the platform, building scalable, highly available, fault-tolerant, big data platform is critical for our success.

What You Will Do:

Help architect highly scalable, available and fault tolerant distributed data processing systems (batch and streaming systems) processing over 10s of terabytes of data ingested every day and petabyte-sized data warehouse
Drive architectural discussions, influence product roadmap, and take ownership and responsibility over new projects.
Lead and mentor junior engineers to ensure systems are built with highest quality, leveraging best practices.
Collaborate with business partners to understand business requirements, develop solutions to support business needs, facilitate issues resolution, and help determine opportunities to leverage current analytical application capabilities
Own the data mapping, business logic, and transformations
Build quality data solutions and refine existing diverse datasets to simplified models encouraging self-service
Drive efforts to improve the data quality across our data pipelines and implement system controls for managing data quality
Build automation to develop observability and help with debugging, performance measurement & optimization on large production clusters
Maintain and support existing platforms and evolve to newer technology stacks and architectures
Collaborate with cross-functional teams such as developers, analysts, and operations to execute deliverables

What you've done and what you bring:

Strong SQL skills
Proficiency in at least one scripting language, Python preferred
Proficiency in at least one object-oriented language is desired, Java preferred
Experience in big data technologies like HDFS, YARN, Map-Reduce, Hive, Kafka, Spark, Airflow, Redshift, etc.
Experience with AWS, Looker is a plus
Strong data modeling skills
10+ years professional experience as a data or software engineer
Experience leading a team or mentoring junior engineers preferred
BS in Computer Science; MS in Computer Science preferred
The Roku culture


Roku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV.


We have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002.",aus,de
137,CyberCoders,Business Services,4,Senior Data Engineer (Remote),"Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1110586&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_3ba80efd&cb=1618160368327&jobListingId=1006995111134&cpc=FA84DF7EA1EC2398&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-5ec3f6be2b295b0a&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT03aUFqZWNQZXcxMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLVHJIMTJudUswdFZCeWRTRTk1OG5KdGJhcVV4YXFFX0w4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWhrRUhaZDdzVmhlNTBtb214SG43bzNNcUdJbThRNzFwS1I3cVVleG9kZUxLZ1ozSTFSRWhaLVlZdXNvTFZtQWdrOU5rX2NuMmc2RjBzaFotajYwVXQtWDFIem1BN2hnWFR4alpjRWJ5QkZXcjJFNVVKN080MnRwUm1Ib1lZTlZ0TGhUakNfeTg3ZjVjY3NJNHhlUFo1b3NaZF8xUy1UU3dmWTNKLTI3dEluVkVGbTVIYmhKeEx3RjFKeUt1Q2R3LThCYTRuMFJ5MFp5MUFkcGM1b2JDYUM4SDQxMnFiUmpxbTQycDF2R1dRNF91cXU3MGR2eVYyQ1B1WHJFM3V5T21fbmFkR0taTHEwOVJ6am11eGlVZ0lBbC1uZjU3NFFYRlk5YkVwQnY0MEt1bTlpdE04Tkdad2N3TVFpZWdzZzgwSXBEbHRnVG13cUxaWk9ZSE94QURrR0JicGt1c3l0MTM1RmNQNXpUVWVtcktWaDZ1aGs2dEgzeWJMYTk3MTNJRm5CT2tjTzJTTTNZNS1NV0hBZHVPV252OVBtWDZaQktuTWJIUWxYSzBYZlB5U0RPbXdNdlpiSlM5LTQyd1lMM1hRdnhodFkweS1tVjktYm8yT0Zsc1pnZmwxdkRTdG5FbmlQM2FyQTZKaGdUN1VzU3VoN0tFbXVHZmVUMDY2LVFnVEZqY0FlaGdnRXdNRHAtQjN0OV9uMXRwNllHVjR2b24wa0dURklEcFFNVjc1ZzJxRUhYNlFxb1VCTGxIQ1BvUUNvVnNZU2Y3WGxYQzRzem5DS3RfdDhmX2szeVhTbHFEdHUtbzVFQXJSckctNGI5VDMzd0tGYTdxN0RkUG5nLVlvaGh6Yy10VnRDcVZtS2dza0JHYjRjMGFIcWk0VFotV2hxbmlRMzZzVmJDLTNZTjVPMUFnQTEtNkpFVWZ0c2xhU2U3bmNSdGs3Vk1jTE5xOVNuNEdMRHRGOFo1TVF1UWJWYzRJLWVWUURlc2JiUlo3bzVldlNyQThLZkRyUS1YUS02SGZfZ29ka1diZDFvSHdqeTJkTjlJc2doUTRzTDd0a0pMY1V3bWFnVFBVMDRLVFEzZTRQcldZeklnVHhIX0RXUEhycndiMlZWODNRZXBKb05tOWF5cWxLSEhIQ3FYczBFbWozZ3R3djA2dEJvaTlUVlh5RlhaMU4xUkk0ZlFzWmg0U2c0c3lNNjJhY0FKZjhuS0hGTVdkV2NYQjhiZVBuNk1JMDhyVnJfbE9TckZsWDVJWk1PcXBCTlM0bW9aNTBFVGN0V2xDaWlTazJ5YVBSNVJORjJpdHBVd0VvbUZmVGxzTG9KQ1l6ZEg1Vm9OYjZFZG92QlVnYVVjcjM3Q2o0QkxqR2JvbzRtSTZOZVhlSGdQUWY4cTBzVDZocmtfSE9fVHBtYjkzbWF3aHE4R3praURoUy1R,"Senior Data Engineer (Remote)
Title: Software Data Engineer
Salary: $140,000 - $160,000

Requirements: 5-10+ years as a Data Engineer + Docker/Kubernetes + Python (or Java) + AWS

We are a SaaS healthcare technology company that has seen very constant growth for the past 5 years and are the recent recipient of another Best Places to Work award.

We're huge on promotions, and can proudly say that we have promoted 50% of employees with over 1 year of tenure. If you have this experience, please apply immediately.
Top Reasons to Work with Us
- Competitive salary ($140k - $160k)
Work w/ Industry Pros who have a few impressive exits under their beltsFull Benefits (health, dental, vision, etc.)Strong GlassDoor ratingHave your voice be heard in and play a role in company directionVery low turnover rateHuge opportunity for career and personal growth
What You Will Be DoingCreate and maintain optimal data pipeline architectureIdentify, design, and implement internal process improvementsAssemble large, complex data sets that meet functional / non-functional business requirementsHandle production issuesEnsure code is high quality through automated tests, monitoring, etc.Collaborate with team to provide visibility into the data layer and related pipelines
What You Need for this Position
5-10+ years as a data engineer

Python or JavaAWSDocker / KubernetesData lake solutions like Hadoop, Hive, Spark, DatabricksExperience in the healthcare industry is a plusBS in CS (or related) is preferred
So, if you are a Senior Data Engineer (Remote) with experience, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",aus,de
138,Roku,Information Technology,4,"SR. Software Engineer, Data Platform","Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_aded5340&cb=1618160368327&jobListingId=1006992634460&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-a29a8451fae99a73,"Do you want to re-write the rules of modern advertising?
Roku is changing how the world watches TV


Roku is the #1 TV streaming platform in the US, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.


From your first day at Roku, you'll make a valuable — and valued — contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers worldwide while gaining meaningful experience across various disciplines.


About the team


Our team's mission is to build and manage state of the art Data Platform to fuel key initiatives involving Big Data Analytics and Machine Learning use-cases at Roku. The platform is used by various teams including Engineering, Data Science, Analytics, Finance, Marketing, Customer Success and Sales to make data driven decisions and delight Roku users. We are looking for a Sr. Software Engineer help us scale and to add new capabilities to the platform.

About the role


Roku pioneered TV streaming and continues to innovate and lead the industry. The Roku Channel has us well-positioned to help shape the future of streaming. Continued success relies on investing in Data Platform Engineering.


The ideal candidate will have endless curiosity and can pair a global mindset with locally relevant execution. You should be a gritty problem solver and self-starter who can drive programs with the product and commercial teams within Roku and across external strategic partner organizations. The successful candidate will display a balance of hard and soft skills, including the ability to respond quickly to changing business needs.

What you'll be doing

Work with stakeholders across the company to gather customer needs and product requirements.
Define system architecture and lead execution of projects end to end.
Be hands on; Participate in code reviews and write code when necessary.
Use programming and distributed systems knowledge to mentor engineers and help unblock them
Low level systems debugging, performance measurement & optimization on large production clusters.
Maintain and support existing platforms and evolve to newer technology stacks and architectures


We're excited if you have

Experience working with large scale, high-throughput, multi-tenant distributed systems
Experience with Hadoop 2.x/YARN based platform
Experience with SQL and NoSQL databases
Solid software development skills in Java or Scala
Participate and contribute to constantly improving best practices in development
Be self-driven, take complete ownership of initiatives and make pragmatic technical decisions
5+ years professional experience as a data or software engineer
BS in Computer Science; MS in Computer Science


The Roku culture


Roku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV.


We have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002.",aus,de
139,Sense Corp,Business Services,4.1,Senior Data Engineer,"Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_360d7096&cb=1618160368328&jobListingId=1006991141889&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-5b447c00189e9d77,"Sense Corp is seeking a brilliant, creative, fun, and passionate Senior Data Engineer. Our Data Engineers work with cross-functional teams and stakeholders, are passionate about data accuracy and reliability and are always looking for new and more efficient ways to extract, process, and transform data. As part of our Technology division, you will collaborate with the team while individually contributing to project deliverables that meet our clients’ needs.
Lead technical teams and developers to design, implement, and operationalize advanced data pipelines for reporting, machine learning, and other business critical applications
Define customer and business requirements to implement robust cloud-based technical architectures and solutions for end users. Regularly interface with client sponsors and team members to meet project deadlines and provide clear communication with the team
Provide documentation and explanation of technical solutions in a professional manner
Collaborate and closely align with solution architects, data analysts, and cloud engineering teams
Requirements
Deep expertise and hands-on experience developing and deploying SQL, Python, and Spark-based data pipelines into production environments
Deep experience with OLTP (MS SQL Server, Oracle, MySQL, PostgreSQL) and OLAP (Redshift, Snowflake, BigQuery, Synapse) database technologies
Significant hands-on technical experience with DevOps and CI/CD processes and tools, such as Azure DevOps, Jenkins, AWS CodePipeline, and Google Cloud Build
Strong experience with major cloud platforms and tooling, especially Azure, AWS, and Google Cloud
Strong interpersonal skills, presentation, and data narration / storytelling abilities with demonstrated ability to present to executive audiences
Strong experience using data manipulation tools to source, transform, and blend data from multiple different data sources
US Citizen or GC Holder
Preferred
Having examples of scaling production-facing applications in large enterprise environments
3+ years of consulting experience
Experience in mentoring and career development for junior resources
Experience using Big Data or Cloud integration technologies such as Databricks, Matillion, Azure Data Factory, AWS Glue, AWS Lambda, etc.
Exposure with AI and automation (ex. RPA) tools and processes
Benefits
Sense Corp has a proud history of ranking among both the Best Places to Work, Best Place for Working Parents, and Healthiest Employers in Austin, Dallas, Houston, and St. Louis. We offer a variety of ways to LEARN, SERVE, GIVE, RELATE, and GROW.
Extensive Training Opportunities
Wellness Program
Leadership & Professional Development
Mindfulness Program
Employee Driven Centers of Excellence
Social & Educational Networks
Enterprise Diversity & Belonging Program
Cultural Observance Days
Community Outreach

About Sense Corp
Sense Corp is a leading professional services firm focused on transforming organizations and government agencies for the digital era. We deliver tailored solutions to help clients solve their most complex challenges and maximize potential. Founded in 1996, Sense Corp maintains operations in Austin, Columbus, Dallas, Houston, Minneapolis, and St. Louis and serves mid-market to Fortune 50 companies.
The Sense Corp Compass
We may be the only consulting firm in the country where being brilliant isn’t enough to land you a job. Sense Corp employees must be brilliant, creative, human, and fun all at once. In other words, we hire terrific, well-rounded people. It’s one reason clients love working with us. And it’s why we enjoy working with each other. Regularly recognized as a Best Place to Work and Healthiest Employer, Sense Corp is driven by a company culture that aims to help employees be the best version of themselves.
Visit us at www.sensecorp.com.
#LI-JP1",aus,de
140,Credible,Finance,4.5,BI Data Engineer,"Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_dd31e39a&cb=1618160368328&jobListingId=1006992629607&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-79c2053719305275,"Who is Credible?

We believe life's changes create financial needs for people and that the traditional financial system often puts up unnecessary obstacles. People celebrate major milestones like going to college, getting married, and buying a home. And most of the time, these milestones come with financial implications.

At Credible, we have built a company with the mission of bringing transparency, choice, simple processes and savings to accessing credit for life's important moments. What you see is what you get. We are committed to being upfront, honest, and clear about your options. There are no mysteries, no hidden fees, and no secret clauses.

Credible is a fast-growing Fintech company that has world class management, has raised multiple rounds of funding, is generating significant revenue and is disrupting the lending market and helping people save money and get out of debt faster.

About the Role:

Our Business Intelligence team is looking for a BI Data Engineer who is passionate about data, analytics, and business strategy. You will help the team learn more about our business, teach others in the company about analytics, and improve the use of our data. You'll be an integral part of providing data-driven insights that inform significant company decisions.

Responsibilities:

Build data pipelines and python-based ETL tools for getting, processing, and delivering data
Develop data models and schemas in our data warehouse that enable performant, intuitive analysis
Partner with teams across the organization to understand their analytics needs and create dashboards and reporting that allow them to execute more effectively
Work with business leaders to define key metrics and build reporting to monitor and understand performance along those metrics
Conduct in-depth data analyses that lead to actionable insights, owning the entire process from ideation to execution to presentation of findings to stakeholders
Become an expert on all aspects of Credible's data and analytics infrastructure
Be the driving force behind the adoption and effective use of our BI tool within every team at Credible

Education and Experience:

BA/BS in a quantitative field
3-5+ years of work experience as a data engineer, or in a highly analytical role
Experience writing SQL queries and using a BI tool
Experience with programmatic scripting using Python to develop ETL pipelines and tooling
Experience using the command line and git
Strong grasp of statistics and experience conducting rigorous data analyses
Experience developing models and visualizations in Looker a plus
Experience at an e-commerce or fintech company a plus

Nice to Have:

The capacity to juggle multiple priorities effectively within a fast-paced environment is critical
You're a highly motivated self-starter with the ability to work efficiently with minimal supervision
Anticipate business needs and think with a business owner mindset – think critically about analyses, don't just complete them
Passion for spreading the value of data throughout the company and communicating insights to a broad audience with varying levels of technical expertise

Why work at Credible?

We are a fast moving, fun-loving, seriously smart group of people who really care about impacting the lives of our customers. We empower our employees to make decisions, take risks, drive our business and make changes when we don't get it right. These are our values:

Exceed Customer Expectations: We provide an exceptional experience to each and every customer that compels them to share it with others.
Take Ownership: We are trusted to make decisions that are in the best interests of our customers and our business. We think and act like owners. We care – and that makes all the difference.
Be Curious: We are curious, ask questions, seek to understand and try new things.
Do the Right Thing: We earn trust by being transparent, respectful and honest with each person with whom we interact.
Get Results: Results fuel our excitement and we know how our personal accomplishments tie to the success of the company.
Be Bold: We are courageous and take risks that scare us. Our enthusiasm for experimenting is how we will find the next breakthrough.

Our benefits:

We offer competitive compensation, generous benefits, free food and a flexible vacation policy.

But mainly, you want to work at Credible because you believe in our mission and want to have a major role in delivering on it! We look forward to getting to know you.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

#LI-CM1",aus,de
141,Visa,Information Technology,4.1,"Sr. Software Engineer - Payment Security and Identity, Data Product Development","Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_49b356eb&cb=1618160368328&jobListingId=1006985436309&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-9d7ab6f8f9fcc360,"Company Description
As the world’s leader in digital payments technology, Visa’s mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company’s dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.
At Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.
You’re an Individual. We’re the team for you. Together, let’s transform the way the world pays.

Job Description
Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area. For a payment system to work well, the risk techniques, performance, and scalability are critical. These techniques and systems can benefit from big data, data mining, artificial intelligence, machine learning, cloud computing, & many other advance technologies and in VISA, we have all of these. If you want to be in the exciting payment space, learn fast, and make big impacts, Distributed Risk Intelligence Platform team within Payment Security & Identity group @ VISA is an ideal place for you!
This position is for a Senior Software Engineer with solid development experience who will focus on creating new capabilities for Risk Platform while maturing our code base and development processes. In this position, you will be a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start.
Essential Functions
Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions.
Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards. Responsibilities span all phases of solution development including:
Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.

Qualifications
Basic Qualifications:
At least 4 years of relevant work experience with a Bachelors Degree or at least 2 years of relevant work experience with a Masters Degree.
Preferred Qualifications:
Bachelors degree in Computer Science or related field with 5 years of Software Development Experience or a Masters degree with 2 years of Software Development Experience.
Exposure to leading-edge tech such as Stream Computing, In-Memory Computing.
Expert in at least one of the following: Golang, Java, or C/C++
Experience with web service standards and related patterns (REST, gRPC)
Experience developing large scale, enterprise class distributed system or subsystems that require high availability, low-latency, & strong data consistency computing
Experience implementing solutions for low-latency, distributed services using open standard technologies.
Experience with Big Data and analytics in general leveraging technologies like Hadoop, Spark, and MapReduce a plus
Experience with distributed caching technologies like REDIS a plus
Experience architecting solutions with Continuous Integration and Continuous Delivery in mind
Strong interpersonal and leadership skills with effective communication (both written and verbal) skills and the ability to present complex ideas in a clear & concise way, a team player with a strong work ethic
Additional Information
Work Hours:
This position requires the incumbent to be available during core business hours.
Travel Requirements:
This position requires the incumbent to travel for work 0% of the time.
Physical Requirements:
This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",aus,de
142,Roku,Information Technology,4,"Sr. Data Engineer, Roku Channel","Austin, TX",$140K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136043&s=58&guid=00000178c1dfb8599f1e639afd1af883&src=GD_JOB_AD&t=SR&vt=w&cs=1_5c0ad563&cb=1618160368329&jobListingId=1006994775606&jrtk=1-1f30tve4du4l2801-1f30tve5ou4a2800-b99c11136a11d17b,"Do you want to re-write the rules of modern advertising?
Roku is changing how the world watches TV

Roku is the #1 TV streaming platform in the US, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.


From your first day at Roku, you'll make a valuable — and valued — contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers worldwide while gaining meaningful experience across various disciplines.

About the team

Data Engineering

With tens of million players sold across many countries, thousands of streaming channels and billions of hours watched over the platform, building scalable, highly available, fault-tolerant, big data platform is critical for our success.

Our team's mission is to build a world class big data platform to bring value out of data for us, for our partners, and for our customers. Our goal is to democratize data, provide reporting and analytics self-service tools, and fuel existing and new business critical initiatives.

About the role


Roku pioneered TV streaming and continues to innovate and lead the industry. The Roku Channel has us well-positioned to help shape the future of streaming. Continued success relies on investing in Data Engineering.

The ideal candidate will have endless curiosity and can pair a global mindset with locally relevant execution. You should be a gritty problem solver and self-starter who can drive programs with the product and commercial teams within Roku and across external strategic partner organizations. The successful candidate will display a balance of hard and soft skills, including the ability to respond quickly to changing business needs.

What You Will Do:

Help architect highly scalable, available and fault tolerant distributed data processing systems (batch and streaming systems) processing over 10s of terabytes of data ingested every day and petabyte-sized data warehouse
Drive architectural discussions, influence product roadmap, and take ownership and responsibility over new projects.
Lead and mentor junior engineers to ensure systems are built with highest quality, leveraging best practices.
Collaborate with business partners to understand business requirements, develop solutions to support business needs, facilitate issues resolution, and help determine opportunities to leverage current analytical application capabilities
Own the data mapping, business logic, and transformations
Build quality data solutions and refine existing diverse datasets to simplified models encouraging self-service
Drive efforts to improve the data quality across our data pipelines and implement system controls for managing data quality
Build automation to develop observability and help with debugging, performance measurement & optimization on large production clusters
Maintain and support existing platforms and evolve to newer technology stacks and architectures
Collaborate with cross-functional teams such as developers, analysts, and operations to execute deliverables

What you've done and what you bring:

Strong SQL skills
Proficiency in at least one scripting language, Python preferred
Proficiency in at least one object-oriented language is desired, Java preferred
Experience in big data technologies like HDFS, YARN, Map-Reduce, Hive, Kafka, Spark, Airflow, Redshift, etc.
Experience with AWS, Looker is a plus
Strong data modeling skills
10+ years professional experience as a data or software engineer
Experience leading a team or mentoring junior engineers preferred
BS in Computer Science; MS in Computer Science preferred


The Roku culture


Roku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV.


We have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002.",aus,de
0,Capital One - US,Finance,4.1,Data Engineer,"Cambridge, MA",$78K - $142K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178c1e1900fbb1a11ee18b507f7&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_43be9b21&cb=1618160489255&jobListingId=4053646766,"314 Main Street (21020), United States of America, Cambridge, MassachusettsData EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 2 years of experience in application developmentAt least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree3+ years of experience in application development1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)1+ years of experience with Ansible / Terraform2+ years of experience with Agile engineering practices2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)2+ years of experience with NoSQL implementation (Mongo, Cassandra)2+ years of experience developing Java based software solutions2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)2+ years of experience developing software solutions to solve complex business problems2+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",bos,de
1,Gannett,Media,3,Data Engineer,"Boston, MA",$113K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044318&s=149&guid=00000178c1e1900fbb1a11ee18b507f7&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_57e2ffff&cb=1618160489256&jobListingId=4056914723,"Req #14763Friday, March 26, 2021Gannett Co., Inc. (NYSE: GCI) is a subscription-led and digitally focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer-Prize winning content, consumer experiences and benefits, and advertiser products and services.Our current portfolio of media assets includes USA TODAY, local media organizations in 46 states in the U.S., and Newsquest, a wholly owned subsidiary operating in the United Kingdom with more than 120 local news media brands. Gannett also owns the digital marketing services companies ReachLocal, Inc., UpCurve, Inc., and WordStream, Inc., which are marketed under the LOCALiQ brand, and runs the largest media-owned events business in the U.S., USA TODAY NETWORK Ventures.To connect with us, visit www.gannett.com.Data EngineerReviewed/reviewed.com, a part of the USA TODAY NETWORK, is looking for a Data Engineer to join its growing Business Intelligence team.The right candidate will have a unique opportunity to design our BI data infrastructure from scratch. You can define the data model, architecture, and processes with few legacy decisions to work around. Its truly a green field opportunity.Our goal is to unify the data we need to fuel the continued growth of Reviewed, and as our Data Engineer you will be a key component of that success. Were looking for someone with a passion for putting data to work in an efficient and impactful way.The right candidate will be excited by the prospect of designing our companys data architecture to support our next generation of content and data initiatives.Reviewed is based in Cambridge, MA, but this role can be remote (eastern time zone workday).Responsibilities:Work closely with company and BI leadership to develop a data strategy based on Reviews business needs and objectives.Leverage that data strategy to develop a comprehensive data model.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Create and maintain Reviews optimal data pipeline architecture.Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources.Troubleshoot data discrepancies; resolve and articulate them.Work with our internal teams and external partners, to analyze and organize both structured and unstructured data.Partner with Reviews analysts to automate reporting to enable multiple audiences within Reviews organization.Requirements:Bachelor's or master's degree in computer science, data science, engineering, MIS or related technical field or equivalent combination of education and experience.2+ years working as a Data Engineer.Experience building and optimizing big data data pipelines, architectures, and data sets.A successful history of manipulating, processing, and extracting value from large, disconnected datasets.Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.Experience building processes supporting data transformation, data structures, metadata, dependency, and workload management.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.Experience with leading BI tools (e.g., Qlik, Data Studio, Looker, Tableau)You are creative, flexible, eager to learn, and able to work productively in a multi-project, deadline-driven environment.Strong project management and organizational skills.Employment is contingent on passing a pre-employment, post-offer background check.Experience working in BigQuery.Experience with digital advertising data (e.g., Google Analytics, Google Ads, Facebook Ad Manager).Experience with affiliate marketing.How to Apply:We are eager to learn more about you and how you fit this role. When you apply, dont limit your upload to a resume; show us what youve done. To do so, put together a single document file that includes the following, in this order:1. Your resume one to two pages.2. A cover letter that outlines how you would approach the job.3. Links to 3-6 online samples of your work. Show us what youve produced or had a hand in that best reflects what you can do in your desired role.It is important that these items be assembled into a single document and uploaded in PDF format. Completing these steps will ensure that your application receives the highest consideration.#ContentWork Environment:Office work takes place in an open floor plan office, with several smaller meeting rooms and test labs throughout the building. Regardless of whether youre onsite or remote, youll be expected to be accessible to the team throughout the day via face-to-face communication (whether in-person or over video calls), email, phone, and Slack.About Reviewed:Buying stuff is easy. Buying the right thing is hard. Thats where we can help. Reviewed brings consumers the most trustworthy reviews available, written by our team of experts. We believe that tough, objective reviews are the best way to analyze products. We provide readers with insightful, practical, and entertaining stories that help them make informed decisions.Reviewed is part of the USA TODAY Network, one of the largest news networks in the country, reaching over 150 million monthly unique visitors.Gannett Co., Inc.is a proud equal opportunity employer. We are a drug free, EEO employer committed to a diverse workforce. We will consider all qualified candidates regardless of race, color, national origin, sex, age, marital status, personal appearance, sexual orientation, gender identity, family responsibilities, disability, education, political affiliation, or veteran status.Other detailsJob Family Data AnalyticsJob Function TechnologyPay Type SalaryRequired Education Equivalent Experiencerecblid xwv4qb887xj9qkuqhvft2x6i3bbj9b",bos,de
2,Liberty Mutual Insurance,Insurance,3.8,Senior Data Engineer,"Boston, MA",$112K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_d0333007&cb=1618160489257&jobListingId=4001425658,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession. We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more, please visit https://www.libertymutualgroup.com/about-lm/careers/benefitsLiberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. We have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Senior Data EngineerAt Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions.GRM Data and Analytics Engineering is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert designing, developing, analyzing & testing innovative data warehouse reporting solutions. This Senior Data Engineer will join an energetic and engaged Business Data Solutions Engineering team focused on delivering exceptional value to our business partners. As a Senior Data Engineer, you will work collaboratively in an agile squad to design and build data pipelines & workflows, ingest, curate & provision data workflows in a Cloud-based environment as well as own responsibility of thorough end-to-end testing.This is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability.We encourage you to apply if this interests you:Work as ONE team committed to excellenceModel and promote a “Data First” attitudeHelp advance Data Engineering operations into the futureWork with a modern tech stackIn this role you will:Work in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiativesAnalyze, develop and execute data integration solutions, in order to manage the information lifecycle needs of an organization.Actively participates in and often leads peer development and code reviews within each Agile sprint, with focus on test driven development and Continuous Integration and Continuous Development (CICD).Designs and builds data provisioning workflows/pipelines, physical data schemas, extracts, data transformations, and data integrations and/or designs using ETL and API microservicesBuilds data architecture and applications that enable reporting, analytics, data science, and data management and improve accessibility, efficiency, governance, processing, and quality of data.Improve speed to market by focusing on current data needs as well as building out the long-term strategic data solutions using AWS, Snowflake, Snaplogic, SQL, Informatica, as well as other modern data technologiesDesign and develop programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data scienceDemonstrate open minded and collaborative approach to creating innovative technical solutionsMentor new and junior developersAnalyze complex technical problems and is expected to recommend process improvements that address complex technology gaps within a single business process and improve data reliability, quality, and efficiencyBachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred. Generally, 5+ years of professional data engineering experienceHighly proficient in data engineering languages and tools, and strong proficiency in general programming languages and frameworks; ability to develop on multiple platforms.Extensive understanding of agile data engineering concepts and processes, such as CICD, pipelines, and iterative development and deploymentsDemonstrated experience delivering data solutions via agile methodologies on AWS, S3, Athena, Snowflake, Snaplogic, Apigee, Orchestration toolsRequires critical thinking, data analysis, and data modeling experience (Data Vault experience a plus)Must be proficient in Python, Javascript functions and SQLExperience with ETL (Informatica) and knowledge of variety of data platformsDemonstrates leadership and active pursuit of optimizing data, CI/CD process and tools, testing frameworks & practicesMust be proactive and self-driven, demonstrated initiative and be a logical thinker.Strong leadership, communication, collaboration skills with a track record of taking solution ownershipThorough knowledge in the following areas; commercial P&C insurance, general IT concepts, strategies and methodologies, thorough knowledge of new data architecture principles and concepts, thorough understanding of layered systems architectures, extensive knowledge of business operations.16",bos,de
3,Liberty Mutual Insurance,Insurance,3.8,Experienced Data Engineer,"Boston, MA",$64K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_1b8ea207&cb=1618160489257&jobListingId=3747950491,"Experienced Data EngineerAt Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions.As an experienced Data Engineer at Liberty Mutual, you’ll consult on highly complex projects and solve technical problems, while working in an agile environment that has the creative energy of a start-up—and the full backing and comprehensive benefits of a Fortune 100 company.We’re currently hiring Intermediate to advanced Data Engineers across Liberty Mutual Technology.We encourage you to apply if this interests you:Work with a team committed to excellenceHelp bring Data Engineering operations into the futureModel and promote a “Data First” attitudeWork with a modern tech stackIn this role you will:Work in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions that meet business and technical initiatives.Improve speed to market by focusing on current data needs as well as building out the long-term strategic data solutions.Design and develop programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science.Demonstrate open minded and collaborative approach to creating innovative technical solutions.Analyze data and technical system problems to design and implement effective, flexible solutions.Handle end-to-end development, including coding, testing, and debugging during each cycle.Develop automated tests for multiple scopes (Unit, System, Integration, Regression).Mentor new and junior developers.Identify and recommend appropriate continuous improvement opportunities.Bachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferredExperience developing back end, data warehouse technology solutionsKnowledge of a variety of data platforms such as: Teradata, DB2 (Cloud based DB a plus)Experience with AWS (such as: S3, Snowflake, Athena), Unix, Informatica & SQLExperience working with agile methodologies and cross-functional teamsAt Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession. We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more, please visit https://www.libertymutualgroup.com/about-lm/careers/benefitsLiberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. We have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.17",bos,de
4,Iora Health,Health Care,3.8,Senior Data Engineer,"Boston, MA",$87K - $157K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2e99ed36&cb=1618160489257&jobListingId=4000069486,"Senior BI Engineer RoleWe're looking for a team-oriented Business Intelligence Engineer who is passionate about transforming Healthcare. We're seeking a Senior Business Intelligence Engineer to help lead our analytics and reporting environment that supports the Iora Health vision. As a key member of our Business and Clinical Intelligence (BCI) team, you will be responsible for reporting and analytics which form the foundation for innovative applications that directly impact the quality of care delivered to our patients. You will be passionate about finding the answers to tricky questions, solving problems, fantastic collaboration and communication, and continuous learning. You will be happy to get your hands dirty while building towards a bigger vision. You will serve as the resident data, reporting, and analytics expert and you will be instrumental in building the systems and culture of an innovative company that is working to transform health care, positively and directly impacting the lives of our patients every day. We're looking for folks who are deeply technical, analytical, articulate, team-oriented, business-minded, and mission driven!This role can be based in MA or NC and will report to the VP of Business & Clinical Intelligence in Boston, MA.ResponsibilitiesBe a key contributor to the design, implementation, automation, and documentation for Iora data, reporting, and analytics processesAs a member of an agile team, design, implement, and document data infrastructure for Iora Health's data warehouseDevelop key reports and dashboards using Looker to provide reporting analysis and analytics insightsRequired Skills5-10 years experience with relational databases and SQL4-6 years experience with PythonExcellent verbal and written communication skillsWorking knowledge and curiosity required to debug and analyze complicated systemPreferred SkillsExperience with RedshiftExperience with Matillion / SSIS / TalendExperience with Looker / TableauWe believe in building a diverse team, and we strive to make our office a welcoming space for everyone. We encourage talented people from all backgrounds to join us. Help us restore humanity to healthcare!About Iora HealthIora Health is transforming health care, starting with primary care. We created a high-impact relationship based care model, that particularly benefits adults on Medicare and those who might need more attention. Our care model changes everything - the team, outcome-focused payment, customer service, and the technology that supports our care.We know that when you invest in relationships with people, you can help them live happier and healthier. Our patients get a team that respects and listens to them. We get paid to keep our patients healthier, and it works - we are successfully improving the lives of our patients while lowering costs.",bos,de
5,Atlantic Broadband,Information Technology,3,Data Engineer,"Quincy, MA",$60K - $109K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044077&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_cf9a755e&cb=1618160489258&jobListingId=3798208698,"Job SummaryThis role is responsible for the extraction, transformation and load of data from our legacy systems into our new Google Cloud environment. This position will be part of the Data & Analytics team.Responsibilities:Assembling large, complex sets of data that meet non-functional and functional business requirementsIdentifying, designing and implementing internal process improvements optimizing data delivery, and automating manual processesBuilding required infrastructure for optimal extraction, transformation and loading of data from various data sources including MySQL, Oracle, flat files, CSV into GCP.The process involves:Data modelling: working with the data analyst and GCP engineers to define the data requirements, the source of the data and the formatsData Architecture: defining, together with the GCP engineers, the architecture of the GCP databasesData pipeline development: this includes extraction, formatting, and uploading of the data.Skills:Ability to build and optimize data sets, 'big data' data pipelines and architecturesAbility to perform root cause analysis on external and internal processes and data to identify opportunities for improvementsExcellent analytic skills associated with working on unstructured datasetsAbility to build automated processes that support data transformation, workload management, data structures, dependency and metadata using tools and scripting languages readily available on a variety of operating systemsEducation & Knowledge:Bachelor's degree in Information Technology, Computer Science or equivalent combination of training and/or experience.Ability to analyze existing systems and software to understand current processes and designsExperience with UNIX/Linux environmentsFamiliarity accessing APIs and consumer Interfaces that utilize XML, JSON, REST, SOAP, etc.Scripting/programming: Powershell, PERL, Bash etcFunctional knowledge of encryption technologies: SSL, TLS, SSH etcKnowledge of relational databases: MySQL/MariaDB, Oracle, MS SQL, Big QueryStrong initiative to find ways to improve solutions, systems, and processes.5 years of experienceJob Type: Full-timePay: $0.00 per hourBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programEmployee discountFlexible spending accountHealth insuranceLife insurancePaid time offReferral programTuition reimbursementVision insuranceSchedule:8 hour shiftSupplemental Pay:Bonus payEducation:Bachelor's (Preferred)Experience:SQL: 1 year (Preferred)Data Warehouse: 1 year (Preferred)Work Location:One locationThis Company Describes Its Culture as:People-oriented -- supportive and fairness-focusedTeam-oriented -- cooperative and collaborativeThis Job Is:A job for which military experienced candidates are encouraged to applyA “Fair Chance” job (you or the employer follow Fair Chance hiring practices when performing background checks)A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or moreA job for which all ages, including older job seekers, are encouraged to applyA job for which people with disabilities are encouraged to applyCompany's website:https://cogeco.wd3.myworkdayjobs.com/CogecoCareers/job/Quincy-MA/Data-EngineerJR290Benefit Conditions:Waiting period may applyWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview process",bos,de
6,"Alteryx, Inc.",Information Technology,3.6,Staff Data Scientist,"Boston, MA",$101K - $161K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_12c3a333&cb=1618160489258&jobListingId=4025060595,"Alteryx is searching for a Staff Data Scientist in our Boston office.We’re looking for problem solvers, innovators, and dreamers who are searching for anything but business as usual. Like us, you’re a high performer who’s an expert at your craft, constantly challenging the status quo. You value inclusivity and want to join a culture that empowers you to show up as your authentic self. You know that success hinges on commitment, that our differences make us stronger, and that the finish line is always sweeter when the whole team crosses together.Alteryx Innovation LabsThe Innovation Labs office, Alteryx's first office presence in Boston, was started earlier this year by the acquisition of MIT-spinout Feature Labs . This rapidly growing team combines the excitement of being part of a fast-paced, innovative startup with the resources, market penetration, and wisdom of a data analytics market leader. Our goal is to turbo-charge machine learning and data science efforts on the Alteryx platform, and to enable anyone to solve dynamic problems. We are working on high-impact, high-visibility projects, and we’re looking for collaborative and knowledge-hungry teammates who want to join us as we work to democratize machine learning.OverviewAs a Staff Data Scientist on the EvalML team, you’ll guide the development of our core open-source automated machine learning tool to power Alteryx’s current and future products, as we bring a brand-new machine learning product to market.You will play a leading role in ensuring that our project delivers a comprehensive set of top-quality cutting-edge features for supervised machine learning, that our project can effectively power the machine learning needs of Alteryx’s product line and that our project continues to gain traction in the open-source community. As part of our R&D team, you’ll work closely with our software engineers to get projects shipped. We are a startup-oriented organization, and the best candidates will bring an iterative and resourceful mindset to the table.ResponsibilitiesHelp product and engineering leadership set and prioritize the data science roadmapMake code contributions to enhance and grow our ML tools and productsHelp improve ML tools through performance testing, and establish repeatable tests and KPIsAuthor public-facing blog posts, demos, presentations and other documentation to showcase our open-source tools and to continue to build the open-source communityWork directly with prospective and current Alteryx customers, and use insights from those interactions to drive value back into Alteryx productsWork with internal analytics teams on their projects and on how they can effectively use our ML toolsRequirements5+ years’ experience with data analysis in one or more domainsExpert understanding of supervised machine learning algorithms, best practices and pitfallsTechnical contributions to both Alteryx’s open-source projects and our enterprise productsConceive, design and document new modeling features in our projectsGuide software engineering team in the development of new features and resolution of bugsFamiliarity with how software and projects are organized, issue tracking, creating and merging pull requests and agile processes.Experience with data analysis in Python, R or similarComfortable working with code written in PythonBonusExperience building or using automated modeling technologies, or other modeling technologies intended to perform well across a variety of use-casesExperience with time series modeling, multi series modeling, NLP featurization, anomaly detection, unsupervised and semi-supervised learning methods, image recognitionSoftware engineering experienceContributions to open-source projectsAcademic publications in data analysis or machine learning techniquesFind yourself checking a lot of these boxes but doubting whether you should apply? At Alteryx, we support a growth mindset for our associates through all stages of their careers. If you meet some of the requirements and you share our values, we encourage you to apply. As part of our ongoing commitment to a diverse, equitable, and inclusive workplace, we’re invested in building teams with a wide variety of backgrounds, identities, and experiences.Compensation:Alteryx is committed to fair and equitable compensation practices. The salary range for this role in Boston is $158,500 - $277,400. This position is also remote-friendly and, as such, compensation will ultimately be in line with the location in which the position is filled. Final compensation for this role will be determined by various factors such as a candidate’s relevant work experience, skills, certifications, and geographic location.This role is eligible for variable compensation including bonus and stock grants.Benefits & Perks:Alteryx has amazing benefits for all Associates which can be viewed here .Interested? Learn more and apply today at alteryx.com/careers !Please contact HR@alteryx.com if you require a reasonable accommodation/adjustment to review our website or to apply online.#LI-JE1",bos,de
7,Aurora Flight Sciences,Aerospace & Defense,4.1,AI/ML Research Engineer II,"Cambridge, MA",$99K - $175K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_723dd24a&cb=1618160489258&jobListingId=4057092315,"Job BriefDevelop, implement, and apply state-of-the-art AI/ML techniques to challenging problems in the aviation domain!Aurora Flight Sciences, A Boeing Company, a world leader in the development of highly autonomous aircraft is seeking a talented and self-motivated individual who can aid Aurora’s efforts to create the next generation of Artificial Intelligence / Machine Learning (AI/ML) technology for unmanned aircraft systems (UAS), aerospace and defense.Aurora is seeking a Research Engineer/Scientist to join our Autonomy Research Division. You will conduct research and development in Artificial Intelligence and Machine Learning (AI/ML) for challenging problems in the aviation domain!DescriptionAurora Flight Sciences, A Boeing Company, is a world leader in the development of highly autonomous aircraft. We are searching for a talented and self-motivated individual to work on cutting-edge research in AI/ML technology applied to unmanned aircraft systems, aerospace, and defense.ResponsibilitiesDevelop and apply AI/ML algorithms to technical challenges relevant to aerospace and defense.Support the rapid development of innovative prototypes to advance the AI/ML field.Collaborate with external partners, including MIT and other research institutions, to conduct joint research projects.Collaborate with researchers and engineers at Aurora and Boeing to transfer knowledge and technology.Assist in the preparation of R&D proposals and patent applications.Minimum RequirementsM.S. or Ph.D. in Engineering, Computer Science, or related fields.Expertise in modern AI/ML techniques.Coding skills in Python or C++.Must be a U.S. Person (U.S. citizen or a permanent resident/Green Card holder).DesiredExperience applying AI/ML to at least one technical area, including autonomous systems, computer vision, robotics, data analytics, human-computer interaction (HCI), or natural language processing (NLP).Experience with ML frameworks, such as PyTorch, TensorFlow, and MxNet.Familiarity with cloud computing or edge computing.Experience writing peer-reviewed publications or project proposals.Aurora Company OverviewAurora Flight Sciences, a Boeing Company, is a leader in the development and manufacturing of advanced unmanned systems and aerospace vehicles. Our mission is to apply autonomy and robotics to the development, production, and operation of advanced aircraft. During the last three decades, Aurora has designed, rapid-prototyped, and flown an average of one new vehicle a year for both government and commercial customers. Now, as an independent subsidiary of Boeing, Aurora’s innovation is combined with Boeing’s size and strength, creating an unprecedented opportunity to shape the future of aerospace systems.Aurora Flight Sciences, A Boeing Company, is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.Aurora Company Overview:Aurora Flight Sciences, a Boeing Company, is a leader in the development and manufacturing of advanced unmanned systems and aerospace vehicles. Our mission is to apply autonomy and robotics to the development, production, and operation of advanced aircraft. During the last three decades, Aurora has designed, rapid-prototyped, and flown an average of one new vehicle a year for both government and commercial customers. Now, as an independent subsidiary of Boeing, Aurora’s innovation is combined with Boeing’s size and strength, creating an unprecedented opportunity to shape the future of aerospace systems.Aurora Flight Sciences, A Boeing Company, is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.",bos,de
8,Verizon,Telecommunications,4,Data Platform Engineer - Internet Of Things,"Waltham, MA",$111K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_30f012c5&cb=1618160489258&jobListingId=4055320169,"When you join VerizonVerizon is a leading provider of technology, communications, information and entertainment products, transforming the way we connect across the globe. We’re a diverse network of people driven by our ambition and united in our shared purpose to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward – and you can too. Dream it. Build it. Do it here.What you’ll be doing...You will be a senior member of the Verizon IoT solutions and platform development team, focusing on design-driven development and front-end delivery. As a data solution design engineer, you will be responsible for the design and implementation of a highly scalable IOT developer platform and applications whose core tenants include an independent UI layer integrated viaAPI with telemetry infrastructure using messaging queues (MQTT/Rabbit/Other lightweight M2M), data ingestion and streaming platforms like Kafka/Kinesis and horizontally scalable micro services that use a variety of data persistence(NoSql, Relational, In-memory).All team members play a vital role in delivering high value and high quality solutions that meet business objectives, and delivering end-to-end performance and scale of complex video based analytic applications that can support millions of IoT devices in the field.The position is part of an agile, cross-functional team that delivers value to the business with high frequency. A continuous delivery / continuous integration (CICD) approach is followed to ensure tight integration and early detection of issues for quick delivery cycle-time.Design and develop well-architected and scalable end to end applications and development platformtouch points for video analytics based applications and IoT telemetry for various verticals like Smart Cities, Industrial IoT, Utilities, and 5G/MEC.Understand thetarget domain personas and the user experience requirements. Design user experiences that are highly scalable and targeted for cloud deployment/Software-as-a-Service (SaaS) model. Ensure applications meet the objectives of the business.Contribute to analysis and design of low latency Microservices APIs that will be consumed by a Cloud IOT platform as well as external developers/third party vendors.Design, review, and optimize data ingestion and transformation processes in streaming, relational databases, and/or NoSQL in cloud environments, to deliver the value of the data to customers.Conduct iterative application tuning and performance baselining.Participate in Agile development, daily scrum, and sprints.Develop high level and detail level designs with cross functional input. Work closely with product managers and other external stakeholders to ensure that the final solution will meet business objectives.Develop features with quality and integrated with continuous integration and delivery infrastructure.Implement and champion best practices in solution design and delivery to optimize business investments.What we’re looking for...Bachelors in Computer Science or 10+ years relevant work experience.6+ years in IOT and/or Computer Vision domain.Experience designing and developing complex-domain applications and highly scalable ingestion and data processing applications.Even better if you have:Strong foundation in Scala/CSS/Java /JS/Go/HTML and other programming languages. Familiar with industry best practices and design patterns.Experience with designing and using horizontally scalable UI layer component systems in Typescript/React16+/JS/ESlint/API/micro services architecture.Hands-on experience of Kafka/Kinesis/Spark streaming platform to build API’s utilizing real-time data pipelines.Hands-on experience on database management system and Query language.Experience with Messaging Systems and protocols (MQTT/CoAP/RabbitMQ).Debugging and monitoring experience of cloud application using Graphite/Grafana, ELK, Google Prometheus, Datadog.Ability to work within an agile, scrum-based team that utilizes Continuous Integration/Continuous Delivery processes.Equal Employment OpportunityWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best.Check out our diversity and inclusion page to learn more.",bos,de
9,Liberty Mutual Insurance,Insurance,3.8,"Manager, Data Engineering","Boston, MA",$108K - $161K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_0f721d21&cb=1618160489258&jobListingId=4027445113,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.Tech at Liberty Mutual offers the challenge and creativity of a startup with the financial backing and stability of a large company – that’s our opportunity for you. Liberty Mutual has been building internal startup teams to deliver innovative products and solutions quicker. As we grow this culture, mindset and capability, we want you to lead this change with us.We are currently seeking a Manager, Data Engineering to be part of the Data teams that support Liberty Mutual’ s Specialty Insurance business within Global Risk Solutions (GRS). In this role, the Manager will manage and lead agile engineering squads, building and maintaining data platforms and data solutions. You will be responsible for overall delivery and partner with Product Owners and Business stakeholders to ensure that the data platforms and solutions drive business value and foster a culture of data driven decision making. You will collaborate with Data Architects, Applications Architects and Solutions Engineers on technology decisions, both on-prem and cloud, to ensure the platform and solutions are scalable, reliable and secure.Key responsibilities of the role includeManage a team of data engineers and product ownersIdentify and improve the technical competencies within the team and establish practices for delivering engineering excellence.Lead agile delivery, and together with aligned Scrum Masters and Product Owners, develop self-directed, innovative, and high performing agile teams.Hire and manages technical talent; coach and counsel team members. Define individual performance objectives and development plans and ensure alignment with organizational objectives. Appraise and evaluate team and individual performance and make compensation recommendations.Fosters partnerships with internal IT and vendor partners to ensure effectiveness and efficiency.Knowledge of technology concepts, strategies and methodologies typically acquired through a Bachelor`s or Master`s Degree in technical or business discipline and a minimum of five years’ experience in a practice relevant domain including delivering software solutions in an agile environment. 3 years in a leadership role preferred.Ability to influence a diverse group of stakeholders through strong leadership skills.Strong problem-solving skills with ability to lead the team to push the solution and progress.A highly experimental mindset to drive innovation amidst uncertainty or ambiguity.A strong focus on the customer experienceHighly Competitive Candidate will have5+ years of experience in data domain (building data warehouse, data marts, data lakes, ETL, analytic solutions, etc.)2+ years of leadership experience managing and leading data teamsExperience with AWS data servicesPrior knowledge or understanding of Underwriting and Claims business domain18",bos,de
10,Liberty Mutual Insurance,Insurance,3.8,"Principal Configuration Engineer, SAP Basis","Boston, MA",$74K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_be51c979&cb=1618160489258&jobListingId=3822421008,"Do you have the skills—and drive—to join a tech team that’s working to digitally transform a trillion-dollar industry? From test-driving the latest technologies to creating intuitive consumer apps, Liberty Mutual is constantly innovating and creating industry-leading solutions that provide peace of mind for our customers worldwide. As a principal software engineer at Liberty Mutual, you’ll consult on highly complex projects and solve technical problems, while working in an agile environment that has the creative energy of a start-up—and the full backing and comprehensive benefits of a Fortune 100 company.We encourage you to apply and bring your expertise if you’re a:Technical problem solver: Going far beyond simply developing error-free source code, test scripts, components and system architectures, you’ll document and build deployment guides aimed at maintaining robust, relevant softwareCustomer-centric engineer: Putting clients’ needs first, you’ll translate customer requirements into technical applications and support the implementation of new softwareMotivated mentor: Exercise your technical chops while coaching and collaborating with junior software engineers.Forward thinker: Merely fixing a problem isn’t enough – using your proactive mindset and initiative, you’ll also identify opportunities to enhance performance, quality and efficiencyPrincipal SAP Basis EngineerThe SAP Basis Engineer is responsible for multiple aspects of the SAP Basis landscape including performance, project management, architecture, and strategy. SAP Basis Engineer will work closely with SAP Basis operations delivery team, application owners, data architects and business analysts to align global business strategies with enterprise IT and SAP technical strategies. Although this is a hands on technical position, candidates should be very comfortable leading and driving projects that require contributions from other teams.Position will participate in SAP Basis strategy and architectural goals within the global organization including education and communication with business partners and stakeholders within the enterprise. Must have working knowledge of SAP Basis configuration management activities including: client copy/refresh, system/client strategies, transport/migration policies, scheduling, performance tuning and monitoring, ABAP & Java stack administration on HANA and traditional systems, support packages application, and SAP upgrade strategies. Also desirable is knowledge on database standards and practices in an SAP environment, particularly in regards to SQL Server database technologies. In addition, the desire to work closely with other Solution Architects to drive resolution of technical issues related to business processes that span multiple applications and messaging technologies.Review SAP Basis strategies and processes and improve efficiencies aligning with business initiatives.SAP technical architecture design of existing and new technologies in a global SAP implementation.Defines and creates standards, guidelines, and quality of service criteria for enabling, implementing and supporting existing and new SAP landscapes and bolt on environment.Maintaining an understanding of current technologies, their trends, business strategies and capabilities.Leads technical performance and security compliance assessments (SOX review) of SAP applications and bolt on.Drive outsourced technical partner in the ongoing support of the operational environments to maximize operational efficiency and enrich end user experienceAccountable for regular performance review and reporting of all SAP systemsEvaluate, test and provide recommendations for new tools for enterprise SAP administration and performance managementProvide project management and oversight for Basis related projects8+ plus years' experience in SAP Basis administration experience with Oracle and SQL Server databasesWorking in an Agile environmentBachelors degree is preferred, and a masters degree is a plusPrior experience with ECC 6.0, SRM 7.0, SNC 7.0, PI 7.3, Solution Manager 7.2, GRC 10.2 and SAP HANA is strongly preferredUnderstand Bolt-on and supporting technologies e.g. Taxware, BSI, Spectrum, SAP Console, PaymetricExperience with global rollout of SAP and corresponding production operation challengesExperience with cloud infrastructure architecture is a plus, AWSSolid experience in large cross-functional teams and flexibility to influence people at management levelsStrong written and verbal communications, with proven experience in delivering management briefingsExtensive and proven experience working with third party service delivery organizationsA strong industry focus to understand the introduction of new SAP technologies and their possible impact to the company’s IT infrastructureDemonstrated track record of working across different technology towers to bring about innovative change and resolving cross application related business issuesA little about usAt Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Bachelor's Degree17",bos,de
11,Liberty Mutual Insurance,Insurance,3.8,Principal Cybersecurity Engineer,"Boston, MA",$137K - $162K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_6d1d9e0c&cb=1618160489259&jobListingId=4056315918,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.Job SummaryThe Principal Cybersecurity Engineer is a role within the Liberty Mutual Cyber Security Operations Center responsible for identifying anomalous activity and conducting investigations which may result in a security incident. The role includes mentoring junior CSOC engineers through incident response consultation or through incident escalation. This is a critical front-line cyber security role responsible for protecting Liberty Mutual’ s assets, networks, and systems from cyber threats.Job ResponsibilitiesPerform incident handling tasks based on daily process and/or procedure.Coordinate global incident response team efforts as a Lead Responder in investigations to identify, contain, and remediate security incidents.Identify potential security control gaps in an enterprise environment and provide solutions to mitigate compromise. Review threat intelligence to ensure enterprise is prepared to defend attacks.Complete forensic analysis of computers and other devices in scope to investigations for evidence or artifacts related to incidents.Conduct analysis of the enterprise network to discover indicators of a network breach or system compromise.Investigate alerts generated by network security controls to prevent data loss and maintain the integrity of corporate information.Participate in Financial sector and Information Security communities to share and consume intelligence to further enhance discovery capabilities.Analyze files and binaries for indicators of malicious capabilities resulting in reporting on findings which can be used for retrospective or future detection.Train associate analysts on the processes of advanced information security investigation and procedures.Develop applications or scripting for forensic and incident response analysis.Deep understanding of key business initiatives and identifies improvements that address highly complex technical functional and technical gaps within single business process.Provides consultation on highly complex technology to address security gaps which enable business processes.Ability to lead projectsRequired 24x7 on-call participation per on-call rotationPreparation, Training, and ExperienceCollegiate level degree in Computer Science, Computer Engineering, Information Security, or other related disciplineActive Cybersecurity certifications such as GCIH, GSEC, GREM, GCFA, GCFE (GCIH desirable)8 years of recent experience working as an information security professionalPrevious experience working in a Cyber Security Operations Center is desirableMust have excellent trouble-shooting and problem-solving skillsKnowledge of frameworks, standards, and best practices such as NIST, PCI, CIS-CSCs, COBIT, MITRE ATT&CK, Cyberkill Chain etcDemonstrated experience working independently as a digital forensics and incident responderDemonstrated understanding of General IT knowledge, Security Fundamentals, Network Systems, Firewalls, IDS/IPS Systems, Security Email Flow, End-point Security, and, Network Security concepts Windows & Linux Systems Administration, malware analysis, cyber threat hunting, cyber threat intelligence, offensive tactics techniques, and procedures, and cloud security fundamentals.Demonstrated experience with application security.Experience using Security Information Event Management platform/case management.Desirable experience building playbooks, scripts, and development of automation in support of security operations.Excellent oral and written communication skills.Desired Certifications:Microsoft Windows Operating System/Server CertificationsCompTiA Linux+;CompTIA Network+;Security Certifications:SANS GIAC GSEC GREM GCIHCisco CCNA Cyber OpsCompTIA CySA+EC-Council CEHOSCPISC2 CISSP or SSCPCloud CertificationsMicrosoft Azure / AWS Security / ISC2 CCSP / CSA CCSA17",bos,de
12,Takeda Pharmaceutical,Biotech & Pharmaceuticals,3.9,Senior Validation Engineer,"Lexington, MA",$120K - $129K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_5f438e33&cb=1618160489259&jobListingId=4055721241,"By clicking the “Apply” button, I understand that my employment application process with Takeda will commence and that the information I provide in my application will be processed in line with Takeda’s Privacy Notice and Terms of Use. I further attest that all information I submit in my employment application is true to the best of my knowledge.Job DescriptionTitle: Senior Validation Engineer IAre you looking for a patient-focused, innovation-driven company that will inspire you and empower you to shine? Join us as a Senior Validation Engineer in our Lexington, MA office.At Takeda, we are transforming the pharmaceutical industry through our R&D-driven market leadership and being a values-led company. To do this, we empower our people to realize their potential through life-changing work. Certified as a Global Top Employer, we offer stimulating careers, encourage innovation, and strive for excellence in everything we do. We foster an inclusive, collaborative workplace, in which our global teams are united by an unwavering commitment to deliver Better Health and a Brighter Future to people around the world.Here, you will be a vital contributor to our inspiring, bold mission.A typical day will include:This position will be responsible for executing equipment, utilities, process and cleaning validation activities and projects for Takeda. Technical duties include setting validation strategy, adhering to domestic and international GMP regulations, incorporating continuous improvements into validation activities and policies, and participate in regulatory inspections.Leadership duties include developing strategy, leading change and motivating others. The scope of responsibility encompasses the product life cycle for existing commercial pharmaceutical and biopharmaceutical products as well as emerging products and platforms. Periodic travel may be required for business meetings with vendors/contractors and to stay current with professional development. Routine local travel to Takeda’s operational sitesPOSITION OBJECTIVES: 30%-80% of Time:Write, execute, summarize, and lead validation activities in the following areas:FacilitiesEquipmentShipping / Cold ChainProcessCleaningSteaming / AutoclaveComputer SystemsPlant AutomationValidation MaintenanceValidation document control and archival programDevelop and assess the following Quality System elements for Validation:Quality Risk Management programCAPAsChange ControlsDeviationsGMP InvestigationsParticipate and contribute in design, development, and process/cleaning validation strategy.Provide technical input to strategy/philosophy for process and cleaning validation.Represent validation during tech transfer activities and lead cleaning and process validation efforts as required.Lead and manage complex validation and technical projectsIdentify opportunities for continuous improvements, deploy best practices, pro-actively update validation programs to reflect current regulations and trends.10%-20% of Time:Participate and lead partner audits and regulatory agency inspections for Validation.Author and review responses to inspection observations and agency questions.Author and review sections of regulatory filings and annual product quality reviews.KEY SKILLS, ABILITIES, AND COMPETENCIES:Qualified candidates will have:Formal leadership experience with demonstrated effectiveness in developing validation strategy, leading complex validation projects and motivating and developing personnel.The successful leader exemplifies trust and openness and a willingness to partner with others.Comprehensive knowledge of global cGMP requirements and expectations (US, EU, Japan, ICH, PIC/S, WHO) as they pertain to validation.Ability to lead cross-functional projects individually and with dedicated staff membersA desire and skill to work as a team member and to influence, and work through others to ensure coordinated goals are achievedWillingness to receive and listen to feedback as well as provide constructive feedback to peers / managementEDUCATION, BEHAVIORAL COMPETENCIES AND SKILLS:Bachelor’s Degree in a technical discipline, preferably engineering or biological sciencesMinimum of 5 years pharmaceutical and/or biopharmaceutical industry experienceAn advanced degree or additional industry certification is a plusCOMPLEXITY AND PROBLEM SOLVING:The person in this role will be instrumental in working with other members of the Quality, Manufacturing and Engineering organizations to develop appropriate validation strategies to enhance the manufacturing systems and processes to compliantly and efficiently achieve organizational goals.The person in this role must have the ability to analyze data, quantify risks, identify gaps, and implement effective corrective actions to increase efficiency and/or improve compliance.The person in this role must be able to make decisions on his/her own as it pertains to individual projects, managing priorities, and timelines. Must have the ability to solve problems on own and escalate issues with proposed solutions as necessary.INTERNAL AND EXTERNAL CONTACTS:InternalThis role provides validation services and support to the global organization.The role is accountable directly to the Manager of Validation to enable validation support of all GMP operations.Interactions will occur with Site Leadership Teams of internal and external organizations (e.g. All GMP functional areas in multiple locations, especially members of manufacturing, supply chain, quality, regulatory, IT, process development)ExternalRegulatory Agencies, Consultants/Contractors, and third-party vendors & business partners.WHAT TAKEDA CAN OFFER YOU:401(k) with company match and Annual Retirement Contribution PlanTuition reimbursement Company match of charitable contributionsHealth & Wellness programs including onsite flu shots and health screeningsGenerous time off for vacation and the option to purchase additional vacation daysCommunity Outreach ProgramsThis role excludes CO applicants.Empowering Our People to ShineDiscover more at takedajobs.comNo Phone Calls or Recruiters Please.LocationsUSA - MA - Lexington - BIO OPSWorker TypeEmployeeWorker Sub-TypeRegularTime TypeFull time",bos,de
13,Liberty Mutual Insurance,Insurance,3.8,Software Engineer,"Boston, MA",$49K - $103K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_dbcad53b&cb=1618160489260&jobListingId=4055962504,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Software Engineer – Machine LearningWe deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.About the job:We are seeking a Software Engineer with full stack skills to participate in software development within an Agile team supporting our Analytic Platforms and Services department. You will be working on Runway, our internally developed platform for managing the deployment of AI/ML predictive models. Runway makes it as fast and easy for data scientists to operationalize their Python and R models while adhering to high standards for security, performance and availability.In addition to full-stack Java development, this role also includes working on templates and ML operations components written in Python. Members of the Runway team work closely with data scientists in all markets, so consulting skills and a desire to apply machine learning and artificial intelligence to high-value business challenges are critical to this role.The industry changes quickly, so we are looking for candidates who can respond to change, pick up new technologies quickly and adapt to changing requirements. We also want candidates who take pride in their work and have strong design and development expertise. We value quality code delivery and expect candidates to demonstrate competence at writing, testing and debugging Java and Python code.Highly competitive candidates will have:Familiar with Python webserver and MLOps libraries, such as Flask, FastAPI, MLflow and AirflowKnowledge of machine learning tools and practicesData engineering skills, including SQL databases, pandas and SparkQualifications:Bachelor's Degree in technical discipline preferably computer science or software engineering2+ years of professional development experience in Java and PythonKnowledge of IT concepts, strategies, methodologies, architectures and technical standardsAnalytical, problem solving, and communication skillsFamiliarity with insurance functions and business operationsExtensive knowledge of design and development toolsConsulting, negotiation and consensus building skillsPresentation and written communication skill14",bos,de
14,Riverside Research,Government,3.7,Lead Radar Research Engineer,"Lexington, MA",$146K - $187K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_eb25f87d&cb=1618160489261&jobListingId=4029740906,"Riverside Research is seeking a Radar Research Engineer to support internal research and development efforts within our Radar Assessment and Development (RAD) Group. With over 50 years of radar-system experience, our Radar Group has established an independent team of national radar subject matter experts with unrivaled experience in development, implementation, and assessment of radar systems and mission performance. This position is focused on design and analysis of radar signal processing algorithms and architectures.All Riverside Research opportunities require U.S. Citizenship.Job Responsibilities:Act as primary lead on internal research and development efforts for the RAD groupManage intellectual property and internal research efforts involving radar and other sensor modalitiesDevelop embedded communication in radar transmissions using traditional communication constellationsDevelop non-linear filtering strategies for bistatic radar STAP, using Volterra and Weiner non-linear filtersPerform seminal research into theoretical and computational modeling of novel materials for radar signature control applicationsRadar system and mission performance assessment, including detection, track, object classification/discrimination performanceTechnical data analysis for a wide array of engineering problems involving large-scale radar systems. These may include ground-based and mobile radar platforms that track ballistic missile and earth-orbiting targets;Plan collection and analysis of experimental dataMaintain dialogue with outside collaboratorsPresent findings at scientific conferencesImplement enhancements to experimental systems and data processing toolsInvestigation and root-cause analysis of system and software performance anomalies;Assistance with system modernization and system architecture studies;Independent Verification and Validation (IV&V), algorithm prototyping, and simulationTest support, Independent Verification and Validation (IV&V), algorithm prototyping, and simulationInvestigation and mitigation of system and software performance anomaliesSystem and mission requirements analysis, feasibility studies, system modernization and architecture studiesRequired Qualifications:Active DoD Secret Security ClearanceMasters in Electrical Engineering or closely related technical field10+ years experienceExpertise programming with MATLAB, C/C++, Java, SIMULINK or other scientific programming languagesAbility to develop new research collaborationsDesired Qualifications:Solid understanding of radar system functionality, performance limitations, and mission support requirementsStrong experience with Digital Signal Processing, RF/Microwave Engineering, Antennas, Electromagnetic Fields and Waves, Communications Systems, Probability/Noise & Stochastic Processes, Microwave Circuits and NetworksDemonstrated ability to develop and manage customer relationships and identify and pursue emerging opportunities such as RFPs, BAA's, SBIRs, and IRADsCritical thinking, problem-solving skills and ability to solve problems to the endTechnical writing skills as evidenced by peer-reviewed publicationsFirst-author publication in peer-review journal with impact factor greater than 2Experience presenting research results at scientific conferencesIND1Riverside Research strives to be one of America's premier providers of independent, trusted technical and scientific expertise. We continue to add experienced and technically astute staff who are highly motivated to help our DoD and Intelligence Community (IC) customers deliver world class programs. As a not-for-profit, technology-oriented defense company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.All positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.Our EEO PolicyRiverside Research is an equal opportunity employer. We recruit, employ, train, compensate and promote without regard to race, religion, sex, color, national origin, age, gender identity, sexual orientation, marital status, disability/veteran, status as a protected veteran, or any other basis protected by applicable federal, state and local law.If you need assistance at any time in our application or interview process, please contact Human Resources at 937-427-7074 or email HR@RiversideResearch.org. A member of the HR team will be available to assist.This contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.This contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.For more information on ""EEO is the Law"", please visit:http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdfhttps://www.dol.gov/sites/dolgov/files/ofccp/regs/compliance/posters/pdf/eeopost.pdf",bos,de
15,Liberty Mutual Insurance,Insurance,3.8,Senior Software Engineer,"Boston, MA",$67K - $135K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_f536a85b&cb=1618160489261&jobListingId=4055962405,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Senior Software Engineer – Machine LearningWe deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.About the job:We are seeking an experienced Senior Software Engineer with full stack skills to participate in software development within an Agile team supporting our Analytic Platforms and Services department. You will be working on Runway, our internally developed platform for managing the deployment of AI/ML predictive models. Runway makes it as fast and easy for data scientists to operationalize their Python and R models while adhering to high standards for security, performance and availability.In addition to full-stack Java development, this role also includes working on templates and ML operations components written in Python. Members of the Runway team work closely with data scientists in all markets, so consulting skills and a desire to apply machine learning and artificial intelligence to high-value business challenges are critical to this role.The industry changes quickly, so we are looking for candidates who can respond to change, pick up new technologies quickly and adapt to changing requirements. We also want candidates who take pride in their work and have strong design and development expertise. We value quality code delivery and expect candidates to demonstrate competence at writing, testing and debugging Java and Python code.Highly competitive candidates will have:Familiar with Python webserver and MLOps libraries, such as Flask, FastAPI, MLflow and AirflowKnowledge of machine learning tools and practicesData engineering skills, including SQL databases, pandas and SparkQualifications:Bachelor's Degree in technical discipline preferably computer science or software engineering5+ years of professional development experience in Java and PythonKnowledge of IT concepts, strategies, methodologies, architectures and technical standardsAnalytical, problem solving, and communication skillsFamiliarity with insurance functions and business operationsExtensive knowledge of design and development toolsProficient in multiple programming languages and toolsConsulting, negotiation and consensus building skillsStrong presentation and written communication skill16",bos,de
16,Liberty Mutual Insurance,Insurance,3.8,Senior to Principal Software Engineer,"Boston, MA",$141K - $151K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_40d4783d&cb=1618160489262&jobListingId=3821707943,"At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That’s why we provide an environment focused on openness, inclusion, trust and respect. Here, you’ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG’s Insider Pro and Computerworld’s 2020 list. For many years running, we have been named by Forbes as one of America’s Best Employers for Women and one of America’s Best Employers for New Graduates—as well as one of America’s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusionWe value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/BenefitsLiberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran’s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.Senior to Principal Software Engineer – Analytics PlatformsWe deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.About the job:We are seeking a Senior to Principal level engineer with Full Stack skills, to participate in software development within an Agile team supporting our Analytic Platforms and Services department. You will be working on our existing analytics application, Cortex. This is an internally developed Java application that is intended to allow analytics teams to quickly create, manage and terminate their own scalable high-performance cloud computing and storage environments to support analytics, machine learning and big data projects.Cortex includes a provisioning service that works with both AWS and Azure, a tools portal that allows users to work with popular data science tools like R and Python, a fully compliant security layer, and several utilities that make it easy to stage data science problems with Cortex. The Cortex team also works directly with Liberty data science teams in all markets to assist them with their projects and gather new requirements and insights to support the ongoing development of the platform.The industry changes quickly, so we are looking for candidates who can respond to change, pick up new technologies quickly and adapt to changing requirements. We also want candidates who take pride in their work and have strong design and development expertise. We value quality code delivery and expect candidates to demonstrate competence at writing, testing and debugging Java code.Desired skills:Generally 5+ years of professional development experience in Java.Experience with Full Stack Development including HTML, JavaScript, React and AngularKnowledge in web service development, design and specifications writing with SOAP or REST.Foundational knowledge or proficient in new and emerging technologies such as AWS, Azure and Cloud, DevOps, CI/CD and MicroServices.Excellent analytical, problem solving, and communication and collaboration skills.General knowledge of agile software development concepts and processes.Must be proactive, demonstrate initiative and be a logical thinker.Experience with layered system architectures and layered solutions; understanding of shared software concepts.Highly competitive candidates will have:PythonSparkR LanguageQualifications:Bachelor's Degree in technical discipline preferably computer science or software development.Generally 5+ years of professional development experienceExtensive knowledge of IT concepts, strategies, methodologies, architectures and technical standardsStrong analytical, problem solving, and communication skillsExperience with layered system architectures and layered solutions; understanding of shared software conceptsExtensive knowledge of IT concepts, strategies and methodologies.Extensive knowledge of a business function(s) and of business operations. Extensive knowledge of design and development tools.Extensive knowledge of architectures and technical standards.Extensive knowledge of layered systems architectures and layered solutions and designs; extensive understanding of shared software concepts.Proficient in multiple programming languages and tools.Proficient in new and emerging technologies.Negotiation, facilitation and consensus building skills.Strong oral and written communication skills; presentation skills.17",bos,de
17,Capital One,Finance,4.1,Master Data Engineer,"Waltham, MA",$107K - $121K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_10c6c083&cb=1618160489263&jobListingId=4058320723,"314 Main Street (21020), United States of America, Cambridge, MassachusettsMaster Data EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 5 years of experience in application developmentAt least 3 years of experience in software development in at least one of the following: Scala or PythonAt least 3 years of experience in SparkAt least 2 years of experience in big data technologies (Cassandra, Accumulo, HBase, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree7+ years of experience in application development3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)2+ years of experience with Ansible / Terraform3+ years of experience with Agile engineering practices3+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)3+ years of experience with NoSQL implementation (Mongo, Cassandra)3+ years of experience developing Java based software solutions4+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)4+ years of experience developing software solutions to solve complex business problems3+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",bos,de
18,"Draeger Medical Systems, Inc.",Manufacturing,3.9,Sr Software Quality Engineer,"Andover, MA",$109K - $117K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_d6806db6&cb=1618160489263&jobListingId=4057109902,"The Job ResponsibilitiesAt Draeger, our work is dedicated to protecting, supporting and saving lives. We are looking for a talented individual to join our patient monitoring team to help deliver new features and product enhancements that will improve patient outcomes and reduce the cost of medical care around the world.Projects at Draeger range from developing new software for acquiring, archiving, and displaying new monitoring data in a desktop or mobile application to developing software for new hardware modules. The ability to work in more than one of these areas is highly valued at Draeger.*Salary will commensurate with experience***This position does not offer a relocation package** As a member of a development team, you will:Provide Quality Engineering support for the software organization during Design & Development.Provide support throughout the product Software lifecycle by participating in Software development reviews, code reviews and formal software technical reviews.Represent Software Quality on Project Cross Functional TeamsEnsure Software development activities and deliverables meets the Quality and Regulatory requirements of FDA and ISO standards and IEC 62304Participate in Risk Assessment activitiesReview and approve new and modified Software product designs for quality characteristics, testability and traceable to product requirements.Review and approve test plans and resultsReview and ensure DHF compliance for all software deliverablesParticipate in software complaint and triage processWork cross-functionally with Quality, Regulatory, Product Qualification (PQ), Supply Chain, and ManufacturingPerform work in compliance to all relevant internal SOPs and FDA/industry regulationsPerforms other duties as needed and assigned within Software Quality OrganizationYour QualificationsMedical device industry experience is a requirement.Education: BS in relevant engineering discipline (e.g. Biomedical, Electrical, Computer Science, or Software Engineering).5 to 8 years of experience working within medical device Quality organizationSoftware engineering/development experience of medical devices software a plusAbility to effectively work on Project teams.Understand the internal processes and intent of all aspects of the QMS related to Design ControlsGood interpersonal and communication skillsFDA QSR RegulationsSpecial Competencies or Certifications:Understanding of IEC62304, ISO 13485, ISO 14971, ISO 9001and IEC 60601-1Knowledge of 21CFR820 and cGMPFamiliarity with source code control, requirements management, and defect tracking software; JIRA, GIT/Bit Bucket, Rational ClearQuest, DOORs experience is a plusProficient with the use of MS Office Products (Word, Excel, PowerPoint).The Dräger WorkplaceIn North America, Draeger employees over 1,400 employees working in our major sites in the United States and Canada (in the US: Andover, MA; Telford, PA; Houston / Coppell, TX, and in Canada: Mississauga, ON), including our Sales and Service workforce employees from coast to coast.The design, development and manufacturing of Draeger’s Patient Monitoring product line takes place in our Andover, Massachusetts location.Equal Opportunity Employer – Disability and VeteranWho we areDraeger is a leading international company in the fields of medical and safety technology. Whether in clinical applications, in industry, mining or emergency services: Draeger products protect, support and save lives. That's what our more than 13,000 employees have been striving for - every day for almost 130 years. Dräger - Technology for Life ®What we offerAdditional/Voluntary InsuranceEducation & TrainingHealth center and gymHealth InsuranceRetirement SavingsSpecial AssistanceTime AwayWorkplace WellnessAdditional/Voluntary Insurance; Education & Training; Health center and gym; Health Insurance; Retirement Savings; Special Assistance; Time Away; Workplace WellnessIf you have any questions, please contactMichael ChristopherE-Mail: usdraegercareers.c.us",bos,de
19,Sentinel Benefits & Financial,Insurance,4.4,Software Engineer,"Wakefield, MA",$42K - $90K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_44d081be&cb=1618160489263&jobListingId=4057318687,"Purpose of Your Role:The Software Engineer is part of the development team, which has the responsibility for supporting, enhancing and integrating home built custom applications using Microsoft .NET, Web technologies, CRM and databases . The Software Engineer conducts requirement analysis, documents technical specifications, writes, reviews, debugs code and helps with the Dev Ops processes. The Software Engineer handles complex issues and problems, collaborates more complicated issues with higher-level staff.The Expertise we’re looking for:Build containerized applications for the cloud and internal servers.Proven success in delivering quality software projects on time, on budget, and within scopeAbility to develop applications with .NET and .NET Core for containers and Kubernetes.Build applications and REST Services with C# using Microsoft .NET, Microsoft.NET Core, Entity Framework and SQL.The Behaviors that you bring:Integrity – Your customer-centric attitude and commitment to doing what is right for our clients.Expertise – You are a team player and continuous learner. You share your knowledge with the team, embrace new learning opportunities, and search for ways to improve our operations.Empowerment – You demonstrate organizational skills, the ability to manage priorities, deadlines, and troubleshoot issues independently.Excellence – Your detail-oriented approach leads to quality processing results for our clients and your communication skills allow you to communicate effectively with clients and internal team members.Innovation – You learn quickly, collaborate with others, and share your ideas for improving our service.The Excellence you deliver:Ability to build REST service oriented applications using Microsoft .NET Core technologiesProgramming with C#, Microsoft MVC, Web APIs, Entity Framework.Work with Content Management system, CRM system, SQL Server and Oracle databases.Day to day maintenance and support of all existing applications in use at Sentinel.Ability to develop applications with .NET and .NET Core for containers and Kubernetes.Utilize TFS, Azure DevOps, Azure Pipelines, and Azure Repos and upgrade DevOps processes within Sentinel.About You:We are looking for innovative thinkers to drive our business and clients forward—someone with customer focus, drive, determination, and the strength of character to challenge the status quo. We strive to surround ourselves with team members who go above and beyond in all job facets and look for people who are willing to embrace change.Education, Skills and Experience:Bachelor's degree in Computer Science or equivalent experience.2-4 years of software engineering experience.Experience with Microsoft Azure technologies.Experience with Microsoft Azure DevOps, Azure Pipelines, Azure Repos and PowerShell.Knowledge of the Kentico CMS system.Proficiency in various protocols and data formats, including REST, JSON, and XML.Authorized to work in the US. We do not sponsor applicants for work visas.Our Company:Sentinel Benefits & Financial Group proudly serves more than 3,500 clients throughout the U.S., and for 30 years, we’ve remained devoted to making a difference in the lives of our people, our clients and our community. With nearly 220 professionals tied to our mission to deliver great service—and a 9-year average associate tenure—we have become the thought leader we are today.Sentinel was recently recognized by The Boston Globe as a Top Place to Work in 2020. In 2021, Sentinel earned a Top Workplace USA Award from Energage. Sentinel is also recognized as one of the largest employee benefits firms in Massachusetts (Boston Business Journal), a top 100 retirement plan adviser (PLANADVISER Magazine), and the 2016 recipient of the Best-in-Retirement Business IMPACT Award™ by Charles Schwab, our in-house experts—and their commitment to excellence—define who we are.Our Culture:Our people care about our organization. We are a company with a mission to be the best in our industry and best within our company. Being part of this company means that you are part of something special. Sentinel Benefits & Financial Group offers paid vacation, 10 Holidays and 2 floating holiday, company sponsored medical and dental insurance, life insurance, AD&D, short and long‐term disability, 401(k) Plan and free parking. Sentinel Benefits & Financial Group is an Equal Opportunity Employer.678pASjvjg",bos,de
20,Congruity360,Information Technology,3.6,WebOps/DevOps Engineer,"Norwell, MA",$63K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1044077&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_55b882e5&cb=1618160489264&jobListingId=4054836599,"Webops/DevOps EngineerCongruity360 is headquartered in the Boston metropolitan area with major offices in New York City, Los Angeles, and Belfast Northern Ireland. Candidates will be given opportunities to work on cutting edge machine learning (ML), natural language processing (NLP) and data modeling technologies as well as more common full stack development and UI/UX projects.The Congruity360 flagship product, Classify360, enables clients to reduce their financial and data risk by increasing their data understanding, classification, and security, allowing clients to meet all of the current, new, and changing laws, regulations, and business drivers. In other words, making intelligent business decisions.We have an immediate need for a talented Senior DevOps Engineer to add to our growing Classify360 engineering team. Please contact us immediately if you want to challenge yourself by working in a startup team within an established company.SUMMARY OF POSITION:Congruity360 is seeking an experienced DevOps Engineer for our market leading Classify360 SaaS solution who will work alongside development, design, UX, automation and operations in order to identify and eliminate constraints in the product life cycle. Bring your superior skills, expertise, and knowledge for deploying 100+ billion data record systems, and we will challenge you with exciting work!ESSENTIAL DUTIES AND RESPONSIBILITIES:Candidates will be expected to perform a variety of tasks, including:· Facilitate collaboration, sharing, and cross-pollination of skills with other engineers, product owners, designers, testers, and business units in order to overcome challenges, increase product quality, and optimize workflows.· Develop solutions encompassing technology, process and people.· Maintain strong expertise and knowledge of current and emerging processes, techniques and tooling.· Work closely with UX, design, development, automation and operations teams to ensure that solutions are designed with customer user experience, scalability, performance and operability in mind.· Effectively manage and assign projects as necessary while lending support to the team.· Actively troubleshoot any issues that arise during testing and production, catching and solving issues before they launch.· Stay current with industry trends and knowledge, always looking for ways to help business improve.· Deploy updates as required while implementing integrations when they arise.· Test our system integrity, implemented designs, application developments and other processes related to infrastructure, making improvements as needed.· Other duties as assigned.· Any other duties delegated by the Classify360 Development or Company management team.ORGANIZATIONAL RELATIONSHIPS:Candidate will report directly to the VP of Development and works with the Classify360 team resources and other Company teams as necessary.Qualifications· 4+ years of experience in DevOps, SRE, Software Development or an equivalent field.· A history of collaboration with development, operations, UX, design and business units within an organization.· 4+ years experience working with Azure. Also working with AWS is a plus.· Experience working with Jenkins. Other CI/CD tools and pipelines such as Buildkite, TravisCI, Concourse CI, or equivalent are a plus.· Experience working with Terraform. Other infrastructure tools such as Azure ResourceManager, AWS CloudFormation, or equivalent are a plus.· Experience working with Kubernetes. Other Docker and Docker orchestration tools such as Docker Compose are a plus.· Knowledge of version control software, Bitbucket is preferred.· Proficiency with Linux.· Excellent oral and written communication skills.· Azure certifications are a BIG PLUS. AWS certifications are a bonus.FUNCTIONAL SKILL REQUIREMENTS:Having any of the following industry and functional skills or knowledge would be a plus:· Information Governance (IG), records management, enterprise search, data classification, compliance, eDiscovery· GDPR, CCPA, and other privacy acts· Information security, data security, cyber security· Financial services, Healthcare, Pharmaceutical, Consumer Good industriesEDUCATIONAL AND EXPERIENCE REQUIREMENTS:A University degree is required with a major in Computer Science, Mathematics or Physics. Candidates must have 7-10+ years total technology related experience with 3+ in an actual DevOps role. Great communications skills, attention to detail, self-motivated, and the ability to work well with people are essential. Some minor inter-office travel may be required.Special notes:We are an equal opportunities employer. Please visit our website to review our diversity and inclusion statement. All considerations will be made on merit. Applicants should note that Congruity360 will complete AccessNI background checks on all candidates offered a position.Job Type: Full-timePay: $130,000.00 - $160,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offRetirement planVision insuranceSchedule:8 hour shiftApplication Question(s):Will you require visa sponsorship?Work Location:One locationVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobCompany's website:www.congruity360.comWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processVirtual meetings",bos,de
21,Massachusetts General Hospital(MGH),Health Care,4.1,Data Engineer,"Boston, MA",$77K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=25073&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_c1e8d0e4&cb=1618160489264&jobListingId=4057766836,"DATA ENGINEER, CENTER FOR PRECISION PSYCHIATRY

PROGRAM SUMMARY:

The Center for Precision Psychiatry is a new and dynamic interdisciplinary center that integrates research, clinical implementation, education and training to advance the emerging field of precision psychiatry. Precision psychiatry aims to identify and leverage individual differences in biology, lifestyle, environment, and the social determinants of health to improve the prevention, diagnosis and treatment of mental health conditions.

POSITION SUMMARY:

The successful candidate will have demonstrable professional experience in the design, implementation, integration, testing and deployment of backend software and systems, including software development in both team-based and independent projects.

PRINCIPAL RESPONSIBILITIES:

Develop, validate, test, document, deploy, and maintain clinical and research applications for precision psychiatry pathology. Applications may include but are not limited to data management systems analytics pipelines, and clinical reporting tools. Support data engineering efforts, including database and API design, data extraction/transformation/load, and data aggregation/integration.Support data science efforts, including computational statistics, machine learning, deep learning, interactive web-based visualizationSupport high performance computing efforts, including on-premise cluster computing, cloud computing, and Linux container orchestrationSupport data management, including big data storage on premises and in the cloud, life cycle management, archiving, security, and access controlMaintenance of local data/GPU workstations and server software environmentsManagement of user-account/data-privacy/security for the workstations and serversAssist group on medical data science projectsData preprocessing Software development with readable, testable code and good documentationTroubleshoot, debug and upgrade existing systemsEnsure software is updated with latest features

Qualifications

SKILLS REQUIRED:

Proven work experience as a Data Engineer or DeveloperProficiency in SQL Proficiency in setting up and maintaining GPU-capable workstations running on windows/mac/linux operating systems, and GPU-capable linux servers with K8S or SlurmKnowledgeable in statistics/machine learning theories and capability to implement in R and PythonKnowledgeable in common data science packages, such as R: tidyverse and Python: PANDAS, NumPy, Scikit-learnKnowledgeable in deep learning frameworks (preferably PyTorch) with capability to build, train and validate models end-to-endExpertise in computer programming and proficiency in at least one general-purpose programming language (Python, Java, Scala, C/C++, Go or equivalent, experience in Python strongly preferred)Knowledge of Unix/Linux-based operating systems and experience in shell scripting requiredExperience in designing RESTful APIs, architecting robust and scalable systems, and deploying and maintaining web services, including web server configuration (e.g., Apache, NGINX), message queues (e.g., RabbitMQ, Apache Kafka), microservice architectures, proxy servers, sidecar patternsExperience working in a software development team, including agile methodology, unit testing, continuous testing and integration, refactoring, code reviews, version control, release management, packaging, and distributionProven track record of delivering high-quality, production-grade softwareExperience with user interface and web development (e.g., JavaScript, React, HTML, CSS) a plusExperience with SQL as well as NoSQL databases and database management (e.g., PostgreSQL, MongoDB, Apache CouchDB, Apache Cassandra) a plusExperience with Linux containers and container orchestration systems (e.g., Docker, Kubernetes) a plusExperience with cloud computing a plusExcellent oral and written communication skills.Excellent interdisciplinary communication skillsEnthusiasm in healthcare related projects

QUALIFICATIONS AND EXPERIENCE:

BS/MS degree in Computer Science, Mathematics, Physical Sciences, Engineering, or related field

EEO Statement

Massachusetts General Hospital is an Equal Opportunity Employer. By embracing diverse skills, perspectives and ideas, we choose to lead. Applications from protected veterans and individuals with disabilities are strongly encouraged. Partner's Healthcare is acting as an Employment Agency in relation to this vacancy.",bos,de
22,Communications & Power Industries,Manufacturing,2.6,Software Test Engineer,"Beverly, MA",$68K - $84K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_3f40766b&cb=1618160489264&jobListingId=4058015955,"DescriptionWill collaborate with hardware engineers and manufacturing personnel to design and develop automated test equipment (ATE) software for data acquisition and product testing. Will write, debug, verify, and maintain ATE software using LabVIEW and legacy BASIC code. Will develop embedded control software. Will document software per established procedures.RequirementsBS degree in ECE preferred. BS degree in Computer Science acceptable. BS degree in Physics or EE with minor in CS or equivalent experience acceptable.One-year programming experience required. Co-op or internship experience acceptable.Familiarity with one of the following: Programming languages: LabVIEW, C/C++/C#, Java, JavaScript, Python, and BASIC. Database management system (e.g., MySQL), Microwave test equipment automation via DCOM and/or SCPI.Must be a U.S. Citizen and able to obtain/maintain a D.O.D. security clearance.",bos,de
23,Slalom LLC.,Business Services,4.3,Data Engineer,"Boston, MA",$52K - $101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=4470&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_d3582c61&cb=1618160489265&jobListingId=3798618403,"Who You’ll Work With

As a modernized technology company, our Slalom Technologists are disrupting the market and bringing to life the art of the possible for our clients. We have passion for building strategies, solutions and creative products to help our clients solve their most complex and interesting business problems. We surround our technologists with interesting challenges, innovative minds and emerging technologies.

What You’ll Do

Develop data platforms including data warehouses, analytic products, data lakes, ETL, ML models, or data pipelines with oversight. Understanding and follow coding standards, development patterns, data and privacy security standards, and produce documentation for use by business and IT stakeholders Profile data sources and develop ETL processes with knowledge of data modeling fundamentals, using both SQL and supporting ETL/ELT tools Execute against provided technical requirements for data solutions, including writing SQL and stored procedures for moving, integration, and cleansing data Work in collaborative agile structure and assist in defining and sizing user stories

What You’ll Bring

3+ years of data engineering and/or data warehousing experience 2+ years of experience building cloud data solutions (Azure, AWS, GCP, Snowflake) and migrating from on-prem to cloud Hands-on experience with big data application development and/or with cloud data warehousing (e.g. Spark, Redshift, Snowflake, Azure SQL DW, BigQuery) Proficient in a relevant programming language for cloud platform e.g. Python/Java/C#/Unix as well as SQL Strong communication skills and a working knowledge of agile development, including DevOps concepts Hands-on experience with BI solutions (e.g. PowerBI, Looker, Tableau, or other format for reporting) Working experience with both version control platforms, e.g. Git, and agile methodologies and supporting tools (e.g. Jira) Familiarity with data warehousing concepts, methodologies, and best practices (e.g. Incremental, SCD, Star Schema, etc.) Willingness to learn new things in, and out of, the data space

About Us

Slalom is a modern consulting firm focused on strategy, technology, and business transformation. In 39 markets around the world, Slalom's teams have autonomy to move fast and do what's right. They are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world's top technology providers. Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 8,000 employees. Slalom has been named one of Fortune's 100 Best Companies to Work For five years running and is regularly recognized by employees as a best place to work. Learn more at slalom.com.

Slalom prides itself on helping team members thrive in their work and life. As a result, Slalom is proud it invest in benefits that include: meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability. We also offer additional benefits such as a yearly $350 reimbursement account for any well-being related expenses as well as discounted home, auto, and pet insurance.

Slalom is an equal opportunity employer that is committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veterans status, or any other characteristic protected by federal, state, or local laws. 

﻿#LI-ES2 #LI-LK1",bos,de
24,Intone Networks,Information Technology,4.4,Data Engineer,"Boston, MA",$59K - $108K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_78dbf024&cb=1618160489265&jobListingId=4029515324,"MUSTS: * 5+ years of in-cloud technologies including cloud databases and ETL tools * 2+ years of experience in building data pipeline with cloud ‘big data’ technologies (prefers AWS Glue, and/or DataBricks) * Experience manipulating data sets through commercial and open source software (e.g. Redshift, Snowflake, Spark, Python, R, Databricks) * Working knowledge of medical claims data (ICD-10 codes, HCPCS, CPT, etc.)",bos,de
25,Casa Systems Inc,Telecommunications,3.2,Corporate Senior Systems Engineer - Wireless,"Andover, MA",$94K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1044074&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_6a9a6a6c&cb=1618160489265&jobListingId=4054333982,"Casa Systems, Inc. (Nasdaq: CASA) is 5G, delivering physical, virtual and cloud-native 5G infrastructure and customer premise networking for high-speed data and multi-service communications networks. Our core and edge convergence technology enables public and private networks for both communications service providers and enterprises. Casa Systems™ products deliver higher performance, improved network flexibility and scalability, increased operational efficiency and lower total cost of ownership (TCO). Commercially deployed in more than 70 countries, Casa serves over 475 Tier 1 and regional service providers worldwide. At Casa Systems, our mission is to deliver ultra-broadband solutions that keep families, communities and the world connected. We harness our passion for innovation to drive technological solutions that allow service providers to do amazing things that improve the way we live.We are seeking to hire a Corporate Senior System Engineer (WIRELESS) to join our growing team based at our corporate headquarters in Andover, MA which is located about 30 minutes north of Boston, MA, USA.The Corporate Senior Systems Engineer will have significant impact as the technical voice of our customer ensuring the pre-sales development end of our product lifecycle management process and customer requirements are developed and road mapped in Casa Systems’ products involving 4G/5G cloud and virtualization solutions. The role includes supporting customer trials, demonstrations, POCs, and third party IOT’s for Casa’s containerized and virtualized 4G/5G access and core network products.ESSENTIAL DUTIES & RESPONSIBILITIES:Subject matter expert in the area of cloud and virtualization infrastructure and mobile solution integration and deployment.Partner with the sales team to drive orders by providing innovative network solutions for new business.Obtain customer requirements and translates these into a (customer specific) solution design and/or Casa offer.Support and drive lab testing for new business opportunities.Validate, integrate and deploy third party products/tools for Casa product solutions and deployment.Able and willing to perform lab trials along with presales activities.Create and develop technical white papers, MOPs, and ATPs.Design, build and maintain cloud and virtualization infrastructure.Validate and document CI/CD infrastructure and MOP for product release build, validation and deployment.QUALIFICATIONS:Undergraduate degree in Computer Science, Electrical Engineering or Telecommunication.7+ to 10 years of relevant experience in network engineering or support environment. Advanced degree strongly preferred.Experience and technical knowledge with 3GPP GPRS/UMTS/LTE/5G core network architectures.Advanced IP internetworking and Linux knowledge.Experience with containerized and virtualized application deployment.Experience with Kubernetes, AWS, Google Cloud, Rancher, OpenShift and OpenStack.Deep understanding of cloud-native architecture.Able to quickly learn new technologies, as required.Able to work in a team oriented, fast-paced environment.Creative and self-motivated.Excellent problem solving, troubleshooting and diagnostic skills.Able to pass background check and drug testing.Able to live Casa’s core values: fun work environment, innovation & risk taking; passion, dedication & perseverance; and honesty & loyalty.Casa Systems, Inc. offers a great work environment, professional development, challenging careers, and competitive compensation. Casa Systems, Inc. participates in the E‑Verify program. Casa Systems is committed to fostering a diverse workforce and inclusive work environment free from unlawful employment discrimination and without barriers to Equal Employment Opportunity (EEO).#LI-JM1HP123Required SkillsRequired Experience",bos,de
26,Thermo Fisher Scientific,Biotech & Pharmaceuticals,3.8,Data Engineer,"Boston, MA",$92K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=133879&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_defcfc99&cb=1618160489265&jobListingId=4057984007,"The Data Engineer role will support the Thermo Fisher Scientific Pharma Services Group to leverage Data Analytics and Data Science to drive profitable growth. The role will report to the Director, Digital Marketing Operations, and will be challenged to support and develop new analytic capabilities for a wide variety of marketing projects.Key Responsibilities:Lead data collection, integration, clean-up, and validation from multiple sourcesBuild robust, efficient and reliable data pipelinesCollaborate with analytics and data science teams to deploy and improve data science models, increasing data accessibility and quality, fostering data-driven decision making, and driving adoption of digital transformation within the organizationImplement processes to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on itPerform data analysis required to troubleshoot data-related issues and assist in the resolutionsDesign databases and pre-process data sets, enabling business to perform sophisticated business analytics efficiently and accurately, with ability to scale across regions and business unitsDevelop, automate, and scale data analytics for business KPIs and key business initiativesCreate dashboards and regular report-out to measure business performances, including promotion effectiveness, share gain, customer acquisition/retention, up sell and cross sell, etc.Identify business problems and areas of opportunities and translate business needs into quantitative analyses that enable business to uncover patterns and insightsWork with business partners to ensure prioritization in line with strategic initiatives and set goals to track progress on a regular basisCollaborate with division and corporate analytics and data science teams to leverage machine learning models to experiment data science within the organization; support feature engineering to optimize model performancesWork closely with data science and data engineering teams to develop strategy for long-term data platform architecture within the organizationMinimum Requirements/Qualifications:BS or MS Degree in computer science, data science, analytics, statistics, applied math or related field5+ years’ experience of performing data integration, pipeline development with data warehousingExperience in manipulating / managing large, complex, and unstructured databasesProficiency in Python and common Python librariesExperience with databases (Oracle, SQL Server, PostgreSQL, Redshift, MySQL, or similar)Experience creating data visualization tools using Tableau or Power BIFamiliarity with Databricks, AWS, or other cloud-based machine learning platformsExcellent written and oral communication skills, including an ability to communicate across audiences with varying technical and business backgroundsAbility to think critically and solve problems that are in line with strategic business objectivesPerforms other duties as assigned by managerKey Success Factors:Strong organizational and communication skills, and proven ability to adapt style to different situations and peopleMust be a business partner, not merely a technical expert – this position plays an active role providing actionable insight across Pharma ServicesStrong analytical skills – and ability to use those skills to influence and drive changeExcellent interpersonal and communication skills (both verbal and written)Ability to interact professionally with a diverse group including VPs, directors, managers, subject matter experts and end-usersSelf-motivated with a bias for action",bos,de
27,McGraw Hill,Education,3.8,Data Engineer,"Boston, MA",$95K - $174K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_03b067b1&cb=1618160489265&jobListingId=4000798266,"Build the FutureDo you enjoy testing the limits of possibility? At McGraw Hill, our Data Integration team drives progress and helps build the future of learning. If you have the passion and technical expertise to thrive in an innovative and agile environment, we want to learn more about you.Your impact on the teamAs a Data Engineer, you will help drive the design and development of highly scalable enterprise data processing and data warehouse use cases deployed on AWS for our core analytics and data science platform. You will create, own, manage, share support of, and drive best practices for a variety of existing and emerging data intensive applications.The Data Integration team is part of our Digital Platform Group, which is responsible for building and supporting innovative digital platforms to power learning across K-12, Higher Education, International, and Professional segments. As part of this group, the Analytics and Reporting team is building best-in-class applications which leverage data and machine learning for advanced analytics and adaptive learning products. If you are interested in contributing to the future of digital and remote learning, join us on this mission!What can you expect from the position?Contribute to complex solution designs, hands-on software development goals, new tool and framework creation, and code reviews.Identify gaps and proactively improve system service level agreements.Provide technical knowledge sharing and coaching to engineers on the development team.Work effectively with Technical Product Management and SCRUM masters to meaningfully contribute to our agile team.What can you bring to the role?At least 5 years of experience with ETL data processing concepts with full implementation cycle experience in enterprise data marts, including advanced SQL development skills.At least 3 years of Architecture and Optimization experience for database systems technologies with a focus on data marts and data warehouses.Having coding experience with a modern development language (Scala, Python, Java).Experience with Apache Spark.Strong understanding of data modeling concepts, including schema development, validation, and evolution (normalized and denormalized).Experience with performance tuning and scaling production databases.Experience with agile engineering practices.As an education innovation company, we're proud to play our part by inspiring learners around the world. If you bring your curiosity, we'll help you grow in a collaborative environment where everyone shares a passion for success.Are you ready for a new challenge? Apply for a career at McGraw Hill and together, we'll impact the world.Other LocationsUnited States-New York-New York",bos,de
28,Harvard University,Education,4.3,Data Engineer,"Cambridge, MA",$69K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1136006&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&cs=1_3e15c981&cb=1618160489266&jobListingId=4054164555,"Job SummaryPlan and conduct comprehensive applications/web development for complex projects; typically work as part of a team to implement complex business solutions. Perform expert coding: design, develop code at an expert level, and manage development projects, teams, programs. May manage multiple projects simultaneously.Job-Specific ResponsibilitiesPlease note: This is a two-year term position with the possibility of renewal dependent upon business need and continued funding.The Data Engineer is a member of the Office of the Vice Provost for Advances in Learning Data Science and Technology team, reporting to the Sr. Data Engineer & Manager of Analytics. Working with a team of Software Engineers, Data Engineers, and Data Scientists, they will support our mission of improving teaching and learning across the University by building innovative software in support of learning management systems (LMS) and cloud data platforms.The Data Engineer will be responsible for designing, testing, deploying, and maintaining software, including web applications, learning platforms, APIs, daily ETL data operations, infrastructure, and data analytics dashboards, to enhance teaching and learning experiences for students, faculty, and staff. They will explore, test, and evaluate new technology stacks and approaches to data architecture to improve the efficiency and stability of the data pipeline developed by this office. This role will require expertise in automating and debugging operations across a complex data pipeline’s entire lifecycle.The Data Engineer will work closely with technology partners, including Harvard University Information Technology, and other entities across Harvard University, to define stakeholder requirements, design re-usable software, and deploy stable code. They will need to prioritize technical tasks within larger projects, requiring coordination with multiple partners.This person will also be a liaison and member of the technical community that will define and implement the next generation of software systems for teaching and learning for online and mixed online and residential courses. At times, such coordination will require the Data Engineer to lead meetings with other technical professionals across the University and beyond.Responsibilities include:Design and build scalable data pipelines and pipeline architectureWrite automation to provision, manage, and monitor cloud computing resourcesDesign schemas and manage SQL databases, document stores, and data warehousesDeploy and monitor pipeline orchestration toolsDevelop APIs to support public-facing web applicationsCollaborate with engineers and data scientists to design and implement machine learning workflowsIdentify ways to scale, optimize, and refactor existing tools and workflowsWork with stakeholders to design data products, assemble data sets, ensure data quality, and deliver meaningful and interpretable reportsWrite documentation and technical specifications for systems and data productsTypical Core DutiesParticipate fully in software development life cycleResearch, design, and implement technical solutions to deliver business requirementsIdentify opportunities to improve and simplify applications portfolio and implement related enhancementsContribute to creation and maturing of software development best practices and new technologiesDraw on relationship and technical skills to act as technical liaison to internal and external clients and to mentor junior staffAbide by and follow the Harvard University IT technical standards, policies and Code of ConductBasic QualificationsMinimum of five years’ post-secondary education or relevant work experienceAdditional Qualifications and SkillsStrong Python programming skills and a passion for writing clean codeAn interest in using data to build learning tools and education technologyDeep understanding of data pipeline/ETL processes and relevant technologies for automation and orchestration (e.g. Airflow, Prefect)Experience provisioning and managing cloud computing resources with AWSExperience with infrastructure-as-code and infrastructure automation technologies (e.g., Docker, Terraform, Cloudformation)Solid understanding of SQL, relational databases (e.g. PostgreSQL) and schema designExperience with tools for analyzing big data (e.g. Spark, Dask)Experience designing and documenting REST APIsExcellent project management and organizational skills(bonus) Experience with NoSQL databases and document stores (e.g. Elasticsearch)(bonus) Experience with GraphQL(bonus) Experience with stream processing and message queueing systems(bonus) Experience with data warehouses/data lakesCertificates and LicensesCompletion of Harvard IT Academy specified foundational courses (or external equivalent) preferredWorking ConditionsWork is performed in an office settingAdditional InformationPLEASE NOTE: During the current period of Covid-19 related restrictions, this position may start as a remote position, with the transition to onsite in Cambridge when the office reopens.We continue to monitor the evolving COVID-19 and the lifting of restrictions. We appreciate your understanding and flexibility with our interview process. We will be conducting interviews virtually for selected candidates until further notice.IMPORTANT NOTE: Your cover letter and resume should be submitted as a combined into a SINGLE DOCUMENT under the resume tab. Cover letters are requested for this role.Harvard University offers an outstanding benefits package including:A creative, high- energy, collaborative environmentGenerous Vacation, Sick, Personal, and Holiday payMedical, Dental and Vision benefits starting on your first dayUniversity-funded retirement plansTuition Assistance ProgramTransportation benefits to help with your daily commuteHealth and wellness discounts, memberships and programsAdditional benefits can be found at https://hr.harvard.edu/totalrewards.Please note: This is a two-year term position with the possibility of renewal dependent upon business need and continued funding. We will be filling two positions.Harvard University requires pre-employment reference and background screening.VPAL is unable to provide work authorization and/or visa sponsorship.VPAL OrganizationThe mission of the Office of the Vice Provost for Advances in Learning (VPAL) is to create and catalyze engaging and scalable learning experiences that make a difference at Harvard and beyond.VPAL partners with schools and faculty to amplify Harvard’s impact worldwide. We deliver online courses on multiple platforms in the spirit of satisfying the widest possible range of student needs and interests. Our courses support both lifelong and professional learning, which compliments many other One Harvard initiatives related to online teaching and learning.Job FunctionInformation TechnologyLocationUSA - MA - CambridgeJob CodeI0758P Applications Professional IVSub-UnitInterfaculty InitiativesDepartmentVPALTime StatusFull-timeSalary Grade058Union00 - Non Union, Exempt or TemporaryPre-Employment ScreeningEducation, IdentityScheduleFull time. Monday through Friday. 35 hours per week.EEO StatementWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",bos,de
29,Validity,Information Technology,3,Sr. DevOps Engineer,"Boston, MA",$103K - $167K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1184999&s=58&guid=00000178c1e1900fbfb9a276f15d816e&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b990e542&cb=1618160489266&jobListingId=4000258326,"About the Role

We are growing our Core Engineering (DevOps) team to meet the challenges of a rapidly growing and changing SaaS company. We are looking to expand our capability to maintain, optimize and evolve our AWS-based cloud operations for our SaaS products.

Our mission is to maintain rock-solid stability and reliability for our customers while making development and management of the environment as easy as possible for our colleagues at Validity. We aspire to follow the SRE/DevOps methodologies and best practices of distinguished tech industry leaders while making the appropriate choices for our organizations scale.

We are looking for an experienced engineer who is confident with cloud infrastructure and code pipelines. In addition to becoming deeply familiar with core tools and technology, they will need to build broader familiarity with a wider set of technologies in the environment. We expect them to own projects and help guide the evolution of our platforms.

Team Dynamic

We support a complex environment that has grown rapidly through mergers and acquisitions. We host applications written in-house, purchased commercially, and from the open-source community. No two days are the same here. This gives our team the opportunity to develop great hands-on experience with many exciting technologies such as Linux, AWS, Docker, and Kubernetes.

Position Duties and Responsibilities

Maintain and optimize our AWS cloud footprint, Kubernetes clusters, SaaS accounts, CI/CD systems, and other platforms. Focus on resiliency, scalability, maintainability, security, and cost.Empower our colleagues on software development teams to use the above services effectively by providing support and documentation. Participate in 24/7 on-call rotation. Provide critical support towards the unplanned work needs of the organization. Triage incidents effectively. Research/develop/deploy creative (but practical) technical solutions to our problems. Use the tools available to us to save the company time and money. Take ownership of longer-term projects. Share your experience and perspective with the Core Engineering team to guide major architectural decisions.Provide subject matter expertise in the DevOps niche we fill in the organization. Collaborate with business application development, DBA, QA, SecOps, corporate IT, and customer-facing services teams as needed. Steer organization towards best practices.

Required Experience, Skills, and Education

A passionate engineer with 4+ years of experience in open-source system administration/operations and software development lifecycle in a public cloud-hosted environment. Post-secondary degree in a technical field such as Computer Science, Management of Information Systems, etc., OR demonstrated equivalent practical experience in the industryFirst-hand experience designing, building, and operating platforms for containerized microservices applications. Understands key challenges in this space. (Most of our production software runs in Docker on Kubernetes.)Expertise with infrastructure as code and configuration management systems (Terraform/Cloudformation/Ansible etc.). Strong understanding of CI/CD pipelines, modern SDLC (GitHub, Jenkins, CircleCI, etc.)Expert Linux system administration skills and understands TCP/IP networking and securityProficient in scripting languages (Bash/Python) and data structures (YAML, JSON, XML, etc.) in the context of templating and automation.Experience implementing and using monitoring/tracing/alerting/observability tools. (Prometheus, Grafana, Datadog, New Relic, PagerDuty, etc.) Excellent troubleshooting skills with a detective mindset. Does not give up on a problem, exhausts all effort and resources to resolve a difficult technical problem. Comfortable operating in a very complex technical environment.Excellent communication and collaboration skills. Validity and the Core Engineering team are distributed across the world. Remote work skills will be critical for this position for the foreseeable future.

Preferred Experience, Skills, and Education

Relevant certifications in DevOps/SRE, AWS, Kubernetes, Docker, Security, Networking, etc.Advanced programming skill in languages like Go, Python, Ruby, JavaExperience working in Agile/SCRUM/Kanban project management environmentDatabase administration/analyst skills (transactional and/or no-sql) skills (Postgres, Mysql, Kafka, Etcd, Zookeeper, Clickhouse, Snowflake)Information security/SecOps skills or experience. (PKI, SSL/TLS, secrets management experience)Experience with auditing/compliance/regulated environments (SOC2, PCI, HIPAA, etc)Understanding of email deliverability concepts (SPF, DKIM, DMARC, public IP management)

Benefits

MedicalDentalVisionPaid HolidaysUnlimited PTOParental Leave

Pay Range: $120,000 - $150,000 base, plus up to 10% bonus opportunity, and stock options.

Final salary may vary depending on skills, location, and/or experience.

This position can be in office/remote, hiring in the following states only:

AL, AR, AZ, CA, CO, CT, FL, GA, HI, ID, IL, IN, KS, KY, MA, MD, ME, MI, MO, NC, NE, NH, NJ, NV, NY, OH, OK, PA, RI, SC, TN, TX, UT, VA, VT, WA

About Validity

For over 20 years, tens of thousands of organizations across the world have relied on Validity solutions to target, contact, engage, and retain customers – using trustworthy data as a key advantage. Validity’s flagship products – DemandTools, BriteVerify, Return Path, Trust Assessments, and GridBuddy – are all highly rated, #1 solutions for sales and marketing professionals. These solutions deliver smarter email campaigns, more qualified leads, more productive sales, and ultimately faster growth.

Validity is a truly unique company - massive revenue growth, top-tier investors, 5-star product ratings, proven ability to acquire and integrate top tech companies and welcome them into the Validity family, winning culture, and a work environment that fosters hard work, trust, and fun.

Headquartered in Boston, Validity has offices in Tampa, Denver, Indianapolis, London, and Sydney. For more information, visit connect with us on LinkedIn, Instagram, and Twitter.

Validity is proud to be an equal opportunity employer. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, or veteran status.

Powered by JazzHR",bos,de
88,Cogo Labs,Information Technology,3.1,Senior Software Engineer,"Cambridge, MA",$125K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1056671&s=58&guid=00000178c1e3d25b8f517bb0544fd7bf&src=GD_JOB_AD&t=SR&vt=w&cs=1_c9d47e6e&cb=1618160637236&jobListingId=2728737752,"At Cogo Labs, we build startup companies from scratch.

We're not venture capitalists. We're a collaborative team of engineers, analysts, and entrepreneurs using innovative tools, big data, and intellectual curiosity to build a platform that spins up successful online businesses, fast.

As a Senior Software Engineer, you will be tasked with guiding a cross-functional team of engineers on high-swing and big impact projects such as building new APIs, services, and libraries that our new startups depend on to grow their businesses. Your passion for mentoring others and innovative technology will be put to the test as you work to help your users make use of the tools and services you build and support and be a leader in fostering best coding practices. Plus you'll get hands-on experience writing new systems in Go, working in Docker and Kubernetes, and working with our state of the art computer and storage systems, meshed with cloud services.

What to expect from Cogo:

Near obsessive use of data to inform business decisions. We believe that efficient growth happens when we make every decision based on solid, well directed analysis.
Unmatched opportunity. We believe in mentoring people to grow as quickly as they can. Today's new grad hires are tomorrow's trail blazers.
Flexibility and novelty. Your role will define itself over time, as you identify the problems that you are uniquely capable of solving.
A fun, supportive culture. Happy employees are the most successful. We take care of our own, and not just because it's good business.
The ability to take big swings. We are a successful company today due to the great ideas that have been generated and executed by our phenomenal Cogo team.

About you:

Have 4+ years of professional programming experience and a BA/BS in CS
Are knowledgeable in at least two of the following: Go, Python, Java or C
Curious and passionate about architecting and building highly scalable, distributed systems
Organized, detail-oriented, and always follows through on things that need to get done
Outgoing and enthusiastic about taking on challenges
Comfortable working in a dynamic, agile, team-oriented environment

If you're reading this and questioning whether you should apply, apply! There's no such thing as a perfect candidate, and we don't expect you to check every box. We're inspired by the uniqueness that people like you bring to the table. The companies that we incubate are only as innovative as the breadth of lived experiences shared by the teams building them. We can't wait to read your application!

Cogo Labs is an equal opportunity employer and individuals seeking employment with us are considered without regards to race, color, religion, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by law.

Cogo Labs Leadership Principles

1. Take Big Swings

Thinking small is a self-fulfilling prophecy. Leaders strive to spend their time exclusively on what's important, and they shed the rest. They seek out the highest return on their team's time and effort.

2. Data Driven

Leaders work backwards from the solution to generate plans. They use data to be sure their time and effort are always leveraged at the most impactful work. They admit when they are wrong and use the data to eliminate their blind spots.

3. Make Moonshine

Leaders create value from spare and under-utilized parts. They're resourceful and tenacious. They expect and require innovation and invention from their teams, and they find ways to simplify. They are situationally aware; they look for good ideas from anywhere.

4. Insist on the Highest Standards

Leaders keep the standards relentlessly high. They demand high quality products, services, and processes because they deliver high quality products, services, and processes. Leaders solve root problems and ensure that when problems get fixed, they stay fixed.

5. Bias for Action

Leaders run everywhere they go. Many decisions and actions are reversible and don't need extensive study. Leaders value calculated risk taking because they know that in business, speed wins.

6. Have Integrity; Earn Trust

Leaders listen attentively, speak candidly, and treat others respectfully. They are vocally self-critical, even when doing so is difficult or embarrassing. Leaders are not arrogant. They benchmark themselves against the best and identify their gaps.

7. Hire and Develop the Best

Leaders raise the bar with every hire and promotion. They want to work with other leaders. They recognize exceptional talent and enthusiastically propel them throughout the organization. Leaders are serious about their role in coaching others.

8. Ownership

Leaders think long-term and don't sacrifice long-term value for short-term results. They own all the inputs to their business. They act on behalf of the entire company, beyond just their own team.

9. Disagree and Commit

Leaders respectfully challenge decisions when they disagree, even when doing so is uncomfortable or awkward. They have conviction; they do not compromise in the name of social niceties. Once a decision is reached, they commit wholly.

10. Dive Deep

Leaders operate at once with immense perspective and granular detail. No task is beneath them. They audit frequently, and they are skeptical when metrics and anecdote differ.

11. Deliver Results

Leaders focus their time on the key drivers for their business. They pursue them obsessively to deliver results with the right quality and in a timely fashion. They rise to the occasion and never compromise.",bos,de
0,KPMG,Business Services,3.9,"Technical Manager, Big Data Engineering","Chicago, IL",$52K - $114K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178c1e798d495c72966e376e84f&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_0cd53e26&cb=1618160884734&jobListingId=3795598425,"Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today’s most important industries. Our growth is driven by delivering real results for our clients. It’s also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it’s no wonder we’re consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you’re as passionate about your future as we are, join our team.KPMG is currently seeking a Technical Manager, Big Data Engineering to join our Digital Nexus technology organization.Responsibilities:Provide technical management for all phases of the system development and implementation process including analysis, design, development, testing, and ongoing support for the client area application systems in an environment of diverse and complex development platformsResearch and evaluate alternative solutions and recommend the most efficient and cost-effective solutions for the systems design, while providing a solution that meets the business’ strategic objectives; include the integration of existing code-sets and/or components as part of the overall design solutions where practical; continually optimize the data pipe with automation, and tools with the latest DevOps and Agile methodologies to improve cycle times, consistency, and qualityDesign and develop multiple, diversified data applications using big data platform leveraging hybrid clouds; applications are primarily consumed for parsing, analyzing, discovering, and visualizing the potential business insightsWork with critical data stakeholders and technical teams for optimal solutions and service delivery; provide strategic, tactical direction in the delivery of big data solutions; work with various cross functional teams such as infrastructure, data and enterprise architects to build scalable, optimal, self-service analytics solutions, both on premise and in the cloudConduct data profiling, cataloging, and mapping for technical design and construction of technical data flows and apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integrationProvide end to end technical ownership and delivery for data supply chain, which includes, Enterprise Data Lake (on-prem & cloud), Data quality and Enterprise Data WarehouseQualifications:Minimum five years of experience in application development, integration and support including leadership roles as a Developer and/or a Project ManagerBachelor's degree from an accredited college or universityPrevious experience should include responsibility for other developers (both onshore and offshore), interfacing with clients and vendors, creation of project schedules and project status reportingHands on experience in architecting and implementing end to end Azure cloud big data solutions, as well as with implementing Real-time Solutions and data integrations; Big Data Management Tool (Zaloni) is a plus; experience in large scale data warehousing implementations and high performance ETL tools is requiredPrior knowledge with building, optimizing the data pipe – CI/CD, integrated - build and deployment automation, configuration management, test automation solutions; in-depth experience with Hadoop, HIVE, HBase, Spark, Kafka, Snowflake, Python, R, SQL, Java, Scala, Zeppelin, RStudio, Spark RDDs and Data Frames, Ambari, Ranger, Kerberos, Atlas and CollibraStrong understanding of Azure Cloud Stack including ADF Data flows, Event Hub, Databricks, HDInsight, SQL Server, Azure DevOps; Professional training and certifications in various big data solutions is preferredKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.",chi,de
1,Ursus,Information Technology,4.4,Senior Data Engineer,"Chicago, IL",$148K - $169K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000178c1e798d495c72966e376e84f&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_41c1fb34&cb=1618160884735&jobListingId=4029522628,"Job Title: Senior Data EngineerLocation: Chicago, ILDuration: PermanentSummary:Come join one of the prominent investing and trading organizations and work on their brand new trading platform.Responsibilities:Collaborating with trading and technology teams on trading strategy, creating applications for both individual traders as well as more robust applications for broader scale use across the entire firm.Owning execution of key initiatives that align with strategic business plans.Providing influence and critical inputs into strategic business plans and trading application architecture.Owning the full product development lifecycle of critical tools that enable trading and firm portfolio management.Ensuring quality and correctness of applications through automated testing as well as manual interaction with the products.Monitoring applications in production for performance and effectiveness, always looking for areas to improve the user's workflow.Optimizing and monitoring critical path performance.Qualifications:Must have proficiency in Python. Any modern JavaScript framework, Go or Java is a nice to have!Experience building full-stack Python based applications. Ideally with some exposure to using a modern JavaScript framework on the front end.Experience with some combination of the following Python libraries; Pandas, NumPy, PyArrow, Scikit-learn, or Tensorflow.Bachelors or Masters Degree in Computer Science, Engineering, or related.8+ years of software development, with some trading or finance industry experience.Familiarity with Linux platformIND123",chi,de
2,"Vizient, Inc.",Health Care,4.2,Software Engineer - ETL,"Chicago, IL",$40K - $86K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_9388b5d0&cb=1618160884735&jobListingId=3657659771,"When you’re the best, we’re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance now and in the future.Summary:In this role, you will develop high-quality software products for Vizient utilizing ETL data processes. You will work with a team of business and technical professionals to better understand the various platform applications and multiple ETL solutions.Responsibilities:Design, develop, enhance, code, test, deliver and debug software independently.Work on larger, more complex or new stories for solution development.Play an active role in story break-up and grooming.Collaborate with others to story completion and participates in architecture/design sessions.Accomplish training requirements and follow established procedures.Utilize applicable tools and technologies in accordance with existing standard operating procedures and framework.Stay up to date on technical trends and emerging technology.Qualifications:Relevant degree desired. Bachelor's degree in Computer Science, Math, or Engineering preferred.2 or more years of relevant experience required.Must have experience developing software and be able to write complex SQL Queries.Experience with ETL solutions using Azure SSIS is strongly preferred.Experience with front end JavaScript development is desired with a preference for Angular.Strong expertise in RDBMS (MS-SQL Server / Oracle) concepts is desired.Experience working in an Agile based development environment, using concepts such as Continuous Integration, TDD, and Paired Programming preferred.Experience utilizing Hadoop Fundamentals desired.#LI-BH#IDSEstimated Hiring Range:$66,500.00 - $96,500.00This position is also incentive eligible.Vizient has a comprehensive benefits plan! Please view our benefits here:http://www.vizientinc.com/about-us/careersEqual Opportunity Employer: Females/Minorities/Veterans/Individuals with DisabilitiesThe Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.",chi,de
3,C&W Services,Business Services,3.3,Reliability Engineer,"Markham, IL",$64K - $100K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044077&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_cdce7b58&cb=1618160884735&jobListingId=4053780014,"Reliability Program ManagerReliability, Maintenance, and Engineering (RME) is hiring for Reliability Program Managers!At Amazon we believe that Every Day is still Day One! We’re working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright and driven people.The Reliability and Maintenance Engineering team plays a vital role in our operational success in the distribution aspect of the business. Being able to identify risk of equipment failure and eliminate the presence of that risk is what our organization strives for. Seeking a proactive reliability program management and leadership role for fulfillment center operations, focusing on maximizing life, reliability and operational performance of equipment such as conveyors, sortation systems, scanners, cameras, robotics, print and apply systems, and SCADA devices and programsDUTIES AND RESPONSIBILITIESCoordinate and plan work activities for the inventory control and maintenance planning technicians to accomplish goals and objectives of North America Customer Fulfillment teamsAct as first level escalation support for the inventory control and maintenance planning technicians during and after business hours ensuring spares and computerized maintenance system support is available.Work closely with FC Operations, Operations Engineering, FC Start up Team, RME Reliability Team, Central Planning, ACES team, and Safety in supporting building systems optimization, maintenance and project implementationMonitor equipment reliability metrics and partner with the operations team to prioritize work and improvements.Lead the Root Cause Analysis and Permanent Corrective Action activities at the site.Identify opportunities to increase equipment reliability and uptime, reduce costs and associated work.Make full use of condition-based and predictive maintenance tools to avoid unplanned repair work.Assist with skill assessments for the Technical positions within NACF Maintenance teamsHandle flexible work load which may come from management or FC operationsParticipate in reliability conference calls and coordinate with reliability central team to complete all tasks requiredServe as the primary conduit for both upward and downward communication with the Central Reliability Team to both feed up information and data to help drive local and network change while also disseminating and driving reliability efforts and programs downward to local your teamsDrive and promote safety culture within the site including subcontractors, suppliers and visitorsProvide engineering guidance to Technicians as needed to ensure maintenance goals are aligned with site operation’s needs.Manage subcontractors and suppliers to deliver goods and services against contracts and expectationsSupport the Maintenance Manager in the implementation of short and long-term projects for the site as requestedDevelop a strong collaborative team-based environment.Perform regular deep dives/data analysis to understand key focus areas for improvement across facilityDeploy, manage, and improve predictive maintenance program, including Thermography, Vibration, and Ultrasound technologiesCreate, deploy, and share best practices at facility and share with other sitesLead continuous improvement events and generate cost savings that exceed site performance goalsBASIC QUALIFICATIONSBachelor’s degree in Electrical or Mechanical Engineering, Engineering Technology, Reliability Engineering or other related engineering OR 2+ years of Amazon experience.5+ years of experience as a Reliability Program Manager or equivalent5+ years of experience with team management, budget responsibilities, supplier management, problem solving, and client/ customer relationsExperience required using CMMS systems and reportingExperience with computers, including MS Excel, Word and OfficeRelevant training in MHE, Controls Systems, PIT as well as general building operationsExperience in project managementExperience with leading and delivering technical trainingUnderstanding of Lean Manufacturing tools such as:5S5YFMEAPDCAValue Stream MappingDMAICRun ChartsPareto AnalysisPREFERRED QUALIFICATIONSStrong communication and presentation/facilitation skillsStrong analytical skills to deep dive into dataAbility to turn complex compliance requirements into scalable processesStrong organizational skillsAbility to align, motivate and lead a team including creating accountabilityPrefer experience managing teams in an industrial environment containing conveyance, process control and powered trucks.Demonstrated communication skills written and verbal including negotiation and conflict resolutionAbility to lead others in a technical role and interact with all levels of management.Reasoning, analytical and problem solving skills.Ability to train others with lesser skillsAbility to interpret and understand policies and procedures and relate them to others.Field service engineering experienceExperience supporting a wide range of different conveyors and sortation systemsAbility to develop and maintain a partnership and communicate effectively, both in writing and verbally with Safety, Operations, Engineering, Sr. Management, peers, contractors and vendorsAbility to multitask and prioritize many different projectsSix Sigma certification from accredited programRoot Cause Analysis formal training and facilitation experiencePMP certificationElectrical and electronic principlesBlueprint and electrical schematic readingExperience in usage of CMMS programs in support of RCA projectsPreventive maintenance proceduresIndustrial electricalIndustrial controlsIndustrial electronics & roboticsAbout C&W Services: A leader in facilities services with over 65 years of experience. C&W Services is one of the largest facility services companies in the USA & Canada with a 65-year history of helping clients drive down operating expenses, increase facility efficiency and up-time, enable strategic business decisions and create positive experiences for the people who work, shop, learn, live and play in the facilities we maintain. We’re building the best team in the industry – our people are the heart and vitality of C&W Services. In joining C&W Services, you’re joining a firm with a rich history, blue-chip client list, and the backing of sister company Cushman & Wakefield, one of the world’s largest property advisory firms and the reason for our success is simple: talented people.C&W Services is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, sexual orientation, gender identity, protected veteran status or any other characteristic protected by law.Job Type: Full-timeBenefits:401(k)Dental insuranceHealth insurancePaid time offWork Remotely:No",chi,de
4,Fresenius Kabi,Manufacturing,3.6,SR VALIDATION ENGINEER,"Melrose Park, IL",$45K - $79K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_23890da0&cb=1618160884736&jobListingId=4000532386,"Job SummaryWe currently have an opportunity for a Sr. Validation Engineer in our Melrose Park Pharmaceutical Manufacturing facility who will provide technical support to operations with equipment/system/process initial validation and equipment/system/process requalifications. Weekends and Off-shift hours are periodically required.ResponsibilitiesSchedules and executes equipment requalifications per Standard Operating Procedures (SOPs). Coordinates and communicates all testing with affected functional groups and evaluates test results. Assembles and composes the final report and circulates for approval.Executes validation studies (utility, equipment, cleaning, process, computer, and new products) to include protocol preparation, scheduling, protocol execution, and final report preparation. Presents results to Regulatory Agency when necessary.Programs and operates department analytical instruments (such as temperature/humidity dataloggers) to perform controlled temperature/humidity chamber qualifications (examples lyophilizers, warehouses, sterilizers, incubators, etc.).Develops/improves validation programs as needed to remain current with cGMPs and industry standards.Schedules and executes HEPA Filter and Critical Area (Class 100) testing per SOP. Programs and operates test equipment such as smoke generators, photometers, velocity meters, etc., ; records and evaluates results.Represents Technical Services in teams assembled to specify, install, validate, troubleshoot and maintain systems, equipment and processes.Conducts and/or participates in deviation investigations to identify root causes and define corrective and/or preventative actions (CA/PA).Maintains and constant improvement of the ISO 50001 energy management system.Identify energy savings opportunities and make recommendations to achieve more energy efficient operation.Monitor and analyze energy consumption.Requirements:Bachelor’s degree in Science or Engineering.3-5 years of related experience with 1-3 years in a cGMP facility with sterilization experience.Knowledge cGMPs, industry guidance, and aseptic techniques.Ability to write reports and record data and a basic understanding of statistical analysis; generate of reports, deviations or other technical documents.PC literate (MS Word, Excel, PowerPoint, Project, Access) competency.Comprehensive understanding of cGMPs and become certified to enter Controlled Areas of the plant (class 100, 10,000 and 100,000).Analytical datalogger programming, operating, troubleshooting, data-collecting desired.Installation, Operational and Performance Qualification protocol generation and execution desired.Understanding of statistical analysis tools and methods preferred.Knowledge of cGMP room classifications, HEPA filter testing and Airflow Pattern testing tools and techniques desired.Knowledge of cGMP Cleaning Validation and cGMP Process and Product Validation requirements and techniques desired.Knowledge and experience in cGMP CA/PA, root-cause analysis, risk assessment and investigation tools and techniques desired.Additional InformationWe offer an excellent salary and benefits package including medical, dental and vision coverage, as well as life insurance, disability, 401K with company match, and wellness program.Fresenius Kabi is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disabilities, or protected veteran status.",chi,de
5,Fresenius Kabi,Manufacturing,3.6,SR QUALITY ENGINEER (CRITICAL SYSTEMS),"Melrose Park, IL",$64K - $75K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1044074&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_67e99651&cb=1618160884736&jobListingId=3691088429,"Job SummaryPrimary Quality Owner of all plant facilities and equipment (critical systems) and associated processes, as well as the quality processes that govern them. Responsible for developing, evaluating, and ensuring compliance and efficient approval of Preventative Maintenance, Metrology, Validation and Qualification activities for all critical systems. Drives the execution and/or coordinates Risk and Gap Assessment analysis to ensure that the plant critical systems and equipment are in a state of control. Proactively leads facilities and equipment quality system enhancement projects to decrease the likelihood of action resulting from a regulatory inspection. Works in partnership with manufacturing operations, research and development, quality control and assurance, engineering, maintenance to solve problems and provide expertise on compliance issues and corporate quality policy requirements relating to critical systems.ResponsibilitiesDelivers Quality ownership of the facilities and equipment (critical systems) and associated processes, as well as the quality processes that govern them .Drives engineering change control (ECR) for critical equipment and controlled areas which include the timely preapproval and post approval of change controls.Provides support to the plant during operational run times as well as during maintenance shutdown activities both of which include off shift coverage.Provides quality oversight for software validation, equipment qualification, and facility commissioning and validation. Drafts, executes and approves validation documentation for critical systems and equipment.Troubleshoots problems related to critical systems and equipment (Water, HVAC, Pest Control, Lyophilizers, Vial Washers, etc). Analyzes data and implements both corrective and preventative actions to enhance processes.Leads, manages or participates in quality projects and teams to implement improvements to the facilities and equipment quality system infrastructure to meet regulatory requirements. Proactively taking ownership of quality processes and implementing solutions in support of continuous improvement.Leads and/or coordinates investigations related to critical systems and equipment. Analyzes data, conducts root cause investigations, performs gap analyses and risk assessments, develops corrective or preventive actions, and implements procedural and physical changes to reduce defects, improve efficiencies, and ensure compliance with all regulatory requirements, e.g., cGMPs, FDA Guidelines, USP, ISPE, ISO etc.Reviews and approves quality documentation such as deviation, OOT, OOS and complaint investigations, ensuring adequate root cause analysis as well as identification and implementation of corrective and preventative actions (CAPA).Reviews and approves quality documentation such as master batch records, specifications, SOPs, and other associated documentation. Analyzes system and document changes for appropriateness and ensures adequate impact analysis.Reviews and approves weekly system releases.Interacts with the regulatory officials to convey the compliance level of the facilities and equipment quality system during regulatory inspections.Provides training to appropriate personnel related to facilities and equipment quality systems.Maintain critical system quality attributes metrics to drive the process of continuous improvement.Responsible for any additional tasks as assigned by the Manager.REQUIREMENTSB.S. degree in a technical science is required. Engineering degree is highly preferred.Minimum 5 years experience in a highly regulated industry required.5 years experience in the pharmaceutical industry highly preferred.5 years experience in change control preferred.Experience in qualification and validation practices required.Working knowledge of aseptic processing is highly preferred.Working knowledge of cGMP practices to include 21 CFR Part 210, 211 and Part11, Electronic Records, USP, ISO 13485 and 14644, and ISPE trends and guidelines.Good organizational and leadership skills, high level of attention to detail, excellent oral and written communication skills with the ability to effectively interact at all levels.Experience in leading cross functional teams, propelling change and driving projects to completion.Skilled in the application of continuous process improvement tools (e.g. six sigma, lean manufacturing, DMAIC)CQE or Black Belt certification a plus.Experience with Trackwise and Documentum preferred.Travel 10-20% as neededIND-1#GDAdditional InformationWe offer an excellent salary and benefits package including medical, dental and vision coverage, as well as life insurance, disability, 401K with company match, and wellness program.Fresenius Kabi is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disabilities, or protected veteran status.",chi,de
6,Leidos,Aerospace & Defense,3.8,"Database Administrator, Senior","Hines, IL",$109K - $129K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_63b59db0&cb=1618160884736&jobListingId=4058529043,"A Senior Database Administrator can create, implement and manage expansive database administration programs. Has experience in reviewing database performance trends, and identifying opportunities for improvement.Applicant must be willing to work weekends and after hours as needed.Primary Responsibilities.Create and maintain database entities, including instances, databases, table spaces, and tables in support of ITOPS IO administered databases.Make changes to the structure of database meta data and support any application changes.Make recommendations of database migration path to insure optimal performance and availability, which shall be provided to COR/VA PM(s) for review and approval prior to any migration.Review performance of databases on the open systems and mainframe platforms and provide and implement COR/VA PM(s) approved recommendations for improved performance.Write, modify, and debug database specific SQL and PL/SQL queries.Where appropriate, coordinate database administration duties with System and Network Administrators to ensure compatibility with hardware and operating systems configurations.Diagnose and correct problems that occur within databases and application interfaces.Recommend strategies for problem notification and availability reporting in database software and applications. All recommendations shall be provided to COR/VA PM(s) for approval prior to any implementation.Develop disaster recovery strategies, and execute or exercise backup/recovery, high availability and disaster recovery strategies. All recommended strategies shall be provided to COR/VA PM(s) for approval prior to any implementation.Develop Security strategies consistent with VA regulations and policies and industry best practices. All recommended strategies shall be provided to COR/VA PM(s) for approval prior to any implementation.Troubleshoot problems and take corrective action, coordinate Contractor specific technical support as necessary.Support users, other software Contractor teams, and database administrators with problems, projects, and implementations.Analyze database infrastructure to insure compliance with VA security standards, database performance considerations, and reverse engineering of existing database environments.When assigned to VA initiatives, develop schedules and plans, communicate progress to management in both verbal and written formats, identify barriers, identify and evaluate alternatives. The Contractor shall participate in fault isolation for database systems.When required, develop and submit for approval Configuration Change Management Plans in accordance with ITOPS IO standards. The Contractor shall follow the change management process prescribed by the Chief, Database Support Services when making all changes to production systems.Basic Qualifications:Bachelor’s in computer science, electronics engineering or other engineering or technical discipline is required with five (5) Database administration experience in large data center environment. 13 years of relevant experience may be substituted for education.Must be US Citizen with ability to obtain Public Trust contract requirementApplicant must be willing to work weekends and after hours as needed.Required Skills:Oracle Database Administration experience required.Additional specific experience in the following is also required:Oracle Golden Gate (OGG)Automatic Storage Management (ASM)VAULT Solaris 10/11Oracle 12C-19CAmazon Web Services (AWS) – Oracle in CloudDUTIES INCLUDE:Database administration support to handle DBA duties including database customer support,database security, database deployment, database performance and general database administration and maintenance at Hines Information Technology Center (HITC).Basic QualificationsBachelor Degree and 5 years of experience. 8 years of additional experience in lieu of DegreeAbility to work in a matrix team environment, actively and effectively managing relationships with customers, build and release managers, technical teams, product development, project managers, and other application managers.Experience in participating in information technology projects involving innovation and/or modernization.Experience developing and reporting upon metrics relative to operational and financial performance.Excellent organization and analytical skills.External Referral Bonus:IneligiblePotential for Telework:Yes, 25%Clearance Level Required:Public TrustTravel:NoScheduled Weekly Hours:40Shift:DayRequisition Category:ProfessionalJob Family:Database ManagementPay Range:Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world’s toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company’s 38,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Va., Leidos reported annual revenues of approximately $11.09 billion for the fiscal year ended January 3, 2020. For more information, visit www.Leidos.com.Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",chi,de
7,BrainWorks,Information Technology,4,Azure Data Architect,"Chicago, IL",$68K - $117K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044072&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_20e190e5&cb=1618160884736&jobListingId=4000915057,"Seeking a Senior-level Data Architect to LEAD the Hadoop to Azure Services / Databricks migration to Azure services/ Databricks.Join this mid-sized, well-established firm that is developing new IoT solutions for popular consumer devices.This role will be located in their contemporary greater Chicago area location (gym, amenities, etc.). Can enjoy telecommuting 1-2 days/week, but this is not a full-time remote role, they value collaboration in office (post pandemic). Must be local or able to relocate later this year to the greater Chicago area.This is a 50% hands-on, full time, direct hire opportunity with base, bonus, benefits and advancement opportunities.This role is perfect for a seasoned professional looking to see immediate impact and be a vital contributor to a dynamic team.Minimal, if any, travel.Sponsorship is available.Degree a must, advanced preferred.Contact: Jason@brainworksinc.com (Sorry, no contracting).BrainWorks, founded in 1991, is a leading executive search firm that prides itself on delivering superior talent to drive business performance. Our consultants are experts in their practice areas, which include CRM, Direct / Database Marketing and Customer Sciences / Advanced Analytics.The Relationship Marketing and Decision Sciences Practice Group places top performing candidates, from mid-level managers to C-level executives, with companies spanning from entrepreneurial start-ups to Fortune 500’s. Some of the business areas in which these candidates specialize include the following: Statistical Modeling, Advanced Analytics, Web Analytics, Digital Analytics, Customer Analytics, and Campaign Management.When you partner with BrainWorks you will receive industry expertise coupled with quality, speed and results guaranteeing a great hire. We look forward to having the opportunity to work with you https://brainworksinc.com .IND123",chi,de
8,Alliant Credit Union,Finance,3.5,Data Scientist,"Rolling Meadows, IL",$88K - $145K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1188405&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_ec3a8e7e&cb=1618160884736&jobListingId=3795209572,"Start a Rewarding Career with AlliantWhat will your day look like?

The Data Scientist is responsible to lead the development, validation, documentation, and implementation of statistical and advanced machine learning models that are used for decisioning and product management throughout member lifecycle, including segmentation, optimization, and prescriptive analytics; work effectively with internal clients to understand the business needs, propose appropriate quantitative solutions, and develop data-driven recommendations to improve member experience and achieve business objectives; provide statistical and analytical inputs for the development and implementation of policies and business plans related to loan origination, portfolio management, loss forecasting and portfolio monitoring; proactively collaborate with cross-functional partners including Business Intelligence, Model Risk Management, and Information Technology (Database Engineers, Application Development and Information Security); and deliver effective presentations of analysis results and recommendations to multiple levels of leadership and business partners. The incumbent is a key contributor to the success of the Risk Analytics team.ResponsibilitiesDo you see yourself doing this?

Use advanced analytics to solve business problems and support business and risk strategic objectives. Collaborate with various partners to prioritize requests/needs and provide a holistic view of the analysis.
Perform advanced data analytics (e.g. data mining, statistical analysis, predictive analytics), and develop, document, and support the deployment of quantitative models, which are used for decisioning and product management through member lifecycle including acquisition, activation, utilization, relationship deepening and retention.
The risk analytics projects may include but not be limited to: automated credit decisioning, risk rating models, pricing models, loan loss forecasting, as well as CECL models and validation.
Acquire and integrate data from multiple data sources for analysis, perform exploratory to advanced predictive and/or modeling analytics, and identify data relationships such as trends, patterns and correlations in order to solve business questions as well as provide actionable recommendations.
Leverage multiple complex data sources such as credit bureau reports, and customer supplied information at large scale to optimize approve / decline and credit line assignment decisions.
Be able to presents data and analysis in a clear and concise manner allowing the internal clients to quickly understand the results and make data driven decisions.
Work jointly with engineers to deploy models into production environment.
Perform model validation and documentation of newly-developed predictive models to ensure they follow best industry practices and are in compliance with internal and regulatory requirements.
Conducting annual model validations to ensure models are working as intended and proactively seek, build and consolidate new data inputs to improve model performance.
Promote a risk-aware culture, ensure efficient and effective risk and compliance management practices by adhering to required standards and processes.
Adhere to and ensure compliance of all business transactions with policy and process of the Bank Secrecy Act. Comply with Privacy Act directives and all other applicable state and federal laws, company procedures and policies. Maintain integrity and ethics in all actions and conversations with or regarding credit union members and their accounts.

QualificationsWhat makes you a great fit?

You’ll be a great fit if in addition to an advanced degree (M.S./PhD) in Mathematics, Statistics, Quantitative Finance, Engineering, Computer Science, or other quantitative field required, and you have:


Require 2+ years of data analytics and modeling experience in the financial services industry (consumer lending preferred)
Hands-on work experience on building and deploying decisioning models that are used for one or more of the areas in credit risk, collections, marketing, or fraud
Expert knowledge in one of the statistical programming languages such as Python or R, and database languages such as SQL
Basic knowledge on lending, credit risk measures (PD, LGD and EAD)
Excellent communication skills and ability to present complex analyses and technical subject matter clearly and concisely to internal customers with different technical backgrounds
Strong teamwork and interpersonal skills to collaborate with people across functions
Self-motivated and impact-oriented


When you’re happy, we’re happy!

As a thank you for joining our team, you’ll benefit from:


Competitive medical, dental, and free vision benefits
Competitive compensation plan
Contributions towards gym memberships
Generous PTO and banking holidays off

Still not convinced?

We’re on the list of 100 Best Medium Companies to work for, check it out here. For more details you can also visit our Glassdoor and LinkedIn profiles.",chi,de
9,Saggezza,Information Technology,4.1,Data Engineer,"Chicago, IL",$65K - $120K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=4341&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_78645156&cb=1618160884737&jobListingId=4025654607,"Data Engineer

Smarter Thinking. Real Results. Technology consulting has been our story for over 14 years. Companies from all industries partner with us for our innovative mindset to help them digitally transform to create market advantages, become resilient, and prepare for whats next. With us, the possible becomes actual.

We provide strategic and innovative consulting services focused on digital experiences, engineering, automation, data and analytics, and Salesforce solutions. Saggezza consultants work as part of a global team, and throughout their tenure, have the opportunity to work on a variety of different projects across various clients and industries. We are chartered to do one thing, and one thing only to bring enabling technology to our clients that allow them to move their business forward.

We are currently looking to hire a Data Engineer to join our team.

Each project will be different, but youll always be responsible for:

Working across multiple clients and industries to add value and strategic insights within data & analytics.Cleaning and preparing data for analysis and processingProviding proficiency in analyzing data and formulating insights/conclusions. Building, developing and maintaining reporting systems that support key business decisions. Helping clients reach solutions by utilizing data management & operations, data quality & governance, cloud transformation, self-service analytics & visualization, and data intelligence. Working hands-on with SQL/SQL server & Python to deliver analytics to clients. Examining and reporting results to stakeholders in leadership, technology, marketing, sales, and product teams.

From a cultural perspective, we look for individuals who possess the following qualities that will contribute to our success and the success of our clients:

Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.

What Youll Definitely Need

A Bachelor's in Computer Science, Information Technology, Mathematics, Engineering or an equivalent field.5+ years of practical hands-on experience working within data modeling, data extraction, data manipulation, and data warehousing concepts.Minimum of 5+ years of practical hands-on experience working with SQL/SQL Server and Python for analytics and data science purposes as well as working in a large data warehousing environment.3+ years of working with data modeling and entity-relationship diagramsExpert level experience writing complex SQL queries, including but not limited to stored procedures, functions, views, and triggers.Knowledge of indexes and how they can be used to enhance query performance.Proficiency in modern data tools and cloud technologies would be advantageous, including but not limited to Spark, Hadoop, Tableau, AWS, Azure, Kafka, GCP & IBM Cloud.Analytical mindset and business acumen. Self-motivated, individual contributor.Great communication and data-oriented personality with strong problem-solving skills.

What Wed Love to See

Experience with analytic modeling in a scripting language (Python, R, etc.).An understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (Depending on specific project requirements).Cloud certification, or any certification related to database or BI Tools.

Dont tick all the boxes? Dont worry about it: we still want to hear from you if you think

youre the right person for the job.

Why Join Our Team?

Diverse culture, experiences, and skills.Our nurturing and supportive environment fosters collaboration across the entire organization.We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.We welcome innovators with entrepreneurial spirits to grow with our team. Consulting Magazine - Fastest Growing Firms 2019Built-In Top Places to Work in Chicago 2020Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 20202020 Inc. 5000 List - Honored as one of the fastest-growing private companies in America

Saggezza is an Equal Employment Opportunity Employer: We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.

MF-01

Powered by JazzHR",chi,de
10,Google,Information Technology,4.5,"Cloud Data Engineer, Professional Services","Chicago, IL",$104K - $122K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_611f20e4&cb=1618160884737&jobListingId=3770938498,"Minimum qualifications:Bachelor's degree in Computer Science, Mathematics related technical field, or equivalent practical experience.Experience with data processing software (Hadoop, Spark, Pig, Hive) and algorithms (MapReduce, Flume).Experience writing software in one or more languages: Java, C++, Python, Go, JavaScript.Experience managing client-facing projects, troubleshooting client technical issues, working with engineering, sales, services, and customers.Preferred qualifications:Experience working data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments.Experience in technical consulting.Experience working with Big Data, information retrieval, data mining or machine learning, as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, TensorFlow).Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments.About the jobThe Google Cloud Platform team helps customers transform and evolve their business through the use of Google’s global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.As a Cloud Data Engineer, you'll guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud Platform. You will work on data migrations and transformational projects, and with customers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform challenges. In this role, you will be working with Google's most strategic Cloud customers, and with the team, you will support customer implementation of Google Cloud products.Google Cloud provides organizations with leading infrastructure, platform capabilities and industry solutions. We deliver enterprise-grade cloud solutions that leverage Google’s cutting-edge technology to help companies operate more efficiently and adapt to changing needs, giving customers a foundation for the future. Customers in more than 150 countries turn to Google Cloud as their trusted partner to solve their most critical business problems.ResponsibilitiesAct as a trusted technical advisor to customers and solve complex Big Data challenges.Create and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.Travel up to 30% of the time as necessary.Communicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",chi,de
11,CapTech Consulting,Information Technology,4,Data Engineer,"Chicago, IL",$72K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_d20da84c&cb=1618160884738&jobListingId=4030967198,"Company DescriptionCapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.Job DescriptionThe Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.Specific responsibilities for the Data Engineer, Analytics position include:Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, Scala, etc)Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insightsDesign, develop, and implement data processing pipelines at scalePresent programming documentation and design to team members and convey complex information in a clear and concise manner.Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.Write and refine code to ensure performance and reliability of data extraction and processing.Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customersParticipate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.Some of our technologies might include: Python, Cassandra, Spark, Java, Scala, Informatica, SQL Server, SSIS, Oracle, Kafka.QualificationsSpecific qualifications for the Data Engineer, Analytics position include:Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experienceDevelopment experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating systemStrong SQL development skillsDevelopment experience with at least two different programming languages (Python, Java, Scala, etc.)Development experience with Unix tools and shell scriptsDevelopment experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)Minimum of 4-5 years experience designing, developing, and testing software aligned with defined requirementsExperience tuning SQL queries to ensure performance and reliabilitySoftware engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test-driven developmentAdditional InformationWe offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands-on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:Competitive salary with performance-based bonus opportunitiesSingle and Family Health Insurance plans, including Dental coverageShort-Term and Long-Term disabilityMatching 401(k)Competitive Paid Time OffTraining and Certification opportunities eligible for expense reimbursementTeam building and social activitiesMentor program to help you develop your careerCapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements). At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.CapTech is a Drug-Free work place.Candidates must have the ability to work at CapTech’s client locations.All positions include the possibility of travel.CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.#LI-AB1",chi,de
12,Neuberger Berman,Finance,4.3,Data Engineer,"Chicago, IL",$67K - $129K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_035b28d6&cb=1618160884738&jobListingId=3771147884,"Summary:We are looking for a hands-on data developer / engineer with strong MS SQL Server experiences. The candidate requires knowledge of RDBMS modeling and development experiences as well as some data science technologies.Responsibilities:Work closely with business stakeholders to understand their analytics, and construct efficient and scalable algorithms to implement themSet up strong foundational procedures, guidelines, and standards for data analytics and processingIntegrate new software tools for data analysis into the existing tool-setBuild automated pipelines for developing, testing, and deploying data analytics applicationsConduct ad-hoc analysis and present results in a clear mannerProcess, clean, and verify the integrity of data used for analysisQualifications:Bachelor degree or equivalent in Computer Science, Data Science, or Engineering5 years of experience of MS SQL Server with knowledge of OLTP and Dimensional Modeling design and development. Familiar with MS SQL Server performance optimization techniques.Experience with T-SQL and various of MS SQL 2012+ advance programming features.Experience with Tableau reporting and analytical toolsExperience working with financial data sets a plusExperience with data integration and workflow tools. Hands-on with large data pre-processing (ETL), and data cleansing.Experience with DevOps tool-sets such as Confluence, JIRA, and Git.Experience working within an Agile software development framework with strongly disciplined approach to software developmentExperience with Azure and Snowflake is a plus.A team-player who is eager to learn with strong analytical and communications skillsNeuberger Berman is an equal opportunity/affirmative action employer. The Firm and its affiliates do not discriminate in employment because of race, creed, national origin, religion, age, color, sex, marital status, sexual orientation, gender identity, disability, citizenship status or protected veteran status, or any other characteristic protected by local, state, or federal laws, rules, or regulations. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact onlineaccommodations@nb.com .Learn about the Applicant Privacy Notice .",chi,de
13,Alliant Credit Union,Finance,3.5,Sr. SIEM Engineer,"Chicago, IL",$81K - $182K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1157700&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_ae25db0b&cb=1618160884738&jobListingId=3821483453,"Start a Rewarding Career with AlliantWhat will your day look like?

You will be responsible for responsible for ensuring system logs, alarms, and events are correctly identified, alerted, analyzed, communicated, and reported. The incumbent will detect and minimize security intrusions by effectively leveraging our Security Information and Event Management (SIEM) system.

Additionally, the incumbent will aid in the monitoring, threat analysis, trend analysis, troubleshooting of security device monitoring, and incident investigation using infrastructure and applications logs from across the enterprise. A strong background in writing SQL queries and managing SIEM systems in a bank or credit union environment is strongly preferred. General direction is received from the Sr. Manager, Security Operations Center.ResponsibilitiesDo you see yourself doing this?

Designing, writing, and monitoring rules to safeguard Alliant’s information assets and effectively identify and mitigate both internal and external threats to these goals
Facilitating the monitoring, detection, analysis, and resolution of security incidents
Providing infrastructure protection by continuously analyzing alerts and logging
Developing new triggers and reporting within SIEM and log retention/management tools
Writing rules for Security Information and Event Management (SIEM) system
Managing the health of the SIEM by working with our third-party vendor
Reviewing SIEM logs and alerts to identify and report possible security events
Designing and writing smart response rules to take automated actions against accounts and devices that have triggered alerts
Responding to security events with 24 x 7 availability
Working with other teams and third-party vendors to research and resolve security and related system integration issues
Monitor and process responses for security events on a 24x7 basis
Remain current and knowledgeable about new threats; analyze attacker tactics, techniques, and procedures (TTPs) from security events across an extensive heterogeneous network of security devices and end-user systems
Ability to investigate security incidents
Leverage automation and orchestration solutions to automate repetitive tasks
Assist with an incident response as events are escalated, including triage, remediation, and documentation
Work alongside other security team members to hunt for and identify security issues generated from the network, including third-party relationships
Share information as directed with other team members and ISACs
Manage security event investigations, partnering with other departments (e.g., IT), as needed
Evaluate SOC policies and procedures, and recommend updates to management as appropriate
Adhere to service level agreements (SLAs), metrics, and business scorecard obligations for ticket handling of security incidents and events.
Leverage knowledge in multiple security disciplines, such as Windows, Unix, Linux, data loss prevention (DLP), endpoint controls, databases, wireless security, and data networking, to offer global solutions for a complex heterogeneous environment
Maintain working knowledge of advanced threat detection as the industry evolves

QualificationsWhat makes you a great fit?

You’ll be a great fit if in addition to the completion of a High School degree or equivalent required, Bachelor’s degree preferred, and you have:


7+ years’ hands-on Information Security detection experience preferably within a bank or credit union with understanding of how banking transactions work
7+ years’ managing rights and troubleshooting of operating systems (e.g., Windows, Redhat Linux) and SIEMs.
Hands-on experience with one or more industry leading SIEM products and related systems (e.g., Splunk, LogRhythm, QRadar, RSA Web Threat Detection), MS SQL, Cisco, Microsoft server products, Redhat Linux, DLP products (e.g., Symantec DLP, Websense DSS) and other log management products.
Experience performing event correlations and writing regular expressions
Experience creating custom rules in SIEM products
Plus ++ Experience analyzing fraud trends and proactively designing solutions to mitigate them
Ability to create complex SQL queries, analyze results and identify trends
Industry certifications (CISSP, CISA, SANS) or willingness to obtain
Available to be on-call 24/7 for Incident Response
Direct experience or familiarity with cyber-attack vectors
Integrity and high standards of personal and professional conduct
Strong interpersonal and written/verbal communication skills (this role involves communicating with end users within various departments such as Fraud and DBAs)
Ability to achieve goals through influence, collaboration, and cooperation
Proficient with Microsoft Office Suite
Experience driving measurable improvement in monitoring and response capabilities at scale
Experience working with SIEM systems, threat intelligence platforms, security automation and orchestration solutions, intrusion detection and prevention systems (IDS/IPS), file integrity monitoring (FIM), DLP, and other network and system monitoring tools
Knowledge of a variety of Internet protocols
Working knowledge/experience with network systems, security principles, applications, and risk and compliance initiatives such as Gramm-Leach Bliley Act (GLBA), Payment Card Industry (PCI), Sarbanes-Oxley Act (SOX), and the General Data Protection Regulation (GDPR)
Demonstrate an analytical and problem-solving mindset
Leverage strategic and tactical thinking
Work calmly under pressure and with tight deadlines

When you’re happy, we’re happy!

As a thank you for joining our team, you’ll benefit from:


Competitive medical, dental, and free vision benefits
Competitive compensation plan
Contributions towards gym memberships
Generous PTO and banking holidays off

Still not convinced?

We’re on the list of 100 Best Medium Companies to work for, check it out here. For more details you can also visit our Glassdoor and LinkedIn profiles.",chi,de
14,Alliant Credit Union,Finance,3.5,Lending Data Analyst,"Rolling Meadows, IL",$44K - $78K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1188405&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_390dce36&cb=1618160884739&jobListingId=3820147336,"Start a Rewarding Career with AlliantWhat will your day look like?

You will support the achievement of Lending business objectives through the development of statistical and data analysis that enables actionable business insight. The Lending Data Analyst is responsible for collaborating with Lending and Technology to develop strategies for business intelligence and data gathering, integrating new data sets, building reports and dashboards, and communicating their finding and recommendations to business partners. In addition, the Lending Data Analyst is responsible for working with Servicing, Business Risk, Audit and Compliance to develop control and monitoring reports for the business. General direction is received from the Supervisor, Loan Servicing Design & Solutions.ResponsibilitiesDo you see yourself doing this?

Design, develop, and maintain statistical models and workflows to inform and support various business strategies and program changes under consideration
Serve as Lending Data lead and local data steward to coordinate data/analytical efforts within Lending through partnership with other Lending SME’s
Responsible for identifying trends, performing data analysis and recommending solutions related to the following processes:



Charge Off, Delinquency and Loss Mitigation Analysis
Customer Segmentation, Contact Strategy and Treatment Choices
Performance Management and Goal Reporting
Operational Reporting


Responsible for data extraction, manipulation, analysis, reporting and presentations
Assist with integrating new data within Datawarehouse
Identify solutions and recommendations to leadership for improve performance and reduce costs
Document and maintain procedures for reports
Ensure data integrity through audits and works with 3rd party vendors to maintain data integrity and accuracy
Assist with troubleshooting, researching and fixing issues.
Effectively communicate technical subjects with non-technical staff and must also be able to translate business requirements into technical specs
Identify continuous operational improvement opportunities and service efficiency initiatives; recommend solutions, and champion the implementation of agreed upon solutions
Remain current on industry trends and implement best practices that result in improved performance
Monitor and resolve any discrepancies in data or at-risk items

QualificationsWhat makes you a great fit?

You’ll be a great fit if in addition to the completion of a Bachelor’s degree in finance, economics, mathematics, business or similar relevant discipline, required, and you have:


3+ years’ experience in report development, business analytics, business intelligence or comparable data engineering role
Prior experience in lending and credit analysis strongly preferred
Experience with BI tools such as Tableau, Tableau Prep, Business Objects, R studio, Python
Experience with business systems analysis or data analytics / business intelligence requirements gathering
Excellent verbal and written communications skills
Highly effective time and project management skills, including ability to coordinate development, testing and implementation
Demonstrated effectiveness in managing multiple priorities and meeting deadlines in a fast-paced environment; flexibility with changing priorities
Demonstrated commitment to quality and continuous improvement
Strong understanding of SQL, data warehousing and business intelligence
Familiar with the current competitive, economic, and regulatory environment of credit unions, banks, and investment finance

When you’re happy, we’re happy!

As a thank you for joining our team, you’ll benefit from:


Competitive medical, dental, and free vision benefits
Competitive compensation plan
Contributions towards gym memberships
Generous PTO and banking holidays off

Still not convinced?

We’re on the list of 100 Best Medium Companies to work for, check it out here. For more details you can also visit our Glassdoor and LinkedIn profiles.",chi,de
15,Balyasny,Finance,4.2,Data Engineer,"Chicago, IL",$106K - $193K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_6a5d8da4&cb=1618160884739&jobListingId=3822851213,"Role overviewThe Risk Technology team is responsible for delivering solutions to our Risk Management, Risk Research, and Portfolio Management teams. The solutions include, but are not limited to: factor modeling, risk/P&L attribution, VaR calculation, risk decomposition, market data processing, limits monitoring, large scale data management, data display and visualization, report automation, and API design and development. Risk systems are inherently data intensive and require a substantial amount of compute and storage resources to synthesize vast numbers of risk measures into actionable business metrics. The data engineer would bring innovative ideas and proven solutions to help scale the risk systems to handle ever increasing data volumes. The engineer will need to be comfortable working in a fast paced environment, be a strong communicator, and have a strong ownership mentality.Qualification10+ years software development experience with focus on building data intensive applicationsDeep expertise in an object oriented programming languages such C# (preferred), C++, or JavaDeep expertise in a data analysis languages such as Python (preferred), R, or MatlabSignificant experience building large scale data solutionsKnowledge of SQL and database experienceSelf-starter who can work independently and be able to drive a project from inception through deliveryBachelor’s or advanced degrees in computer science, mathematics, engineering, or closely related field requiredPrior experience in financial services industry, preferably in asset management, a plus",chi,de
16,Intone Networks,Information Technology,4.4,Data Engineer,"Chicago, IL",$56K - $103K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_c3665d13&cb=1618160884739&jobListingId=4027320199,"Data Engineer for a FinTech Company Focus is on Open Stack Data Engineer. Role will include moving data sources to Snowflake, decommissioning of legacy SQL and development in Python.",chi,de
17,LogicGate,Information Technology,4.5,Data Engineer,"Chicago, IL",$73K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=4341&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1f6c052a&cb=1618160884739&jobListingId=3748657273,"LogicGate is a venture-backed, Chicago-based technology company that needs YOU to help us as we continue to disrupt the wide world of GRC (governance, risk, and compliance). At LogicGate, youll join a group of bright, welcoming people ready to learn, grow, and do the right thing for our customers.

We are seeking a highly-motivated Data Engineer to join our Information Security & Technology team, who is empowered to design and build pipelines that support key business intelligence and product growth functions. Youre the type of person that is driven to set a vision for how a company should consume data, test and refine assumptions, and partner with various stakeholders to make it a reality.

What youd achieve

Help define, evolve our data platform with scale and growth in mind Work closely with senior leadership across our Product, Marketing, and Customer teams around data products that will drive our business objectives to the next level through actionable informationCraft data stack & architecture recommendations and work with various Engineering & InfoSec stakeholders to make it happen, securelyMaintain efficient and extensible data frameworks to focus and prioritize data consumersSet the standard for ELT processes across the organization

What value youd bring

You have 5+ years of experience designing and implementing modern data pipelines in AWS or GCPYou have expertise in developing and maintaining relational database structures and relationshipsYou have a solid background partnering with DevOps teams to manage requirements for version-controlled infrastructure and supporting cloud servicesYou are comfortable architecting and deploying data orchestrators, preferably Airflow You believe in writing great documentation with a desire to educate others on leading data engineering practicesYou are knowledgeable about software engineering practices across the development lifecycle, including agile methodologies, source management, build processes, testing, and operationsYou have a familiarity with data quality automation

What we have to offer:

Time Off


16 Days PTO + 8 company holidays + 2 Floating Holidays5 physical/mental health days (sick days)Equitable Parental Leave Policy 
Healthcare


Blue Cross Blue Shield for Medical, Dental and Vision LogicGate covers 80% of employee premiums
401(k) Match ProgramWork Environment


Modern office with standing desks (featured in ChicagoInnos Office Envy Series) Weekly catered lunch + kitchen stocked with coffee, seltzer, and snacks Flexible hours and Work From Home optionsPersonal Space/Mothers Room
Flex Rewards


Pre-tax commuter benefits Monthly funds on Zestful debit card for Fitness, Family, Education or CharityPartial ownership of company through stock options

Here are just a few things weve been up to recently:

We secured $24.75M in Series B Financing in December 2019 to help us continue our missionWe earned our placement as the #1 GRC Solution on the G2 Grid an honor weve received many times over!We were included on Built In Chicagos list of Best Small Companies to Work For in 2020

Oh, and we have a lot of fun while were at it. Youll have the chance to participate in things like company-led charity involvement, monthly employee events, and regular Friday happy hoursplus a lot more.

Not too familiar with GRC? Thats oka lot of us werent when we were in your shoes either. Heres what you need to know:

GRC stands for governance, risk management, and complianceGRC professionals help their companies manage uncertainty, act with integrity, and stay on the right side of the law. Bottom line: they keep their companies on the right track. GRC is a huge market, and growing fast. Not only is it a $35 billion industry today, its predicted to grow to $64 billion by 2025. This is what were going after!

LogicGate is dedicated to creating a community of diverse professionals, as we believe this creates a strong sense of belonging which ultimately enables our business to succeed. We are passionate about creating safe, inclusive spaces for all those who come through our doors! We’re proud to be an equal employment opportunity employer who does not discriminate on the basis of race, gender, sexual orientation, gender identity, age, national origin, disability, religion, veteran or military status, or any other protected status.

Powered by JazzHR",chi,de
18,Syngenta,Agriculture & Forestry,4.1,Data Engineer,"Downers Grove, IL",$76K - $133K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_8b1a3b3d&cb=1618160884740&jobListingId=3775856999,"About SyngentaSyngenta is a global leader in agriculture; rooted in science and dedicated to bringing plant potential to life. Each of our 28,000 employees in more than 90 countries work together to solve one of humanity’s most pressing challenges: growing more food with fewer resources. A diverse workforce and an inclusive workplace environment are enablers of our ambition to be the most collaborative and trusted team in agriculture. Our employees reflect the diversity of our customers, the markets where we operate and the communities which we serve. No matter what your position, you will have a vital role in safely feeding the world and taking care of our planet. Join us and help shape the future of agriculture.Syngenta is changing the agriculture industry and we want you to be part of that. Digital innovations, data and new technologies will transform the way that crops are managed in the future and enable farmers and agronomists to enhance efficiency and sustainable food production. You will help to develop solutions that turns data into meaningful information and ultimately helps to grow more food with fewer resources.Job Description & AccountabilitiesCreate and maintain optimal data pipeline architecture, assemble large, sophisticated data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big Data’ technologies.Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency, and other key business performance metrics.Work with partners including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader Qualifications.Qualifications5+ years of hand on experience in a Data Engineer role, who has attained a bachelor’s degree in computer science, Information Systems.3+ years of experience with AWS services: Redshift, Glue, S3, EC2, RDS.3+ years of hands on experience of Python programming with object-oriented/object function scripting languages.2+ years of experience Qlik Sense, Qlik view tools is preferred.3+ years of experience with neo4j Graph DB, MongoDB, or other NOSQL databases.Experience working with Salesforce data and SOQL will be a plus.Experience with AWS services like EMR, RDS, Lambda, SNS, SQS etc. (nice to have).Experience with stream-processing systems: Kafka, Spark-Streaming, etc. (nice to have).What We OfferFull Benefit Package (Medical, Dental & Vision) that starts the same day you do.401k plan with company match, Profit Sharing & Retirement Savings Contribution.Paid Vacation, 12 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts among others.A culture that promotes work/life balance, celebrates diversity and offers numerous family-oriented events throughout the year.Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.Family and Medical Leave Act (FMLA)(http://www.dol.gov/whd/regs/compliance/posters/fmla.htm)Equal Employment Opportunity Commission's (EEOC)(http://webapps.dol.gov/elaws/firststep/poster_direct.htm)Employee Polygraph Protection Act (EPPA)(http://www.dol.gov/whd/regs/compliance/posters/eppa.htm)#RemotePrimary Location: USA-Illinois-Downers GroveOther Locations: USA-Illinois-Chicago, USA-Illinois-LisleJob: IS & Business Architecture - Data & Analytics",chi,de
19,"Grubhub Holdings, Inc.",Information Technology,4.1,Data Engineer II,"Chicago, IL",$100K - $123K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=133938&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_712599f7&cb=1618160884740&jobListingId=4054131645,"About The Opportunity:We’re all about connecting hungry diners with our network of over 300,000 restaurants nationwide. Innovative technology, user-friendly platforms and streamlined delivery capabilities set us apart and make us an industry leader in the world of online food ordering. When you join our team, you become part of a community that works together to innovate, solve problems, grow, work hard and have a ton of fun in the process!Why Work For UsGrubhub is a place where authentically fun culture meets innovation and teamwork. We believe in empowering people and opening doors for new opportunities. If you’re looking for a place that values strong relationships, embraces diverse ideas–all while having fun together–Grubhub is the place for you!More About the RoleThe Retention team at Grubhub is focused on growing our active diner business, which manifests itself in many ways, from creating email marketing campaigns to passing our marketing-determined recommendations to our product. We are looking for an experienced, adaptable, and energetic self-starter, who would like to build products and pipelines with a direct business impact. The engineer will work daily across marketers and data scientists alike, and have ample opportunity to supplement their technical expertise with business development skills, becoming almost a “business” data engineer. Pipelines and processes created in this role will be essential to execution of business needs, so we are looking for somebody who can not only complete the engineering task, but is innately curious about the subsequent business impact. Culture fit is important on this team - we’re hard workers and proactive teammates. As a Data Engineer of a team of data scientists and marketers, we are looking for not only an engineering domain expert, but one who enjoys mentoring and developing others’ engineering know-how.The Impact You Will Make:Be a flexible swiss army knife in owning deployment of production pipeline systems, from email programs to in-product integrations.Closely work with analysts and marketers alike to assist in building out big data assets, pipelines, and campaigns. Don’t be afraid to learn and understand the business - the engineer best suited to succeed in this role will embrace the business needs as the primary ends, not a constraint.Assist team members in technical engineering aspects, particularly with job optimizations and Spark application troubleshooting/tuning.Proactively find opportunities to better our business and underlying operations through engineering improvements.What You Bring to the Table:Expert skills in querying with SQL, expert programming in Python, distributed systems/big data processing with Spark.3+ years experience writing test-driven development ETL jobs, both complex and small/flexible, within a business context.Experience mentoring/coaching engineers along with overseeing the technical work of developers from other teams.Great communication skills/working with teammates, both technical and non-technical.Got these? Even betterInfectious enthusiasm and energy, we are looking for culture leaders.Bachelor’s Degree in Science, Programming or Engineering related field.Experience deploying machine learning models into big data pipelines.Rigorous attention to detail and accuracy, structured and organized.Adaptability and collaborative skills.And Of Course, Perks!:Flexible PTO/PTO. Grubhub employees enjoy a generous amount of time to recharge.Health and Wellness. Excellent medical benefits, employee network groups and paid parental leave are just a few of our programs to support your overall well-being.Competitive Pay. You’ll receive a competitive base salary with eligibility for generous incentives, bonuses, commission or RSUs (role-specific).Learning and Career Growth. Your personal and professional development is a priority at Grubhub. We empower you to be a leader and grow your career through training, coaching and mentorship opportunities.MealPerks. Get meals on us! Our employees get a weekly Grubhub credit to enjoy and support local restaurants.Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives like Wellness Wednesdays, Slack competitions and virtual happy hours!Social Impact. At Grubhub we believe in giving back through programs like the Grubhub Community Relief Fund and donating $1 million to the Equal Justice Initiative in 2020. Employees are also given paid time off each year to support the causes that are important to them.COVID-19 Response. All of our employees are currently working from home and will be for the foreseeable future. We look forward to seeing everyone in-office when it’s safe to return.Grubhub is an equal opportunity employer. We welcome diversity and encourage a workplace that is just as diverse as the customers we serve. We evaluate qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. If you’re applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an email to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.",chi,de
20,Accenture,Business Services,4,Azure Data Engineer,"Chicago, IL",$93K - $104K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_0133db67&cb=1618160884740&jobListingId=4054676165,"Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.The Azure Technical Architect Delivery is responsible for delivering Data On Cloud projects for Azure based deals. The ideal candidate would also be responsible for developing and delivering Azure cloud solutions to meet todays high demand in areas such as AIML, IoT, advanced analytics, open source, enterprise collaboration, microservices, serverless, etc. The Azure Data Engineer is a highly performant engineer responsible for delivering Cloud based Big Data and Analytical Solutions at our clients. Responsibilities include evangelizing data on cloud solutions with customers, leading Business and IT stakeholders through designing a robust, secure and optimized Azure architectures and ability to be hands-on delivering the target solution. This role will work with customers and leading internal engineering teams in delivering big data solution on cloud. Using Azure public cloud technologies, our Data Engineer professionals implement state of the art, scalable, high performance Data On Cloud solutions that meet the need of todays corporate and emerging digital applicationsAs part of our Data A&I Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!Role & ResponsibilitiesProvide subject matter expertise and hands on delivery of data capture, curation and consumption pipelines on AzureAbility to build Azure data solutions and provide technical perspective on storage, big data platform services, serverless architectures, hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and securityParticipate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platformConduct full technical discovery, identifying pain points, business and technical requirements, “as is” and “to be” scenariosBuild full technology stack of services required including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations, management and automationApply Accenture methodology, Accenture reusable assets, and previous work experience to delivery consistently high-quality workStay educated on new and emerging technologies/patterns/methodologies and market offerings that may be of interest to our clientsAdapt to existing methods and procedures to create possible alternative solutions to moderately complex problemsUnderstand the strategic direction set by senior management as it relates to team goalsUse considerable judgment to define solution and seeks guidance on complex problemsPrimary upward interaction is with direct supervisor. May interact with peers and/or management levels at a client and/or within Accenture. Establish methods and procedures on new assignments with guidanceManage small teams of deliver engineers successfully delivering work efforts (if in an independent contributor role) at a client or within AccentureFor now, all Accenture business travel, international and domestic, is currently restricted to client-essential sales/delivery activity only.Please note: The safety and well-being of our people continues to be the top priority, and our decisions around travel are informed by government COVID-19 response directives, recommendations from leading health authorities and guidance from a number of infectious disease expert.Basic QualificationsAt least 3 years of consulting or client service delivery experience on AzureAt least 3 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutionsExtensive experience providing practical direction within the Azure Native services and HadoopExtensive hands-on experience implementing data migration and data processing using Azure services: ADLS, Azure Data Factory, Azure Functions, Synapse/DW, Azure SQL DB, Event Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.Minimum of 3 years of hands-on experience in Azure and Big Data technologies such as Powershell, C#, Java, Node.js, Python, SQL, ADLS/Blob, Spark/SparkSQL, Databricks, Hive and streaming technologies such as Kafka, EventHub, NiFI etc.Well versed in DevSecOps and CI/CD deploymentsCloud migration methodologies and processes including tools like Azure Data Factory, Data Migration Service, SSIS, Attunity (Qlik), Event Hub, Kafka, etc.Minimum of 3 years of RDBMS experienceExperience in using Big Data File Formats and compression techniquesExperience working with Developer tools such as Azure DevOps, Visual Studio Team Server, GitLabs, Jenkins, etc.Experience with private and public cloud architectures, pros/cons, and migration considerations.Bachelors or higher degree in Computer Science or a related discipline; or equivalent (minimum 12 years work experience). If Associate’s Degree, must have equivalent minimum 6 years work experienceNice-to-Have CertificationsDP-200 Implementing an Azure Data SolutionDP-201 Designing an Azure Data SolutionAZ-400: Designing and Implementing Microsoft DevOps Solutions Nice-to-Have Skills/QualificationsDevOps on an Azure platformExperience developing and deploying ETL solutions on AzureIoT, event-driven, microservices, Containers/Kubernetes in the cloudFamiliarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.Multi-cloud experience a plus - Azure, AWS, GoogleWhat We BelieveWe have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more hereEqual Employment Opportunity StatementAccenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. Our rich diversity makes us more innovative, more competitive and more creative, which helps us better serve our clients and our communities.All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.Accenture is committed to providing veteran employment opportunities to our service men and women.For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy StatementRequesting An AccommodationAccenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.Other Employment StatementsApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States. Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.Unless expressly indicated, this role is not open in the State of Colorado.",chi,de
21,Mars,Manufacturing,4.1,"Jr Data Engineer - Chicago, IL or Newark, NJ","Chicago, IL",$67K - $78K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=134216&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_30bd63a3&cb=1618160884740&jobListingId=4057178950,"Jr. Data EngineerChicago, IL OR Newark, NJMars Inc is amid a significant Digital Transformation journey. Our ability to solve difficult problems across Mars in a User Centric, Agile and efficient approach through Data & Analytics are fundamental to drive value for Mars Inc. The opportunities are vast for Mars which creates an exciting & rewarding experience for each associate. Connecting & deriving breakthrough insights from our various segments across multiple business units will help us make a more positive impact to the business and to our consumers. Building on this momentum we are creating several exciting digital roles in this space across Mars to inject the step-change in talent and experience that we require. Across the disciplines of Data Science, Data Engineering and Business Translation we are seeking qualified associates to join Mars and help us establish this breakthrough capability and influence how we operate in this new space.What are we looking for?BS in Data Engineering or related subject requiredPost-graduate qualifications in computer science, data engineering or relatedProfessional qualifications in advanced data design, software, big data, etc.Technical expertise and experience in database and data engineering capabilitiesExperience in designing and building databases, data warehouses, analytics and BI platforms, including in grocery, retail, healthcare or manufacturingExperience with Big DataIncluding use of cloud platforms like AWS or Azure, technologies across traditional and contemporary software (e.g. SQLServer, Hadoop), programming languages such as SQL, Java, C#, C++, Python, R, PySpark, etc.Track record in building and developing successful data warehouses and data pipelinesWhat are the key responsibilities?Design cloud-based data solutions to enable insight and analyticsStructuring data in a consumable format that allows it to be manipulated efficiently and modelled easilyLead, and develop engineering projects in collaboration with other team members (including offshore talent partners) to ensure rapid development of reliable, scalable and sustainable data solutions, using global best practicesDrive agile processes and team sprints to ensure efficient use of resourcesEnsure right technologies are in place to support our needs – deliver engagements with up-to-date capabilities available in the industryEngage and collaborate with data and IT owners across Mars ecosystem to drive data quality, availability and governanceHarvest and maintain a semantic and smart data layer and ensure holistic leadership of the data solution within the environmentWrite, test, debug and deploy codeForms part of the Analytics Open Hub Global Data and Analytics team to deliver the strategy, execute plans, providing specific and deep expertise in data design, data warehousing, big data platforms and data engineeringDevelop a clear understanding of the data sources available, with a hands-on orientation, and the expected uses or opportunities from the data to design and deliver the right data solutions to drive insight and scalable, sustainable value creationHands-on delivery through direct or indirect onshore/offshore data teamsWorks closely with data source owners and Data Science teams to shape and deliver right plansEnsure continually improving performance of solutions and ongoing nimble & lean approachAnalyse complex business requirements to build the technical specifications for new solutionsAct as an expert technical resource for designing and building data pipelinesSelf-starter, with a demonstrated ability for personal development beyond formal trainingWhat can you expect from Mars?The opportunity to learn, develop and take charge of your own career.An industry competitive compensation package including generous benefits (i.e. 401k, health, etc.)Commitment to our Purpose and our Five Principles.An environment where all Associates feel valued, supported and comfortable being themselves at work.#LI-KA1",chi,de
22,PATRA,Insurance,3.8,Data Engineer,"Chicago, IL",$77K - $138K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_94891faa&cb=1618160884740&jobListingId=4055375267,"About PatraPatra is a leading provider of Technology-Enabled Services to the insurance industry. Patra's team of global experts allow brokers, MGAs, wholesalers and carriers to capture the Patra Advantage - profitable growth and organizational value.Patra powers insurance processes by optimizing the application of people and technology; supporting insurance organizations as they sell, deliver and manage policies for their customers.About this jobAs part of the Data & Analytics team, the Data Engineer will facilitate the development of enterprise data management solutions in support of Patra's strategic initiatives. This individual will work closely with Data Analysts and Data Scientists to develop and implement data strategies that support the democratization, integration, and standardization of data at an enterprise level, ensuring consistency of business definitions and data quality. The ideal candidate will possess strong technical and communication skills, as well as proven experience in data management, information management, and the insurance industry in general.Core DutiesProvide Business Intelligence and Data Warehousing solutions in support of analyticsBuild a robust, fault-tolerant data pipeline that cleans, transforms, and aggregates unorganized and messy data into databases or data sourcesWork with business teams to define requirements and translate to dataRecommending new data streams and ensuring data integritySupporting and providing data in a ready-to-use form to data scientists who are looking to run queries and algorithms against the information for predictive analytics, machine learning and data mining purposes.Assemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leaderIdentifying new projects and opportunities, and the associated data requirementsMaintain technical knowledge by attending educational workshops, reviewing publications, establishing personal networks, and participating in technical societiesMinimum Requirements - Education & ExperienceBachelor's degree in Computer Science or related technical degreeWork experience as a data engineer or in related field, 5-10 years preferredMaster's degree preferredP&C Insurance and Consulting experience preferredMicrosoft BI Certified Engineer preferredKnowledge, Skills and AbilitiesAbility to analyze existing tools and databases, and provide recommendationsAbility to translate business requirements into non-technical, lay termsIntermediate to Advanced working SQL knowledge and experience working with relational databases as well as working familiarity with a variety of databases.Understanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball)Experience in methodologies and processes for managing large scale databases on premise as well as cloud solutionsExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementDemonstrated experience in handling large datasets, structured and semi-structured data formatsBuild processes supporting data transformation, data structures, metadata, dependency and workload managementA successful history of manipulating, processing and extracting value from large disconnected datasets.Understanding of metadata standardsWorking ConditionsWork from homeMinimum internet speed of 6 mbps download and 3 mbps upload; no satelliteCompensationCompetitive Salary / Benefits / PTOPhysical Requirements*Constantly perform desk-based computer tasksFrequent sittingOccasionally stand/walk, writing by hand, use of telephone, lift/carry/push/pull objects that weigh 11-20 poundsSort/file paperwork, rarely twist/bend/stoop/squatConsistent with its obligations under the law, the Patra Corp will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.Work StandardsInterpersonal Skills: Demonstrates the ability to work well with Patra colleagues and clients and with external organizationsPromotes Culture of Respect & Safety: Demonstrates commitment to personal responsibility and value for safety and respect; communicates concerns; uses and promotes safe respectful behaviors based on training and lessons learnedSubject to and expected to comply with all applicable Patra Corp policies and procedures",chi,de
23,CNA Insurance,Insurance,3.6,Data Engineer,"Chicago, IL",$103K - $120K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_dfbbef0a&cb=1618160884741&jobListingId=4056173112,"Data Engineer-INF0001Z0Supervisory Position: NoDescriptionJob SummaryAn individual contributor role that provides a high level of expertise in the design development and integration of strategic high-priority data applications across the entire software development lifecycle (Agile). This role may also provide guidance to others to support the building of complex technical capabilities.Essential Duties & ResponsibilitiesPerforms a combination of duties in accordance with departmental guidelines:Participates in the building of large-scale data processing systems and data lakes optimized for both computational and storage efficiency on Google Cloud Platform. Applies technical knowledge on data modeling and best engineering practices.Working as a key team member delivers results creating value for the CNA brand customers and key internal stakeholders. Works with external (and offshore) resources as required.May lead or sub-lead the design implementation and automation of data pipelines sourcing data from internal and external systems transforming the data for the optimal needs of various systems and business requirements.May lead or sub-lead robust unit testing to ensure deliverables match the design and provides expertise to support subsequent release testing.Actively adheres to established quality and reliability standards and ensures team adheres to the same quality and standards working in an Agile development environment.May lead or sub-lead the design of complex physical data models projects and cloud-based data lake constructs including SQL/NoSQL database systems. May lead or sub-lead the creation of integrated data views based on business or analytics requirements.Researches identifies and implements process improvements that address complex technology gaps. Builds strong knowledge of technology enablers.May lead or sub-lead the design and building of data solutions and applications that enable reporting analytics data science and data management.Maintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; participating in professional societies. Drives the evolution of CNA application development processes and standards.Applies machine learning to work as applicable.May perform additional duties as assigned.Reporting RelationshipTypically Director or aboveSkills Knowledge & AbilitiesStrong knowledge of relational database concepts ETL/ELT star schema data modeling.Strong data integration design and development ensuring accuracy and ease of consumption. Strong troubleshooting and problem solving skills.Proficient in Python or advanced SQL in a business environment with large-scale complex datasets.Strong communication and interpersonal skills and the ability to work effectively with peers and team members in a highly matrixed environment.Preferred experience in building data analytics solutions using Google Cloud Platform services such as Google BigQuery Cloud Storage Dataflow DataProc Pub/Sub Cloud Composer or DataPrep. AWS including Amazon Redshift Postgres Elastic MapReduce a plus.Preferred experience with the insurance industry its products and services.Experience in implementing big data processing technology. Apache Spark preferred.Working knowledge of Business Intelligence tools preferred.Education & ExperienceBachelor’s degree with Master’s preferred in Computer Science Information Technology related discipline or equivalent work experience.Typically 5+ years of experience in data analytics or application development.2+ years of coding proficiency in at least one programming language (Python Java SQL).Experience using Agile methods preferred.Applicable certifications preferred (GCP Data Engineering).EEO Statement: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.Job Information SystemsPrimary LocationUnited States-Illinois-ChicagoOther LocationsUnited StatesOrganization TechnologyJob Posting Apr 8, 2021Unposting Date Ongoing",chi,de
24,The University of Chicago,Education,4.2,Software/Data Engineer,"Chicago, IL",$54K - $104K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_bf21b44f&cb=1618160884741&jobListingId=3770743299,"DepartmentPME Galli LabAbout the DepartmentThe Pritzker School of Molecular Engineering (PME; https://pme.uchicago.edu/) was established in May 2019 and evolved from the Institute for Molecular Engineering, which was founded in 2011. The PME integrates science and engineering to address global challenges from the molecular level up. The PME’s rigorous academic and research programs are made possible through the University of Chicago’s unique partnership with Argonne National Laboratory. The Pritzker School of Molecular Engineering is the first new school at the University of Chicago in three decades and the first school in the nation dedicated to molecular engineering. In the next phase of growth as a School, the PME will continue to expand its team of world-class faculty researchers and empower students from diverse backgrounds to collaborate with faculty in cutting-edge facilities. The PME aims to bring solutions for urgent societal problems to the forefront, while training the next generation of scientific leaders and entrepreneurs. The Midwest Center for Computational Materials (MICCoM; http://miccom-center.org/) is a computational materials science center established by the Department of Energy in 2015 and renewed in 2019. The center is seeking a software data engineer to participate in software and data related projects.Job SummaryThe Midwest Center for Computational Materials (MICCoM is seeking a Software/Data Engineer. The ideal candidate should have experience in the development of complex software and data architectures and in generating and using databases.The Software/Data Engineer will perform a variety of activities related to software support and/or development: the engineer will provide analysis, design, development, debugging, and modification of computer code for end user applications, beta general releases, web pages, and production support. The software/data engineer will work with a team of 15+ PhDs/postdocs.ResponsibilitiesMaintain and develop software and data infrastructure, including:Database storage, query efficiency, and scalabilityREST APIs and GUI front-endsCommunicate with users for support, feedback, and strategic developmentSoftware testing unitsSoftware deploymentInvestigates, analyzes and resolves day-to-day technical problems using standard procedures.Supports and maintains existing applications. Works with web developers and responds to requests from users.Performs other related work as needed.Minimum QualificationsEducation:Minimum requirements include a college or university degree in related field.-Work Experience:Minimum requirements include knowledge and skills developed through 2-5 years of work experience in a related job discipline.-Certifications:-Preferred QualificationsEducation:Master's or PhD in Science, Engineering or related fieldExperience: 2-5 years of work experience in related field Research/scientific experienceStrong technical skillsPrevious programming with Python3Knowledge of C++ and/or FORTRAN is a plusExperience with containers (Docker, Singularity etc.) Experience in managing large codes/projects in a team (version control systems, issue trackers, unit test, continuous integration)Knowledge of software design (design patterns, agile development, etc.)Web (HTML5, JavaScript, AJAX, jQuery) and app designScientific background (e.g. physical or engineering sciences)Technical Skill or Knowledge:Experience with molecular dynamics simulations and/or electronic structure calculations is a plusPreferred Competencies Excellent problem-solving skills Ability to take initiative, organize and complete projects with minimal supervision Ability to work independently in an organized manner prioritizing the work of multiple projectsAbility to work collegially and as part of a teamAbility to manage a large volume of work often restricted by deadlinesAbility to use appropriate resources to resolve an issueApplication DocumentsResume (required)Reference Contact Information - 3 (required)When applying, the document(s) MUST be uploaded via the My Experience page, in the section titled Resume/CV of the application.Job FamilyInformation TechnologyRole ImpactIndividual ContributorFLSA StatusExemptPay FrequencyMonthlyScheduled Weekly Hours40Benefits EligibleYesDrug Test RequiredNoHealth Screen RequiredNoMotor Vehicle Record Inquiry RequiredNoPosting StatementThe University of Chicago is an Affirmative Action/ Equal Opportunity /Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form .We seek a diverse pool of applicants who wish to join an academic community that places the highest value on rigorous inquiry and encourages a diversity of perspectives, experiences, groups of individuals, and ideas to inform and stimulate intellectual challenge, engagement, and exchange.All offers of employment are contingent upon a background check that includes a review of conviction history. A conviction does not automatically preclude University employment. Rather, the University considers conviction information on a case-by-case basis and assesses the nature of the offense, the circumstances surrounding it, the proximity in time of the conviction, and its relevance to the position.The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu . Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",chi,de
25,McKinsey & Company,Business Services,4.4,Data Engineer - GCI Analytics,"Chicago, IL",$52K - $101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_15abd7a6&cb=1618160884741&jobListingId=3775555467,"QUALIFICATIONSBachelor's or master's degree in management information systems, information technology, computer systems or another quantitative field3+ years experience in a data engineer roleExperience in data pipeline development and design using ETL or ELT techniquesHands-on ANSI SQL experience and performance tuning techniquesKnowledge of database fundamentals (E.g. AWS Redshift, SQL Server, Postgres)Knowledge of programming languages (e.g. Python)Knowledge of reporting tools and technologies (e.g. Tableau) is a plusUnderstanding of AWS Cloud services is preferredSelf-starter and able to manage own high-capacity workload as defined by other team membersAble to manage multiple projects and delivery schedules under tight delivery timelinesStrong multi-tasking abilities, flexibility and patience in a fluid environmentAbility to offer a consultative approach to solve technical problemsProfessional attitude and service orientation; team playerStrong written and verbal communication skillsWHO YOU'LL WORK WITHYou will be based in our Chicago, Waltham or Dallas office as part of our GCI analytics team.GCI is a small, entrepreneurial and growing office which provides analytics, research, benchmarking and consulting services to clients in corporate banking and the payments industry.Clients secure our expertise and data-driven insights to evaluate business line performance and to make operational improvements and product development decisions. With the look and feel of a start-up, we are a wholly owned subsidiary of McKinsey and Company and operate both within McKinsey teams and also independently under our own brand and management team.WHAT YOU'LL DOYou will provide end-to-end data engineering support across several multi-client performance studies both in the creation and design of the data pipelines and in periodic updates.In this role, you will conduct mapping of client data to in house taxonomy as well as data importing and execution of translation algorithms. You will coordinate with the team and client throughout this process. You will also provide data staging and validation techniques, along with querying and extraction. As needed, you will collaborate with analysts to create new datasets and analyses.As your career progresses, you will have opportunities to contribute to different consulting engagements where you will create custom data deliverables to inform team and client decision-making. You will also have the opportunity to learn new skills such as building APIs, Plotly Dash visualization using Python, develop deeper skills in AWS Cloud Platform, data pipeline automation using Kedro or Airflow etc.",chi,de
26,HelloFresh,Consumer Services,3.6,Senior Data Engineer,"Chicago, IL",$103K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=8095&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_a94f499a&cb=1618160884741&jobListingId=4029118147,"Come see what's cookin' at HelloFresh!

At HelloFresh, we want to revolutionize the way we eat by making it more convenient and exciting to cook meals from scratch. We have offices all over the world and we deliver delicious meals to millions of people.

We are the industry leader in meal-kit subscription services and we're growing all the time. We have distinct meal-kit services that cater to everyone with the most menu variety in the market, which allows us to reach an incredibly wide population of people.

The HelloFresh team is diverse, high-performing, and international, and our work environment is an inspiring space where you can thrive as a result.

Job Description:

As a Senior Data Engineer at HelloFresh, you will be collaborating to build a robust and highly performant data platform using cutting-edge technologies. You will develop distributed services that process data in batch and real-time with a focus on scalability, data quality, and business requirements. You will have the opportunity to work on challenging data-related problems and building a self-serve data platform.

You will…

Build reusable technology that enables teams to capture, process, store, and serve their data products in an easy way
Build and maintain complex and scalable ETL pipelines
Work closely with the data infrastructure team
Collaborate closely with business stakeholders such as Marketing, Product Analytics, etc.
Drive data quality and governance

At a minimum you have…

Extensive experience in Software Engineering and the ability to design, implement and deliver maintainable and high-quality code with Python
Previously worked on OOP and design patterns
Ability to deliver scalable production-ready solutions
Strong problem-solving skills
Extensive experience with Apache Spark, Hive, and Kafka
Experience with AWS infrastructure (S3, EMR, Glue, Athena)
Experience with data modeling and data warehousing solutions
Exceptional written and verbal communication skills, ability to build effective communication structures in a fast-growing engineering organization
Exceptional technical background and a demonstrated clear impact on achieving business goals
Demonstrable past experience with Agile methodologies, with a strong focus on data-driven experimentation, lean thinking, and quick iterations
If you have experience in Machine Learning that is a big plus

You'll get...

Competitive Salary & 401k company match that vests immediately upon participation
Generous parental leave of 16 weeks & PTO policy
$0 monthly premium and other flexible health plans
75% discount on your subscription to HelloFresh (as well as other product initiatives)
When in office; snacks, cold brew & monthly catered lunches
Company sponsored outings & Employee Resource Groups
Collaborative, dynamic work environment within a fast-paced, mission-driven company

It is the policy of HelloFresh not to discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because he or she is a protected veteran.",chi,de
27,Vivid Seats,"Arts, Entertainment & Recreation",3.7,Data Engineer II,"Chicago, IL",$88K - $100K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=4128&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_a8382c0a&cb=1618160884742&jobListingId=4056109997,"This position is open to fully-remote candidates who can work from anywhere in the United States and Canada. Candidates also have the option to work from one of our office locations in Chicago or Toronto.

We strongly encourage all interested applicants to apply to our open roles regardless of how many qualifications they meet. Most of our posted positions have a degree of flexibility in the stated requirements.

The Opportunity:

As a Data Warehouse Engineer, you will operate as a partner to our business stakeholders to deliver data as a product; based upon their delivery needs (e.g., dashboards, reports, standard queries) meaningful data insights in a manner that is appropriate for the business. You’ll partner with engineering and business teams to ingest and transform data sources into our data warehouse, build clean/abstracted data models, and implement BI tooling as necessary. You’ll mature operational stability and performance of the data reporting platform through best practices, automation and monitoring while staying up to date on new and emerging technologies, planning accordingly to incorporate valuable concepts to enhance our data schema and capabilities.

To be successful, you’ll need:

Experience working with business and product leaders to define data reporting and dashboard requirements Experience managing data/metadata with cloud data warehouse platforms (preferably Snowflake, Amazon Redshift) Experience supporting and developing data access tools and dashboards (Tableau, Power BI, Looker, others) Expert SQL query experience ETL pipeline and tooling experience; including troubleshooting Scripting experience using Java, Python or Bash Proficiency in working in Mac and Linux environment A willingness to participating in an on-call rotation

Additional Experience of Interest:

Experience with configuration as code tools such as Ansible, Terraform etc. Familiarity with containerization and orchestration e.g. Docker, Kubernetes Experience with continuous integration, testing, and deployment using tools such as Jenkins

What We Offer:

Vivid Seats is the largest independent online ticket marketplace, sending tens of millions of fans to live events. Experiences Matter - which is why we continue to grow year over year. Working at Vivid Seats puts you front and center at the opportunity to scale our best in class platform that allows our fans to sit closer and experience more.

At Vivid Seats, you will have the opportunity to work with the flexibility and speed of a startup; while operating at massive, profitable scale. We keep our teams lean, allowing each employee direct accountability of creating a positive ticket buying experience. We are relentless and move quickly to release new features and content to our applications. Good ideas are heard and implemented, and hard work rewarded. Being a part of our team means having the ability to drive impact and own the innovation that connects our tens of millions of unique monthly users to the memorable experiences that only live events create.

We are passionate about creating memorable experiences for our fans and the best in class experience for our employees. Vivid Seats offers competitive compensation levels, individual and team-based bonus opportunities, 401K matching, a generous benefits package and Flex PTO policy plus a variety of workplace perks.",chi,de
28,DRW Trading Group,Finance,4.2,"Data ETL Engineer, FICC Options","Chicago, IL",$72K - $135K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_5dc087cb&cb=1618160884742&jobListingId=4055093696,"DRW is a diversified, technology-led principal trading firm. We trade our own capital at our own risk, across a broad range of asset classes, instruments and strategies, in markets around the world. As the markets have evolved over the past 25 years, so has DRW – growing to include real estate, cryptoassets, venture capital and several industry acquisitions. With more than nearly 900 employees at our Chicago headquarters and six global offices, we work together to solve interesting problems and capture opportunities. It’s a place of high expectations, deep curiosity, and constant collaboration, with some of the smartest, most passionate people you will meet.DRW is looking for an exceptional Data ETL Engineer with an expertise in Python to join a team of highly talented technologists tasked with building a proprietary options trading platform. Your role will focus on all areas of software engineering, including design, development, implementation, testing, and post-trade analysis while using the latest technologies.To qualify for this role, you:have 2+ years’ experience using Python on Linuxcan demonstrate expertise in data management, ETL workflows, process managementenjoys the challenge of maintaining processes and daily jobs with high uptime requirementscan operate in multiple language domains, including Java and Pythonhave a BS or advanced degree in Computer Science, Mathematics, Statistics, Physics or Engineering from a top universityBonus points if you have:experience with Rancher, Docker, Airflow, Graphana, or Prometheusexperience with UI/UX design and development in .NET or JavaScriptcontributed to open source projectsa demonstrated interest in keeping up with new developments in programming languages and other relevant technologies.an understanding of economics and the geopolitical landscapeFor more information about DRW's processing activities and our use of job applicants' data, please view our Privacy Notice at https://drw.com/privacy-notice.California residents, please review the California Privacy Notice for information about certain legal rights at https://drw.com/california-privacy-notice.LI-GV1",chi,de
29,Abt,Retail,3.7,Database Administrator,"Glenview, IL",$45K - $85K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1044074&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_0e809449&cb=1618160884742&jobListingId=3823171544,"Abt Electronics has an immediate opening for the position of a Database Administrator. We are a family owned company who has been in business since 1936 and continues to experience strong growth year after year. Abt Electronics specializes in electronics, appliance & furniture sales, delivery, installation and servicing all the products we sell. We are a perennial winner of the Chicago Tribune’s Top Workplace Award. We are looking for a highly motivated, flexible & friendly DBA to join our in office team. If this is you, we want to hear from you!In addition, must be comfortable contributing/working in an entrepreneurial, fast-paced and fun work environment. Primary duties include:Provision MySQL / Oracle instances, both in clustered and non-clustered configurations.Ensure performance, security, and availability of databases.Prepare documentation and specifications.Handle common database procedures, such as upgrade, backup, recovery, migration, etc.Profile server resource usage, optimize and tweak as necessary.Evaluate all architecture for Database applications and prepare layouts for all logicalDesign and implement structures for all physical objects and recommend changes on applicationsSkills and Qualifications:Minimum of 3 years of experienceStrong proficiency in MySQL/MariaDB/Oracle database managementUnderstanding of MySQL’s underlying storage engines, such as InnoDB and MyISAMExperience with replication configuration in MySQL/MariaDBKnowledge of de-facto standards and best practices in MySQL/MariaDBProficient in writing and optimizing SQL statementsAbility to plan resource requirements from high-level specificationsFamiliarity with other SQL/NoSQL databases such as PostgreSQL, MongoDB, etc.Proficient understanding of code versioning tools such as {{Git / Mercurial / SVN}} We offer our team members:Medical/Dental (Blue Cross and Blue Shield PPO Network) & Vision (VSP)401(k) (Charles Schwab) which includes a matching programLife & Disability insurance (Lincoln Financial)Generous Paid Time Off/Sick Pay ProgramContinued training & career developmentEmployee discounts on all products we sellNo sponsorships offered at this time",chi,de
30,DYNAMIC MANUFACTURING INC,N/A,4.6,Applications Engineer II,"Hillside, IL",$91K - $96K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1044074&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_37fd1a82&cb=1618160884743&jobListingId=3794183745,"JOB SUMMARY:Responsible for managing, designing, implementing, and maintaining moderate complexity applications projects. Candidate must demonstrate an intermediate understanding of electrical and mechanical concepts.Essential Functions:Mentor less experienced Applications EngineersAssist in managing projectsInterface and collaborate with Production Engineers, Quality Engineers, Mechanical Design Engineers, Maintenance Technicians and Calibration TechniciansDesign or assist in the design of, implement, and maintain:Advanced industrial equipment such as air-decay testers, pick to light boards, and displacement measurementComponent testers to test components such as 2-Pin Hall Effect Sensors, 3-Pin Hall Effect Sensors, and chainsNVH testersHardware and software interface with Hi-Pot testers to display and save test resultsVision Inspection SystemsElectrical control for pneumatic and hydraulic pressesQualifications:Advanced knowledge of and work experience (10+) in:Data acquisition systems such as NI hardware, Measurement and Computing and PLCs (Automation Direct family brands, Allen Bradly, Omron…), Arduino, Raspberry piTypes and functionality of sensors, for selection, design, implementation, and maintenance purposesIndustrial signal conditioners such as Dataforth and Analog DevicesBest practices for wiring, shielding, grounding, and signal noise cancelationPCB designWork Experience (10+) in:Drawing electrical schematics using AutoCAD, AutoCAD Electrical and VisioLabView, C, Ladder LogicCreating user-friendly PC-based Graphical Interfaces and HMIsSaving data to Microsoft Access and SQL databasesCognex Vision System and Barcode ScannersKeyence and Banner Engineering product linesStrong communication skillsOrganized, skilled in technical writing and thorough in documenting work",chi,de
31,American Medical Association,Non-Profit,3.7,IT Data Engineer II,"Chicago, IL",$62K - $119K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1136006&s=58&guid=00000178c1e798d4b5e1043a6a37dd6a&src=GD_JOB_AD&t=SR&vt=w&cs=1_5170ca75&cb=1618160884743&jobListingId=4053755897,"IT Data Engineer IIChicago, ILThe American Medical Association (AMA), a nonprofit, is the nation's largest professional Association of physicians. We are a unifying voice and powerful ally for America's physicians, the patients they care for, and the promise of a healthier nation. To be part of the AMA is to be part of our Mission to promote the art and science of medicine and the betterment of public health.As an employer, we are dedicated to many efforts, including employee learning and development, social responsibility, diversity and inclusion and wellness.Our well-defined culture has strongly impacted the prosperity of our organization. Our foundational values of Respect, Integrity, Innovation, Impact, Collaboration, Agility, Equity, and Trust are at the core of our efforts and continue to shape the success of the AMA.We have an opportunity at our corporate offices in Chicago for an IT Data Engineer II on our Information Technology team. As an IT Data Engineer II you will enrich and maintain enterprise data tools: data catalog, governance, and privacy. You will also connect to data systems and applications throughout the organization, tagging and curating the data assets, establishing automatic and manual data lineage, and build a centralized repository of technical and business metadata so stakeholders across the organization can find the most relevant and trusted data to forward their business initiatives. The IT Data Engineer II will identify and store technical and business metadata, intelligently discover and map relationships between data domains and enable usage by a wide variety of enterprise data stakeholders. Furthermore you will utilize the AI/ML features of the data catalog engine to scale to the enterprise, and ensure that the scanned data can be classified and remediated for data management and regulation adherence, including GDPR and CCPA.RESPONSIBILITIES:Cultivate integrated and well-managed data assets across the AMAContinuously enrich the data catalog as directed by manager by ingesting data from a wide variety of data sources, including relational databases, flat files, unstructured data, NoSQL data, ETL repositories, and reporting repositories: configure data sources, data domains, and their relationships within data catalog, data governance and data privacy modules.With manager and technical colleagues, continuously improve and optimize data definition, data quality, data profiling, and data lineage functionality available within data catalog tool suite.Create, maintain, and administer the data catalog, data governance and data privacy access model to ensure proper role-based groups can access the right information.Collaborate with Enterprise Data Office stakeholders to ensure proper integration of data catalog, data governance, and data privacy tools.Collect & understand data flows across the metadata ecosystem. Work with data owners, data stewards and data consumers to remediate issues and document data mapping within the data catalog and data governance tools.Participate in implementation, configuration, and support of technology supporting data assetsTechnical support of the data catalog, data governance and data privacy modules: including user setup, optimizing data scans, monitoring data tool suite, and system configuration.Establish data connectors, schedule updates and monitor services that extract technical metadata from a wide variety of data sources (data warehouses, reporting repositories, etc.).Establish system monitors, and manage upgrades, patch releases for data catalog, data governance, and data privacy tools.Support Desk Ticket Resolution (Internal and Informatica Ticket Resolution) based on Service Level Agreements (SLAs); escalate issues to technical leadership as appropriate.Coordinates application outages with technical and business stakeholders.May include other responsibilities as assigned.REQUIREMENTS:Bachelor’s Degree in Computer Science, Statistics, Information Systems or another related field3+ years of professional or technical experience required; preferred experience includes data analysis, data visualization data, mapping, data modeling, data profiling, or data reporting.Broad technical skills necessary, with a solid understanding of data systems and infrastructure.Previous hands-on experience with ETL, data profiling, and data lineage tools preferred.Data analysis and problem-solving skills are required to analyze system architecture, data models, and must have deep appreciation for data standards and quality.Experience learning and successfully applying new technologies.Knowledge and general understanding of the concepts and techniques of data architecture.Ability to work with cross functional teams, perform root cause analysis and resolve issues in a fast-paced environment.Written and verbal communication skills, including interpersonal skills and the ability to collaborate with technical and non-technical colleagues.Ability to express technical concepts effectively verbally and in writing.Ability to travel occasionally, work long hours and meet with vendors and high-level business leaders.The AMA offers competitive salaries, including an incentive plan; excellent benefits and progressive technology. Our office is a business casual environment and we respect work-life balance. The American Medical Association is located at 330 N. Wabash Avenue, Chicago, IL 60611 and is convenient to all public transportation in Chicago.We are an equal opportunity employer, committed to diversity in our workforce. All qualified applicants will receive consideration for employment. As an EOE/AA employer, the American Medical Association will not discriminate in its employment practices due to an applicant’s race, color, religion, sex, age, national origin, sexual orientation, gender identity and veteran or disability status.THE AMA IS COMMITTED TO IMPROVING THE HEALTH OF THE NATION",chi,de
58,"Darwill, Inc.",Business Services,3.9,Data Engineer,"Oakbrook Terrace, IL",$75K - $114K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178c1e8d332ba4a2ff49f5c6a27&src=GD_JOB_AD&t=SR&vt=w&cs=1_89281092&cb=1618160964916&jobListingId=3773882987,"Responsibilities/Essential Functions:Darwill is growing and we are looking to add a Data Engineer to our Data Science Practice. The Data Engineer will work as part of a collaborative team to build and maintain scalable data platforms that support data-informed decision-making across the organization.Build and maintain data infrastructure and manage data storage and useBuild data expertise and own data quality across the organizationDesign, build and launch new data models and efficient data pipelines (including ETL processes) in productionPartner with cross-functional teams of Account Executives, Data Scientists, and Software Engineers to understand data needs and deliver on those needsBuild and maintain reporting dashboards using BI tools like TableauSupport data processing and reporting at scaleTriage mission-critical issues and drive to resolutionSupport existing processes running in productionQualifications:Master of Science in Computer Science, Mathematics, or other technical field3+ years’ experience working in SQL and relational database management systems3+ years’ experience with dimensional data modeling, schema design, and data warehousing2+ years’ experience in ETL design, implementation, and maintenance2+ years’ experience with AWSAbility to write well-abstracted, reusable codeAbility to analyze data to identify deliverables, gaps, and inconsistenciesAbility to decompose and solve data problems and to find answers on ownVery strong communication skills and ability to work collaboratively with peers and stakeholdersVery strong work management skillsPreferred Qualifications:Experience in a Direct Marketing/Measurement companyExperience with data analyticsExperience with pythonExperience with AWS",chi,de
60,Kehe,Business Services,3.4,Data Engineer,"Naperville, IL",$54K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=25073&s=58&guid=00000178c1e8d332ba4a2ff49f5c6a27&src=GD_JOB_AD&t=SR&vt=w&cs=1_f8b35f45&cb=1618160964916&jobListingId=4055710552,"Overview

Good people, working with good people, for our common good.

Sound good?

KeHE-a natural, organic, specialty and fresh food distributor-is all about ""good"" and is growing, so there's never been a more exciting time to join our team. If you're enthusiastic about working in an environment with a people-first culture and an organization committed to good living, good food and good service, we'd love to talk to you!

Primary Responsibilities

The Data Engineer will assist in the design and implementation of a modern cloud data architecture that will enable KeHE to continue pushing the limits in the advanced analytics space. This role will work in close conjunction with the Data Science and Enterprise Data teams while also closely collaborating with other departments in the organization to construct scalable solutions that leverage both internal and external data sources. This person will possess a wide range of skills such as; creating reliable pipelines, sources and integrates the data, design and build optimized data delivery solutions. We are looking for an experienced data professional who will integrate traditional and emerging technologies to unlock greater efficiency and scalability of the data.

Essential Functions


Develop, construct, test and maintain optimal data pipeline/ETL architecturesWork closely within the team to prepare data for predictive and prescriptive modelingOptimize AWS data delivery infrastructure for greater scalabilityUtilize SQL as well as big data tools and frameworks to optimize data acquisition and preparation from enterprise data lake and data warehouseWork with Enterprise Cloud Architecture teams to strive for greater functionality in our data systemsDevelop architecture required to return data to data warehouse for front-end product utilizationCurate data models in the data warehouse to be used by front-end advanced analytics designersProvide production level code reviews for the teamHelp design, maintain and implement quality assurance and testing approachesDeploy scripts and architectures to production via Jenkins


Minimum Requirements, Qualifications, Additional Skills, Aptitude


Bachelor's Degree in Computer Science, Mathematics, Engineering, Management Information Systems or related field1-3 years of experience building data pipelines within the AWS ecosystem1-3 years of experience designing and implementing data warehouse solutionsAdvanced SQL and data design conceptsProficient programing experience using Python, R or similar language with experience building production level codeProficient working with Jenkins and deploying to production via Jenkin's jobsDesire to stay up to date with current technologies and best practices for data management and data scienceDrive innovation and efficiency through new approachesAbility to work in a team environment that promotes collaboration

Preferred Experience and Abilities:

Experience implementing AWS architecture using Serverless FrameworkUnderstanding of C programming languageExperience utilizing big data tools such as PySpark, Scala or others


Requisition ID

2021-9941
",chi,de
61,VMware,Information Technology,4.3,"Data Engineer - Opportunity for Working Remotely Chicago, IL","Chicago, IL",$93K - $111K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=00000178c1e8d332ba4a2ff49f5c6a27&src=GD_JOB_AD&t=SR&vt=w&cs=1_1d2ce867&cb=1618160964917&jobListingId=4054770165,"The Elevator Pitch: Why will you enjoy this new opportunity?This Data Engineer position provides a unique opportunity to grow your career by deepening your Analytics expertise and learning more sophisticated data science techniques to deliver better insights while also providing customer facing exposure. You will have opportunities to participate in design, by presenting data and valuable points of consideration to resolve problems. This customer experience is critical for anyone with a passion in data and analytics looking to broaden their business acumen.Success in the Role: What are the performance outcomes over the first 6-12 months you will work toward completing?Work with data engineering team to learn the environment and start delivering on solutions within 90 days. During this time frame, identify critical design and test issues needed to ensure an on-time delivery. Within 180 days, person should be able to pick up subject area independently and deliver the solutions.The Work: What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis?Most of your time will be spent analyzing data and writing high-quality code with excellent test coverage using Informatica/Python/HIVE/HANA/Spark and BOBJ/Tableau. You can expect to be the owner and take accountability for the quality of your code.Collaborate in-person and through Slack/Zoom or e-mail with data engineering team to brainstorm solutions.Spend time learning VMware’s standard operations, products, and improving your engineering and professional skills. We want you to be curious, learning both from team members and individual study.What is the leadership like for this role? What is the structure and culture of the team like?The hiring manager for this role is Arvind Panwar, Manager, Data Engineering, Sales. His expertise has been built from the frontlines with roles in Analytics solutions, program management and most recently in management of a data engineering team for the past one year.Arvind’s management philosophy is about encouraging everyone on the team to be independent thinkers and helping other team members. Arvind looks for people who can think out-of-the-box and then execute on a good idea. Innovation = Creativity and Execution.The core team is made up of three data engineers and 3 BI engineers software developers and close partnership with a member of other data engineering team. The team works flexible hours, arranging schedules to fit their needs and taking consideration for phone calls with global colleagues and business stake holders, primarily in US, EMEA, India and Costa Rica.What are the benefits and perks of working at VMware?You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com.Employee Stock Purchase PlanMedical Coverage, Retirement, and Parental Leave Plans for All Family TypesGenerous Time Off Programs40 hours of paid time to volunteer in your communityRethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilitiesFinancial contributions to your ongoing development (conference participation, trainings, course work, etc.)Wellness reimbursement and online fitness and wellbeing classesThis job requisition is not eligible for employment-based immigration sponsored by VMware.#LI-REMOTECategory : Engineering and TechnologySubcategory: Software EngineeringExperience: Manager and ProfessionalFull Time/ Part Time: Full TimePosted Date: 2021-04-07Cloud Management: VMware’s Cloud Management team delivers vRealize Suite, a solution that’s essential to accelerating our customers’ journey to digital transformation. It’s our market-leading, state-of-the-art cloud management platform designed to deliver and manage IT services across private, public, and hybrid clouds. VRealize Suite is an integrated, comprehensive solution that meets the challenge of managing a cloud infrastructure from a single pane of glass. We’re changing the way users design, build, view, and manage public and private clouds, and enabling them to run with optimal performance, insightful analytics and automated delivery. Join our user-focused team of software engineers, data scientists, web designers, product managers, and marketers. You’ll gain valuable experience in the fast-growing field of cloud infrastructure management from a pioneer and industry leader.VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",chi,de
62,Epsilon,Business Services,3.6,Software Engineer- Core Platform,"Chicago, IL",$76K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=1044074&s=58&guid=00000178c1e8d332ba4a2ff49f5c6a27&src=GD_JOB_AD&t=SR&vt=w&cs=1_f9f2387e&cb=1618160964917&jobListingId=3776046878,"Company DescriptionPositioned at Publicis Groupe's core, Epsilon is a leader in interaction management, empowering brands to transform ordinary customer experiences into meaningful, human experiences. Through a connected suite of products and services, Epsilon combines leading-edge identity management, industrial strength data and technology expertise with big brand acumen gained over five decades working with the industry’s top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands turn meaningful human interactions into exceptional business outcomes.Job DescriptionSoftware Engineer, Core Platform EngineeringFunctions as a member of the Ad server team writing high-performance, low-latency software for our world-class RTB and ad delivery platform.Seeking an engineer with a passion for writing performant, efficient, and maintainable code with test coverage. This engineer is expected to work effectively with a team of experienced software engineers in the area of backend Java development. They will work with leadership and peers to develop solutions grounded in provided requirements. The ideal candidate proactively seeks out and recommend new technologies and techniques to enhance the platform. Primary development language is Java.Key ResponsibilitiesImplement and maintain platform code and components.Provide subject matter expertise while interfacing with platform, operations, and engineering.Ensure features are covered with tests in support of our continuous integration environment.Assist with locating performance bottlenecks and troubleshooting critical production issues.Collaborate with peers in designing solutions across the stack.A successful candidate has…BS in Computer Science or related technical discipline or equivalent practical experience, 3+ years.Knowledge of high-performance software and clean architecture methodologies and principles.An expert command of modern object-oriented software.Bonus qualificationsExperience in the Ad Tech industryExperience working on low-latency, high-throughput software running on the JVM.Experience working with public cloud providers and technologies such as AWS, Azure, Kubernetes, and Docker.QualificationsAdditional InformationGreat People, Deserve Great BenefitsWe know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.Epsilon is an Equal Opportunity Employer. Epsilon’s policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.Epsilon will provide accommodations to applicants needing accommodations to complete the application process.#LI-AM1*REF23111W",chi,de
63,ThoughtWorks,Information Technology,4.2,Lead Data Engineer (remote),"Chicago, IL",$117K - $215K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=133270&s=58&guid=00000178c1e8d332ba4a2ff49f5c6a27&src=GD_JOB_AD&t=SR&vt=w&cs=1_d16ecdf3&cb=1618160964917&jobListingId=4030871969,"Chicago, Illinois, USAAre you at your most vibrant when you’ve successfully distilled data into its simplest, most meaningful form?ThoughtWorks is a global software consultancy with an aim to create a positive impact on the world through technology. Our community of technologists thinks disruptively to deliver pragmatic solutions for our clients' most complex challenges. We are curious minds who come together as collaborative and inclusive teams to push boundaries, free to be ourselves and make our mark in tech.As consultants, we work with our clients to ensure we’re evolving their technology and empowering adaptive mindsets to meet their business goals. You could influence the digital strategy of a retail giant, build a bold new mobile application for a bank or redesign platforms using event sourcing and intelligent data pipelines. You will learn to use the latest Lean and Agile thinking, create pragmatic solutions to solve mission-critical problems and challenge yourself every day.Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.You’ll spend time on the following:You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problemsYou will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challengesYou will collaborate with Data Scientists in order to design scalable implementations of their modelsYou will pair to write clean and iterative code based on TDDLeverage various continuous delivery practices to deploy, support and operate data pipelinesAdvise and educate clients on how to use different distributed storage and computing technologies from the plethora of options availableDevelop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutionsCreate data models and speak to the tradeoffs of different modeling approachesOn other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new productSeamlessly incorporate data quality into your day-to-day work as well as into the delivery processHere’s what we’re looking for:You are equally happy coding and leading a team to implement a solutionYou have a track record of innovation and expertise in Data EngineeringYou’re passionate about craftsmanship and have applied your expertise across a range of industries and organizationsYou have a deep understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and HadoopYou have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production settingHands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributionsYou are comfortable taking data-driven approaches and applying data security strategy to solve business problemsYou’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environmentsWorking with data excites you: you have created Big data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systemsAdvocate your data engineering expertise to the broader tech community outside of ThoughtWorks, speaking at conferences and acting as a mentor for more junior-level data engineersAssure effective collaboration between ThoughtWorks’ and the client’s teams, encouraging open communication and advocating for shared outcomesA few important things to know:While we’ve traditionally been a traveling consultancy, travel is not required for this role at the moment. We anticipate the need for travel to our client locations in the future when it’s deemed safe.Not quite ready to apply? Or maybe this isn’t the right role for you? That’s OK, you can stay in touch with AccessThoughtWorks, our learning community (click ""contact me about recruitment opportunities"" to hear about jobs in the future).It is the policy of ThoughtWorks, Inc. to provide a work environment free of discrimination. The Company will take affirmative action to ensure applicants and ThoughtWorks employees are treated without regard to race, color, religion, sex/gender, national origin, ethnic origin, veteran or military status, family or marital status, disability, genetic information, age, sexual orientation, gender expression or gender identity. This also includes individuals who are perceived to have any of the aforementioned attributes. ThoughtWorks will adhere to all federal, state, and municipal laws and regulations governing employment.",chi,de
0,xentity corporation,Information Technology,5,Data Engineer / Data Developer,"Golden, CO",$63K - $86K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044077&s=149&guid=00000178c1ed7f8382a36c09dd27fbe5&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_f4bf785c&cb=1618161271097&jobListingId=4057129052,"Data Engineer Data Developer - Denver, COWe are a fast-growing data consulting and support services firm - focused on large data programs in data types such as geospatial, open, big, and IoT data. We have high profile clients and projects that our staff really delivery for, as well enjoy knowing they make a large difference.This role supports data transformation platform engineering development and operations technical support. This includes support Open Data system management, ETL scripting, development support of open source and COTS ETL code and integrations to publish open data by providing infrastructure, web applications, harvest ETL processes, and general support. The role will manage an ETL environment to maintain dataset updates to a centralized portal, setup new ETL scripts for data management, for primarily publicly available data.Role Needs: *This role is the tech side of data: . While for a data solution, the effort is more technical in nature and will grow into lead developer efforts to more complicated solutions in cloud, DevOps, containers, and advanced script development in NodeJS, Python, etc.Lots of Client time.:  We’ll be working with clients to refine and groom requirements. Strong Communicator, enjoys client interaction, and can set realistic, achievable goals. We look for differentiators in staff who focus on client satisfaction, care about the mission, and have empathy for organizations adapting to this fast moving technology world.We are looking for candidates who think data is awesome: , like learning new leading edge tech, and thrive in rapid learning environments (new subject matter, complete with lingo, acronyms, other client context).Candidates enjoy working in Agile Kanban or Scrum environments : and are self-motivated environments - yes it is primarily a remote and virtual team. They like working with peers on requirements, design, and solution and believe ‘iron sharpens iron’.Capable of thriving in context switching environments.:  This may be most important as the data world changes fast. If you do not enjoy change, stop here. This role will require being on data engineer sprints that are on 2-3 data engineer tracks in similar domain and technology.Position Requirements: Bachelor’s degree preferred with min 3 yrs exp or Coding certifications with 5 or more years exp.: Ability to work multiple, time-sensitive tasks and rapidly context switch across subject matter, communication architecture products, and stakeholder audiences.Ability to work independently as well as as part of an integrated team.Excellent written communication skills.Demonstrate strong analytical and critical thinking skills.Strong foundation in Development and Operations Principles.Must be able to pass basic gov background, drug and reference checksTechnical Experience Required: Data Management: Metadata, ETL/Data Pipelines.Programming Languages: SQL, Python, Linux/Bash, Docker/containers.Development Practices: MVC, ETL, configuration management, extending code.Tools and Software: Familiarity with GitHub, G-Suite, Kanban boards, PostgreSQL.Preferred (Study up pre-interview is fine!)Experience with DevOps & infrastructure management tools (terraform, serverless, etc)Web Development Expertise (Front-end and back-end)Familiary (not expert) Open Data Metadata standards (ISO, DCAT, FGDC, Dublin Core)Experience with PHP & JavascriptBenefits: We emphasize a balance of work and life and target 40-50 hour weeks with ample time to refresh with great paid-time off.Salary & Bonus Programs - Competitive Salary. Multiple Recognition and Rewards Bonus Programs (Performance Bonus plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (6) Sick LeaveMedical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care with 100% of employee or 80% employee and 50% family. Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.About Xentity: Our President has a vision to continue to focus on solutions that transform the Next Generation. Using data integration, knowledge solutions, and amazing increases in computing to impact energy, geosciences, land management, we can bring quality and simplifications to existing and new data flow! Imaging being on a team that brings advanced concepts like high performance computing, AI, data science, fuzzy logic, changing interfaces human-computer points mobile or augmented reality and many more disruptions. This truly can put the I back in IT and GIS.... by concentrating on pragmatic knowledge-first data designs, leadership and management, and the all too forgotten focus on outreach and engagement strategies and solutions.Job Type: Full-timePay: $60,000.00 - $70,000.00 per yearSchedule:Monday to FridayWork Location:One locationWork Remotely:Temporarily due to COVID-19",co,de
1,Verizon,Telecommunications,4,Senior Javascript Engineer,"Denver, CO",$74K - $171K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_12a179c6&cb=1618161271097&jobListingId=4055312194,"When you join VerizonVerizon is a leading provider of technology, communications, information and entertainment products, transforming the way we connect across the globe. We’re a diverse network of people driven by our ambition and united in our shared purpose to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward – and you can too. Dream it. Build it. Do it here.What you’ll be doing...Verizon is serious about innovation. About being the first and being the best. Verizon Location Technology sits at the core of the Strategy and New Business Development organization and is a critical part of driving innovation across our global customer base, both inside and outside of Verizon. Backed by more than 50 years of location-based expertise, Verizon Location Technology is harnessing the power of location intelligence to build innovative, customizable and complex location solutions with end-to-end development for our customers. The team is bringing a new level of location awareness to devices using 5G and Multi-Access Edge Computing. This new mapping technology is enhancing our customer's current suite of products and will be a part of all autonomous computing technologies built by Verizon. Join us in building tomorrow with the best of today.As a Senior level JavaScript Engineer, you will be solving deep technical problems and building innovative solutions in a fast-paced environment working with smart and passionate team members. You will be working as part of our team driving, designing, creating and maintaining components of our mapping and location-based SDKs. You will work closely with product owners, additional stakeholders and software engineering teams to develop high-quality software.Design, build, and support the core Mapping and Service JavaScript SDKs for our B2D and Enterprise customers.Ensure that code adheres to defined standards and best practices for performance, speed, scalability, and quality.Practice Agile development methods and exemplify core values of transparency, collaboration, acceptance of change, and iterative development.Routinely deliver working software solutions that meet user story acceptance criteria.Facilitate technical conflict resolution with active listening and critical thinking.What we’re looking for...You are detail oriented, self-directed, self-motivated, with a strong capacity for working successfully and collaboratively with members across the organization. You possess an understanding of componentized web development, utilizing languages such as HTML 5, React, Java, Webpack, and Node.js.You’ll need to have:Bachelor’s degree or four or more years of work experience.Four or more years of relevant work experience.JavaScript / HTML / CSS experience, along with experience integrating with back-end systems.Experience in programming with NodeJS, React JS /Angular JS/ Ext JS, XML, HTML5, CSS3, JavaScript, ECMAScript 7, Object and mapping relationship frameworks (ex: Active Record), Flexbox Grid.Basic security frameworks experience XSA/CORS, SQL injection.Experience with CI/CD frameworks.Experience developing and calling RESTful Web services.Experience with cloud based services such as Amazon Web Services.Experience with containerization frameworks such as Docker and Kubernetes.Even better if you have:Sharp analytical abilities and proven design skills.Ability to write clear, self-documenting, and testable code.Demonstrated success in architecting new applications.Proficiency in Computer Science fundamentals - object oriented design, data structures, algorithms, design, problem solving, and complexity analysis.Knowledge of professional software engineering practices for the full software development life cycle including coding standards, code reviews, source control management, build processes, testing, and operations.Experience with Agile methodologies, OO modeling, web services, unit testing, code review, source control, UNIX, middleware, and databases.Experience in any spatial or mapping technologies.Proven track record of delivery.Experience working with geographically distributed teams and partners, including managing dependencies from internal / external partners.CompensationOur benefits are designed to help you move forward in your career, and in areas of your life outside of Verizon. From health and wellness benefits, short term incentives, 401 (k) Savings Plan, Stock Together, paid time off, parental leave, adoption assistance and tuition assistance, plus other incentives,we’ve got you covered with our award-winning total rewards package. For part-timers, your coverage will vary as you may be eligible for some of these benefits depending on your individual circumstances.If you are hired into a Colorado work location, the compensation range for this position is between $94,700 and $175,900 based on a full-time schedule. The salary will vary depending on your location and confirmed job-related skills and experience. This is an incentive based position with the potential to earn more. For part-time roles, your compensation will be adjusted to reflect your hours.Equal Employment OpportunityWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best.Check out our diversity and inclusion page to learn more.",co,de
2,"Alteryx, Inc.",Information Technology,3.6,Lead Software Engineer - Tools and Infrastructure,"Broomfield, CO",$121K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_4c888b9a&cb=1618161271098&jobListingId=4025183705,"We’re looking for problem solvers, innovators, and dreamers who are searching for anything but business as usual. Like us, you’re a high performer who’s an expert at your craft, constantly challenging the status quo. You value inclusivity and want to join a culture that empowers you to show up as your authentic self. You know that success hinges on commitment, that our differences make us stronger, and that the finish line is always sweeter when the whole team crosses together.Position Overview:Come join our Quality System Engineering team and develop robust test engineering frameworks. The team’s mission is to enable development teams to deliver high-quality software through framework, tooling, and risk management capabilities. This role will be perfect for you if you have an unwavering passion for, and focus on, high-performing and scalable products, engineering excellence, and engineering productivity.Drive testing framework and tooling strategy to support Alteryx products.Participate in architectural design forums to ensure non-functional system considerations are incorporated and fully testable.Consult with technical leads across engineering to review software component interfaces and capture framework capability requirements.Advise the Product Engineering team to provide software improvement recommendations and highlighting risk areas.Analyze field quality issues in partnership with accountable team to derive RCA and identify Corrective Actions outcomes.Foster a culture of engineering enablement, providing domain specific knowledge and best practices across Engineering (katas, training, demos).Build robust and scalable CI/CD pipelines to ensure only the highest quality software is released.Act as a customer advocate, committed to delivering quality throughout the company.Required Skills:5+ years as a Software Engineer with emphasis on component and integration testing for native and web-based product architecturesDesigned and developed reliable testing frameworks that enable full coverage and execute within a CI/CD pipelineExperience with scalable testing technologies, including Jest, TypeScript, Pytest or similarDemonstrated proficiency with JavaScript or Python and web driver libraries, utilizing standard patterns to develop complex methods with measurable outcomesOutstanding written and verbal communication across globally distributed teamsProven innovator with a track record of implementing quality improvement plansValued Skills:Data analytics experience: Python, R, AlteryxData Science: ML and/or AI modelingCompensation:Alteryx is committed to fair and equitable compensation practices. The salary range for this role in Broomfield, CO is $117,000 to $198,900. This position is also remote-friendly and, as such, compensation will ultimately be in line with the location in which the position is filled. Final compensation for this role will be determined by various factors such as a candidate’s relevant work experience, skills, certifications, and geographic location. This role is eligible for variable compensation including bonus and stock grants.#LI-CP1Find yourself checking a lot of these boxes but doubting whether you should apply? At Alteryx, we support a growth mindset for our associates through all stages of their careers. If you meet some of the requirements and you share our values, we encourage you to apply. As part of our ongoing commitment to a diverse, equitable, and inclusive workplace, we’re invested in building teams with a wide variety of backgrounds, identities, and experiences .Benefits & Perks:Alteryx has amazing benefits for all Associates which can be viewed here .",co,de
3,Excelitas Technologies,Manufacturing,3.3,Customer Quality Engineer,"Boulder, CO",$58K - $96K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_150c440b&cb=1618161271098&jobListingId=4055240647,"Overview:Responsible for coordinating customer quality assurance requirements into company quality management processes and deliverables. Drives continual improvement, customer-focused quality partnership, and ISO 9001 compliance consistent with REO’s needs.This role is responsible for supporting and maintaining the site Quality Management System to conform to the currently released versions of ISO9001 and customer and regulatory requirements as applicable.This role reports to the Quality Systems Manager.Duties and Responsibilities:Participate and contribute in New Product Introduction process and understand specification development and verification for transition to production:Planning and ensuring product quality as per specifications during the project and in the series,Compliance with the legal requirements (for example, CE, ...) and the ongoing changesCreation of test planningVerification of prototype and preproduction series (DVTP)Planning product quality and process quality (control plan) and the documentationCombining the product test results and their evaluationImplementation of risk management and coordination with notified bodiesPresentation and documentation of design reviewsCoordinating customer first article inspectionPresentation and dissemination of Lessons LearnedAct as the direct customer interface for quality-related matters for assigned customers.Modify quality performance analysis and reporting to meet customer requirementsMonitor Return Material Authorization retest and FA cycle time for assigned customers.Participate in the MRB programCoordinate process analysis and improvement through the implementation of statistical tools and Six Sigma methodsProfessionally manages customer communications regarding quality escapes, repaired product turn-around time and status (SORMA), correlation of testing parameters and deviations to specifications, when required.Support and where applicable conduct internal and external auditsParticipate in specific production yield improvement projectsQualifications:Bachelor’s Degree in engineering, math, science or technology or a combined seven years’ experience as a Manufacturing Engineer or Quality Engineer.Minimum five years’ experience in a manufacturing environment.ASQ Certified Quality Engineer is desired.Excellent customer-facing ability.Working knowledge of ISO 9001.Familiar with FAR/DFARS and flowdown of quality assurance requirementsFormal training in statistical techniques in a manufacturing environment; Lean and Six Sigma training and certification highly desired.Strong data mining and analysis skills.Ability to take responsibility for quality of all products including assembly, testing and yields.Experience in NPI process management and product quality planning is a big plusUnderstanding and familiar with design control processes including: design review processes, manufacturing process instructions, MRB, failure analysis and corrective/preventive actions and verification testing is highly preferred.Proficient in MS Office and MS Project is preferred.Benefits: Medical, Dental, Vision, 401K, Paid Time Off, Holiday Pay, Tuition Reimbursement, Long term and Short-term disabilityPay Range $59,000 - $80,000 DOEThis position requires the use of information, which is subject to the International Traffic in Arms Regulations (ITAR)Visa sponsorship is not available for any position at ExcelitasEqual Opportunity/Affirmative Action EmployerMinorities/Females/Disability/Veteran/Gender Identity/Sexual Orientation#LI-KR1RequirementsWe are looking for a Customer Quality Engineer for our manufacturing company. This person is responsible for coordinating customer quality assurance requirements into company quality management processes and deliverables. Drives continual improvement, customer-focused quality partnership, and ISO 9001 compliance consistent with REO’s needs. This role is responsible for supporting and maintaining the site Quality Management System to conform to the currently released versions of ISO9001 and customer and regulatory requirements as applicable. This role reports to the Quality Systems Manager.PLEASE READ AND AGREE TO THE STATEMENT BELOW TO PROCEED AND SUBMIT YOUR APPLICATION FOR THIS ROLE:Thank you for your interest in Excelitas. We respect your privacy. We need your consent to save your contact information and CV and for you to confirm that we can contact you in the future. Please know that Excelitas will never share or sell your contact data.",co,de
4,Perspecta,Aerospace & Defense,3.6,Software Engineer and Integrator,"Colorado Springs, CO",$53K - $111K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_ccce6c96&cb=1618161271098&jobListingId=4000848544,"Business Group HighlightsIntelligenceThe Intelligence group provides high-end systems engineering and integration products and services, data analytics and software development to national and military intelligence customers. Serving federal agencies and the Intelligence Community for more than 50 years, the Intelligence group helps our clients meet their mission needs by providing trusted advisors, leading-edge technologies, and innovative solutions.ResponsibilitiesPerspecta is seeking an experienced Software Engineer to lead an agile approach to software integration between multiple segments The Ground Systems Software Engineer and Integrator will support the Ground Segment Team on a new program at Perspecta, focused on systems engineering and integration of a new Space Domain architecture with a new Ground System. The Ground Systems Software Engineer and Integrator will support the overall software architecture to include the internal and external system interfaces including any operator displays and controls. The Ground Systems Software Engineer will identify, describe, and decompose into fine-grained software services that meet system functional, performance and resilience requirements. The Ground System may leverage Commercial Cloud Services for Infrastructure, Platform, and Software as a service (IaaS, PaaS, SaaS) to meet system security, scalability, redundancy, and resilience requirement, and recommend the best incorporation of DevSecOps practices and methodology into the development of Ground System software to meet program cost, schedule and performance objectives. This is an opportunity to start at the ground level to shape and design the software support to a future Ground System. Specific duties include:Attend and participate in software design and development reviews; track, assess, and advise the Government on software technical execution; and review critical software technical documentation.Monitor the development of the System's software and identify software risks and opportunities for inclusion in the System ROM Program.Lead an Agile Team across the Space Segment and Ground Segment, leveraging DevSecOps principles to ensure cyber security requirements and best practices are incorporated and addressed early in the development process.Recommend cross-functional teams that support all application development and operations activities defined in this task. Capacity of a team shall be monitored and measured using stories to ensure optimal productivity.Plan, analyze, and design all ground software and provide the following products:Software Development Plan (SDP), Software Requirements Specification (SRS), Software Design Description (SDD), Software Test Plan (STP), Software Test Report, Software Architecture Description, and Software Product Specification (SPS).QualificationsRequires 10 to 12 years with BS/BA or 8 to 10 years with MS/MA or 5 to 7 years with PhD.Required Skills:BS or BA degree in information systems, computer science, system analysis with an emphasis in information technology.Software architect experience (e.g., infrastructure/technical, solution/application, information/data, security/provisioning or enterprise/business).Very strong technical knowledge of cloud technologies and IT concepts specifically Amazon Web Services (VMWare, HyperV, Cisco, CA Technologies, Microsoft, EMC, etc.)Satellite ground systems knowledgeKnowledgeable about AWS infrastructure offerings.Knowledgeable about AWS service offerings.Experience with acquisition processes and space, ground or communications systemsDemonstrated capability and success working in team environmentsStrong communication and briefing skills with peers and senior leadersExcellent ability to work within team structureCustomer focused and capable of representing the customer in community formsDesired QualificationsExperience with application / data migration to AWSKnowledge of DevOps principles and Container platforms such as Docker and KubernetesExcellent written and verbal communication skills; Ability to effectively communicate technical information to managersMandatory Certifications: AWS Certified Solution Architect or AWS DevOps EngineerThe Colorado Equal Pay for Equal Work Act requires employers in the state of Colorado to disclose the following information. If the position applied to is not located in Colorado, the following information may not apply. Salary Minimum: $82,992.00 Salary Maximum:$177,424.00 The base salary range above represents the low and high end of the Perspecta salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and paid time off (PTO).About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
5,SCRAM Systems,N/A,3.9,Senior Mechanical Engineer,"Denver, CO",$99K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_175afc8a&cb=1618161271099&jobListingId=4000320968,"Job Description:ESSENTIAL FUNCTIONS AND BASIC DUTIESDesign, develop, analyze, and test mechanical components used in portable, ruggedized electronics and cellular products; taking complete ownership of mechanical design / electronics packaging for assigned projects. Typically act as sole mechanical engineer on a cross-functional team.Create CAD models and engineering drawings for parts and assemblies.Review with Test Engineering, Manufacturing Engineering, Supply Chain, and Quality to ensure DFM, DFA, and DFT aspects are inherent part of design.Work closely with Test Engineering and Manufacturing Engineering to design mechanical portion of test and assembly fixtures.Contribute to bringing ideas through prototyping, proof-of-concept, testing, and implementation.Act as mechanical project lead with design tActively participate in cross-functional efforts to improve technology, increase product performance, reduce costs, find root cause of product issues, correct design defects, and address supplier and material quality issues.Required Experience:Skills and Abilities:Track record of applying mechanical engineering principals to design successful electronics products beyond just 3D CAD design. Examples including strength of materials, stress analysis, dynamic shock / impact analysis, thermal / heat transfer analysis, fluid mechanics, and materials science.Experience designing parts and assemblies fabricated from a wide variety of manufacturing processes including injection molding, machining, stamping, and screw machining.Experience designing products containing complex printed circuit board assemblies and antennas; and knowledge of printed circuit board fabrication and SMT assembly processes.Expertise in SolidWorks 3D modeling and 2D drawing.Familiarity and experience conducting various environmental and reliability tests such as shock, vibration, and temperature.Experience using a variety of problem solving techniques and ""quality"" tools such as DOE, statistical analysis, FMEA, TQM, root-cause-analysis, and Taguchi techniques.Proven communication and teamwork skills.Education and experienceBS degree in Mechanical Engineering with minimum of 8 years’ experience designing portable, ruggedized, electronics or cellular products, orBS degree in Mechanical Engineering Technology with minimum of 10 years’ experience designing portable, ruggedized, electronics or cellular products.COMPENSATION AND BENEFITS:AMS offers a competitive compensation and benefits package:Medical, dental, visionLife and disability plansGenerous time off policies401k with company matchHeath savings account and flexible spending accountsEmployee Assistance Plan ProgramEducational opportunities including seminars, conferences, tuition reimbursement programHiring Salary Range: $103,000.00 to $114,000.00 annualized (Compensation to be determined by the education, experience, knowledge, skills, and abilities of the applicant, alignment with market data and internal pay scales.)All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.From: SCRAM Systems",co,de
6,ANB Bank,Finance,2.8,Data Analyst,"Denver, CO",$37K - $67K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_30d59c4f&cb=1618161271100&jobListingId=4057806664,"DescriptionANB Bank hires individuals who provide excellent customer service and build meaningful relationships with our customers and within our communities. ANB is committed to rewarding our team members who strengthen our company and culture. ANB offers competitive compensation and a comprehensive benefits package for this position.Hiring Pay Range: $50,000.00- $60,000.00 per yearBenefits package offered, subject to eligibility requirements, includes:Company subsidized Medical, Dental, and Vision Insurance available for Employee, Employee +Spouse, Employee +Child(ren), and Employee +FamilyHealthcare and Dependent Care Flexible Spending AccountHealth Savings Account and Limited Purpose Flexible Spending Account for High Deductible Health Plan (HDHP)Company Provided Employee Life, Employee AD&D, and Long-Term Disability InsuranceSupplemental Life Insurance for Employee, Spouse, and Child(ren)Supplemental AD&D Insurance for Employee and SpouseShort-Term DisabilityDiscretionary Annual Bonus and 401(k) MatchPaid Vacation, Sick, and Holiday TimeEmployee Banking ServicesANB Bank is committed to providing Equal Opportunity in Employment. The Bank is continually trying to improve recruitment, employment, development and promotional opportunities for its employees. Our selection decisions are based on job-related factors and not on the basis of age, race, sex, color, religion, national origin, disability, sexual orientation, veteran status, or any other status protected by federal, state, or local law.SUMMARYAs a Customer Care Center Representative for ANB Bank, you will provide client service to respond to questions/concerns and assist through resolution of various issues. Facilitate product acquisition through various channels of the Bank (e.g. phone, e-mail, online-chat, and internet). Gather information and close on product sales demonstrating intermediate skills and knowledge of ANB Bank products and benefits. Identify customer events to provide solutions on products and close on product sales that meet the customer's needs and facilitate the customer's financial security through relationship sales. Empathize with customers and provide offers & solutions to make it easy for customers to acquire an ANB Bank product. Live the brand - We are a Bank like no other, expect more.ESSENTIAL DUTIES AND RESPONSIBILITIES include the following:Maintains current knowledge and consistent compliance with Bank Secrecy Act (BSA)Independently analyzes business needs and data resources to propose, create and maintain operational and technical reporting from various applications and databases.Manages data quality of the data warehouse, working with technical teams to ensure confidentiality, integrity and availability of dataManages operational and data reporting processes and ensures reports are available when needed.Will participate in strategic thinking sessions and manage relationships with operational groups for reporting needsWorks with senior management to prioritize report development and data acquisitionIndependently mines data through advanced computerized models and on an ad-hoc basis to extrapolate patterns and trends of the business.Participates in multidiscipline, high-performance work teams/groups, preferably in a leadership capacityExhibits excellent analytical and problem solving skills, including the ability to accurately gather, analyze and interpret data, identify and define problems, and make recommendations for resolution. This includes effective troubleshooting and managing technical escalations.Gather and analyze information relevant to current and new products and servicesRoutinely complete complex assignments requiring independent action and a high degree of initiative to resolve issues with consistency and accuracyParticipate in and/or chair project meetings, documenting issues, action items and able to provide status updates and information on assignmentsEffectively interact with employees, vendors, contractors, and senior managementProvide leadership, management, and strategic support for a variety of large- and small-scale projectsWork closely with technology managementTravel to various banking locations and working non-standard hours will be required from time to timePerform other duties as required by supervisorOther duties may be assignedEDUCATION and/or EXPERIENCEBachelor’s degree in Mathematics, Economics, Business, Computer Science, or a related discipline and 4 years related experience and/or training; or equivalent combination of education and experience. Minimum of 3 years’ experience with Microsoft Office Suite including PowerPoint, Excel, Word and Outlook required. General understanding of banking products, services, forms, and regulations preferred.Equal Opportunity Employer / Affirmative Action / Minorities/Female / Disabled / Veteran",co,de
7,LOCKHEED MARTIN CORPORATION,Aerospace & Defense,4.1,Data Engineer,"Littleton, CO",$75K - $118K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=133498&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_a4118ed5&cb=1618161271100&jobListingId=4024614459,"The coolest jobs on this planet… or any other… are with Lockheed Martin Space. Lockheed Martin is a pioneer, partner, innovator and builder. Our amazing people are on a mission to make a difference in the world and every single day we use our skills and experiences to create, design and build solutions to some of the worlds’ hardest engineering problems.The Data and Analytics Center of Excellence (COE) is a new department under Space’s Business Innovation, Transformation and Enterprise Excellence (BITEE) organization responsible for innovation across the Space enterprise.We are establishing a new Data Governance and Management platform and need a motivated engineer to help us discover, collect, transform and analyze datasets across Space. This full-time position will involve:Understanding of systems engineering principles to design and implement solutions that span the data lifecycle: collect, ingest, process, store, persist, access, and deliver data at scale and at speedAssisting on tasks defined by the bi-weekly Space Data Governance Board. The candidate will have the opportunity to interface with data stewards and subject matter experts across the entire Space functional and program organizationsSearching for and collecting information on various data topicsPerforming data analysis and metricsWorking with local, distributed and cloud-based technologies; data virtualization and smart caching and the data security required to protect and access the dataBuilding data pipelines that clean, transform and aggregate unorganized data into databases or data sourcesAssisting with creating conceptual, logical and physical data model designs, data extract/transform/load processes, reporting and analyticsThe ideal candidate will have a demonstrated interest in data with an engaging, problem solving mindsetBasic Qualifications:Proficiency with languages/tools such as SQL, Python, R, and/or GitThe ability to develop or script tools that efficiently preprocess, modify, aggregate, load, index, and archive large data collectionsDatabase experience with Microsoft SQL Server, PostgreSQL or OracleDesired Skills:Experience with agile development practicesExperience with statistics and statistical modelingProficiency with visualization tools such as Tableau and BrainspaceExperience with relational/structured database development/designExperience with non-relational/unstructured, graph or big data database development/designExperience with data virtualizationData Security, data access methods and authentication/authorization protocolsIntellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problemsStrong analytical and critical thinking skillsBASIC QUALIFICATIONS:job.QualificationsLockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.EXPERIENCE LEVEL:Experienced Professional",co,de
8,Inovonics,Telecommunications,3.6,Sr. Test Engineer,"Louisville, CO",$95K - $120K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1044077&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_71e77cec&cb=1618161271101&jobListingId=3820772152,"Salary range $85k - $95kPOSITION TITLE:  Sr. Test EngineerREPORTS TO:  Test Engineering ManagerSUMMARY OF POSITION: Provides technical support for the development, implementation, maintenance, and improvement of test systems used in the manufacture of wireless products and accessories.DUTIES AND RESPONSIBILITIES: · Ensures all electronic assemblies and finished products meet functional test specification and quality standards.· Key member of the test system design team involved with test specification development, test hardware and software design review, and implementation for new and existing products.· Develops product test specifications and plans along with interface requirements, flow and strategy.· Plans, designs, develops and implements automation scripts for tests.· Executes test cases, publishes test reports and generates tickets for bugs and issues.· Plan, propose, and justifies cost-effective factory test capability and capacity including ICT, board-level and sub system-level functional tests, and automation.· Evaluates and applies design-for-test (DFT), design-for-manufacturing (DFM), and built-in-test (BIT) strategies and lead the manufacturing test development effort to include test hardware (fixture) & software requirements.· Provides Tier 2 Technical Support (S/W & H/W) to end users of ES products and Inovonics SW products.QUALIFICATIONS: · BSEE or MSEE with 4+ years of test engineering or product development experience, preferably in volume wireless electronic manufacturing.· Superior and proven knowledge of analog or RF circuit analysis, electronic theory, and test instrumentation, with “hands-on” electronic troubleshooting experience, to the component-level.· Experience recommending, developing, and implementing test strategies.· Experience with product and test fixture verification, qualification, and validation requirements.· Experience with DBMS and statistical analysis tools for data analysis, and report generation.· Strong written and verbal communication skills and ability to work in cross-functional teams.· Proven self-starter with initiative, creativity, and excellent problem-solving skills.EDUCATIONAL REQUIREMENTS: · BSEE or MSEE· Supervisory, management, or project management experience is a plusCOMPENSATION AND OTHER: Commensurate with experienceInovonics values diversity of thought and background and provides equal employment opportunity to all qualified applicants without regard to race, color, religion, national origin, gender, sexual orientation, age, veteran status, or disability.Job Type: Full-timePay: $85,000.00 - $95,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programFlexible scheduleFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offParental leaveRetirement planTuition reimbursementVision insuranceSchedule:Monday to FridaySupplemental Pay:Bonus payEducation:Bachelor's (Preferred)Work Location:One locationCompany's website:https://www.inovonics.com/Work Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",co,de
9,Amazon.com Services LLC,Information Technology,3.8,Data Engineer - Advertising Analytics Data Pipeline,"Boulder, CO",$71K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=133043&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_d3a0963c&cb=1618161271101&jobListingId=3773341553,"3+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQLBachelor's degree in computer science, engineering, mathematics, or a related technical discipline5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasetsDemonstrated strength in data modeling, ETL development, and data warehousingExperience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, Presto, etc.)Knowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingProficiency in, at least, one modern scripting or programming language such as Python, NodeJS, Java, or Scala.Are you passionate about using Big Data to build customer trust and grow new business? Global advertisers rely on our team's performance insights to drive future investment in Amazon's Advertising Platform and improve the relevance of ads shown to customers. We are looking for passionate Data Engineers to own and optimize the big data pipeline that consumes the massive data sources we require to generate unique insights. Data is at the center of every product we will develop as we create brand new systems that serve the needs of our large and growing base of advertisers.You will share in the ownership of the technical vision and direction for advanced analytics and insight products. You will be a part of a team of top notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence. Members of this team will be challenged to innovate using big data technologies. We are looking for people who are motivated by thinking big, moving fast, and changing the way customers use data to drive profitability. If you love to implement solutions to hard problems while working hard, having fun, and making history, this may be the opportunity for you!Amazon is well positioned to grow its share of a fast growing online advertising industry due to its unique assets - e-commerce data, service oriented architecture, and startup culture. Be part of a team of industry leading experts that builds and operates one of the largest big data analytics platforms at Amazon. Amazon is applying the latest machine learning and big data technologies available to change the way marketers purchase, track, measure, and optimize their advertising spend. We apply these technologies on terabytes of data (over 10B new events per day) and operate clusters that push scalability limits of the existing technologies. We seek to measure every possible signal indicating impact of advertising to provide the most objective result of marketing spends.For Colorado-based jobs: This position starts at $97,600 per year. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a range of medical, financial, and/or other benefits, dependent on the position offered. For more information regarding Amazon benefits, please visit https://www.amazon.jobs/en/benefits. Applicants should apply via Amazon’s internal or external careers site.Experience working with and tuning AWS big data technologies (EMR, Spark/Hive, S3). Experience working with SQL based systems and building data pipelines.Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.#adsto #madsjob",co,de
10,Perspecta,Aerospace & Defense,3.6,Ground Systems Requirements Engineer,"Colorado Springs, CO",$44K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_07ef0d06&cb=1618161271101&jobListingId=4000868243,"Business Group HighlightsIntelligenceThe Intelligence group provides high-end systems engineering and integration products and services, data analytics and software development to national and military intelligence customers. Serving federal agencies and the Intelligence Community for more than 50 years, the Intelligence group helps our clients meet their mission needs by providing trusted advisors, leading-edge technologies, and innovative solutions.ResponsibilitiesThe Ground Systems Requirements Engineer will support the Ground Segment Team on a new program at Perspecta, focused on systems engineering and integration of a new Space Domain architecture. The Ground Systems Requirements Engineer supports the requirements development, decomposition, flow down, verification and validation across the entire lifecycle from concept to disposal for the ground system. The Ground System will consist of hardware and software architecture as well as all internal and external system interfaces, including operator displays and controls. The Requirements Engineer shall support trade studies that provide recommendation on the potential use of Commercial Cloud Services in the Ground’s Infrastructure, Platform, and Software as a service (IaaS, PaaS, SaaS) to meet security, scalability, redundancy, and resilience requirements. The Ground System requirements are iteratively matured through the systems engineering lifecycle. Specific responsibilities include:Support system requirements verification, validation, and traceability activities.Use Model-Based Systems Engineering approach from design through production.Support the preparation of all lifecycle readiness reviews including entry and exit criteria. , action items and liens issued at the reviews, and the production of review briefing materials. Reviews include system and various segment SRRs, SFRs, PDRs, CDRs, and other reviews as required, requiring the preparation and update of baseline requirements.The Ground System Requirements Engineer designs, develops, evaluates and modifies end-to-end systems and systems-oriented products through their entire life cycle, generates quantifiable requirements based on customer description, system planning and design, and acquisition logistics, and ensures requirements comply with client requirements and government standards through formal verification methods.QualificationsRequires 5 to 8 years with BS/BA or 3 to 5 years with MS/MA or 0 to 2 years with PhD.Required skills:Hold an active Top Secret ClearanceExperience with satellite and satellite ground systems (requirements, acquisition, development, or operation)Understanding of all aspects of the requirements formulation and validation and ability to assess program requirement risk areas and to programs design baseline cost and acquisition schedules.Possess a strong Ground Systems Engineering background across the TCPEDExperience with system design, development, integration, and testingExperience with System Integration, identifying key integration pointsAbility to represent key decisions and identify risks to the customerDesired Qualifications:Bachelors of Science Degree in Science, Technology, Engineering or Mathematics (STEM)Ability to organize and prioritize numerous customer requests in a fast pace deadline driven environmentExperience supporting IC or DoD in Systems Engineering and Systems IntegrationPossess SAFE Agile certification and ability to apply agile practices to deliveryPossess AWS certificationThe Colorado Equal Pay for Equal Work Act requires employers in the state of Colorado to disclose the following information. If the position applied to is not located in Colorado, the following information may not apply. Salary Minimum: $67,017.60 Salary Maximum:$143,291.20 The base salary range above represents the low and high end of the Perspecta salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Perspecta's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Perspecta provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and paid time off (PTO).About PerspectaWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector—from investigative services and IT strategy to systems work and next-generation engineering.Our promise is simple: never stop solving our nation’s most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to do just that, as a partner of choice across the entire sector.Perspecta is an AA/EEO Employer - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.As a government contractor, Perspecta abides by the following provisionPay Transparency Nondiscrimination ProvisionThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of the other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c).",co,de
11,Sambasafety,Information Technology,4.8,Data Engineer,"Denver, CO",$63K - $121K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=4341&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_8323a174&cb=1618161271102&jobListingId=3821709638,"Data Engineer

Who we are:

Hi, were SambaSafety and we offer the industrys most comprehensive driver monitoring software. Our technology helps everyone from large corporations to small companies ensure only the safest individuals are driving on behalf of their business. These companies trust SambaSafety to keep their employees safe on the roads, helping protect their brand, greater community and bottom line. Simply put, we save lives and are on a mission to reduce crashes on American roadways 20 percent by 2025.

Weve built an inclusive, supportive, and exceptional culture where every employee is empowered in their role. Dont take our word for it; weve been recognized as a Top Workplace by The Denver Post and Built In Colorado. And our employees rate SambaSafety top-notch, with a rock solid 4.7-star rating on Glassdoor.

Our environment is very unique in that we deal with a multitude of data sources to support our data driven safety strategies. This means that we are always seeking new ways to challenge the status quo when it comes to solving problems. There is never a shortage of ways to challenge your mind and grow when you are a SambaSafety Engineer. This manifests in not only the tech we use but also the practices and methodologies we employ to reach our goals.

What Youll Do:

Data Movement at a large scale.Code for and architect streaming pipelines to include data acquisition, staging, as well as integration of new data sources.Implement data classification of incoming data and manage access control.Develop transformation processes for handling batch and streaming data.Participate in discussions around dimensional analysis and entity resolution for a complex disparate data sourced system.Provide data usage pattern for analytics, API and other consumption patterns from target data store.Build an CICD automation pipeline facilitating automated deployment and automated testing.Deliver end to end comprehensive documentation along with code samples for other teams to leverage.Most importantly you will be part of a team that is raising the bar when it comes to data, data movement and data stewardship. Working in a unique environment of build it, test it, support it, own it that makes your daily contributions something you can be proud of.

What youll need:

Degree in Computer Science, Software Engineering, or a related discipline.3+ years experience with ETL tools and or streaming concepts3+ years Java development experience, or an equivalent language with a desire to learn new things.Strong knowledge of modern software engineering principles, patterns and best-practices.Understanding of micro-services architectures.Experience designing and supporting high traffic, highly available systems.Strong communication skills. The ability to effectively explain technical concepts to team members, architects and team leads.Extensive experience deploying software to a cloud platform environment. AWS, GCP, Azure.Understanding of modern Devops concepts. Docker, Kubernetes, Serverless, Terraform.Experience with NoSQL, as well as relational data stores. PostgreSQL, Mysql, RedshiftDB, Redis, Cassandra, Snowflake, etc.Experience with distributed messaging and streaming technologies, RabbitMQ, Kinesis, Kafka, Spring cloud data flow, NiFi.Some exposure to Hadoop, Hive, Spark, PrestoDB.Capable of delivering on multiple competing priorities with little supervision.

Benefits and Perks:

Unlimited Paid Time Off and Paid Volunteer Days401k match and generous Healthcare Benefits including a fully employer paid family medical planWellness &Tuition ReimbursementZoom Happy HoursFlexible Work From Home schedule & a Monthly Internet stipendLots of Samba swagSamba Virtual Events including our famous Samba SprintA chance to work with some of the brightest minds in technology

Our team of talented and committed safety professionals is exceptional. At SambaSafety we strive to foster an inclusive culture that supports, encourages and celebrates a wide array of diversity. We are committed to create a space where all employees can show up as their authentic selves every day, and we work to advance employee equality, diversity and inclusion.

SambaSafety provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, gender identity, and expression or genetics.

Come join us to find out for yourself what all the excitement is about!

Powered by JazzHR",co,de
12,Verizon,Telecommunications,4,Front End Software Engineer,"Lone Tree, CO",$86K - $137K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_95cf4917&cb=1618161271103&jobListingId=4055309232,"When you join VerizonVerizon is a leading provider of technology, communications, information and entertainment products, transforming the way we connect across the globe. We’re a diverse network of people driven by our ambition and united in our shared purpose to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward – and you can too. Dream it. Build it. Do it here.What you’ll be doing...We are honored that you are considering Visible as your next place of employment. Visible is the first all-digital wireless carrier in the U.S. Named by Fast Company as one of the most innovative companies in the world, Visible offers unlimited messages, minutes, and data, on Verizon’s Network. Visible is designed to fundamentally change the way millions of consumers sign up for and manage their phone service. Although headquartered in Denver, we have a permanent Work from Home Structure, and our team members work remotely.The position is for a Front End Software Engineer. You will be working as part of our team driving, designing, creating and maintaining components of our websites.Work with internal visible team and Partners to build the UI / UX and wireframes for the new company web and back-end applications in an Agile / DevOps environment.Provide senior-level proficiency and direction on following Tech stack:React (preferred), Angular, Java, Webpack, Node.js, HTML 5.Track progress of multiple project plans/Sprints.Review project approach framework and designs with engineering staff and Product team, analyze the feasibility on the approach, and identify potential risks/issues.Work with Product manager and UX team to assist and drive the “best in class”, intuitive, engaging and simple customer interaction.Work with Product and Design teams to drive customer journey for mobile and web experience.Participate in UX research and usability.What we’re looking for...We need people who love modern, responsive web page designs. We're looking for innovative engineers who are passionate about writing code and unafraid of solving big problems. You will bring creative ideas and energy to a team, take some risks, and challenge our thinking. You possess an understanding of web development, utilizing languages such as React.js, Angular.js, Java, Webpack, and Node.js.You'll need to have:Bachelor’s degree or one or more years of work experience.Even better if you have:A Degree.Experience in Full Stack development across HTML 5, React, Angular JS, Java, Webpack, Node.js.Experience with Agile (SCRUM, Kanban, XP), OO modeling, web services, unit testing, code review, source control (git, subversion).Knowledge in Computer Science fundamentals – object oriented design, data structures, algorithms, design, problem solving, and complexity analysis.Experience working with geographically distributed teams and partners.Good analytical abilities and proven design skills.Experience delivering mobile applications with support across a wide range of devices/hardware.Ability to effectively communicate with others, performs work in a team environment, and relay necessary information as appropriate.CompensationOur benefits are designed to help you move forward in your career, and in areas of your life outside of Verizon. From health and wellness benefits, short term incentives, 401 (k) Savings Plan, Stock Together, paid time off, parental leave, adoption assistance and tuition assistance, plus other incentives,we’ve got you covered with our award-winning total rewards package. For part-timers, your coverage will vary as you may be eligible for some of these benefits depending on your individual circumstances.If you are hired into a Colorado work location, the compensation range for this position is between $63,100 and $117,100 based on a full-time schedule. The salary will vary depending on your location and confirmed job-related skills and experience. This is an incentive based position with the potential to earn more. For part-time roles, your compensation will be adjusted to reflect your hours.Equal Employment OpportunityWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best.Check out our diversity and inclusion page to learn more.",co,de
13,Pie Insurance,Insurance,4.8,Data Engineer,"Denver, CO",$59K - $108K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136006&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_8f5f90ef&cb=1618161271103&jobListingId=3749741285,"We are an insurtech company where smart people can see the impact of their work as we tackle meaningful problems together. We think it’s fun to disrupt an industry that has been slow to change. But we aren’t shaking things up for the sake of change, we’re here to solve big problems using technology and an innovative approach to improve how small business owners access insurance. Like our small business clients, we are a diverse team of builders, dreamers, and entrepreneurs, so at the heart of every decision we make is the idea that if it doesn’t serve our clients, it doesn’t serve us. We hire passionate people who like to work hard, yet we also know that life exists outside the office. Small businesses are the backbone of the economy; talented team members are the backbone of Pie. We are pie-oneering a whole new approach to insurance.As a Data Engineer at Pie Insurance, you’ll be a member of the team responsible for transforming the commercial insurance market by delivering best-in-class data architecture solutions and driving more accurate data-driven decision making.Our team is looking for an experienced data engineer. We expect you’ll have spent at least 3 years in the data warehouse and/or data analytics space. Of course, you’ll also need certain skills and abilities to do the work.How You'll Do ItAs a data engineer with Pie, you will work with our data architect to Pie-oneer our data environment. This individual will be a key member that will work directly with our data architect to define the future state of our data architecture. This role will work in data architecture, data analytics, ETL development, and data reporting.Success in this position will be establishing how data comes into and flows through the Pie insurance platform. This data will be used to help our organization quote customers based on data on best policy and prices for their workers compensation insurance.The Right Stuff3-5 years working in data as an engineer. Building data solutions for a company who uses data as a primary part of their business.Experience in data warehouse and/or data analytics. Qualified candidates may also come from a strong database skill-set involved in analytics architecture.Strong experience in writing complex SQL queries.Strong experience in ETL/ELT platforms is strongly preferred.Exposure to one major SQL RDBMS or analytics database. (Snowflake, Redshift, MySQL, Postgres, Oracle, SQL Server, etc.)Big Data and Business Intelligence exposure would help in the success of this role.Our goal is to make all aspects of working with us as easy as Pie! That includes our offer process. When we have identified talent that is a good fit for Pie, we work hard to present an equitable and fair offer. We look at your knowledge, skills and experience that you bring, along with your compensation expectations and align that with our company equity processes to determine our offer ranges.We value and want to support our team members, and are proud to offer a comprehensive compensation package which includes the following:Compensation Range for position: $113,000 - $145,000Other Benefits: Each year Pie reviews Company performance and may grant discretionary bonuses to eligible team members.Pie Insurance is an equal opportunity employer. We do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, marital status, age, disability, national or ethnic origin, military service status, citizenship, or other protected characteristic.Pie Insurance participates in the E-Verify program. Please click here, here and here for more information.Our AchievementsPie Insurance raises an additional $118M in fundingPie Insurance Named a Top Colorado Company 2020Pie is rated Excellent by our customers on TrustpilotCheck out our great reviews from current and former employees on GlassdoorPie raises an additional $127M in funding",co,de
14,Holcim (US) Inc.,"Construction, Repair & Maintenance",3.7,Reliability Engineer II,"Florence, CO",$70K - $110K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_407728cb&cb=1618161271103&jobListingId=4053838098,"OverviewOVERVIEWThe Reliability Engineer will work closely with equipment suppliers, plant staff and Process Area Teams to ensure successful operation of the plant.ResponsibilitiesRESPONSIBILITIESDemonstrates a commitment to communicating, improving and adhering to safety policies in all work environments and areas.Responsible for monitoring reliability based systems including preventative maintenance systems, vibration analysis and condition monitoring.Participate in the creation of preventative maintenance routines (PMRs) and bills of materials (BOMs) for new equipmentManagement of the preventive/predictive maintenance programs (Inspection, Vibration, Oil Analysis, NDT, thermography, etc.) to ensure optimum equipment availability.Responsible for the preventative maintenance work order system with coordinated execution of the area operations and central maintenance teams.Provide leadership, guidance, and direction for reliability team and plant area teams in a manner consistent with LafargeHolcim valuesSupport, demonstrate, and facilitate the concepts of development and involvement of employees, continuous learning and continuous improvement in a values based high performance organization.Accountable for providing leadership, development and coaching on individual performance to direct reports to achieve business results.Analysis and elimination of repetitive problems through root cause analysis, Pareto analysis, statistical review, FMEA and similar techniques.Responsible for the facilitation of continuous improvement processes around equipment availability and reliability.Support and guide sustainable improvements in MTBF of major equipment.Other duties as assigned.QualificationsQUALIFICATIONSRequired Education: Bachelor's/University DegreeField of Study Preferred: Mechanical/Electrical EngineeringRequired Work Experience: 5+ years in cement or similar manufacturing environmentRequired Computer and Software Skills: Comprehensive computer software knowledge required including; Excel, Word, Project, Autocad, PowerPoint is required, SAP experience is desired.Additional Requirements:Demonstrated planning, organizational and project management skillsStrong interpersonal skills, including the ability to work in a cross-functional teamEffective communication and presentation skills: the ability to explain technical information to nontechnical peopleSolid decision making skills and independent judgment requiredAdaptable to change; to take an innovative approach towards problem solving; self startingAbility to follow up on critical assignments and monitor information to ensure data integritySolid technical and professional knowledgeDemonstrated experience in heavy industrial maintenance (3-5 years or more) requiredKnowledge of the cement manufacturing process would be a benefit. Three to five years mechanical and electrical maintenance experience is required.Demonstrated experience in setting up reliability systems in heavy industry requiredExperience in FFT analysis of vibration spectra on a range of heavy industrial plant requiredExperience in practical application of FMEA, NDT inspection techniques preferredWorking knowledge of instrumentation, process controls, motors, starters and VFD´s an advantageEstimated Wage Range$64,000 - $83,839Pay TypeSalary",co,de
15,Xero,Information Technology,4.3,Infrastructure Systems Engineer,"Denver, CO",$85K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_bb330824&cb=1618161271104&jobListingId=3822878401,"Xero is a beautiful, easy-to-use platform that helps small businesses and their accounting and bookkeeping advisors grow and thrive.At Xero, our purpose is to make life better for people in small business, their advisors, and communities around the world. This purpose sits at the centre of everything we do. We support our people to do the best work of their lives so that they can help small businesses succeed through better tools, information and connections. Because when they succeed they make a difference, and when millions of small businesses are making a difference, the world is a more beautiful place.You’ll work in collaboration with your team and other Xeros to help create and deliver beautiful software to our customers, faster. You'll regard engineering teams as your customers, and test, measure and learn how best to provide them value.You’ll maintain the standard for engineering excellence at Xero and support your team members in building products together. You’ll contribute to our cross functional environment by working towards the same objectives, using modern principles and practices.You'll help build and manage software that solves engineering problems at scale. You will be enabled to seek clarity with technical complexities and be able to demonstrate smart ways to simplify. You’ll be able to make data-driven decisions that will release value early to solve Xero customers' problems more effectively.What you’ll bring with youHands-on experience automating infrastructure in a cloud environment, preferably AWSA customer focused mindset and the ability to directly engage with our PaaSPractical experience with infrastructure-as-code (e.g. Terraform, Cloudformation, Ansible or Chef, etc.)Exceptional troubleshooting and analytical abilitiesExperience with a programming language (e.g. Python, C# or Java, etc.)Experience administering Windows/Linux servers in a highly available environmentAn understanding of relational database management experience with a preferred emphasis on SQL ServerFamiliarity with agile software development methodology and tooling, including continuous integration and deliveryAn understanding of network services and/or building and maintaining a Kubernetes clusterA strong desire to automate processes, build software tools, and create infrastructure-as-code solutions in a DevOps environmentWhat you’ll doBe customer-focused; Obsess over customers and directly engage with them; identify customer pain points and solve real customer problems based on observing their struggles and analysing customer data.Be kind; embrace our culture where we encourage diversity in a psychologically safe workplace. Voice your own opinion while considering the opinions of others.Be engaged; actively contribute to your team activities, initiatives and technological challenges, while working towards your product roadmaps. Maintain processes and monitoring to drive incremental improvement.Be collaborative; work with the team and others to achieve a good outcome using a working style that suits the problem at hand. Take operational responsibility for services, which may include 24x7 on call rotation.Be coached; proactively work with your manager on your personal and career development, highlighting any training/development needs and following through with actions agreed.Success looks likeContributing to product discovery activities and aligning with the agreed roadmapTaking ownership of personal/career developmentCommunicating effectively and respectfully giving and receiving feedbackDisplaying empathy and inclusion in interactions with othersMeeting agreed Service Level Objectives for operational performanceEnsuring continued improvement in ways of working for efficient deliveryProviding support and guidance to teams that use our platform servicesPlaying an active role within the Communities of Practice in XeroCritical competenciesLiving the vision & values.Keeps Xero’s vision and values at the forefront of decision-making, actions, communication and behaviors.Delivery.Has track record of innovating and delivering technology in a team and solving customer’s problems through software.Growth mind-set.Understands that competency is not fixed but is enhanced through dedication and hard work.Self-awareness.Has an awareness of EQ and is capable of recognizing one's own emotions and of those around you.Balance.Maintains a healthy personal/work-life harmony. Considers the wide range of learning and social opportunities at Xero against the needs of the team.Great communication skills.Speaks and writes clearly, succinctly and articulately without relying on jargon.Relationship building. Successfully builds trust and credibility with their team, customers and stakeholders.ExperienceExperience in delivering code to production in a commercial environment.Ability to work with others and navigate areas of conflict in an open, positive and proactive way.Experience of modern product and engineering principles and practices.Xero is an equal opportunity employerXero celebrates diversity. We are committed to creating an inclusive environment where our employees can do the best work of their lives. We are committed to transparency and to equal pay for equal work. Total compensation for this role includes a base salary of $85,000 to $105,000, commensurate with experience, plus an annual grant of Xero shares, calculated as a percentage of base salary.Xero offers access to low-cost, high-quality health care options through Cigna and Kaiser (in CA & CO only)Xero will match 100% on the first 3% of 401k contributions plus 50% match on next 2% of contributionsEmployees enjoy 21 days of paid time off per yearEmployees have 10 days of wellbeing leave to care for their minds, bodies, and familiesUS employees enjoy 11 paid holidays per yearXero offers an industry-leading 26 weeks of parental leave at 100% payXero offers a number of employee wellness programs, to include yoga, mindfulness and nutrition workshops, EAP, free flu shots, team meals, and a monthly wellbeing allowanceWhy Xero?Diversity of people brings diversity of thought, and we like that. A collaborative and inclusive environment is important to us. Working at Xero will provide you with a diverse and inclusive environment alongside people who will respect, challenge and support you to have fun while you do the best work of your life. We are a place where personal development, flexible working, innovation, and well-being are not just inspired but celebrated. We value our people and offer a wide range of compelling benefits and perks, including Xero shares.Xero’s collaborative culture is underscored by our values - #Ownership, #Challenge, #Beautiful, #Human and #Team - which empower us to understand and serve customers, attract top talent and continuously innovate. From the moment you step through our doors, you’ll feel welcome and supported to do the best work of your life.",co,de
16,Transamerica,Insurance,2.9,Data Scientist,"Denver, CO",$86K - $150K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_0fb8b089&cb=1618161271104&jobListingId=4058095145,"Job Description SummaryTransamerica has been helping people feel better about the future for more than 100 years, and we’re proud of the trust we’ve earned. But we believe our responsibility goes beyond insurance, investments, and retirement accounts. We’re also in the business of helping people improve their financial and personal well-being, so they can add more years to their lives, and more life to their years.Job DescriptionWhat You Will Do: As part of the Advanced Analytics group, the Data Scientist works with product managers, data engineers, and other data scientists to develop innovative solutions that transform the way Transamerica conducts business.What You Will Learn: In this role, you will gain exposure to Transamerica’s rich history and culture. You will be working with a team of ambitious and engaged professionals who bring fresh ideas and diverse perspectives to help us continually shake up the status quo and stay on the forefront of reinventing how we meet our business partners’ needs.What Success Looks Like:Design experiments and formulate machine learning problems to address major business challenges and innovation opportunities.Work with product managers and data engineers to discover, collect, cleanse, and refine the data needed for analysis and modeling.Analyze large datasets to extract actionable insights and inform experimental design and model development.Write lucid, compelling summaries to communicate results of analyses, model development, and testing that inform how the business should act.Collaborate with peers, challenging assumptions and providing constructive criticism and ideas for improvement.Build models using a variety of statistical and machine learning techniques, assessing the best type of model for the problem context, and using advanced techniques and customizations to optimize model performance.Harden models for production deployment and monitor model performance over time.What You Need:Master’s degree or PhD in computer science, machine learning, data science, mathematics, statistics, or a related quantitative field.Three years of experience in a data science or machine learning role.Excellent knowledge of major machine learning algorithms.Fluent in Python and R.Experience with machine learning libraries and platforms, like pandas, scikit-learn, and Tensorflow.Solid statistical analysis skills and a good understanding of experimental design.Excellent analytical and problem-solving skills.Experience working effectively and efficiently with large data sets.Excellent communication skills and the ability to use data to tell a story.Willingness to learn and keep pace with the latest advances in data science and machine learning.Experience leveraging NLP tools and techniques for text mining and natural language understanding preferred.In-depth experience with computer vision applications of machine learning is a plus.Experience with the AWS ecosystem, particularly Redshift, EC2, S3, and SageMaker, is a plus.Working Conditions:Office environmentCompensation**Please note that the compensation information that follows is a good faith estimate for this position only and is provided pursuant to the Colorado Equal Pay for Equal Work Act and Equal Pay Transparency Rules. It is estimated based on what a successful Colorado applicant might be paid. It assumes that the successful candidate will be in Colorado or perform the position from Colorado. Similar positions located outside of Colorado will not necessarily receive the same compensation. **CompensationThe salary rate for this position generally ranges between $105,000 - $173,250. This range is an estimate, based on potential employee qualifications, operational needs and other considerations permitted by law. The range may vary above and below the stated amounts, as permitted by Colorado Equal Pay Transparency Rule 4.1.2.Bonus EligibilityThis position is also typically eligible for Annual Bonus based on the Company Bonus Plan/Individual Performance and is at Company Discretion at a rate of 15%.What You Receive:A Comprehensive Wealth + Health package. It’s our passion to empower people, and especially our employees, to add years to their lives and more life to their years. That means a healthy account balance and a healthy body to match. As you’ll come to discover, Wealth + Health is a central part of everything we do!Wealth Benefits; Competitive Pay, Bonus, and Benefits Package; Pension Plan, 401k Match, Employee Stock Purchase Plan, Tuition Reimbursement, Disability Insurance, Employee Discounts, Career Training & Development Opportunities, Certification SponsorshipHealth and Work/Life Balance Benefits; Be Well Company sponsored holistic wellness program which includes Wellness Coaching and reward dollars, Parental Leave, Adoption Assistance, Employee Assistance Program, College Coach Program, Back-up Care Program, Paid Time Off to Volunteer, Employee Matching Gifts Program, Employee Resource Groups, Inclusion and Diversity Programs, Employee Recognition ProgramOur commitment to inclusion & diversity means that we value differences. We encourage the unique perspectives of individuals and are dedicated to creating a respectful and inclusive work environment.",co,de
17,Akerna,Information Technology,1.4,Data Engineer,"Denver, CO",$88K - $121K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=4348&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_a6693e82&cb=1618161271104&jobListingId=4056194991,"Job Title: Data Engineer

Location: Remote

Department: Engineering

Reports To: Director of Engineering Operations

Salary Range: $100,000 - $105,000 AnnuallyWho We Are:Akerna is a leading enterprise software solutions provider that enables regulatory compliance and inventory management. At Akerna we are passionate about solving problems that better our world. We provide data-driven solutions worldwide across the entire supply chain. Our technology empowers the industry to prove outcomes that positively change lives every day. We have a passionate and purposeful work environment where we live by five principles: Do the right thing, Be part of the solution, Show people you care, Grow together, and Make an impact.Essential Job Duties:· Architect, implement, and document the Snowflake and ETL infrastructure

· Evolve current data flow to account for new data sources and increased data volume

· Maintain the integrity of data within our data pipeline and warehouse

· Develop data models and views for internal and external client reporting purposes

· Integrate data from 3rd party services and custom pipeline

· Develop ETL jobs and tests to process, validate, transport, collate, aggregate, and distribute data

· Collaborate with product managers and analysts throughout the company to deliver reliable data that powers actionable insightsMinimum Qualifications:· 2+ years of data engineering experience

· Experience working with data warehousing concepts including data model design and optimization strategies

· Experience using and maintaining BI visualization tools

· Experience with version control systems such as Bitbucket etc.

· Experience automating business and reporting processes

· Creating production ready scripts with Python and SQL

· Very strong verbal and written communication skillsSkills/Abilities Preferred:· BS/MS in Computer Science, Math, Physics, or other technical fields

· At least 12 months of experience with Snowflake

· Proficiency in building data pipelines in a CI/CD environment

· Experience working with incremental data loads and data archiving

· Experience designing and deploying high-performance systems with reliable monitoring and logging practices

· Experience using data collection platforms such as Fivetran

· Familiarity with at least one cloud ecosystem: AWS/Google Cloud

· Experience of working in an agile environment and using tools such as JIRA/Asana/TrelloWhat We Offer:

Competitive salaries
100% company-paid medical, dental and vision insurance
Generous vacation policy
Remote Workforce

NOTE: Thank for your interest in working with us. Akerna is an Equal Employment Opportunity employer. Employment decisions are based on merit and business needs, and not on race, color, creed, age, sex, gender, sexual orientation, national origin, religion, marital status, medical condition, physical or mental disability, military service, pregnancy, childbirth and related medical conditions or any other classification protected by federal, state or provincial and local laws and ordinances. Reasonable accommodation is available for qualified individuals with disabilities, upon request. This Equal Employment Opportunity policy applies to all practices relating to recruitment and hiring, compensation, benefits, discipline, transfer, termination and all other terms and conditions of employment.",co,de
18,DISH,Telecommunications,3.3,Data Engineer,"Englewood, CO",$59K - $107K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=132977&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_f06f9c07&cb=1618161271105&jobListingId=4026935438,"DISH is a Fortune 250 company with more than $13 billion in annual revenue that continues to redefine the communications industry. Our legacy is innovation and a willingness to challenge the status quo, including reinventing ourselves. We disrupted the pay-TV industry in the mid-90s with the launch of the DISH satellite TV service, taking on some of the largest U.S. corporations in the process, and grew to be the fourth-largest pay-TV provider. We are doing it again with the first live, internet-delivered TV service – Sling TV – that bucks traditional pay-TV norms and gives consumers a truly new way to access and watch television.Now we have our sights set on upending the wireless industry and unseating the entrenched incumbent carriers.We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve to join our team as we embark on the next chapter of our story.Opportunity is here. We are DISH.What You'll Do:Lead teams in design, development and delivery of data solutions in wireless space using cloud data platformsManage day-to-day development activities for new data solutions and troubleshooting existing implementations.Work with product owners and technical leads to lead technical discussions and resolve technical issuesApply best practices of data integration for data quality and automationWork with product vendors to identify and manage open product issuesSolve complex data integration problemsDevelop and maintaining code for data ingestion and curation using databricksWork with business analysts to understand business requirements and use casesTechnical requirements:Minimum of 5 years of experience delivering data solutions on a variety of data warehousing, big data and cloud data platforms.3+ years of experience working with distributed data technologies (e.g. Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines;Strong Software Engineering experience with proficiency in at least one of the following programming languages: Spark, Python, Scala or equivalentExperience with building data ingestion pipelines both real time and batch using best practicesExperience with building streaming ingestion pipleline using Kafka streams, Apache Flink, or othersExperience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.Experience supporting and working with cross-functional teams in a dynamic environmentExperience with relational SQL and NoSQL databases, including Postgres, and Mongodb.Experience with change data capture tools (CDC) preferred such as Attunity/goldengateExperience with scheduling tools preferrable Control-M,Airflow or AWS Step functions.Strong interpersonal, analytical, problem-solving, influencing, prioritization, decision- making and conflict resolution skillsExcellent written/verbal communication skills.#LI-YT1Compensation: $74,700.00/Yr. - $118,425.00/Yr.From versatile health perks to new career opportunities, check out our benefits on our careers website.Employment is contingent on Successful completion of a pre-employment screen, which may include a drug test.",co,de
19,WorkBoard,Information Technology,4.7,Data Science Engineer,"Denver, CO",$102K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_d243156b&cb=1618161271105&jobListingId=4030665289,"WorkBoardWork with purpose.WorkBoard's mission is to help companies and the people in them achieve their best results. We pioneered the Enterprise Results Management solution category so leaders can communicate strategy and align efforts well in a faster changing world, and so team members are energized by the purpose and impact of their work. Our customers drive faster growth and competitive advantage because they have higher alignment, real-time transparency, and sharper focus on the results that matter. Companies like Cisco, Microsoft, Juniper, Workday, 3M, Zuora, Anthem, Humana, and many others use WorkBoard's platform, expert services, and professional certification programs to achieve their ambitious vision.WorkBoard has built a clear lead in the space – it is the size of all the other OKR app providers combined, in large part because its founders and team members are experienced company builders focused on true, differentiated value for our customers. WorkBoard is backed by top-tier venture investors including Andreessen Horowitz, GGV Capital, Workday Ventures, and Microsoft's M12 fund.THE OPPORTUNITYAt WorkBoard we help customers achieve their sustainable growth advantage by making alignment and accountability remarkably easy! The people that make the decision to bring-in WorkBoard are P&L owners and Business Innovation Leaders. As a result, WorkBoard is an important partner to the leadership team and in order to bring this promise to life for our customers, our application reaches every single employee.What does this mean for you?Rich, deep data set to draw insights from and influence internal and product and engineering leadershipBe part of the foundational team with great people, who have an entrepreneurial mindset and bring their absolute best every day.Leverage your mastery of business, communication, and technical skills to consult with experts in most successful enterprises in the business world.Provide customer feedback and work with the engineering team to translate the feedback into product features.COMING INBring at least 5 years of combined experience in Business Intelligence, Data Science and Data WarehousingSoftware development expertise in Python.Expertise in SQL and experience with large relational database systems.Experience creating an Events framework to enable better data analyticsExperience with Data Visualization standard methodologiesExperience working with the Product team to define and create Product Success metrics and engagement drivers.BS in Computer Science, Engineering or related technical or equivalent experienceHave worked at a fast growing SaaS organization where you've demonstrated personal accountability and willingness to go above and beyond the job description.You are genuine, warm, positive, empathetic, and engaging with a passion for technology, and customer success.WITHIN ONE MONTH, YOU'LL:Become a certified OKR Coach and WorkBoard Expert!Demonstrate 100% understanding of WorkBoard's underlying data structure and it's mapping to our UI ObjectsHave action plans in place to achieve your Key Results!WITHIN THREE MONTHS, YOU'LL:Have a deep understanding of the problem space we are building the platform for, and how are various offerings are interconnected to provide a comprehensive business solutionFully understand the Schema of our core product tablesUnderstand our current Analytics events structure and frameworkUnderstand our user engagement and product analytics for 3 areas better than anyoneWITHIN SIX MONTHS, YOU'LL:Fully understand the Schema for our entire Relational DatabaseUnderstand and be a point of contact for our event logging pipeline and the business logic associated with the eventsAbility to have client-facing conversations on our published metrics and help them understand the product logicMaintain / Enhance our internal Dashboard in Python and SigmaWork with App Engineering, Product and Customer Success teams to roll out in-product data focused featuresDig deep into data to find levers to increase adoption and success and work cross functionally to drive awareness of these leversTHE TEAMYou'll join a team where everyone—including you—is striving to constantly improve and reimagine the best value and quality of experience we provide as a company and solution. We are an incredibly supportive team, aim to be voracious learners in all of our interactions, and thrive on excitement of supporting our customers' success. When problems arise, everyone pitches in. As a team, we are excited about a lot of things—what ""best"" looks like for our customers and how we team ourselves, and what ""breakthrough"" looks like for product and customer experiences—and we share these passions across the company.OUR VALUES - WE LIVE BY THE 4 HsHumble experts ~ Hungry for the opportunity ~ Intellectually honest ~ Operating as one happy teamA FEW OF OUR AWESOME BENEFITSFlexible PTO & sick daysPaid holidaysHealth insurance401K with employer matchingQuarterly All-Hands MeetingsAnd much more!THE WORKBOARD STORYWorkBoard provides a powerful, modern results platform to help companies achieve their growth plans. Unlike most enterprise software, our solution is important to every employee, so we strive to set the high bar for capabilities that delight and enable everyone to be more successful at work. WorkBoard is strategic to companies and personally relevant to the people that work in them.We are proud to be an equal opportunity workplace committed to building a team culture that celebrates learning, diversity and inclusion. If you're hungry to grow your skills while growing a company, your sense of urgency matches the size of our market opportunity, and you value and enable team mates' contributions, then come join us!",co,de
20,iCIMS,Information Technology,4.1,Principal Security Engineer,"Denver, CO",$83K - $134K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_bed11c15&cb=1618161271105&jobListingId=4031353273,"Job OverviewThe Principal Security Engineer will act as a key member of iCIMS Security Engineering team and handle diverse security-related tasks and issues for our rapidly growing company, including managing risk through a shared vision with business and security leadership. The Principal Security Engineer will provide expertise and guidance focusing on security engineering, while working with our product engineering and hosting teams by helping engineer the ‘sec’ in DevSecOps. In addition, the Principal Security Engineer will be responsible for research and development for our security solutions and related business cases, both in the cloud and on-premise, and will work closely with iCIMS most senior software architects and engineers.The Principal Security Engineer will report directly to the Chief Information Security Officer (CISO) and will collaborate with technical leadership, various product/technology and corporate teams, and business stakeholders to develop strong security solutions to meet operational goals for high availability, performance, stability, security and cost efficiency.This position is focused on security engineering and architecture and maintaining and improving core security systems and architectures with a strong cloud focus. The ability to code is highly desirable. Engaging in professional development to maintain continual growth in professional skills and knowledge essential to the position, with the expectation iCIMS will support this requirement.About UsiCIMS is the talent cloud company that empowers organizations to attract, engage, hire, and advance the right talent that builds a diverse, winning workforce. iCIMS accelerates transformation for a community of approximately 4,300 customers, including 40 percent of the Fortune 100. Dedicated to maintaining an inclusive, inspirational, and innovative work environment, and committed to consistent growth, we have a wide range of opportunity for career advancement within our organization. Come grow with us—apply today!ResponsibilitiesWork closely with Chief Information Security Officer in the coordination and facilitation of iCIMS security goals and initiativesAct as a senior representative for Information Security across the company, providing guidance and direction on matters pertaining to Information Security.Leverage expert level knowledge of comprehensive security approaches against common and advanced attacks and exploits.Participate in addressing security incidents and events in order to protect customer and corporate data and critical systems.Provide product, project, and ad hoc information security support and guidance while ensuring recommended solutions and processes adhere to iCIMS security standards and policiesPrepare for and participate in ISO 27001 certification and SOC2 compliance audits and associated audit preparationExercise excellent knowledge of security tools and technology including, but not limited to, tools related to Security Information and Event Management (SIEM), intrusion detection/prevention systems (IDS/IPS), integrity monitoring, anti-virus/anti-malware, vulnerability management, data loss prevention (DLP), advanced persistent treat (APT), and policy complianceUtilize a strong foundation in key technologies including servers, networking, operating systems, databases, SaaS, and cloud bases services to allow for effective evaluation and recommendations for securing these systemsEvaluate and recommend security related technologies and solutions for future implementationHandle sensitive and/or confidential material and information with suitable discretionConsistently ensures that business is conducted with integrity at all times and that behavior aligns with iCIMS’ policies, procedures, and core competencies.QualificationsAt least 5 years of experience in an information security analyst/engineering role with a prior background in information technology.Advanced knowledge of common Information Security frameworks such as ISO 27001/2, Control Objectives for Information and Related Technology (CoBIT), Information Technology Infrastructure Library (ITIL) and National Institute of Standards and Technology (NIST) preferredHighly developed organizational skills and attention to detail including the ability to handle multiple projects and priorities simultaneously with a high degree of professionalism and client service orientationExcellent communication and interpersonal skills. Articulates thoughts and ideas clearly, concisely, and persuasively including the ability to communicate security and risk-related concepts across all stakeholder groups (written and oral): Executive team, management peers, and external customers.Ability to work effectively within a fast paced, changing environment that is going through high growthA self-starter with the demonstrated ability to take initiative, who can proactively identify issues/opportunities and recommend actionsStrategic analysis/creative problem solving, business judgment and financial acumen are requiredComputer literacy; Microsoft Office (PowerPoint, Excel, Outlook)Education/Certifications/Licenses RequiredBachelor’s Degree in Information Security, Computer Science, Information Management Systems, or equivalent experienceInformation security related certification/s such as CISA, CISM, CISSP or equivalent preferredEEO StatementiCIMS is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sexual orientation, gender identity, national origin, protected veteran status or disability status and will not be discriminated against on the basis of disability.Compensation & BenefitsTarget Compensation - $92,600 - $123,500Your actual pay will be based on your skills and experience — talk with your recruiter to learn more.iCIMS offers the following benefits: medical, dental, vision, 401(k), an open vacation policy, sick days, short-term disability, long-term disability, maternity/bonding and parental leave, tuition reimbursement, flexible savings accounts, paid holidays, life and AD&D insurance.",co,de
21,Apple,Information Technology,4.3,Optical Data Engineer,"Boulder, CO",$90K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_6389df39&cb=1618161271105&jobListingId=3821582358,"SummaryPosted: Feb 8, 2021Weekly Hours: 40Role Number:200220890Apple is looking for a highly motivated individual with experience in the fields of data analytics and optics to join the Panel Process and Optics (PPO) Engineering team.The successful candidate will be responsible for working with a team of optical engineers and process engineers to manage and analyze data from optical fabrication processes to identify key behaviors and establish relevant dependencies. The candidate will also be responsible for communicating and reviewing these findings with the team. Responsibilities will span working with the team to ensure data availability and integrity, performing data-mining and data interrogation, communicating findings, and working with the team to establish next steps in the technology development. A successful candidate needs to be flexible, receptive to ideas from others, team oriented, and willing to work with technologists, engineers and others to push the technology envelop. Expect this work to include collaborating with multi-functional teams responsible for crafting and producing exciting new displays and assembly technologies.Key QualificationsData professional with expertise in Data Science, Analytics, Six Sigma practices, or similarExperience developing data analytics systems for early-stage projects to help team learn about unknown dependenciesExperience interfacing and networking Windows-based measurement instruments (both COTS and custom)Knowledge of tools such as Python, JMP, Tableau, and how to work with SQL, or similar.Knowledge of optics and display performance metrics (MTF, contrast, uniformity), radiometry, and photometry is a plusFlexible and collaborative, willing to work in fast paced technology development and prototyping environmentExperience with reviews of work and analyses with product development team once technology development is completedDescription- Apply knowledge of data analytics to derive dependencies of optical performance on process and in-coming material variables- Ensure integrity in data pipeline for existing and new parameters- Work with multi-functional teams on exploring those key insights through further data collection or analysis- Build and maintain dashboards for key insights- Ensure that the data-pool is maintained appropriately- Act as prime interface for database management team and tool implementationEducation & ExperienceMinimum Bachelors Degree with 5+ years of experience in data science, analytics, optical engineering, applied physics, electrical engineering or related fieldAdditional RequirementsIf you are a Colorado resident, this is for you:At Apple, we see the whole you. We carefully consider a wide range of compensation factors, including your background and experience. These considerations can cause your compensation to vary. Optical Data Engineer starts at a minimum annual salary of $91,800. The actual pay may be higher depending on your skills, qualifications, and experience. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Every Apple employee also has the opportunity to become an Apple shareholder, because all team members are eligible for stock grants and also a discount when purchasing Apple stock.We offer all kinds of ways to experience well-being, confidence, and satisfaction. Learn more about Apple benefits.Note: Apple benefits programs are subject to eligibility requirements.",co,de
22,​Markesman Group,Government,5,TechSIGINT Data Engineer,"Aurora, CO",$73K - $106K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_4be61253&cb=1618161271105&jobListingId=3774195549,"Description:Provide support and related services in Colorado for the implementation of enterprise data representations for the TechSIGINT mission domain. The successful individual will perform end-to-end systems engineering for data flows from the perspective of data format, implementation, and support. This position requires strong systems engineering expertise from cradle to grave with limited, high-level direction, in the areas of:Performing high-level requirements analysis to support application of TechSIGINT Data standards. Duties require a broad range of knowledge including information technology, requirements, technical architecture analysis (e.g., understanding data flow diagrams, system architecture diagrams, etc.), and an understanding of functional and system analysis.Coordinating across teams that leverage multiple development methodologies (e.g., Waterfall, Agile (Scrum & Kanban), Spiral, etc.) simultaneously.Possessing an instinctive aptitude to leverage information and knowledge sharing networks and navigate conflict in a way that fosters constructive outcomes.TechSIGINT data experience is a requirement.Ability to develop pseudocode is a requirement.TS/SCI with poly requiredAbout Markesman GroupMarkesman Group provides clients with Enterprise IT and Intelligence solutions driven from best value. As a small business leader in the technology sector, Markesman Group provides government clientele with IT support services which sustain its day to day operations from strategic framework to implementation and performance engineering. Markesman Group seeks highly qualified professionals to develop and further as leaders in business, technology, strategy, operations, and innovation.We are an Equal Opportunity/Affirmative Action Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state, or local law.",co,de
23,American Financing Corporation,Finance,3.9,"Software Engineer - Ruby, Full Stack","Aurora, CO",$66K - $77K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_8e1752e8&cb=1618161271105&jobListingId=4053990150,"JOB SUMMARYWe are looking for a talented and enthusiastic person to become the newest member of our growing Customer Experience Tech team at American Financing. We are continually iterating on our designs and program flows to provide the best possible user experience.DUTIES AND RESPONSIBILITIESMaintaining and extending internal and customer-facing Rails applicationsModeling dataWorking on server-side templatesBuilding APIsWriting client-side JavascriptQUALIFICATIONS AND EXPERIENCEDesire to share ideas, learn and explore new approachesProduction experience using Ruby on Rails 4.2+ (Rails 5 a plus)HTML, CSS (HAML, SASS a plus)Database modeling and optimization experienceComfortable using version control, ticketing systems and testing frameworks (Git, Jira, RSpec knowledge a plus)Strong communication and collaboration skills3+ years professional programming experienceMortgage industry knowledge a plusDenver metro area resident preferredBENEFITS AND PERKSMedical, Dental, Vision, 401kPaid time offPaid Sick TimePaid HolidaysLong-term paid disabilityPaid parental leaveWork from homeFull set of office equipment providedAmerican Financing Corporation (AFC) is an Equal Opportunity Employer. AFC does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis protected by law. All employment is decided on the basis of qualifications, merit and business need.At American Financing, we’re innovators with imagination. We’re fast-paced and fun. And we’re a collaborative group that respects and values the individuality of all employees.Together, we do what it takes to help borrowers achieve their financial goals. And we stay ahead of the competition by challenging ourselves to become more efficient. We are one of the fastest-growing national mortgage lenders because we don't follow the status quo.Wherever your passions lie, you can find rewarding work and new opportunities here.Casual work environmentFamily-owned, Customer-focusedDenver Post Top WorkplaceTop 50 Family-Owned BusinessBest of Colorado BusinessInc. 5000 Fastest-growing Private Company",co,de
24,DISH Network,Telecommunications,3.3,Big Data Engineer,"Englewood, CO",$90K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=132977&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_4ed7f39a&cb=1618161271105&jobListingId=4056293270,"Department Summary:Sling TV L.L.C. provides an over-the-top (internet delivered) television experience on TVs, tablets, gaming consoles, computers, smartphones, smart TVs and other streaming devices. Distributed across a variety of strategic device partners, including Google, Amazon, Apple TV, Microsoft, Roku, Samsung, LG, Comcast, and many others, Sling TV offers two primary domestic streaming services that collectively include more than 100 channels of top content. Featured programmers include Disney/ESPN, NBC, AMC, A&E, EPIX, NFL Network, NBA TV, NHL Networks, Pac-12 Networks, Hallmark, Viacom, and more.For Spanish-speaking customers, Sling Latino offers a suite of standalone and extra Spanish-programming packages tailored to the US Hispanic market. And for those seeking International content, Sling International currently provides more than 300 channels in 20 languages (available across multiple devices) to U.S. households.Sling TV is the #1 Live TV Streaming Service. Sling TV is a next-generation service that meets the entertainment needs of today’s contemporary viewers. Visit www.Sling.com. We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve to join our team as we embark on the next chapter of our story.Opportunity is here. We are Sling.Job Duties and Responsibilities:What you’ll be doing:This role will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler, who enjoys optimizing data systems and building them from the ground up.This position will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.The successful candidate will:Create and maintain optimal data pipeline architecture;Assemble large, complex data sets that meet both functional and non-functional business requirements;Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.;Build the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies;Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics;Collaborate with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs;Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader;Work with data and analytics experts to strive for greater functionality in our data systems.Skills, Experience and Requirements:A successful Data Engineer will have:A Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree.Technical requirements:Five+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines;Strong Software Engineering experience with proficiency in at least one of the following programming languages: Golang, Java, Python, Scala or equivalent;Implement data ingestion pipelines both real time and batch using best practices;Experience with building stream-processing applications using Apache Flink, Kafka Streams or others;Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.;Experience supporting and working with cross-functional teams in a dynamic environment;Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.Experience with ELK stack.Ability to work in a Linux environment.Ideal qualifications:Experience in building distributed, high-volume data services;Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.;Knowledge of data science tools and their integration with data lakes;Experience in container technologies like Docker/Kubernetes#LI-CA1 #LI-SB1#LI-SLING2",co,de
25,"CGI Group, Inc.",Business Services,3.7,Azure Data Engineer,"Denver, CO",$70K - $104K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=133286&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_934f3000&cb=1618161271105&jobListingId=4056107728,"Azure Data EngineerPosition DescriptionSeeking a sr data engineer with 8-10 years of industry experience including developing and deploying applications on Microsoft Azure Databricks platform. This individual should be self-motivated to drive solutions and proactively create and present (in sufficient detail) the documentation required to support and describe technical solutions. The candidate will work with cloud architects to establish pipeline to Azure data stores using either NiFi or DataBricks. Will build templates for engineering processes in cloud. Will act as the lead data engineer on the project.The data engineer will be responsible for development, deployment, maintenance, diagnostics and support of spark ETL jobs on the MS Databricks platform.Will streamline code, rationalize datasets and tables to arrive at single source of truthWill build detailed architecture diagrams or Entity Relationship Diagrams for all workflows and processes8+ years of hands on experience with cloud automation and scripting in an Azure environment.Experience in development of apache Spark code using PySpark or ScalaExperience in using Azure Databricks PlatformExperience in using Azure Data Factory to call Azure Databricks notebook activitiesExperience in using Git based repositoriesGood fundamental knowledge about distributed computing, RDBMS and Dimensional modeling conceptsExposure to Azure DevOpsExposure to Azure Storage (Blob/Data Lake Store), Azure Catalog, Databricks Delta.Strong communication and presentations skills required.SQL, TeraData SQL 10+ years 5Cloud Platforms (Azure) 8+ years 5NiFi, DataBricks 8+ years 4Scripting languages (HTML, Javacsript, jquery, Angular js, .Net, Python etc) 8+ years 5Hive 6+ years 4Est. Salary Range (Colorado Only): $97k-144kDisclaimer: In accordance with Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, a good faith hourly or base salary range must be posted for all positions where the work may be performed in the state of Colorado. Therefore, this good faith salary range will only apply where this described position will be performed in the state, and should not be considered the compensation range in other locations or for other positions.At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:Competitive base salariesEligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category401(k) Plan and Profit Participation for eligible membersGenerous holidays, vacation, and sick leave plansComprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and moreYour future duties and responsibilitiesRequired qualifications to be successful in this roleBuild your career with us.It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change-supporting our clients' digital journeys and offering our professionals exciting career opportunities.At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.Be part of building one of the largest independent technology and business services firms in the world.Learn more about CGI at www.cgi.com .No unsolicited agency referrals please.",co,de
26,AE2S,Business Services,4.7,Engineering Assistant / Engineer-in-Training (EIT),"Denver, CO",$57K - $76K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_f79b9b58&cb=1618161271105&jobListingId=4056131365,"Job Description:Advanced Engineering and Environmental Services (AE2S) is an award-winning, specialized civil/environmental consulting engineering firm that provides professional services and a unique brand of extreme client service. Our work environment is consistently recognized both locally and nationally for our great culture and values, proven recognition programs, and social atmosphere.Great Culture and Spirit where Creativity is FosteredSignificant Opportunities to Grow and AdvanceCore Values which Speak to the Heart of AE2S and its EmployeesLarge, Diverse, and Challenging Projects with the Latest TechnologyFamily-Friendly with Flexibility and Work-Life BalanceAE2S offers more than just competitive compensation and a best-in-class insurance package to our employees and families; our benefit plan is one of the richest plans currently in the marketplace today!100-percent paid Family Health Insurance100-percent paid Employee Dental and Vision InsuranceDiscretionary Bonus PlanMatching 401(k) Contributions with Discretionary Profit Sharing ContributionsPaid Time Off (PTO) Credits for Past ExperienceWellness ProgramEngineer-in-Training (EIT) - Denver, COAn Engineer in Training (EIT) will work under the direct supervision of project management and design engineers and will have the opportunity to develop skills in report preparation, design, plans and specifications, construction observation, and construction administration, with an emphasis on personal/career development.Anticipated Starting Salary Range: $57,000/year to $65,100/year(Compensation is subject to variation due to such factors as education, experience, skillset, etc.)ResponsibilitiesPerform construction observation and administration on water and municipal related projectsAssist Project Manager with the development and preparation of plans, specifications, and estimatesAssist project managers in design and construction of pipelines, storage tanks, pump stations, treatment systems, rural water, and municipal facilitiesAssist professional surveyors with field work on crews performing data gathering for designs or construction stakingAssist in preparation of technical reportsMaintain project and company tracking information in Vantagepoint platformJob Requirements:BasicBachelor's degree in Civil Engineering or related fieldFundamentals in Engineering certified or ability to obtain within 6 monthsStrong written and oral communication skillsAbility to travel as requiredPreferredMaster's degree in Environmental Engineering, Civil Engineering, or related fieldAutoCAD or Civil 3D experience2 years intern experience on water, wastewater, or rural water projectsPhysicalAbility to work in adverse weather conditionsAbility to walk up to 3-miles on uneven terrainAbility to stand or sit for prolonged periods of timeOccasionally climb, stoop, bend, kneel, crouch, reach, and twistOccasionally lift, carry, push, and pull light to moderate amounts of weightMay require lifting and carrying up to 20 pounds, with rare lifting of up to 50 poundsAbility to inspect equipment, structures, or materials to identify the cause of errors or other problems or defects.May be required to wear Personal Protection Equipment (PPE) including but not limited to, flame resistant clothing, hard hat, and protective footwearMay require occasional evenings and weekends with overtime expectations varying with workloadMay be required to travel to off-site locations including occasional overnight stays out of townAE2S is an Equal Opportunity / Affirmative Action Employer",co,de
27,Arrow Electronics,Business Services,3.2,RPA-Applications Engineer,"Centennial, CO",$80K - $125K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1044074&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_17131fe9&cb=1618161271105&jobListingId=4027828295,"Position:RPA-Applications EngineerJob Description:RPA-Applications EngineerWe currently have an outstanding opportunity for a passionate, experienced RPA Applications Engineer to join our ECS Global Intelligent Automation team. This role will leverage techno-functional knowledge and skill to help execute the strategy, architecture, design, and implementation of scalable IT solutions across the ECS Global IA organization.In the technical role, you will be accountable for defining, developing, assessing, approving, and delivering complex and innovative automation solutions utilizing and deploying robotic and other automation tools and technologies. As we progress into a more digital world, this position will need to provide inputs into the Digital strategy for Arrow. This person will act as a Subject Matter Expert for the technology and associated processes related to Robotics and Automation Systems, will ensure that good practices are embedded across Arrow ECS. This person will be responsible for design and architectural governance of the UI Path platform as well as developing detailed knowledge of the automation product’s usage within the organization. In this role, you will utilize an RPA toolset to deliver business value. Working side-by-side with RPA Business Analysts and developers, you will take ideas and propositions voiced from internal business groups, and innovate them into business solutions. Maintaining UI Path, patching, upgrades, and lifecycle management of the UI Path product will be regular job duties.This role will also be responsible for understanding overall business model, engage in business and IT discussions, gather requirements, write business and functional specifications, explain issues/requirements to technical teams, perform end to end testing, solve business and system issues in assigned modules/areas and serve as a true liaison between business and technical teams.Additionally, this individual will cultivate relationships across senior business leadership and other IT teams to help prioritize, coordinate, and deliver projects and initiatives within the organizational roadmap. This includes working with the business and technology areas to understand and drive requirements for IT delivery in a fast-paced environment.What You'll Be DoingThe Robotic Process Designer will work with business operations team/ product owners to understand the current business processes/ applications and subsequently design and develop Robotic process flows and objects to automate business processes.Determines system specifications, input/output processes and working parameters for hardware/software compatibility. Coordinates design of subsystems and integration of total system. Ensures these products or technical environments are optimally integrated with the rest of the technological environment and consistent with best practices.He/she makes sure the Robotic process flows is aligned to Robotics Center of Excellence established operational model, governance, development and testing standards and deployment model.Lead design sessions with product owners/stakeholders across the organization to deliver innovative products, solutions, and enhancements.High degree of technical aptitude over a wide scope of automation architecture, data analysis, data model design and AI applications to provide technical direction and mentorship to team.Review already implemented automation solutions in the organization and strive for constant improvements on top of those for ever increasing value to business.Define metrics for success of a project, engage stakeholders for alignment. Drive project to meet the success criteria.Partner with cross-functional leaders to generate ideas/hypotheses/opportunities to drive business value through automation.Drive efforts for application upgrade, alerts mechanism etc.Drive Proof of Concept efforts on new technologies emerging in automation space.Ensure project and support efforts meet service level expectations of business stakeholders and drive quality through best practice, standards, and process observation.Should be well versed with database design for RPA reporting requirements.Coordinate with offshore team for delivery.What We Are Looking ForThe ideal candidate for this position should possess a good understanding of IT development methodologies and demonstrate strong knowledge in ERP business processes.Leadership skills:Strong communication skills (written and verbal) with the ability to articulate complex concepts diverse audiences – speak “non-technical” when needed.Demonstrated problem solving and critical thinking skills – able to deal with ambiguity and organizational agility to evaluate options and make informed and timely decisions.Demonstrated interpersonal and relationship building capabilities; effectively balance team building and a results-oriented approach.Experience with large, complex, multi-national projects and teams; working collaboratively across business and IT stakeholders to deliver solutions through traditional and agile methods.Ability to define, articulate and market IA vision and value statements across the stakeholder community.Technical Skills:Deep Knowledge of architecting IT applications, data modeling and business analysis techniques, business concepts/ processes.Create, maintain, and enhance Intelligence Automation components (orchestrator, metadata, reports, metrics, dashboards) and manage overall IA environment, including configuration, releases, user administration and standards.Participate in building custom applications, data modelling, business process analysis, documentation of functional and technical specifications and business review of IA deployments.Experience of having worked on ERP solutions in various ERP subject areas (Sales, Inventory, Quoting, Order Management, Purchasing, Shipping, Costing, Pricing, Accounts Payable, Accounts Receivable, General Ledger). Either Microsoft Dynamics AX or Oracle ERP experience is preferred.Identify, understand, assess, prioritize, document, and communicate requirements, risks, dependencies, and potential roadblocks relating to Intelligent Automation development.Reviews, identifies areas for improvement and makes recommendations to leadership.Demonstrated proficiency authoring basic to complex queries in SQL & familiarity in underlying ERP applications database architecture.Good understanding of Master Data Management (MDM).Experience/Education8+ years of executing IT specific focus on the various Technology stack (Oracle PL/SQL, Uipath, Power BI), Oracle / Microsoft ERP and knowledge of key business processes .Must have experience supporting / managing any IT ERP track as part of a larger strategic program.4-year degree from an accredited college/university in Information Systems or related field or equivalent related experienceWhat’s In It For YouAt Arrow, we recognize that financial rewards and great benefits are important aspects of an ideal job. That is why we offer competitive financial compensation, including various compensation plans, and a solid benefits packageMedical, Dental, Vision Insurance401k, With Matching ContributionsGenerous Paid Time OffHealth Savings Account (HSA)/Health Reimbursement Account (HRA) OptionsGrowth OpportunitiesShort-Term/Long-Term Disability InsuranceDeeply discounted RTD Passes, with convenient office location off RTD Light Rail (Dry Creek Exit)On-site Café with Catering Option for Busy Lifestyles (availability subject to COVID-19 office guidelines)24/7/365 On-site Gym and Lockers, Free for Use to All Employees! (availability subject to COVID-19 office guidelines)Annual Hiring Range/Hourly Rate:$108,000.00 - $132,000.00Actual compensation offer to candidate may vary from posted hiring range based upon geographic location, work experience, education, and/or skill level. The pay ratio between base pay and target incentive (if applicable) will be finalized at offer.Location:US-CO-Denver, Colorado (Panorama Arrow Building)Time Type:Full timeJob Category:Information TechnologyEEO Statement:Arrow is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, gender, sexual orientation, gender identity, national origin, veteran or disability status. (Arrow EEO/AAP policy)",co,de
28,CoreSite,Information Technology,3.8,"Senior Data Engineer - Denver, CO","Denver, CO",$113K - $198K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=14295&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_6db0c3f0&cb=1618161271105&jobListingId=4027269195,"As a member of the company’s information technology team, the Senior Data Engineer is responsible for development, testing, and deployment of technology components. The position will participate in requirement specifications with the business, and will contribute to the overall design and implementation of the evolving enterprise software and data solutions. The Senior Data Engineer will work with the business to proactively understand their software and data requirements, and will own the development life-cycle required for implementing the desired solution. The Senior Data Engineer will be responsible for delivery, provide guidance to more junior data engineers and provide guidance related to best practices.

Duties:

Deliver innovative solutions that provide value to both internal and external end users Consult / partner with the business on current software and data priorities Document, calculate ROI and communicate proposed technology solutions Participate and lead in architecture and design discussions Comply and provide guidance with Software Development Lifecycle (SDLC) methodology and governance strategies Utilize skills that span across disciplines and comfortably play different roles in more than just one area MDM, ETL and data engineering Work hand in hand with the Dev/Ops team to solidify and enhance our CI/CD pipelines Contribute to and modify automated test suite Troubleshoot software issues, data accuracy and performance issues Develop, maintain, monitor, and support technology solutions Promote and demonstrate the behaviors consistent with CoreSite’s culture and 8 Guiding Principles Other projects and duties as assigned

Requirements

Knowledge, Skills & Abilities:

Communication skills including: communicating at technical and business levels, and the ability to interact with people from all organizational levels Ability to identify the root cause of a problem, recommend solutions to solve the problem, and implement the solutions to solve the problem Ability to analyze requirements, retrieve source data, and present accurate results in a timely manner Accomplished in using best practices for gathering and documenting complete and detailed requirements Ability to translate ideas into technical designs and contributing in technical design sessions Pivot easily within a constantly changing Agile environment and are comfortable with a high degree of change Bachelor’s degree in Information Technology or other applicable field preferred 10+ years overall experience including: Experience with Salesforce a plus Experience with AWS a plus Experience with API development a plus Experience with Mulesoft a plus

Education/Experience:

4+ years’ experience in Data Engineering role 2+ years’ experience in Software Engineer role 4+ years’ working with Microsoft SQL Server Experience with Microsoft SQL SSIS, SSAS, SSRS

Physical Demands:The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is occasionally required to stand; walk; sit; use hands to handle, or feel objects; reach with hands and arms; climb stairs; balance; stoop or kneel; talk and hear. The employee must occasionally lift and/or move up to 25 pounds.

Benefits

Not only does CoreSite have a fun, team-focused work environment, but we also offer great benefits!

Medical and Vision coverage through Cigna Heath Care Telemedicine through MDLive Dental Insurance through Delta Dental Life Insurance and Short-Term & Long-term Disability Insurance fully paid by the company Voluntary coverage benefits for Life and AD&D, Critical Illness, Accident Coverage, and Hospital Indemnity Medical and Dependent Care Flexible Spending Account (FSA) Plans and Health Saving Account (HSA) Plans 401(k) retirement savings plan with a generous company contribution Free parking or a company contribution towards a public transit pass Paid Parental Leave 16 days of Personal Time Off (PTO) 10 paid Holidays Wellness program with annual incentive

Applicant Privacy Notice: CoreSite is committed to protecting the privacy and security of personal information submitted by applicants. The California Consumer Privacy Act (CCPA) requires us to provide you information about our personal information handling practices. As a result, we’re providing this Privacy Notice that describes how we collect, use, share, and update personal information from individuals who wish to be considered for employment with CoreSite. To read the Applicant Privacy Notice, please go to https://www.coresite.com/applicant-privacy-notice.",co,de
29,Amazon.com Services LLC,Information Technology,3.8,Software Engineer - Big Data Analytics,"Boulder, CO",$66K - $105K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=133043&s=58&guid=00000178c1ed7f83b6e1bac2d6551ac3&src=GD_JOB_AD&t=SR&vt=w&cs=1_7b032e38&cb=1618161271106&jobListingId=3776082656,"2+ years of non-internship professional software development experienceProgramming experience with at least one modern language such as Java, C++, or C# including object-oriented design1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.Bachelor’s degree in Computer Science or related fieldEquivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education3+ years professional experience in software developmentComputer Science fundamentals in object-oriented designComputer Science fundamentals in data structuresComputer Science fundamentals in algorithm design, problem solving, and complexity analysisProficiency in, at least, one modern programming language such as C, C++, Java, or PerlAre you passionate about using Big Data to build customer trust and grow new business? Global advertisers rely on our team's performance insights to drive future investment in Amazon's Advertising Platform and improve the relevance of ads shown to customers. We’re looking for strong Software Engineers that can combine EMR, Redshift, Hadoop, Elastic Search and other technologies to build the next generation of our analytics and visualization platform. If this sounds interesting we’d love to hear from you!Amazon is well positioned to grow its share of a fast growing online advertising industry due to its unique assets - e-commerce data, service oriented architecture, and startup culture. Be part of a team of industry leading experts that builds and operates one of the largest big data analytics platform at Amazon. Amazon is applying the latest machine learning and big data technologies available to change the way marketers purchase, track, measure, and optimize their advertising spend. We apply these technologies on terabytes of data (over 10B new events per day) and operate clusters that push scalability limits of the existing technologies. We seek to measure every possible signal indicating impact of advertising to provide the most objective result of marketing spends.This role will involve designing and developing software products that impact many areas of our business. The individual in this role will have responsibility help define requirements, create software designs, implement code to these specifications, provide thorough unit and integration testing, and support products while deployed and used by our stakeholders.We are open to hiring this role in Seattle, Chicago, Toronto, Santa Monica, Arlington, Jersey City/NYC, Austin, and Boulder/Denver.Experience building complex software systems that have been successfully delivered to customersKnowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operationsAbility to take a project from scoping requirements through actual launch of the projectExperience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.Experience improving web latency in complex large scale deployments.Experience in databases, analytics, big data systems or business intelligence productsExperience mentoring and training other engineersAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.This position starts at $120,700/yr. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a range of medical, financial, and/or other benefits, dependent on the position offered. For more information regarding Amazon benefits, please visit https://www.amazon.jobs/en/benefits. Applicants should apply via Amazon’s internal or external careers site.#madsjob#sspajobs",co,de
30,Lowe's Home Improvement,Retail,3.5,SR. DATA ENGINEER - BIG DATA PLATFORMS,United States,$86K - $197K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1110586&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_9c4a6c10&cb=1618161346955&jobListingId=1006991146118&cpc=F7A2269C793D5877&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-59a08035d5c2c7ab&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1JcVBBdFJvUElCMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMUmUtN0t1VkxuSmhYQ3JKeUxucHdmbVdfN2Vic0ZKQWI4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyOFVRRzFXVmhUQlNuTjF6TWluVFppdWxTR0diSVA2ZVlOUWlXakNYcEsxeExTaXd2Wk92UlNjUzZCUDJjNlZxSXZvaWVwaFhQNUQ3RFJraTJVdUdYMzEza0J4Q184b0laSllBMVhXTmFmQ19fQlBBcDZmejBhNTBkVjlDcTRyV2I0R1c5azFxWjdBR0M2VEtQb25jUUgxOU93NktxUWdYUmlNaGZjdnJtcF9UU0pPaTlrLWdvTVNKbTZvMjROcWdHd3dwa2RPT0ZJYUduZU5KTHpPLUhLeF9CWHIwdXRMVmNRakdUbEpEQ0FMVkIxdkREalpQZkFtcW1LNFNBT2FzWWkwZGdIbGdSYlNMUmVhN0RZWVJxYUVNYnc3TlYyLVJYRV9ERDcxRnpiZDlhc2xaM1JlbkpLMWdNaWIxU3BFOFg0dzk0c1R3Q1FHVWNCTUJjOG5xUXNSVElpc2RKYTN5aUhvRlBQTkxXQ2dXMnZzdk9FcC0yZjJ1WDJoRU02a3RuZzU5ck1oM2FPYVY4bVZCenV5MGlwRW5CRzhFYjZ6VHJSZmg1eklxTEx2eXhFRFVLY3RIVnNVdmNldTdaSjVmaEdQOUFobUV5Ylk3NlZZOGpKLWNGV2ZnLVBwUFNZbnhmeUkyb1VaenhWbzFPM3E2STVvVlM2bFQ0TDFabjFKcjQ5aHpVS2xjU2IydGJIa1NmOUw5UU9mQmpiY3Nzb0pqQ19hSnZzRERQVFBGbjh3dkJNZmlncFFaUlFZejc0YW5jemp6b05DSXhQZnFoS0c5ZC0zeW1GSmRfTFdja2QzZjlKaVVxQzdaT3NjZ3RYd2xYRWd3ejB5T1RwUFlQUTlxVWpoSFlrQnZmd2hrMnFqalNKVWtWcTFScDVQdm90ak9lc2tPTk5OTzZMWUF3Tzd3RWtOdkhfcQ,"At Lowe’s – Data, Analytics and Computational Intelligence – we run large Big Data Platforms for Data Processing, ML, Data Analytics. If you are passionate about setting up Big Data Platforms on-prem and on cloud, working on debugging issues, platform triage, etc. this is for you. You will be challenged with managing multiple Big Data platforms on Hadoop, exploring new technologies, set up of data storage platforms involving Open Source technology, integrating data platforms with Catalog, BI Tools, setting up platform for ML model training, deployment, etc.This person needs to be motivated towards learning, exploring technologies, guiding team members, collaborating with users and be able to set up a modern platform for Data Processing, Storage, Data Preparation, Training and Deployment.JOB SUMMARY: The primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver modules, stable application systems, and Data or Platform solutions. This includes developing, configuring, or modifying complex integrated business and/or enterprise infrastructure or application solutions within various computing environments. This role facilitates the implementation and maintenance of complex business and enterprise Data or Platform solutions to ensure successful deployment of released applications.Key Responsibilities: Translates complex cross-functional business requirements and functional specifications into logical program designs, modules, stable application systems, and data solutions; partners with Product Team to understand business needs and functional specificationsCollaborates with cross-functional teams to ensure specifications are converted into flexible, scalable, and maintainable solution designs; evaluates project deliverables to ensure they meet specifications and architectural standardsGuides development teams in the design and build of complex Data or Platform solutions and ensures that teams are in alignment with the architecture blueprint, standards, target state architecture, and strategiesCoordinates, executes, and participates in component integration (CIT) scenarios, systems integration testing (SIT), and user acceptance testing (UAT) to identify application errors and to ensure quality software deploymentParticipates and coaches others in all software development end-to-end product lifecycle phases by applying and sharing an in-depth understanding of complex company and industry methodologies, policies, standards, and controlsHas solid grasp of software design patterns and approaches; understands application level software architecture; makes technical trade-off decisions at application levelAutomates and simplifies team development, test, and operations processes; develops detailed architecture plans for large scale enterprise architecture projects and drives the plans to fruitionSolves complex architecture/design and business problems; solutions are extensible; works to simplify, optimize, remove bottlenecks, etc.Provides mentoring and guidance to more junior level engineers; may provide feedback and direction on specific engineering tasksPlatform Engineering ResponsibilitiesAdministering crucial and complex Bigdata/Hadoop infrastructure to enable next generation analytics and data science capabilities.Adding immediate value by establishing big data environments based on Hadoop.Innovating and evolving our big data capabilities through research and hands-on practice.Operating a multi-tenant service, encompassing cluster management, security, resource and quota management, partitioning. monitoring chargeback, data governance, quality and lineage.Performance monitoring and Benchmarking experience to run various workloads. As needed participation in after-hours maintenance windows to update, change, and install various systems; Participation in the 24 x 7 On-Call Rotation.Hands-on experience in Hadoop cluster set up, performance fine-tuning, monitoring, and administration.Manage Bigdata application on On-prem and Public cloudMinimum QualificationsBachelor's Degree in Engineering, Computer Science, CIS, or related field (or equivalent work experience in a related field)5 years of experience in Data, BI or Platform Engineering, Data Warehousing/ETL, or Software Engineering4 years of experience working on project(s) involving the implementation of solutions applying development life cycles (SDLC)Platform Engineering Qualifications4-5 years of experience in Hadoop, NO-SQL, RDBMS or any Cloud Bigdata components, Teradata, MicroStrategyExpertise in Java/Scala/Python, SQL, Scripting, Teradata, MicroStrategy, Oracle, MySql, SQL Server, Hadoop (Sqoop, Hive, Pig, Map Reduce), Spark (Spark Streaming, MLib), Kafka or equivalent Cloud Bigdata componentsPreferred QualificationsIn most cases Lowe’s will not be able to provide sponsorship for roles located in the Tech HubMaster's Degree in Computer Science, CIS, or related field5 years of IT experience developing and implementing business systems within an organization5 years of experience working with defect or incident tracking software5 years of experience writing technical documentation in a software development environment3 years of experience working with an IT Infrastructure Library (ITIL) framework3 years of experience leading teams, with or without direct reports5 years of experience working with source code control systemsExperience working with Continuous Integration/Continuous Deployment tools5 years of experience in systems analysis, including defining technical requirements and performing high level design for complex solutionsAbout Lowe’s: Lowe’s Companies, Inc. (NYSE: LOW) is a FORTUNE® 50 home improvement company serving approximately 18 million customers a week in the United States and Canada. With fiscal year 2019 sales of $72.1 billion, Lowe’s and its related businesses operate or service more than 2,200 home improvement and hardware stores and employ approximately 300,000 associates. Based in Mooresville, N.C., Lowe’s supports its hometown Charlotte region and all communities it serves through programs focused on creating safe, affordable housing and helping to develop the next generation of skilled trade experts. For more information, visit Lowes.com.About Lowe’s in the Community: As a FORTUNE® 50 home improvement company, Lowe’s is committed to creating safe, affordable housing and helping to develop the next generation of skilled trade experts through nonprofit partnerships. Across every community we serve, Lowe’s associates donate their time and expertise through the Lowe’s Heroes volunteer program. For the latest news, visit Newsroom.Lowes.com or follow @LowesMedia on Twitter.Lowe’s is an equal opportunity affirmative action employer and administers all personnel practices without regard to race, color, religion, sex, age, national origin, disability, sexual orientation, gender identity or expression, marital status, veteran status, genetics or any other category protected under applicable law.Job Type: Full-timePay: $86,227.00 - $197,447.00 per yearBenefits:Health insurancePaid time offSchedule:Monday to FridayEducation:Bachelor's (Required)Experience:data: 5 years (Preferred)Work Location:Multiple locationsWork Remotely:Temporarily due to COVID-19",co,de
31,xentity corporation,Information Technology,5,Data Engineer / Data Developer,"Golden, CO",$60K - $70K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1110586&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_33ad35c9&cb=1618161346955&jobListingId=1006993835755&cpc=6FC5BA77C9A4CD78&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-64b1037efbc0e57b&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT1jeDdNaTlUWGpHUzgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpLVzJTQVBUVlNVNDFVdU9ocmFMS0tZTFE1QUZYamhaQXo4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX2RUYjl3eFpoRlhiVVdGSFBBN1U5SHdTaFJmd3NzdjZDMGwydkF1UEhCYmlVWEUyd1F1bGp6bFo3bVdqTVpvQVNPRWI3N0I5WFZKc2k5cVVpWm15ZVF6UHN4enVndXFOdjlrVU9GcWV0Q1EwVXRDZDhKdFU1OXBYV29xd1lqWFZmNWcycUVIWDZRcW9TajZQMEU4N1NOcEVMMnRFQ2RJX0M0c3puQ0t0X3Q4Zl9rM3lYU2xxRHR1LW81RUFyUnJHLTRiOVQzM3dLRmE3cTdEZFBuZy1Zb2hoemMtdFZ0Q3FWbUtnc2tCR2I0YzBhSHFpNFRaLVdocW5pUTM2c1ZiQy0zWU41TzFBZ0ExLTZKRVVmdHNsYVNlN25jUnRrN1ZNY0xOcTlTbjRHTER0RjhaNU1RdVFiVnN3NUMwd3JaSDdRcTJCNmpEM2Y0QVdIcVJiSzFuUDhlRE41MjVDUmVkSTdnRlB5bUM4LWlSRzA4MTlxdEVYbEJkQlRhcTBfT01TQjg4ZGJJYy1TRVQ4VzFCN09MVmZqdU9NM0x4RTJGY19iRzVJNEtEd2FJS0FaeWk0MDc2dzVaYll3N1pMQVloRk16N1djZjhGNWRyeTVWXzloTjAtSTRWQnRmMGgtWWEyd1k1NEpYWXl5eTYyeFhjcVhTeTRXblJuU2MzRWlmUFMyZS1vTF9wZHMtY1g4d3ZCTWZpZ3BRWlJRWXo3NGFuY3pqem9OQ0l4UGZxaEtHOWQtM3ltRkpkX0xXY2tkM2Y5SmlVcUM3Wk9zY2d0WHdsWEVnd3oweWpRRkZRMzdlNUVIaEhZa0J2ZndoazJxampTSlVrVnExUnA1UHZvdGpPZXNrT05OTk82TFlBd083d0VrTnZIX3E,"Data Engineer Data Developer - Denver, COWe are a fast-growing data consulting and support services firm - focused on large data programs in data types such as geospatial, open, big, and IoT data. We have high profile clients and projects that our staff really delivery for, as well enjoy knowing they make a large difference.This role supports data transformation platform engineering development and operations technical support. This includes support Open Data system management, ETL scripting, development support of open source and COTS ETL code and integrations to publish open data by providing infrastructure, web applications, harvest ETL processes, and general support. The role will manage an ETL environment to maintain dataset updates to a centralized portal, setup new ETL scripts for data management, for primarily publicly available data.Role Needs: *This role is the tech side of data: . While for a data solution, the effort is more technical in nature and will grow into lead developer efforts to more complicated solutions in cloud, DevOps, containers, and advanced script development in NodeJS, Python, etc.Lots of Client time.:  We’ll be working with clients to refine and groom requirements. Strong Communicator, enjoys client interaction, and can set realistic, achievable goals. We look for differentiators in staff who focus on client satisfaction, care about the mission, and have empathy for organizations adapting to this fast moving technology world.We are looking for candidates who think data is awesome: , like learning new leading edge tech, and thrive in rapid learning environments (new subject matter, complete with lingo, acronyms, other client context).Candidates enjoy working in Agile Kanban or Scrum environments : and are self-motivated environments - yes it is primarily a remote and virtual team. They like working with peers on requirements, design, and solution and believe ‘iron sharpens iron’.Capable of thriving in context switching environments.:  This may be most important as the data world changes fast. If you do not enjoy change, stop here. This role will require being on data engineer sprints that are on 2-3 data engineer tracks in similar domain and technology.Position Requirements: Bachelor’s degree preferred with min 3 yrs exp or Coding certifications with 5 or more years exp.: Ability to work multiple, time-sensitive tasks and rapidly context switch across subject matter, communication architecture products, and stakeholder audiences.Ability to work independently as well as as part of an integrated team.Excellent written communication skills.Demonstrate strong analytical and critical thinking skills.Strong foundation in Development and Operations Principles.Must be able to pass basic gov background, drug and reference checksTechnical Experience Required: Data Management: Metadata, ETL/Data Pipelines.Programming Languages: SQL, Python, Linux/Bash, Docker/containers.Development Practices: MVC, ETL, configuration management, extending code.Tools and Software: Familiarity with GitHub, G-Suite, Kanban boards, PostgreSQL.Preferred (Study up pre-interview is fine!)Experience with DevOps & infrastructure management tools (terraform, serverless, etc)Web Development Expertise (Front-end and back-end)Familiary (not expert) Open Data Metadata standards (ISO, DCAT, FGDC, Dublin Core)Experience with PHP & JavascriptBenefits: We emphasize a balance of work and life and target 40-50 hour weeks with ample time to refresh with great paid-time off.Salary & Bonus Programs - Competitive Salary. Multiple Recognition and Rewards Bonus Programs (Performance Bonus plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (6) Sick LeaveMedical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care with 100% of employee or 80% employee and 50% family. Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.About Xentity: Our President has a vision to continue to focus on solutions that transform the Next Generation. Using data integration, knowledge solutions, and amazing increases in computing to impact energy, geosciences, land management, we can bring quality and simplifications to existing and new data flow! Imaging being on a team that brings advanced concepts like high performance computing, AI, data science, fuzzy logic, changing interfaces human-computer points mobile or augmented reality and many more disruptions. This truly can put the I back in IT and GIS.... by concentrating on pragmatic knowledge-first data designs, leadership and management, and the all too forgotten focus on outreach and engagement strategies and solutions.Job Type: Full-timePay: $60,000.00 - $70,000.00 per yearSchedule:Monday to FridayWork Location:One locationWork Remotely:Temporarily due to COVID-19",co,de
32,Akerna,Information Technology,1.4,Data Engineer,"Denver, CO",$100K - $105K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_c4d97194&cb=1618161346955&jobListingId=1006992785329&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-6abfbfbb7f39f8ed,"Job Title: Data Engineer
Location: Remote
Department: Engineering
Reports To: Director of Engineering Operations
Salary Range: $100,000 - $105,000 Annually
Who We Are:
Akerna is a leading enterprise software solutions provider that enables regulatory compliance and inventory management. At Akerna we are passionate about solving problems that better our world. We provide data-driven solutions worldwide across the entire supply chain. Our technology empowers the industry to prove outcomes that positively change lives every day. We have a passionate and purposeful work environment where we live by five principles: Do the right thing, Be part of the solution, Show people you care, Grow together, and Make an impact.
Essential Job Duties:
Architect, implement, and document the Snowflake and ETL infrastructure
Evolve current data flow to account for new data sources and increased data volume
Maintain the integrity of data within our data pipeline and warehouse
Develop data models and views for internal and external client reporting purposes
Integrate data from 3rd party services and custom pipeline
Develop ETL jobs and tests to process, validate, transport, collate, aggregate, and distribute data
Collaborate with product managers and analysts throughout the company to deliver reliable data that powers actionable insights
Minimum Qualifications:
2+ years of data engineering experience
Experience working with data warehousing concepts including data model design and optimization strategies
Experience using and maintaining BI visualization tools
Experience with version control systems such as Bitbucket etc.
Experience automating business and reporting processes
Creating production ready scripts with Python and SQL
Very strong verbal and written communication skills
Skills/Abilities Preferred:
BS/MS in Computer Science, Math, Physics, or other technical fields
At least 12 months of experience with Snowflake
Proficiency in building data pipelines in a CI/CD environment
Experience working with incremental data loads and data archiving
Experience designing and deploying high-performance systems with reliable monitoring and logging practices
Experience using data collection platforms such as Fivetran
Familiarity with at least one cloud ecosystem: AWS/Google Cloud
Experience of working in an agile environment and using tools such as JIRA/Asana/Trello
What We Offer:
Competitive salaries
100% company-paid medical, dental and vision insurance
Generous vacation policy
Remote Workforce
NOTE: Thank for your interest in working with us. Akerna is an Equal Employment Opportunity employer. Employment decisions are based on merit and business needs, and not on race, color, creed, age, sex, gender, sexual orientation, national origin, religion, marital status, medical condition, physical or mental disability, military service, pregnancy, childbirth and related medical conditions or any other classification protected by federal, state or provincial and local laws and ordinances. Reasonable accommodation is available for qualified individuals with disabilities, upon request. This Equal Employment Opportunity policy applies to all practices relating to recruitment and hiring, compensation, benefits, discipline, transfer, termination and all other terms and conditions of employment.",co,de
33,Flowhub,Information Technology,4.4,Data Engineer,Colorado,$115K - $120K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_41c3fb24&cb=1618161346956&jobListingId=1006984366701&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-05688091c5f0432b,"At Flowhub, we're about more than technology — we're on a mission to make legal cannabis accessible to everyone. Founded in 2015, Flowhub pioneered the first Metrc API integration to help dispensaries stay compliant. Today, over 1,000 dispensaries trust Flowhub's point of sale, inventory management, business intelligence, and mobile solutions to process $3B+ cannabis sales annually. We exist to make safe cannabis products accessible to every adult on planet Earth.

Flowhub creates user-friendly business management and compliance products that increase revenue in the highly regulated cannabis industry. Our Engineering department is highly creative, incredibly resourceful, and obsesses over the user experience.

We are seeking a Data Developer specializing in Big Data and Data Integration in Denver. The successful candidate will work with the enterprise data teams within the organization and will be accountable for the design and development of data pipelines, processes and integrations. The ideal candidate is a strategic thinker always willing to learn, with strong analytics background and team player, comfortable working at a fast pace, and carries considerable experience with enterprise data implementations, data integration, data management, advanced analytic software applications, excellent knowledge of technical concepts, and knowledge of metadata management, data privacy and compliance requirements (HIPAA, CCPA, GDPR) as well as Service Oriented Architecture. In addition, the candidate is comfortable prototyping and quickly iterating in a notebook-based environment to understand data structures, troubleshoot data integrity issues and provide quick insights to stakeholders.

Top Skills

At least 4 years of experience working with relational datasets as a data engineer.
Experience with relational SQL and NoSQL databases, including Postgres and MongoDB.
Experience with Python data stack is required. This includes but is not limited to NumPy, SciPy, Pandas, Scikit-learn, Jupyter, Plotly, Flask, SQLAlchemy.
Experience with data pipelines and workflow management tools is required, with Airflow being a big plus.
Experience with a cloud technology stack is required, with GCP being a big plus.
Hands-on experience with BigQuery is highly preferred but not required.

Additional Skills & Qualifications:

Experience in implementing big data solutions using GCP services.
Able to recommend appropriate data processing and storage solutions on the GCP stack
Ability to develop and maintain a data REST or GraphQL API using Flask
Experience with stream-processing systems such as Dataflow.
Experience with big data processing tools such as Spark or Kafka

Compensation: $115k to $120k

About Flowhub

At Flowhub, we envision a future where safe cannabis products are accessible to every adult on planet Earth. Founded in 2015 by CEO Kyle Sherman, Flowhub provides highly regulated retailers with a mission-critical retail operating system that automates complex compliance mandates like transaction limits and state reporting. Our mission is to empower dispensary growth and help business owners achieve their dreams.

Founded in Denver, but fully remote with teams across multiple states, Flowhub is trusted and loved by over 1,000 cannabis retailers and partners across the U.S., processing over $3 billion in cannabis sales annually. As the pioneer and original API integrator to Metrc, the state track and trace system used in most legal cannabis markets, Flowhub helps cannabis retailers automate and simplify business operations through technology to keep companies and government transparent, keep cannabis products off the black market, and build a robust scalable industry that is approachable for all adults and medical patients.

Flowhub is backed by top-tier investors including e.ventures, Evolv Ventures (the Kraft Heinz-backed venture capital fund), and Poseidon Asset Management, as well as Iqram Magdon-Ismail, a co-founder and former CEO of Venmo. Flowhub has raised nearly $45 million in venture funding.

Kyle Sherman is also the founding director of the Cannabis Trade Federation (CTF) & US Cannabis Council (USCC), a national coalition of cannabis-related businesses that represent all aspects of the industry including cultivators, dispensaries, wholesalers, distributors, and ancillary businesses. USCC's mission is to build a future of legal access to cannabis delivered through an equitable and values-driven industry by advancing cannabis legalization at the federal and state level, and promoting restorative justice for communities harmed by cannabis prohibition.",co,de
34,Media News Group,Media,2.5,Salesforce Data Engineer - MNGi,"Denver, CO",$115K - $120K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_764ff1a7&cb=1618161346956&jobListingId=1006994371656&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-c497f66ecf73015a,"We’d love you to join our thriving MediaNews Group product development team whose mission is to create people-centric, software experiences that empower our local news and digital partners. We help small teams play big!
Be part of a digital media landscape in the midst of rapid change; our team is at the center of a new content, marketing, and revenue-sustainable experience that puts content, people and performance first. You will be joining not only a team, but also a pragmatic way of working – we are agile, lean, and minimum viable process-oriented as we transform from a build-to-scale mindset through four core principles: be transparent; be disciplined; be bold; be together. Join us!
We are excited to be hiring a Data Engineer to join our high-performing team of experts as we continue to develop and enhance our Salesforce implementation for all parts of our business. Our Salesforce Lightning implementation includes Sales Cloud, CPQ, Tableau CRM, Partner Communities, and Pardot integration with plans to expand into other suite offerings. We are only a few years into our Salesforce journey, so you will have the opportunity to shape the course towards scale and meeting the needs for our customers. You will be part of the larger Product & Technology team which prioritizes learning, continuous improvement, and flexibility, allowing for many personal and professional growth opportunities.

Essential Functions
Collaborate with data warehouse team and salesforce administrators to develop and configure integrations with salesforce and a variety of external platforms
Collaborate on relational and dimensional data modeling and database design.
Implement systems that validate data, ensure quality and consistency as data moves from source systems to production.
Troubleshoot data issues, validate result sets, recommend and implement process improvements, provide ad-hoc and scheduled reports and analysis.
Salesforce Platform Development/Configuration
Manage development-related Salesforce Release upgrades and documentation.
Developing customized solutions within Salesforce
Creating development goals and working within a product management timeline

Competencies & Skills
3+ years of relevant Software Engineer experience
2+ years of experience in the following:
ETL processes
Python
SQL
Working with web service APIs
Version control system such as Git
Linux and/or OS X
PostgreSQL or other RDBMS data stores
Knowledge of database design and architecture principles, including in the data warehousing space
1+ year of experience working with Salesforce
Salesforce Developer Certification preferred
Advanced knowledge of Salesforce Lightning
Experience with complex Apex code",co,de
35,Pinnacol Assurance,Insurance,4.1,Data Engineer,Colorado,$115K - $120K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_3b368792&cb=1618161346957&jobListingId=1006987717953&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-df0ae2f55f3d0b2c,"Pinnacol Assurance does just one thing, and does it better than anyone: provide caring workers' compensation protection to Colorado employers and employees. Although employers are required by law to provide Worker's Comp insurance, we believe our service is making a meaningful impact in worker's lives across Colorado in their moments of need.

We have big hearts and love big ideas. We've been around for over 100 years, but don't let that fool you. Pinnacol is committed to taking care of Colorado employers and workers in the most innovative of ways! We celebrate continuous improvement, new ideas, compassion, teamwork, integrity and excellence.

With our number one priority to keep everyone safe, along with the heart of Pinnacol's ""culture of caring"" to do what is right and not what is easy, we're currently having our team members work from home. During remote work, we're still making time for fun! We host virtual painting classes, virtual yoga and Zumba classes, and virtual happy hours!

What you'll do:

As a Data Engineer, you play a key part in realizing our mission to provide customers with tools they love to use. As a member of the Data Transformation Team you will be responsible for data management tasks including design, development, and data security in a Google Cloud Platform environment. You will leverage your experience and skills to design solutions that will deliver Pinnacol data products while operating as a key contributor on a team of dedicated professionals working toward a common product vision.

Our Tech Stack:

Google Cloud Platform, Python, SQL (Postgres, BigQuery, Oracle dialects), Airflow, Docker, Terraform, GitLab

We have an open mind about implementing new technologies and processes where beneficial. Bring your experience and recommendations.

What you can expect:

Build new data products and systems from various internal and third party data sources that use custom code in Python, SQL/NoSQL, Google Cloud-Composer(Airflow), Apache Beam and other technologies
Create reliable, maintainable and scalable data solutions
Champion software and data engineering best practices by developing, refining, iterating, integrating, testing, staging, and deploying maintainable technical solutions.
Develop secure solutions which adhere to data privacy laws and regulations using Data Loss Prevention toolsets and secure storage practices.
Enhance our platform capabilities and make recommendations to support a rapidly growing organization.
Identify system or program problems efficiently and effectively and propose pragmatic solutions.
Participate in code pull/merge request and design reviews
Create design documents that satisfy business requirements, follow adopted methodologies and lead to efficient, easy to maintain, and reliable systems
Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code
Remain current on the external environment for industry leading tools, technology, analytics and best practices to continuously improve Pinnacol's customer value proposition.
Train other employees as needed
Present business and technical subjects to team members or other internal groups
Perform other duties as assigned

What you need to be successful:

Knowledge of data engineering best practices and experience in implementing them through designing and implementing data solutions in cloud environments in one or more of the following cloud environments (GCP, AWS or similar)
Experience with ETL/ELT tooling and practices using batch (Airflow or similar) or near-real time (Spark, Apache, Flink, Kafka, or similar) methodologies
Experience with container technologies especially Docker
Knowledge of Cloud-based Data storage and security best practices
Adaptation: Ability to adapt in order to work effectively in ambiguous or changing situations, and with diverse individuals and groups
Communication: Ability to communicate highly technical ideas to a wide variety of audiences, including technical and non-technical audiences
Innovation: Ability to generate novel solutions and creative ideas in order to identify system or program problems, and propose pragmatic solutions
Teamwork: Ability to work effectively with people and cooperate with others in developing and releasing software with a team
We can't do our work without people like you.
Our employees are extraordinary and committed to making a difference. Here's some of the ways we show our appreciation.
Our benefits go beyond the basics. You'll get to choose from diverse benefit offerings for medical, dental and vision.
We care about each other. We enjoy a positive, collaborative work environment. We are hard workers and high performers.
Take a day (or 20!) off. Enjoy 20 paid days off your first full year plus 9 paid holidays.
Take care of yourself. Sign up for unique wellness programs, including on-site, company-paid fitness facilities and classes
Get your learning on. We promote a learning culture to help you master your current job and cultivate the skills of the future through a variety of on-site, online, and off-site professional development opportunities.
Give back and get paid. Through our employee volunteer program, Pinnacol in Action, employees receive paid time off to volunteer with Colorado nonprofits.
Share in our success. You'll have the opportunity to earn a quarterly incentive, up to 20 percent of your annual base salary, when your team exceeds their goals and objectives.

When we find the right person, we try to put our best foot forward with an offer that excites you. We consider what you'd like to be paid, the skills and experience you bring, what similar jobs pay in the Denver area and make sure there's equal pay for equal work among those you'll be working with. When meeting the requirements, the minimum of what you can expect for this position is 109,820.00. The actual offer will vary depending on the candidate's skills and competencies.

Want to love your work? Apply today!",co,de
36,Frontdoor,Business Services,3,Data Engineer,"Denver, CO",$115K - $120K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_e00a5fcf&cb=1618161346957&jobListingId=1006991054451&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-c18e58cc60aabd41,"Company Overview

Frontdoor is a company that’s obsessed with taking the hassle out of owning a home. With services powered by people and enabled by technology, it is the parent company of four home service plan brands (American Home Shield, HSA, Landmark and OneGuard) and an expanding portfolio of home services. Frontdoor serves more than two million customers across the U.S. through a network of 16,000 pre-qualified contractor firms that employ over 45,000 technicians. The company’s customizable home service plans help customers protect and maintain their homes from costly and unplanned breakdowns of essential home systems and appliances. With more than 45 years of experience, the company responds to over four million service requests annually (or one request every eight seconds). For more details, visit frontdoorhome.com.

Position Overview

As an intermediate level Data Engineer, you will use various methods to transform raw data into useful data systems. You will create algorithms for the purpose of aligning data systems with business goals. You will manage projects within larger projects.

Job Responsibilities

Analyze and organize raw data from multiple sources to produce requested or required data elements

Build and maintain data systems and pipelines to support increases in data volume and complexity

Create and maintain optimal data pipeline architecture

Contribute towards the development, construction, and maintenance of data models within data warehouses using dimensional modeling

Conduct complex data analysis and report on analysis to end-users using system tools and database or data warehouse queries and scripts

Interpret trends and patterns

Prepare data for prescriptive and predictive modeling

Program and maintain reports, dashboards, data generators and other end-user information portals or resources

Explore ways to enhance data quality and reliability

Identify opportunities for data acquisition

Develop analytical tools and programs to troubleshoot data related issues and assist in the resolution of data issues.

Collaborate with analytics and business teams to improve data models in order to increase data accessibility and foster data driven decision making in the organization

Manage projects within larger projects

Job Requirements

Bachelor's degree in Computer Science, Statistics, or similar field

2 - 5 years experience in relevant field

Experience with SQL database design

Experience with schema design and dimensional data modeling

Experience designing, building, and maintaining data processing systems

Data engineering certification, such as IBM Certified Data Engineer, is a plus

Ability to broadly apply principals, theories, and concepts to job assignments

Understanding of and ability to follow standardized practices and procedures for problem-solving for a diverse range of challenges

Technical and operational proficiency in solving moderately complex problems

Strong verbal and written communication skills, as well as data presentation skills

Technical expertise with data models, data mining, and segmentation techniques

Knowledge of programming languages, such as Java and Python

Strong numerical and analytical skills

Knowledge of big data pipelines, cloud databases, and data architecture

Frontdoor is a company that’s obsessed with taking the hassle out of owning a home. With services powered by people and enabled by technology, it is the parent company of four home service plan brands: American Home Shield, HSA, Landmark and OneGuard, as well as AHS Proconnect , an on-demand membership service for home repairs and maintenance, and Streem, a technology company that enables businesses to serve customers through an enhanced augmented reality, computer vision and machine learning platform. Frontdoor serves more than two million customers across the U.S. through a network of more than 16,000 pre-qualified contractor firms that employ over 45,000 technicians. The company’s customizable home service plans help customers protect and maintain their homes from costly and unexpected breakdowns of essential home systems and appliances. With nearly 50 years of experience, the company responds to over four million service requests annually (or one request every eight seconds).For more details, visit frontdoorhome.com.

Job Category: Engineering

ID: R0015370",co,de
37,Invitae,Biotech & Pharmaceuticals,4.1,Senior Data Engineer,Colorado,$115K - $120K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_18ec535a&cb=1618161346958&jobListingId=1006992635871&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-63c72f0a24908565,"Invitae is dedicated to bringing comprehensive genetic information into mainstream medicine to improve healthcare for billions of people. Our team is driven to make a difference for the patients we serve. We are leading the transformation of the genetics industry by making genetic testing affordable and accessible for everyone to guide health decisions across all stages of life.

POSITION SUMMARY:

This is an opportunity to build infrastructure to power innovative biotechnology. The person in this role will help plan, develop, and build data infrastructure critical to our In Vitro Diagnostics program. This person will be responsible for the accuracy and usability of data central to the development and regulatory approval of Invitae's cancer diagnostics. This person will work closely with program technical leads, data scientists, and quality assurance personnel to think creatively and achieve ambitious goals to advance the treatment of genetic diseases.


RESPONSIBILITIES:

Contribute to our mission of enabling precision oncology through genetic testing
Collaborate with multiple teams and own solutions from end-to-end
Design and develop tools and infrastructure to enable teams to consume and analyze data faster
Understand our complex data ecosystem and build ETL solutions
Build custom software and database systems which integrate with commercial software including a laboratory information management system
Support continuous integration and continuous development through automated configuration management tools
Maintain and augment existing systems to meet the needs of evolving processes
Adhere to standard operating procedures and work in a manner compliant with regulatory standards


QUALIFICATIONS:

Are self-starters and can work towards a larger goal with minimal guidance
Have 6+ years of relevant industry experience, including 3 years of hands-on experience working with large datasets, pipelines, data modeling, and data warehousing
Have a focus on high-quality code, including automated testing and coding best practices
Have architected distributed systems with infrastructure automation, monitoring and alerting
Are familiar with key components of our tech stack including Python, AWS, Docker, Terraform, and Jenkins


Bonus points for experience with and/or enthusiasm for:

Laboratory Information Management Systems (LIMS)
Clinical data from medical devices
Working in a regulated field
Molecular biology / genomics

Expected Pay Rate in Colorado from: $xx

Compensation for the role will depend on a number of factors, including a candidate's geographic location, qualifications, skills, competencies and experience and may fall outside of the range shown.


Invitae offers a competitive total rewards package, which includes healthcare coverage, 401k, and a broad range of other benefits, outlined below:

Health, dental, vision, short- and long-term disability, and basic life insurance coverage
Paid time off, holiday pay, parental leave, and other health and wellness supports


At Invitae, we value diversity and provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.",co,de
38,Maxar Technologies,Aerospace & Defense,3.9,Senior Data Engineer,"Westminster Hills, CO",$108K - $180K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_dc503090&cb=1618161346958&jobListingId=1006989251310&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-6b61ff4964243ca8,"Job Details
Maxar is looking for a data-oriented computer scientist to join the Data Intelligence team as a Senior Data Engineer in Westminster, CO. This role can also be performed remotely. The individual should dig data-pipelines, drive data-value, be passionate about delivering scalable, supportable solutions, and know a thing or two about AWS.
Responsibilities:
Develop high-quality, resilient and supportable data pipelines and business solutions
Analyze and Interpret data from various systems
Provide technical leadership and insight
Validate data and maintain healthy data flows
Work on a fast-paced agile team
Minimum Requirements:
Must be a U.S. citizen and be willing and able to obtain Secret security clearance
Bachelor's degree in Computer Science or similar field.
Minimum of 8 years of software development experience.
Experience creating data pipelines including ETL, aggregations, SQL tuning and some relational modeling
Experience with Spark analytics engine processing large data sets
Experience with Scala and Python
Experience with SQL dexterity including complex queries, SQL tuning, CTEs and working with JSON data
Experience using relational database such as Postgres
Preferred Experience:
Master's Degree
Ability to use a wide variety of open source technologies and cloud services
Designing and implementing resilient, scalable, and supportable systems in AWS
Complex, multi-step ETLs including DAG creation and scheduling in tools such as Airflow
Distributed SQL engines such as Presto or Trino
Java experience
Data visualization technologies such as Tableau, Redash, python dash or R shiny
Communication with stake holders and business leaders to clarify requests and suggest value-add solutions
AWS technologies such as EMR, RDS, EC2 and S3
GIS or PostGIS or exposure to GIS data
Stream processing technologies such as Flink, Kafka or Kinesis
Working with apps and data flows that run on Kubernetes
Building and/or using data APIs
The compensation range for this position is $108,000.00 to $180,000.00 annually, dependent on skills and experience. This position is also eligible for a bonus plan.
Maxar Technologies values diversity in the workplace and is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",co,de
39,CyberCoders,Business Services,4,Cloud Data Lake Engineer,"Littleton, CO",$100K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1110586&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_87567224&cb=1618161347032&jobListingId=1006995111763&cpc=F4EED0218A761C36&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-10b2a61c7d8a0069&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT13MXNxczYzWkdyaTgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpMV2pvZ1NIMTBtLWFHZTJoZTJabDI1dTk2SUx6UEUwMFA4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWhIeGduLWV0QzdkcHN5d1VjUkRYekNMSVZCOThYMVRHSVI3YTNRSVRBV1o1dGEyVGlCSXMxWmxidzd3TlA1emxSTjRHWVpDaGd6VHlXVUNKWlhTVXRtUWRfZGZhb3BPaW4zaGR4eDh4c2Y4NEtHeGpOYkdQOWtwcnNrMzZxX0tBY2Z1cDBEWG54cF9Lb3l0cnloWlZnYTU1ekhDaDIxNy0xWHdlaklSdDBWM0pjMDZLeUZ2UnFKX0VJcUpnVm1wTG5fQVNIZXFqWW1Pd0Y2Rzk3OVl4ZDVNeGZVblhjRkNEaVhNemR6TWxCRG9naE5ZaDhQSVpiS2tDWGd2Si1DUmZKY0lXa19YS0JiYWtpVkpiVDJpaE1sMEw1cmpDT2c3V25mZTJpakc5QldiOTU1MXFnUVR3V0FkaG1nLTNUUlo4WGozYkRuWHhSUUxQSnpQTUo3R2tudkZEMktGUWMzVGdSdUdRV29oU3ZkTXZ2NFoxY0hYdmlSRGtmc1BabkZ2Zk4zdmNqVmt6ZE9lQmJzc1FneWEwTDJDa1RCUWJwc0RVaElOd244MFItVm9CdlpLUXFuRFRiV1FlUVpqZS1TUzVNN1J5MElYOGhleEpab1ZUMlgtdmk5UnhpalBSbDczc0NBS2VVWWFYLVhTeEhJbUJkMG1FR08xVTJqQnhVai1kbTZ2YmlUYm1RRTRNbGlya2k4cDhIRDVuZ1FITllLdnlOYmxlb0ZCYTVielFQbXNaV2Y2YU9nT01YV0tqTXJIZk1vX1FYOENlUVhLeEcwY1Z4VnhscG5MdFh5ZGxmclBRdkptNm8yNE5xZ0d3d3BrZE9PRklhR25lTkpMek8tSEt4X0JYcjB1dExWY1FqR1RsSkRDQUxWQjF2RERqWlBmQW1xbUs0U0FPYXNZaTBkZ0hsZ1JiU0xSZWE3RFlZUnFhRU1idzdOVjItUlhFX0RENzFGemJkOWFzbFozUmVuSksxZ01pYjFTcEU4WDR3OTRzVHdDUUdVY0JNQmM4bnFRc1I2Z08xVEVpb0NWQzEwaEd5WHlVd3VMcWJDaXJkbzcyTUJFTElIMkxwSjNmN1E5TExoZl9DYUdTNEl6N2dsSTdjR1BOZ1R1bUFxZHlfdWdBRkV4TkhSOUs3V0pBcFdFZDhyVjVyUWozWTMyWlpRMzRtd1pFdGNRRTFTNVJDY3FKeU5tM0ktNDY0djFxdXRaRER0VXBPeGFXQll1b29hdE1EcUFpSkJzZjRnMXhaYW9HNTZZUmZyWGJJYTFrN2tnU1dtZEZGdm9feFh6bmFiaE1iSU9nQ0xKUEk3TDFMWFlsOFB2R2ZNYW9XVlR0Vm9OYjZFZG92QlVnYVVjcjM3Q2o0aE02MFBob2dPWDZ0TEUtb2E1UHh6cUgxdmQ5VG9wNXpCd2JKVm1teTlCdWljSEszaXo4MzZRaXk4bmpBcEtWMWxzbWRxN0ZYNXdQelpJX2U2SGRVblE,"Cloud Data Lake Engineer
If you are a Cloud Data Lake Engineer with experience, please read on!

With offices located in beautiful Denver, Colorado, we are building a next gen 5G network to disrupt and change the way the world communicates. Our goal is to fuel innovation for nearly every single industry in existence. We are looking for high energy 5G wireless professionals to join our winning team and help take us to the next level.
What You Will Be DoingBuild and implement complex data solutions in the cloudUtilize best practices for the design and implementation of the data lake storage approach on Public Cloud: including data store, formats, encryption, compression, and access controlsUncover and recommend remediation for data quality anomaliesInvestigate, recommend and implement data ingestion and ETL performance improvementsDevelop and execute test plans to validate codeOn-board end-to-end datasets to the data lake and relevant access provisioningDesign and implement a data catalog that democratizes data access in a secure wayConnect applications to the data lake for data consumptionConsult with business stakeholders and translate their requirements into analytics and reports on the data lake
What You Need for this PositionExperience with cloud and commercial Data Lake platforms
Experience with Apache Hadoop and the Hadoop ecosystem, including hands-on experience in implementation and performance tuning Hadoop/Spark implementations.
Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro)
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)
Experience developing software code in one or more programming languages (Java, Python, etc.)
Bachelors degree or equivalent experience in Computer Science, Engineering, or Mathematics

Nice to Have

Masters or PhD in Computer Science, Physics, Engineering or Math
Hands on experience leading large-scale global data warehousing and analytics projects
Ability to think strategically about business, product, and technical challenges in an enterprise environment
Ability to collaborate effectively across organizations
Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development
Demonstrated industry expertise in the fields of database, data warehousing or data science
Implementing AWS services in a variety of distributed computing, enterprise environments
Desire and ability to interact with different levels of the organization from development to C-Level executives
What's In It for You
For your hard work and dedication, you will be rewarded with a competitive base salary, RSUs and benefits including but not limited to:
Competitive base salary + bonusFull benefits package (health, dental, vision, HAS, FSA)PTO plan, up to 6 weeks annuallyTuition reimbursement, employee company discount401(k) + Match
So, if you are a Cloud Data Lake Engineer with experience, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",co,de
40,Oracle,Information Technology,3.7,Senior Oracle Big Data Engineer,"Broomfield, CO",$89K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_b62f2ce3&cb=1618161346958&jobListingId=1006991595965&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-80d9125806cee424,"Senior Oracle Big Data Engineer-21000HHO

No Visa Sponsorship is available for this position.

Applicants are required to read, write, and speak the following languages: English

Preferred Qualifications
The Oracle Data Cloud is on the cutting edge in development of measurement and targeting methodologies for digital and offline advertising. The largest advertisers, CPG companies, and social media platforms in the world use these methods to help better understand and plan their advertising strategies.
As a Senior Oracle Big Data Engineer (Software Developer III) you will be implementing and tuning high-performance big data computing methodologies at-scale. This data powers our SaaS B2B web application that helps our customers optimize their advertising spend for media campaigns across various web and tv platforms.
Primary Responsibilities:
Ingest data into Oracle Exadata Database while optimizing for real-time aggregation and filtering with SQL queries across hundreds-of-billions of rows of data
Write optimized SQL for features using query plan analysis
Use of partitioning, indexing, parallelization, caching, various forms of storage, precomputing, and other strategies to provide fast real-time queries over big data
Scale-out across multiple Oracle Exadata Databases partitioned for many customers
DevOps code ownership from development throughout customer usage
Troubleshoot performance degradation and resource contention
Prepare data reports for analysis of data correctness
Communicate with team members, project management and data scientists to understand requirements and strategically implement robust software designs
Consistently strive to produce the best implementations of the fastest, most accurate digital media measurement products in the market.

Skills and qualifications:
Our management team is looking for a qualified candidate who will be energized by the dynamics of an entrepreneurial work environment. If you thrive on change, run with new challenges, and you’re interested in what you’ve read so far, you have the qualities we’re looking for in a candidate.

Here’s a summary of the skills you’ll need for this position:
BS computer science or related field
5-10 years of experience in software development or MS in Computer Science
Experience with big data tools (Oracle Exadata, Spark, Hive, etc).
An understanding of software development practices including functional programming, object-oriented programming, unit and integration testing, deployment pipelines, etc.
An understanding of cloud architecture patterns such as containerization, cluster computing, message queueing, workflows, etc.
Experience with Python and/or JVM languages
The desire to continually learn and test your own boundaries
Collaborative, positive attitude with desire to work in a demanding, fast paced, and dynamic work environment for a rapidly growing business unit
Exceptional problem solving and troubleshooting skills
Unrelenting focus on practical business implications

About us
Are you ready to take a leading role with one of the most innovative and exciting technology companies that is transforming the marketing world?
While advertising and media continue to grow digitally and revolutionize marketing “online”, 93% of all consumer spending is still happening “offline”. Marketers want to find buyers of their products - not just “clickers”. Oracle Data Cloud is leveraging the power of big data, technology and predictive analytics to fuse offline sales across various digital and tv platforms. By helping marketers build, reach and measure purchase-based audiences, ODC serves as core marketing infrastructure for a data-driven world.
 Even in the face of our sustained growth we've managed to preserve the energy, creativity, nimbleness, individual empowerment and fun of an emerging company. We're Colorado-based and have offices in NYC, Boston, Chicago, San Francisco, Detroit and London.

Detailed Description and Job Requirements
Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience.
Colorado Pay Range: From $88,737 to $159,727 per annum
Eligible for bonus and equity
Oracle offers a comprehensive benefits package which includes the following:
1. Medical, dental, and vision insurance, including expert medical opinion
2. Short term disability and long term disability
3. Life insurance and AD&D
4. Supplemental life insurance (Employee/Spouse/Child)
5. Health care and dependent care Flexible Spending Accounts
6. Pre-tax commuter and parking benefits
7. 401(k) Savings and Investment Plan with company match
8. Flexible paid time off (unlimited or accrued vacation and sick leave)
9. Paid parental leave
10. Employee Stock Purchase Plan
11. Adoption assistance
12. Financial planning and group legal
13. Voluntary benefits including auto, homeowner and pet insurance

Oracle is an Affirmative Action-Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veterans status, age, or any other characteristic protected by law.

Job: Product Development
Location: US-CO,Colorado-Broomfield
Job Type: Regular Employee Hire
Organization: Oracle",co,de
41,KSM Consulting,Business Services,4.3,Senior Data Engineer,"Denver, CO",$89K - $160K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_8ccf7883&cb=1618161346959&jobListingId=1006988100685&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-c4984ca084f39f18,"Company Description
At KSM Consulting, you are bigger, bolder, and brighter. You bring innovative ideas to the table, and you learn from the experts sitting beside you. You stand on the shoulders of giants and on some days, you are the giant. That’s what we call…
You. Amplified.
At our data, technology, and digital transformation consulting firm you’ll be exposed to the latest industry trends as well as some of the most challenging problems our clients face. And through deep understanding, tenacity, collaboration, and know-how, you help those clients find the solution that’s right for them. In everything you do, you’ll help your clients, colleagues, and communities thrive. We serve clients across the nation from our headquarters in Indianapolis, IN and teams in Denver, Co, Lansing, MI, Columbus, OH, Fort Wayne, IN, Atlanta, GA and Washington D.C.

Job Description
As a Data Engineer, you will work closely with many teams across our company on complex, advanced analytical projects to perform data sourcing, data profiling, and other data manipulation functions.
You will be directly responsible for the solutions we build for our clients, addressing their business needs through requirements gathering and collaborating on solution reviews. We are looking for self-starters with the skills necessary to empathize with the clients’ needs, translate technical complexities, develop appropriate solutions, and contribute to the growth of our technology and data-driven company.
Here’s what a typical day for you might look like:
Work closely with the solution leads, project managers, data architects, and data scientists on solution design, architecture, and implementation
Perform extraction, transformation, and loading of data from a wide variety of data sources using various data engineering tools and methods.
Query and process large data sets and perform data profiling and data quality assessments.
Design and implement data solutions for integration across systems that are both secure and operational.
Assist in creating database models and architecture design and documentation
Conduct research and development as well as contribute to the long-term positioning of and emerging technologies related to data sourcing, cleansing, and integration
Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code.
Improve operations by conducting systems analysis; recommending changes in policies and procedures.
Participate in client-facing project activities such as requirements gathering, solution reviews, and explaining technical complexities and business benefits in layperson terms.

Qualifications
Some of the qualifications and skills we are expecting include the following:
A Bachelor’s degree in Computer Science, Engineering or a similar field is required (Master’s a plus)
6+ years of data engineering, software engineering, or similar experience
6+ hands-on industry experience working with SQL on various relational database platforms (Microsoft, Oracle, Hana, Postgres, etc.)
5+ hands-on industry experience working with enterprise ETL/DW tools like Azure Data Factory, Snowflake, Redshift, Informatica, Pentaho, etc.
5+ years of non-technical client facing interactions (in a consulting space preferred)
3+ years of hands-on experience with object-oriented programming in Python (preferred) or similar such as Go, Rust, C#, etc.
2+ years of using a cloud platform (AWS or Azure preferred), cloud certifications a plus
Hands-on experience with aspects of data engineering design and implementation including data sourcing, data modeling of warehouses/marts/repositories, data integration/transformation/ETL, APIs, reporting, business intelligence and analytics
Hands-on experience with NoSQL databases like MongoDB (preferred), CouchDB, Cosmos, etc. a plus
Hands-on experience with Graph databases like Neo4j (preferred), Cosmos DB, Neptune, etc. a plus
Able to provision environments independently and deploy code a plus (CI/CD extra plus)
Experience with Docker for containerization and Kubernetes for orchestration a plus
Experience with “big data” and distributed tools like Hadoop, Spark, Cloudera, etc. a plus
Collaborative team player who is detailed oriented, focused on solution quality and execution
Progressive mindset particularly around deployment models and emerging technologies
Comfortable working across a wide range of project sizes and industries

Additional Information
What you should know about KSMC:
KSMCers are humble, hungry, and smart. We solve big problems, serve lots of clients, and are entirely committed to delivering transformative outcomes.
KSMCers are team players, deeply dedicated to the mission of the organization and to helping everyone around us be successful.
KSMC compensates well, rewarding performance that delivers positive outcomes for our clients and ensuring incentives are aligned to achieve our goals.
KSMC leaders work hard, serving as a shining example of what it means to be a great KSMCer. They are servant leaders, helping their team to be successful in all possible ways.
We have a great benefits package including unlimited vacation, significant 401k contributions, and lots of ways to develop yourself.
We pride ourselves in having the best talent in the industry and hope that you’re up for the challenge!
What our team members say about us…
“I love our true empathy and concern for our clients, it's very rare and appreciated. It is a pleasure to be a part of an organization like KSMC.”
“I learn something new every single day, and I feel like I'm a part of building an organization that has legs. I appreciate that I'm consistently humbled by the talent and caliber of our team.”
“The culture of the company is amazing, and the climate of my team is great. The benefits that employees are offered are better than competitors, and the one-on-one presence that my team lead gives is extremely beneficial to me.”
All qualified applicants will receive consideration for employment without regard to age, color, sex, disability, national origin, race, religion, or veteran status.
Equal Opportunity Employer",co,de
42,Amazon.com Services LLC,Information Technology,3.8,Software Development Engineer - Big Data,"Boulder, CO",$121K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_6bcf3898&cb=1618161346959&jobListingId=1006991559695&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-d081fd0ed8e18ae7,"
2+ years of non-internship professional software development experience
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.

Are you passionate about Big Data and Distributed Systems? Are you interested in building new state-of-the-art products at Petabyte scale? Be part of a team of industry leading experts that operates one of the largest big data analytics systems at Amazon. We own the campaign performance reporting product for all of advertising and are responsible for end to end processing of attribution for all advertising products. We are applying the latest machine learning and AWS big data technologies available on terabytes of data a day (over 50B new events per day) operating Petabyte size clusters. We constantly invent on our cutting-edge event-driven architectures to stay ahead of growing scale. Our streaming data must always be the fastest, most high-fidelity data as it enables advertisers to optimize and measure of success for a campaign. The charter of this team is focused on systems and services responsible for generating attribution reporting. This function will define and produce the metrics used to analyze the performance of our high growth advertising business

We are looking for an experienced software engineer that can combine open source technologies such as Hadoop, Hive, Spark and Presto, as well as AWS services like EMR, Redshift, Kinesis and DynamoDB to build the next generation of our Attribution reporting systems and services. You will be responsible for designing and developing software products that will provide measurement and reporting to a wide set of users across all of Amazon's advertising suite across display, search, native, and video on all devices. Candidates for this position should have strong software engineering fundamentals as well as real-world experience. You will be able to demonstrate a variety of architectural approaches and design patterns and have a demonstrated competence in designing maintainable and scalable software written in a high-level language. You will show your ability to adapt to changing technical environments and devise creative solutions to vexing software problems. Candidates must have the ability to communicate effectively, both in writing and orally, to engineers and executives.

Join the fast growing Amazon Ads business! Amazon is leveraging its highly unique data to change the way marketers purchase, track, measure, and optimize their advertising spend. You will encounter some of the toughest and most inspiring technical challenges of your career as you build petabyte-scale services, invent new big data paradigms, and scale for extreme growth.


Experience building complex software systems that have been successfully delivered to customers
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations
Ability to take a project from scoping requirements through actual launch of the project
Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.
Experience improving web latency in complex large scale deployments.
Experience in databases, analytics, big data systems or business intelligence products
Experience mentoring and training other engineers

This position starts at $120,700/yr. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a range of medical, financial, and/or other benefits, dependent on the position offered. For more information regarding Amazon benefits, please visit https://www.amazon.jobs/en/benefits. Applicants should apply via Amazon’s internal or external careers site.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us

#adssde
#madsjob",co,de
43,Spiceworks,Information Technology,3.9,Senior Data Engineer - Spiceworks,"Denver, CO",$121K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_318284d9&cb=1618161346959&jobListingId=1006992426609&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-a8a27ee0b45e7e2c,"Sr Data Engineer
Who you are:
You are detail oriented with a curious nature. You have experience in working to find trends in data sets and developing algorithms to help make raw data more useful. You have strong communication skills and understand the purpose behind the work that you do. You have experience with multiple programming languages and over 5 years of experience with data engineering as Senior level staff.
Ownership of data products, pipelines, and stakeholder integrations is our bread and butter and this thrills you! With your background in optimizing data retrieval and how to develop the outputs needed for stakeholders - reports, dashboards, or other visualizations. You are excited to build with us!
What you’ll do:
The typical Data Engineer's role at Spiceworks Ziff Davis is both fluid and challenging. You will work to run data through pipelines and augmentations and data science technology in order to score the leads and interest levels across multiple categories of interest. Each day, you will build small, reusable components in a large landscape of data, you’ll collaborate with business teams to improve data models that feed our business intelligence tools and increase data accessibility, write integration tests, and contribute to the internal engineering documents..
You’ll have nuanced relationships across teams and you’ll be a critical point of contact for the Data Engineering function. In this role, you will work across a data landscape with diverse technologies and potentially work in situations that are not clearly defined - as some tools do not have owners and you will need to go into the system that you’ve never coded in before, but you’ll be responsible for diagnosing issues and identifying solutions.
You will have the standard ELT (Extract, Load, Transform) responsibilities but as this is a Senior-level role, you’ll also be responsible for spearheading initiatives with other teams - ranging from assisting Data Science in developing and deploying microservices to be utilized to augment data to debugging a fluctuation in data being produced by intermediate proxy services.
You will be in close contact with teams across the business and will serve as a reliable, seasoned Engineering team member.
What will be your responsibilities?
Design, coordinate, and implement data integrations between other teams in the forms of databases, file payloads, microservices - using the appropriate technology for the use-case (SNS, S3, AuroraDB, K8s Background Job, etc)
Design, implement and maintain data pipelines for both loading disparate system's data into a Data Warehouse, as well as building out data products.
What does it take to do this job?
Experience working alongside Data Scientists to make use of the data that they collect
In-depth knowledge of distributed systems and computer science
A background in our primary technologies: AWS Components, Kubernetes, Docker, Snowflake (ANSI-SQL), Python, Matillion (Data Flow Orchestration), Data Dog
Familiarity with technologies and languages like HTML/CSS/Javascript, Make, Ruby on Rails, Golang, Scala
Demonstrated expertise with SQL (T-SQL and/or ANSI-SQL)
Expertise with some modern programming languages (Python, Ruby, etc)
High comfort level with Docker
Empathy Statement:
Spiceworks Ziff Davis is a safe, inclusive workplace for people of all backgrounds and walks of life. We strongly encourage you to apply if you are from a marginalized or underrepresented group, particularly in the technology industry. Some candidates may see a long list of job requirements and feel discouraged because they don't match every single bullet point - we suggest, please apply anyway.
Work from Anywhere:
We're flexible on location wherever possible - we are a Work From Anywhere company. We don't believe in a ""perfect"" candidate because we believe in our core value, ""Evolve and Adapt Quickly"". If you believe this is a role that you'll be excited to work in every day, want to be a part of a culture like ours, and will be relentless about pushing boundaries to succeed, please apply.
Who we are: Spiceworks Ziff Davis (SWZD) is a trusted global marketplace that connects technology buyers and sellers with the most actionable and precise intent data. We are uniquely positioned to offer tech brands unmatched visibility into accounts that are truly in-market, by leveraging our scale, quality and diversity of intent data. With unparalleled access to the world’s most influential technology buyers through a combination of first-party (Community, Tools, Editorial) and third-party intent data, SWZD is a leader in intent-backed, intelligent, omnichannel marketing.
-XXX-
About SWZD | Open Job Opportunities | The 2021 State Of IT",co,de
44,CyberCoders,Business Services,4,REMOTE - Sr. Front End Engineer - AI & Data-Driven Startup,"Denver, CO",$90K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1110586&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1726bc08&cb=1618161346959&jobListingId=1006988869397&cpc=FA84DF7EA1EC2398&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-3a797c17797d78c3&jvt=aHR0cHM6Ly93d3cuaW5kZWVkLmNvbS9yYy9nZC9wbmc%2FYT03aUFqZWNQZXcxMjgzVlZhUU1ReFRKV0NUUmdJOElBUTlQVUR6RlctbEpJeWJGOFROS2hiS1pKdjZxMUpWQVhFdGJ0S3o1QlhYREw4cFJOYjZFWU5lME5yYlI4ZnYtZ3lFak82TDN6MXcyX1FqNWF3UGNVb1ZhdEtaTTdMb1R1Rm11eHFReEVZZGZrdDIzU2Iwc3AwaDRkUXVuYmJaV3FocVk3bFZGdWpoZGNiZFZ3cVJSVEdwMFE5VzNqUTNUWWh2ODdfbnZQcGhWZDNhSlV5V3U5aE5sQTc4MVluZkc5QVFadFJkZFkxbGsyaGZFZUZuUENxZzB2SDVCci1leTk1OU5rX2NuMmc2RjBzaFotajYwVXQtWDFIem1BN2hnWFR4alpjRWJ5QkZXcjJFNVVKN080MnRwUm1Ib1lZTlZ0TGhUakNfeTg3ZjVjY3NJNHhlUFo1b3NaZF8xUy1UU3dmWTNKLTI3dEluVkVGbTVIYmhKeEx3RjFKeUt1Q2R3LThCYTRuMFJ5MFp5MGF1SEhDVHdDdFRnQzZqWGZFcW8zTzBQQWQ2M3RtTHFOR2NiRXNpVHVNTWtDSEwzUVRtNFpnRDB0SXQwRGUtcUZTWEszemRYdGhXeTJ6R0poMG0wMkc5b1hxTW1EeGJuRzlpdE04Tkdad2N3TVFpZWdzZzgwSXBEbHRnVG13cUxaWk9ZSE94QURrR0JicGt1c3l0MTM1RmNQNXpUVWVtcktWaDZ1aGs2dEgzeWJMYTk3MTNJRm5CT2tjTzJTTTNZNS1NV0hBZHVPV25pQzI1UU44ZmU5VTZFWU8xbGYtaUt4LXk3WHNYckxCSHk5LTQyd1lMM1hRdnhodFkweS1tVjktYm8yT0Zsc1pnZmwxdkRTdG5FbmlQM2FyQTZKaGdUN1VzU3VoN0tFbXVHZmVUMDY2LVFnVEZqY0FlaGdnRXdNRHAtQjN0OV9uMXRwNllHVjR2b24wa0dURklEcFFNVjc1ZzJxRUhYNlFxazNubTMyZmpNalhwN1h6UGVUQU1WSzRzem5DS3RfdDhmX2szeVhTbHFEdHUtbzVFQXJSckctNGI5VDMzd0tGYTdxN0RkUG5nLVlvaGh6Yy10VnRDcVZtS2dza0JHYjRjMGFIcWk0VFotV2hxbmlRMzZzVmJDLTNZTjVPMUFnQTEtNkpFVWZ0c2xhU2U3bmNSdGs3Vk1jTE5xOVNuNEdMRHRGOFo1TVF1UWJWWGwwZHctMmowVXFnY0RKMDVDRWlVai1zMnZOQmdIc202SGZfZ29ka1diZDFvSHdqeTJkTjlJc2doUTRzTDd0a0pMY1V3bWFnVFBVMDRLVFEzZTRQcldZeklnVHhIX0RXUEhycndiMlZWODNRZXBKb05tOWF5cWxLSEhIQ3FYczBFbWozZ3R3djA2dEJvaTlUVlh5RlhaMU4xUkk0ZlFzWmg0U2c0c3lNNjJhY0FKZjhuS0hGTVdkV2NYQjhiZVBuNk1JMDhyVnJfbE9TckZsWDVJWk1PcXBCTlM0bW9aNTBFVGN0V2xDaWlTazJ5YVBSNVJORjJpdHBVd0VvbUZmVGxzTG9KQ1l6ZEg1Vm9OYjZFZG92QlVnYVVjcjM3Q2o0Mkg0Qm5ZaTh2ZmVOZVhlSGdQUWY4cTBzVDZocmtfSE9fVHBtYjkzbWF3aHE4R3praURoUy1R,"REMOTE - Sr. Front End Engineer - AI & Data-Driven Startup
WE ARE STILL ACTIVELY HIRING AND WORKING DURING COVID.

We are a rapidly growing AI and data-driven startup that is looking to make cycling one of the top participation sports in the world! Our Engineering organization is led by industry leaders such as the co-founder of Zwift. We are a fast-paced environment and looking for passionate people who want to scale, build long-term careers, and RETIRE with us!

Currently, we're looking for a Senior Front End Engineer who has experience with Angular, React, or Vue.
What's In It for YouCompetitive Compensation Contingent On Experience
Health Benefits (PEO)A culture dedicated to healthAn opportunity to shape our technical destiny and be more than just a Front End Engineer Engineer
What You Need for this PositionExperience building responsive web application front-endsExperience with consumer-oriented applications
Experience with Angular, React, or VueBuilt front-ends for systems used by thousands of usersExperience working with third-party APIs and/or other data sources; you may have experience developing web APIs of your ownInterest in collecting, managing, and analyzing sensor data collected from mobile devices directly or paired devices using Bluetooth and/or Bluetooth Low Energy (BLE)
What You Will Be DoingWork alongside a team of back-end engineers and some specialist engineers (including a cartography/geospatial expert and a social networking expert) to develop our broad service for bicyclists, bringing your background and capability with front-end technologiesInitially work on a responsive web application built using Svelte, custom CSS, and JavaScriptMay expand to also working on native mobile applications using to-be-determined technology, potentially including Swift, Kotlin or Java, React Native, or FlutterCollaborate with the back-end team to design API endpoints and overall information architectureCollaborate with the product and UX/UI team to realize the product vision, and provide valuable feedback on the scope and viability given constraints of time, performance, and device capabilitiesInteract with others working on front-end components, including some of our specialists such as a 2D graphics expert designing highly-interactive map overlaysProvide our users with an app experience with high performance and responsiveness
So, if you are a Senior Front End Engineer with the experience above, please apply today!Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.


Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",co,de
45,CSH IT Service,N/A,-1,ITD Data Analytics Senior Integration Engineer,"Englewood, CO",$90K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_16bc7df2&cb=1618161346959&jobListingId=1006985318752&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-fa040e9467e4ef85,"Overview:
CommonSpirit Health was formed by the alignment of Catholic Health Initiatives (CHI) and Dignity Health. With more than 700 care sites across the U. S. & from clinics and hospitals to home-based care and virtual care services CommonSpirit is accessible to nearly one out of every four U. S. residents. Our world needs compassion like never before. Our communities need caring and our families need protection. With our combined resources CommonSpirit is committed to building healthy communities advocating for those who are poor and vulnerable and innovating how and where healing can happen both inside our hospitals and out in the community.
Responsibilities
Position Summary
The Sr. Integration Engineer works to analyze, design, and build integration requirements for development and changes to
business processes, policies, and information systems integration. The Sr Integration Engineer implements and maintains interface
technical solutions that enable the organization to achieve its integrations goals. This position performs a variety of complicated
tasks and reports to the Integration Manager.

Responsibilities
Designs, develops, tests, implements, and maintains Integration API solutions.
Strategize and develop an API Management roadmap for the enterprise
Performs source code/versioning management function adhering to technical management guidelines.
Leads and coordinates code/peer reviews of single facility or application focused development work to insure it aligns to the
business and technical requirements.
Provides application development services for support and projects that align to the software development life cycles, organizational governance policies, and industry best practices.
Leads cross functional application development activities to achieve project objectives.
Contribute to and maintain a thorough understanding of application standards, policies, and procedures.
Ensures application development deliverables are completed on a time, budget, and quality.
Researches and recommends appropriate application development best practices, and tools.
Develop and applies business knowledge in multiple functional areas.
#LI-DH
API, EST, API, Java, J2EE, Python developer
Qualifications
Qualifications and experience
Experience building REST APIs/Micro-services/streaming architecture
Experience as Java/J2EE/Python developer and strong knowledge of the java/javascript frameworks(Spring/Angular JS)
Knowledge in an API Management suite (like Axway,Apigee,Mulesoft) Requires at least 5 years development experience
designing and building functional programs and application.
Cloud based experience
Expert working knowledge in an agile /SDLC development models Good working knowledge of Cerner Foreign System
Interfaces/Open Engine, IBM, Axway MFT, and Cloverleaf, Rhapsody Professional or Expert Certification preferred.
Excellent verbal and written communication skills Knowledge on containerization frameworks

CommonSpirit Health participates in E-verify.",co,de
46,Invitae,Biotech & Pharmaceuticals,4.1,Data Engineer,Colorado,$90K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_5a9a166b&cb=1618161346959&jobListingId=1006987220796&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-318ab5de7f5e3a40,"Invitae is dedicated to bringing comprehensive genetic information into mainstream medicine to improve healthcare for billions of people. Our team is driven to make a difference for the patients we serve. We are leading the transformation of the genetics industry by making genetic testing affordable and accessible for everyone to guide health decisions across all stages of life.


POSITION SUMMARY:

This is an opportunity to build infrastructure to power innovative biotechnology. The person in this role will help plan, develop, and build data infrastructure critical to our In Vitro Diagnostics program. This person will be responsible for the accuracy and usability of data central to the development and regulatory approval of Invitae's cancer diagnostics. This person will work closely with program technical leads, data scientists, and quality assurance personnel to think creatively and achieve ambitious goals to advance the treatment of genetic diseases.


RESPONSIBILITIES:

Contribute to our mission of enabling precision oncology through genetic testing
Design and develop tools and infrastructure to enable teams to consume and analyze data faster
Understand our complex data ecosystem and build ETL solutions
Build custom software and database systems which integrate with commercial software including a laboratory information management system
Support continuous integration and continuous development through automated configuration management tools
Maintain and augment existing systems to meet the needs of evolving processes
Adhere to standard operating procedures and work in a manner compliant with regulatory standards


QUALIFICATIONS:

Are self-starters and can work towards a larger goal with minimal guidance
Have 2+ years of relevant industry experience, preferably working with large datasets, pipelines, data modeling, or data warehousing
Have a focus on high-quality code, including automated testing and coding best practices
Are familiar with key components of our tech stack including Python, AWS, Docker, Terraform, and Jenkins


Bonus points for experience with and/or enthusiasm for:

Laboratory Information Management Systems (LIMS)
Clinical data from medical devices
Working in a regulated field
Molecular biology / genomics


Expected Pay Rate in Colorado from: $xx

Compensation for the role will depend on a number of factors, including a candidate's geographic location, qualifications, skills, competencies and experience and may fall outside of the range shown.


Invitae offers a competitive total rewards package, which includes healthcare coverage, 401k, and a broad range of other benefits, outlined below:

Health, dental, vision, short- and long-term disability, and basic life insurance coverage
Paid time off, holiday pay, parental leave, and other health and wellness supports


At Invitae, we value diversity and provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.",co,de
47,DISH Network,Telecommunications,3.3,Senior Big Data Engineer,"Englewood, CO",$90K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_90a10c05&cb=1618161346960&jobListingId=1006994782057&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-36d4b6ee680e0260,"Department Summary:

Sling TV L.L.C. provides an over-the-top (internet delivered) television experience on TVs, tablets, gaming consoles, computers, smartphones, smart TVs and other streaming devices. Distributed across a variety of strategic device partners, including Google, Amazon, Apple TV, Microsoft, Roku, Samsung, LG, Comcast, and many others, Sling TV offers two primary domestic streaming services that collectively include more than 100 channels of top content. Featured programmers include Disney/ESPN, NBC, AMC, A&E, EPIX, NFL Network, NBA TV, NHL Networks, Pac-12 Networks, Hallmark, Viacom, and more.
For Spanish-speaking customers, Sling Latino offers a suite of standalone and extra Spanish-programming packages tailored to the US Hispanic market. And for those seeking International content, Sling International currently provides more than 300 channels in 20 languages (available across multiple devices) to U.S. households.
Sling TV is the #1 Live TV Streaming Service Sling TV is a next-generation service that meets the entertainment needs of today’s contemporary viewers. Visit www.Sling.com. We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve to join our team as we embark on the next chapter of our story.
Opportunity is here. We are Sling.
Job Duties and Responsibilities:

Sling (DISH) is looking for a Data Engineer responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Skills, Experience and Requirements:

You would be considered a great fit for this role if you have the following:
Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree.
5+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines.
Strong Software Engineering experience with proficiency in at least one of the following programming languages: Java, Python, Scala or equivalent.
Implement data ingestion pipelines both real time and batch using best practices.
Experience with building stream-processing applications using Apache Flink, Kafka Streams or others.
Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Ability to work in a Linux environment.
These qualifications would make you stand out among other applicants:
Experience in building distributed, high-volume data services.
Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.
Knowledge of data science tools and their integration with data lakes.
Experience in container technologies like Docker/Kubernetes.",co,de
48,"CGI Group, Inc.",Business Services,3.7,Azure Data Engineer,"Denver, CO",$90K - $130K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_b3f12014&cb=1618161346960&jobListingId=1006991548778&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-20b09824407295ec,"Azure Data Engineer


Position Description

Seeking a sr data engineer with 8-10 years of industry experience including developing and deploying applications on Microsoft Azure Databricks platform. This individual should be self-motivated to drive solutions and proactively create and present (in sufficient detail) the documentation required to support and describe technical solutions. The candidate will work with cloud architects to establish pipeline to Azure data stores using either NiFi or DataBricks. Will build templates for engineering processes in cloud. Will act as the lead data engineer on the project.
The data engineer will be responsible for development, deployment, maintenance, diagnostics and support of spark ETL jobs on the MS Databricks platform.Will streamline code, rationalize datasets and tables to arrive at single source of truthWill build detailed architecture diagrams or Entity Relationship Diagrams for all workflows and processes8+ years of hands on experience with cloud automation and scripting in an Azure environment.Experience in development of apache Spark code using PySpark or ScalaExperience in using Azure Databricks PlatformExperience in using Azure Data Factory to call Azure Databricks notebook activitiesExperience in using Git based repositoriesGood fundamental knowledge about distributed computing, RDBMS and Dimensional modeling conceptsExposure to Azure DevOpsExposure to Azure Storage (Blob/Data Lake Store), Azure Catalog, Databricks Delta.Strong communication and presentations skills required.
SQL, TeraData SQL 10+ years 5
Cloud Platforms (Azure) 8+ years 5
NiFi, DataBricks 8+ years 4
Scripting languages (HTML, Javacsript, jquery, Angular js, .Net, Python etc) 8+ years 5
Hive 6+ years 4

Est. Salary Range (Colorado Only): $97k-144k

Disclaimer: In accordance with Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, a good faith hourly or base salary range must be posted for all positions where the work may be performed in the state of Colorado. Therefore, this good faith salary range will only apply where this described position will be performed in the state, and should not be considered the compensation range in other locations or for other positions.
At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:
Competitive base salariesEligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category401(k) Plan and Profit Participation for eligible membersGenerous holidays, vacation, and sick leave plansComprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and more
Your future duties and responsibilities

Required qualifications to be successful in this role

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change-supporting our clients' digital journeys and offering our professionals exciting career opportunities.


At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com .

No unsolicited agency referrals please.",co,de
49,DISH,Telecommunications,3.3,Big Data Engineer,"Englewood, CO",$99K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_a590bc2c&cb=1618161346960&jobListingId=1006992436084&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-326ab05560ede6d3,"Sling TV L.L.C. provides an over-the-top (internet delivered) television experience on TVs, tablets, gaming consoles, computers, smartphones, smart TVs and other streaming devices. Distributed across a variety of strategic device partners, including Google, Amazon, Apple TV, Microsoft, Roku, Samsung, LG, Comcast, and many others, Sling TV offers two primary domestic streaming services that collectively include more than 100 channels of top content. Featured programmers include Disney/ESPN, NBC, AMC, A&E, EPIX, NFL Network, NBA TV, NHL Networks, Pac-12 Networks, Hallmark, Viacom, and more.
For Spanish-speaking customers, Sling Latino offers a suite of standalone and extra Spanish-programming packages tailored to the US Hispanic market. And for those seeking International content, Sling International currently provides more than 300 channels in 20 languages (available across multiple devices) to U.S. households.
Sling TV is the #1 Live TV Streaming Service. Sling TV is a next-generation service that meets the entertainment needs of today’s contemporary viewers. Visit www.Sling.com. We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve to join our team as we embark on the next chapter of our story.
Opportunity is here. We are Sling.
What you’ll be doing:
This role will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler, who enjoys optimizing data systems and building them from the ground up.
This position will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
The successful candidate will:
Create and maintain optimal data pipeline architecture;
Assemble large, complex data sets that meet both functional and non-functional business requirements;
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.;
Build the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies;
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics;
Collaborate with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs;
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader;
Work with data and analytics experts to strive for greater functionality in our data systems.
A successful Data Engineer will have:
A Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree.
Technical requirements:
Five+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines;
Strong Software Engineering experience with proficiency in at least one of the following programming languages: Golang, Java, Python, Scala or equivalent;
Implement data ingestion pipelines both real time and batch using best practices;
Experience with building stream-processing applications using Apache Flink, Kafka Streams or others;
Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.;
Experience supporting and working with cross-functional teams in a dynamic environment;
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with ELK stack.
Ability to work in a Linux environment.
Ideal qualifications:
Experience in building distributed, high-volume data services;
Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.;
Knowledge of data science tools and their integration with data lakes;
Experience in container technologies like Docker/Kubernetes
#LI-CA1 #LI-SB1
#LI-SLING2
Compensation: $99,360.00/Yr. - $157,665.00/Yr.
From versatile health perks to new career opportunities, check out our benefits on our careers website.
Employment is contingent on Successful completion of a pre-employment screen, which may include a drug test.",co,de
50,DISH,Telecommunications,3.3,Senior Big Data Engineer,"Englewood, CO",$99K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_3d952ec2&cb=1618161346960&jobListingId=1006994829695&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-8216738e6f253409,"Sling TV L.L.C. provides an over-the-top (internet delivered) television experience on TVs, tablets, gaming consoles, computers, smartphones, smart TVs and other streaming devices. Distributed across a variety of strategic device partners, including Google, Amazon, Apple TV, Microsoft, Roku, Samsung, LG, Comcast, and many others, Sling TV offers two primary domestic streaming services that collectively include more than 100 channels of top content. Featured programmers include Disney/ESPN, NBC, AMC, A&E, EPIX, NFL Network, NBA TV, NHL Networks, Pac-12 Networks, Hallmark, Viacom, and more.
For Spanish-speaking customers, Sling Latino offers a suite of standalone and extra Spanish-programming packages tailored to the US Hispanic market. And for those seeking International content, Sling International currently provides more than 300 channels in 20 languages (available across multiple devices) to U.S. households.
Sling TV is the #1 Live TV Streaming Service Sling TV is a next-generation service that meets the entertainment needs of today’s contemporary viewers. Visit www.Sling.com. We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve to join our team as we embark on the next chapter of our story.
Opportunity is here. We are Sling.
Sling (DISH) is looking for a Data Engineer responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
You would be considered a great fit for this role if you have the following:
Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree.
5+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines.
Strong Software Engineering experience with proficiency in at least one of the following programming languages: Java, Python, Scala or equivalent.
Implement data ingestion pipelines both real time and batch using best practices.
Experience with building stream-processing applications using Apache Flink, Kafka Streams or others.
Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Ability to work in a Linux environment.
These qualifications would make you stand out among other applicants:
Experience in building distributed, high-volume data services.
Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.
Knowledge of data science tools and their integration with data lakes.
Experience in container technologies like Docker/Kubernetes.
Compensation: $99,360.00/Yr. - $157,665.00/Yr.
From versatile health perks to new career opportunities, check out our benefits on our careers website.
Employment is contingent on Successful completion of a pre-employment screen, which may include a drug test.",co,de
51,DISH Network,Telecommunications,3.3,Big Data Engineer,"Englewood, CO",$99K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136043&s=58&guid=00000178c1eea8528fe5fcc4af7a22d7&src=GD_JOB_AD&t=SR&vt=w&cs=1_cdd261bc&cb=1618161346960&jobListingId=1006991924028&jrtk=1-1f30uta3k3oiq001-1f30uta48u4a2800-6a4ed44d0e74ec35,"Department Summary:

Sling TV L.L.C. provides an over-the-top (internet delivered) television experience on TVs, tablets, gaming consoles, computers, smartphones, smart TVs and other streaming devices. Distributed across a variety of strategic device partners, including Google, Amazon, Apple TV, Microsoft, Roku, Samsung, LG, Comcast, and many others, Sling TV offers two primary domestic streaming services that collectively include more than 100 channels of top content. Featured programmers include Disney/ESPN, NBC, AMC, A&E, EPIX, NFL Network, NBA TV, NHL Networks, Pac-12 Networks, Hallmark, Viacom, and more.
For Spanish-speaking customers, Sling Latino offers a suite of standalone and extra Spanish-programming packages tailored to the US Hispanic market. And for those seeking International content, Sling International currently provides more than 300 channels in 20 languages (available across multiple devices) to U.S. households.
Sling TV is the #1 Live TV Streaming Service. Sling TV is a next-generation service that meets the entertainment needs of today’s contemporary viewers. Visit www.Sling.com. We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re looking for people with boundless energy, intelligence, and an overwhelming need to achieve to join our team as we embark on the next chapter of our story.
Opportunity is here. We are Sling.
Job Duties and Responsibilities:

What you’ll be doing:
This role will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler, who enjoys optimizing data systems and building them from the ground up.
This position will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
The successful candidate will:
Create and maintain optimal data pipeline architecture;
Assemble large, complex data sets that meet both functional and non-functional business requirements;
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.;
Build the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies;
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics;
Collaborate with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs;
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader;
Work with data and analytics experts to strive for greater functionality in our data systems.
Skills, Experience and Requirements:

A successful Data Engineer will have:
A Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree.
Technical requirements:
Five+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines;
Strong Software Engineering experience with proficiency in at least one of the following programming languages: Golang, Java, Python, Scala or equivalent;
Implement data ingestion pipelines both real time and batch using best practices;
Experience with building stream-processing applications using Apache Flink, Kafka Streams or others;
Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.;
Experience supporting and working with cross-functional teams in a dynamic environment;
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with ELK stack.
Ability to work in a Linux environment.
Ideal qualifications:
Experience in building distributed, high-volume data services;
Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.;
Knowledge of data science tools and their integration with data lakes;
Experience in container technologies like Docker/Kubernetes
#LI-CA1 #LI-SB1
#LI-SLING2",co,de
140,Amazon.com Services LLC,Information Technology,3.8,Senior Data Engineer - Advertising Analytics Data Pipeline,"Boulder, CO",$84K - $131K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=133043&s=58&guid=00000178c1f1d97a897022f2e603a6b5&src=GD_JOB_AD&t=SR&vt=w&cs=1_c116f70f&cb=1618161556298&jobListingId=3820715750,"5+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQLBachelor's degree in computer science, engineering, mathematics, or a related technical disciplineExperience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, Presto, etc.)Knowledge of data management fundamentals and data storage principlesKnowledge of distributed systems as it pertains to data storage and computingProficiency in, at least, one modern scripting or programming language such as Python, NodeJS, Java, or Scala.Are you passionate about using Big Data to build customer trust and grow new business? Global advertisers rely on our team's performance insights to drive future investment in Amazon's Advertising Platform and improve the relevance of ads shown to customers. We are looking for passionate Data Engineers to own and optimize the big data pipeline that consumes the massive data sources we require to generate unique insights. Data is at the center of every product we will develop as we create brand new systems that serve the needs of our large and growing base of advertisers.You will share in the ownership of the technical vision and direction for advanced analytics and insight products. You will be a part of a team of top notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence. Members of this team will be challenged to innovate using big data technologies. We are looking for people who are motivated by thinking big, moving fast, and changing the way customers use data to drive profitability. If you love to implement solutions to hard problems while working hard, having fun, and making history, this may be the opportunity for you!Amazon is well positioned to grow its share of a fast growing online advertising industry due to its unique assets - e-commerce data, service oriented architecture, and startup culture. Be part of a team of industry leading experts that builds and operates one of the largest big data analytics platform at Amazon. Amazon is applying the latest machine learning and big data technologies available to change the way marketers purchase, track, measure, and optimize their advertising spend. We apply these technologies on terabytes of data (over 10B new events per day) and operate clusters that push scalability limits of the existing technologies. We seek to measure every possible signal indicating impact of advertising to provide the most objective result of marketing spends.This role is open to candidates sitting in Boulder, CO or Seattle, WA.This position starts at $110,000/yr. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a range of medical, financial, and/or other benefits, dependent on the position offered. For more information regarding Amazon benefits, please visit https://www.amazon.jobs/en/benefits. Applicants should apply via Amazon’s internal or external careers site.Experience working with and tuning AWS big data technologies (EMR, Redshift, S3)Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategyExperience providing technical leadership and mentoring other engineers for best practices on data engineeringKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.#adsto #madsjob",co,de
141,DISH,Telecommunications,3,Data Engineering Analyst,"Englewood, CO",$50K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=132977&s=58&guid=00000178c1f1d97a897022f2e603a6b5&src=GD_JOB_AD&t=SR&vt=w&cs=1_7a7bdc28&cb=1618161556298&jobListingId=4028564826,"At DISH, our technology teams challenge the status quo and reimagine capabilities across industries. From product development to software design to big data and beyond, our people play vital roles in connecting consumers with the products and platforms of tomorrow.We are looking for a Data Engineering Analyst to work hand-on with DISH Network’s Enterprise Data Warehouse (EDW) and Operational Data Store (ODS) systems. Collects, evaluates, and prepares data analysis and/or other complex analysis on databases for a specific business unit. Prepares data quality analysis (DQA) artifacts, including recommendations and data profiles used in the analysis and interpretation of data as appropriate, and source to target mappings. Ensures quality control of databases through the development and maintenance of test plans and quality control procedures and may assist in development and implementation of measurement systems. This position will be responsible for Data Analysis activities to support Data Warehouse projects.Primary responsibilities for the position include:This person will be required to discover, analyze, profile and document findings on source data systemsCreate source to target mappings using business rules to transform dataAssist development team during the development phase to resolve data issues and understand data constraintsThe candidate will create and maintain data sets for Data Mining and Predictive AnalyticsOnce development activities are completed the candidate will drive the testing of the final data outputThe ideal candidate will be a self-starting individual who is able to dive into details and quickly provide summary level readouts of the source dataThe position requires very strong communication skills as the candidate will be required to interact regularly with all levels within the organization, including developers, architects, business users and managementAssist with Tableau dashboard developmentA successful Data Engineering Analyst will have:Bachelor's degree from four-year College or University; or three to four years related experience within an IT Department, preferably within a Data Warehouse and/or equivalent combination of education and work experienceThe ideal candidate will have extensive experience in data analysis and creating data sets from multiple source systemsExposure to and experience in data warehousing conceptsStrong SQL skills is a must.Experience working with various data sources (structured, semi structured and unstructured)Preferred Skills:Experience with Teradata, Oracle, MS SQL Server are highly desiredExperience with AWS (S3 , Athena and Redshift)Experience with TableauExperience working within the Telco/Cable/Satellite/Wireless industry a definite plus#LI-YT1Compensation: $74,520.00/Yr. - $102,810.00/Yr.From versatile health perks to new career opportunities, check out our benefits on our careers website.Employment is contingent on Successful completion of a pre-employment screen, which may include a drug test.",co,de
0,Intuit,Information Technology,4.3,"Software Engineer 2, Big Data","Los Angeles, CA",$96K - $177K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=149&guid=00000178c1f3088d88b57b6e25713ee4&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_bfcc7877&cb=1618161634080&jobListingId=3750152288,"OverviewThe Intuit Data Engineering team is looking for a Software Engineer 2, Big Data with a winning track record in Big Data and Distributed Systems. We’re using data in groundbreaking ways to uncover customer insights, personalize customer experiences through AI/ML, and provide a unified customer view across all Intuit products.Note: By applying to this position your application is automatically submitted to the following locations: Mountain View, Los Angeles, San Diego and the following teams at Intuit.What you'll bringBS in Computer Science. MS Preferred.Strong CS fundamentals including data structures, algorithms and distributed systems.Strong database fundamentals including SQL, performance and schema design.Strong programming skills in Java, C++, Python, Ruby or similar.2+ years of hands-on software engineering experience.2+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.Experience with Hadoop, Hive, HBase, Spark, Kafka, Storm, Druid, Cassandra, Columnar Databases and Graph Databases.Experience with varios offerings from AWS, including S3, EMR, Redshift, Data Pipeline, Athena and Kinesis is a plus.History of contributing to open source projects is a plus.2+ years DevOps experience including configuration, optimization, backup, high reliability, monitoring and systems version control.Track record working with data from multiple sources – willingness to dig-in and understand the data and to leverage creative thinking and problem-solving.Excellent interpersonal and communication skills, including business writing and presentations. Ability to communicate objectives, plans, status and results clearly, focusing on critical few key points. Demonstrated ability to work in a matrix environment, ability to influence at all levels, and build strong relationships.Knowledge of enacting service level agreements and the appropriate escalation and communication plans to maintain them.How you will leadDesign and develop big data and real-time analytics solutions using industry standard technologies.Develop web services that make big data available in real-time for in-product applications.Work with data architects to ensure that Big Data solutions are aligned with company-wide technology directions.Lead fast moving development teams using agile methodologies.Lead by example, demonstrating best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting, and incident response.Communicate progress across organizations and levels from individual contributor to senior executive. Identify and clarify the critical few issues that need action and drive appropriate decisions and actions. Communicate results clearly and in actionable form.Work with our core technologies – Hadoop, Spark, AWS, Vertica, Tableau, Cassandra, Graph Databases and others.Demonstrate strong implementation aptitude to translate objectives into a scalable solution to meet the needs of the end customer while meeting deadlines.Demonstrate commitment to your professional development by attending conferences, taking classes, giving technical presentations, and participating in developer communities inside and outside of Intuit.",la,de
1,GoodRx,Biotech & Pharmaceuticals,4.7,Senior Data Engineer,"Santa Monica, CA",$112K - $205K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=149&guid=00000178c1f3088d88b57b6e25713ee4&src=GD_JOB_AD&t=SRFJ&vt=w&cs=1_375015ac&cb=1618161634081&jobListingId=4057117749,"At GoodRx, we believe that all Americans should have access to convenient and affordable healthcare. As a nation, we spend about $3.5 trillion annually on our healthcare, but too many Americans struggle to get the care they need, and prices just keep rising. Our marketplaces for prescription medicines and telehealth have helped Americans save $25 billion since 2011. GoodRx is a public company; we're based in Santa Monica with additional offices around the country. We're a low-key and tight-knit group that likes to find new ways to fix big problems. If you share our belief that you can do well by doing good, let's talk.We’re committed to growing and empowering a more inclusive community within our company and industry. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.With that said, research shows that women and other minority groups apply only if they meet 100% of the criteria. GoodRx is committed to leveling the playing field, and we encourage women, people of color, and those in the LGBTQ+ communities to apply for positions even if they don’t necessarily check every box outlined in the job description. Please still get in touch – we’d love to connect and see if you could be good for the role!About the Role:GoodRx is looking for extremely smart and curious data engineers, who are deft at working with a wide variety of languages, such as Python and SQL, a variety of raw data formats, such as parquet and CSV, in a fast-paced and friendly environment. You will collaborate and work with teams across GoodRx to build outstanding data pipelines and processes that stitch together complex sets of data stores in order to guide marketing decisions.Responsibilities:Collaborate with product managers, data scientists, data analysts and engineers to define requirements and data specifications.Develop, deploy and maintain data processing pipelines using cloud technology such as AWS, Kubernetes, Airflow, Redshift, EMR.Develop, deploy and maintain serverless data pipelines using Event Bridge, Kinesis, AWS Lambda, S3 and Glue.Define and manage overall schedule and availability for a variety of data sets.Work closely with other engineers to enhance infrastructure, improve reliability and efficiency.Make smart engineering and product decisions based on data analysis and collaboration.Act as in house data expert and make recommendations regarding standards for code quality and timeliness.Architect cloud-based data infrastructure solutions to meet stakeholder needs.Skills & Qualifications:Bachelor’s degree in analytics, statistics, engineering, math, economics, science or related discipline.5+ years professional experience in the big data space.5+ years' experience in engineering data pipelines using big data technologies (Spark, Flink etc...) on large scale data sets.Expert knowledge in writing complex SQL and ETL development with experience processing extremely large datasets.Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions.Deep familiarity with AWS Services (S3, Event Bridge, Glue, EMR, Redshift, Lambda)Ability to quickly learn complex domains and new technologiesInnately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findingsThrives in fast-paced startup environmentGood To HaveExperience with customer data platform tools such as Segment.Experience using Jira, GitHub, Docker, CodeFresh, Terraform.Experience contributing to full lifecycle deployments with a focus on testing and quality.Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement.GoodRx is America's healthcare marketplace. The company offers the most comprehensive and accurate resource for affordable prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast, as well as a telehealth marketplace for online doctor visits and lab tests. Since 2011, Americans with and without health insurance have saved $25 billion using GoodRx and 15 million consumers visit goodrx.com each month to find discounts and information related to their healthcare. GoodRx is the #1 most downloaded medical app on the iOS and Android app stores. For more information, visit www.goodrx.com.",la,de
2,Hewlett Packard Enterprise,Information Technology,4,Senior Spark/Cassandra software engineer,"Los Angeles, CA",$76K - $149K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_19e6a463&cb=1618161634081&jobListingId=4054060287,"Hewlett Packard Enterprise advances the way people live and work. We bring together the brightest minds to create breakthrough technology solutions, helping our customers make their mark on the world.HPE makes Hybrid IT simple. HPE helps customers to design the right mix of Hybrid IT to serve their unique needs. We bring next generation infrastructure that uses intelligent software to simplify and accelerate the delivery of new apps, services and business insights. Providing with new ways to deliver and manage IT on-premises and in the cloud.Designs, develops, troubleshoots and debugs software programs for software enhancements and new products. Develops software including operating systems, compilers, routers, networks, utilities, databases and Internet-related tools.Education and Experience Required:Strong Scala programming skills, Akka, DSL design, concepts of functional programming in ScalaExperience with Spark/Cassandra connector, SBTExpert skills in programming Spark RDDs, joins and dataframesUnderstanding of Mesos-based Spark deploymentCassandra data modeling, solid understanding of consistency levels, partitioningSolid grasp of Cassandra internals - read/write paths, indexes, tombstonesCassandra performance monitoring and troubleshooting, JVM and garbage collection tuningCassandra administration skills - compaction, repairs, backup and restoreBachelor's or Master's degree in Computer Science, Information Systems, or equivalent.Typically 6-10 years experience.Knowledge and Skills:Extensive experience with multiple software systems design tools and languages.Excellent analytical and problem solving skills.Experience in overall architecture of software systems for products and solutions.Designing and integrating software systems running on multiple platform types into overall architecture.Evaluating forms and processes for software systems testing and methodology, including writing and execution of test plans, debugging, and testing scripts and tools.Excellent written and verbal communication skills; mastery in English. Ability to effectively communicate product architectures, design proposals and negotiate options.In a typical day as a Software Engineer, you wouldAnalyse, design, program, debug, and modify software enhancements and/or new products used in local, networked, or Internet-related computer programs, primarily for end usersWrite code and complete programming by using current programming languages and technologiesPerform testing and debugging of applicationsComplete documentation and procedures for installation and maintenanceInteract with users to define system requirements and/or necessary modificationsEffectively communicate product architectures, design proposals and negotiate options at management levelsCollaborate with peers, junior engineers, technicians and external design partnersTypically interact with high-level individual contributors, managers and program core teamsLead a project requiring software applications developmentIf you are…Good at partnering, innovating, and making things happen. You are aligned to our core values.Holding a Bachelor's or Master's degree in Computer Science, Information Systems, or equivalentA professional with strong analytical and problem solving skillsExperienced in software application design tools and programming languagesExcellent in verbal and written communication and presentationJoin us and make your mark!We offer:A competitive salary and extensive social benefitsDiverse and dynamic work environmentWork-life balance and support for career developmentAn amazing life inside the element! Want to know more about it?Then let’s stay connected!https://www.facebook.com/HPECareershttps://twitter.com/HPE_Careers1075596",la,de
3,Age of Learning,Education,3.9,Machine Learning Engineer,"Glendale, CA",$72K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=1044761&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_cffbc3b4&cb=1618161634082&jobListingId=3822108930,"Company Overview:Age of Learning is a leading education technology innovator based in Glendale, California, with a talented team of more than 600 individuals comprised of nationally-renowned educators, curriculum experts, developers, artists, writers, designers, engineers, producers, product managers, analysts and marketing experts! Together we develop engaging, effective digital learning technology and content to help children build a strong academic foundation for lifelong success.  Our flagship product ABCmouse.com Early Learning Academy® is a comprehensive online curriculum and the #1 digital learning product for young children. To-date, more than 30 million children worldwide have completed over 8 billion Learning Activities on ABCmouse. We recently launched Adventure Academy, the first massively multiplayer online (MMO) game designed specifically to help elementary- and middle-school-aged children learn. It features thousands of engaging Learning Activities—including minigames, books, original animated and live action series, and more—in a fun and safe virtual world. Other Age of Learning programs include immersive English language learning products for children in China and Japan; ReadingIQ, a digital library and literacy platform; and a groundbreaking personalized, adaptive digital learning system that individualizes math instruction for every child through AI-driven technology. We are committed to helping all children succeed. We provide our educational programs at no cost to teachers, Head Start programs, public libraries, and other community organizations, and have served millions of children through these initiatives. We recently established the Age of Learning Foundation to expand this work globally. As we expand our global reach and increase the educational impact of our programs, we’re looking for passionate, ambitious, and collaborative leaders to become a part of our growing team.Summary: Age of Learning is seeking a Machine Learning Engineer that can use statistical machine learning to elevate and personalize each child’s experience in our award-winning educational game, My Math Academy. You will be building models, doing feature engineering, and working with an engineering team to ship the models in production and monitor their success.Responsibilities: Build and evaluate classification and regression models, using techniques like logistic regression, XGBoost, and stacked ensemble modelsCollaborate with engineering and design teams to put models in productionPull data from a large relational database and do reproducible feature engineeringIterate on a model to improve metricsBuild unsupervised learning models, using techniques like KNNWrite clean code; use Git; write unit tests; participate in code reviewsDevelop insights from data and communicate them to stakeholdersMonitor models in productionRequired Qualifications: 4+ years of statistical programming experienceComfortable with software engineering best practices, like writing functions, using abstraction, testing, and code reviewSkilled in R and/or PythonFamiliar with the tidyverse, especially the ggplot and dplyr librariesSkilled at SQL, efficiently query large datasets and comfortable writing JOIN queries and WINDOW functionsSkilled at GitCan do feature engineering and build and evaluate predictive models, using metrics like AUC or precision-recall to evaluate successFamiliar with exploratory data analysisCan generate meaningful interpretations of data and communicate it effectively to a technical audience Ability to generate actionable recommendations to product team from analytics insightsPreferred Qualifications:Experience working with a predictive model in a production environmentCan communicate interpretations of data to a non-technical audienceAble to write an algorithm to find a path between two nodes on a graphExperience with AWS and has built a predictive model in SagemakerKnowledge of client-server architectures and can communicate directly with a production engineering teamA good judgment about when to optimize for performanceDocker experienceExperience with educational games, or any kind of games or mobile applicationIntegrated with the R or Python community, staying up to date on the latest techniques for software engineering, predictive modeling, and feature engineeringCan create an R packageFamiliar with Learning Science literature and algorithms, such as Spaced Repetition, IRT, etc. Age of Learning currently provides: • 90% - 100% of health and welfare benefit premiums• A 401(k) program with employer match• 15 paid vacation days plus 11 observed national paid holidays• Team bonding events and a highly collaborative environment• Commitment to Equal Opportunity Employment in addition to an inclusive and supportive company culture • Access to our internal DEI Task Force that focuses on ensuring our products represent all children on a global scale• Opportunities for professional growth through professional learning and development programs • A temporary 100% remote work environment, due to COVID restrictions, to help ensure the safety of our employees • Monthly internet stipend provided due to temporary remote work environment",la,de
4,"Bluebeam, Inc.",Information Technology,3.8,Lead DevOps Engineer,"Pasadena, CA",$108K - $175K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_34c9b870&cb=1618161634082&jobListingId=4028341776,"At Bluebeam, we empower people to promote the way the world is built. We create smart software solutions that make construction sites more efficient, connected and safe and improve the lives of design and construction professionals everywhere.This role is a full-time, onsite position. Due to COVID-19, all new employees will be required to start work remotely until we are able to return to the office. More information will be provided in the interview process.About the role:Bluebeam is looking for a Lead DevOps Engineer to join our team. You'll help us better our software engineering practice. You will help develop solutions, and allow our engineering team to build our next generation of cloud native applications.What you'll do:Develop automation frameworks (Infrastructure as code, CI/CD pipelines) and tooling that will be consumed by the entire engineering organization.Support and mentor engineer teams to own their own configurations, parameters, and application secretsIdentify roadblocks and inefficiencies in the current workflow, and work with teams to plan and remediate improvements.Manage incidents and incident responses to ensure proper follow-up and mitigation.Consult with architecture in analyzing and identifying the right pieces in building our unified cloud platform. Be involved in decision-making, such as time estimation, build vs. buy.Drive project progress and communicate project status to partnersSupport legacy technologies and be a part of the solution in migrating them to cloud native solutions.What we'd like to see in you:5+ years of experience with building, deploying, administration and monitoring of SaaS applications and related infrastructure on both Windows (.NET) and Linux platforms.Experience with AWS, with emphasis on components such as autoscaling, lambda functions, Kinesis, SQS, IAM, and secrets manager.Experience with infrastructure tools like Terraform and CloudFormation.Experience scripting with languages like Python, PowerShell, bash.Experience with Kubernetes (EKS or self managed)Experience with configuration management tools such as Puppet, Chef, Ansible.Knowledge of both RDBMS and NoSQL data platforms such as like MySQL, MSSQL, MongoDB, ElasticSearch, Redis, and Elasticsearch..Experience with build systems such as Jenkins, Bamboo.Understanding of different types of git workflows and the differences between them.Experience with monitoring and APM tools such as New Relic, AppDynamics, SolarWinds,Experience with system hardening and implementing security controls.Web development experience (frontend or backend) would be a great plusPositive attitude and ability to work in a fast-paced environment.What We OfferPeople-focused, entrepreneurial start-up culture with the backing of a stable, global, corporate entity – NemetschekCompetitive compensation and benefits package (medical, dental, education reimbursement, 401k, wellness resources)Work-life balance fostered through a culture of diversity, inclusion, and appreciation of individual lifestyle needsYou will have the opportunity for continuous professional developmentIf you think you are a good match for the Bluebeam team, please send the following:Resume(Optional) Cover Letter - be creative! We wanna know why Bluebeam, why you and what makes you a great addition to the team!If you move further in the process - you will complete a take-home test exercise at a later stageAbout BluebeamThe construction industry is adopting new technology at a feverish pace. Tablets and cell phones are replacing paper blueprints, drones are surveying jobsites in 3D, and cloud collaboration is changing the way teams work together. Bluebeam plays a crucial role in this transformation. The key to our success is a customer-focused approach to product development: we work with the industry to create solutions for the industry. Today, over 2 million people throughout the world use Bluebeam. In the US, we're a critical partner for the majority of top AEC firms, and rapidly expanding our presence globally, with offices in Sweden, Germany and the UK.Come design and build your future with us.Bluebeam is proud to be an equal opportunity workplace. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, or veteran status.#LI-CT1",la,de
5,Army National Guard,Government,4.2,12Y Geospatial Engineer,"Los Alamitos, CA",$34K - $75K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_a3382a34&cb=1618161634083&jobListingId=4055722415,"Job DescriptionYou can play an important part in disaster relief missions as a Geospatial Engineer for the Army National Guard. In this role, you will extract and supply geographic data that supports military operations of all kinds and help commanders visualize the battlefield during combat.As a Geospatial Engineer, your primary responsibility will be to collect and process military geographic information from decentralized sources (remote sensed imagery, digital data, intelligence data, existing topographic products, and other collateral data sources), present this information to leaders, and return decisions to the field.You may also:Supervise topographic surveying, cartography, and photolithography activitiesAssist in topographic planning and control activitiesAssist in determining requirements and providing technical supervision of geographic intelligence programsJob DutiesCreate geographic data and compile them into mapsCreate and maintain multiple geospatial databasesPrepare military-style briefs covering all aspects of the terrainSome of the Skills You’ll LearnBasic knowledge of Geographic Information SystemsImagery interpretation and exploitationHelpful SkillsInterest in geography, maps, and chartsAbility to demonstrate basic computer skills and work with drafting equipmentConceptualize ideas into computer-generated 2-D/3-D geospatial productsPreference for a technical career fieldThrough your training, you will develop the skills and experience to enjoy a civilian career with construction, engineering, and architectural firms, as well as with government agencies as a surveyor, mapmaker, cartographer, cartographic technician, or photogrammetrist.Earn While You LearnInstead of paying to learn these skills, get paid to train. In the Army National Guard, you will learn these valuable job skills while earning a regular paycheck and qualifying for tuition assistance.Job training for a Geospatial Engineer requires 10 weeks of Basic Training, where you'll learn basic Soldiering skills, and 20 weeks of Advanced Individual Training (AIT) and on-the-job instruction, including practical application of geographic information systems. Part of this time is spent in the classroom and part in the field.Benefits/RequirementsBenefitsPaid trainingA monthly paycheckMontgomery GI BillFederal and State tuition assistanceRetirement benefits for part-time serviceLow-cost life insurance (up to $400,000 in coverage)401(k)-type savings planStudent Loan Repayment Program (up to $50,000, for existing loans)Health care benefits availableVA home loansBonuses, if applicableMost non-prior service candidates will earn between $200 and $250 per drill weekend, subject to changeRequirementsMilitary enlistment in the Army National GuardMust be at least a junior in high school, or have a high school diploma or a GED certificateMust be between the ages of 17 and 35Must be able to pass a physical exam and meet legal and moral standardsMust meet citizenship requirements (see NATIONALGUARD.com for details)Requires military enlistment. Programs and benefits are subject to change. Ask your Army National Guard recruiter for the most up-to-date information. Actual MOS assignment may depend on MOS availability.Other Job InformationJob ID: 1361758ZIP Code: 907205001Job Category: EngineerAge Requirements: Must be between the ages of 17 and 35 administrator map reader aide",la,de
6,The Wonderful Company,Manufacturing,3.7,Data Architect,"Los Angeles, CA",$112K - $144K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1044077&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b55c4385&cb=1618161634083&jobListingId=4056413824,"The Data Architect is a hands-on leader who will own the building of data and analytics across various Wonderful Company and champion its use.The Data Architect will play a key role with the high performing global IT team in managing and planning all activities around reporting, data analytics and AI. You will need to work closely with business units under direction from IT leads for executing new projects. The Data Architect will need deep understanding of data warehouse design methodologies, ETL processes and familiar with best practices as well as hands on experience.The Wonderful You as a Data Architect: Data warehouse Design Skills: Main focus area includes exceptional skills with data design and managementETL processes Skills: Strong knowledge of ETL processes and SQL query expertise.Business Processes Familiarity: Understanding of supply chain, financial and manufacturing transaction processes. Experience working with ERP systems and data modelling is mandatory.Debugging / Problem Solving Skills: In order to be an effective problem solver, you would need to have out of the box thinking for debugging and problem solvingProject Management skills. Ability to plan, set milestones, deadlines and plan what needs to be done is essential. Handling multiple priorities and keeping your ear to ground for quick shifting focus for business continuity. Working with internal customers and external vendors for finishing projects on time is essentialAnalytical skills. It comes with the focus on data handling that candidate possesses strong analytical skills. You will be answering complex questions around data validation. Exceptional analytical skills will guide you to handle such queriesBS/MS in computer science or related field7-9 years of extensive hands-on experience in end-to-end architecting, configuring, implementing, and administrating databases and data warehouse solutions for a medium to large group or organizationStrong Experience with data warehousing ETL process design/development/support (Azure Data Factory, Informatica, ODI). Solid understanding of database design and best practices.8+ years of working experience on relational database and related technologies is required.Experience with Microsoft Analytics stackExcellent understanding of star/snow-flake schema, SCDs and de-normalized operationsExperience working with Salesforce is a plus.Acute attention to detail with a high level of data integrity and accuracy.Wonderful's Dedication to You as a Data Architect: Competitive benefits package including Medical (including 24/7 online access to a physician), Vision, Dental and 401k with match eligibilityOpportunity for development and internal mobilityManager and leadership training, weekly L&OD webinars, and eLearning offeringsTraining in continuous improvement and project managementWonderful Giving (wonderfulgiving.com) - allowing you to donate company money to a cause of your choiceCompany focus on wellness and health including virtual yoga and mindfulness classesHeadquartered in Los Angeles, The Wonderful Company is a privately held $5 billion company dedicated to harvesting health around the world through its iconic consumer brands. The company's 10,000 employees worldwide are committed to bringing consumers everywhere the freshest, most wholesome pistachios, citrus and pomegranates; bottling the finest water and wines; and creating colorful bouquets that are sure to touch the heart. This commitment is reflected in the company's market share: Wonderful Pistachios® is America's No. 1 tree nut and America's fastest-growing snack; Wonderful® Halos® is the No. 1 mandarin orange in America; POM Wonderful® is the No. 1 100% pomegranate brand in America; FIJI® Water is America's No. 1 premium imported bottled water brand; JUSTIN® Wine has the No. 1 Cabernet Sauvignon in California; and Teleflora® is the world's leading floral delivery service.The Wonderful Company's connection to consumers has health at its heart and giving back at its core. The company has a long-standing commitment to corporate social responsibility, including more than $1 billion invested in environmental sustainability; $65 million in charitable giving, education initiatives, and innovative health and wellness programs each year; and $143 million toward the construction of two charter school campuses in California's Central Valley.To learn more about The Wonderful Company, its products and its core values, visit www.wonderful.com, or follow us on Facebook, Twitter and Instagram. To view the current Corporate Social Responsibility report, visit www.wonderful.com/csr.The Wonderful Company is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.Please click here to view our Privacy Notice.Job Type: Full-timeBenefits:401(k)Dental insuranceEmployee discountHealth insuranceLife insurancePaid time offVision insuranceSchedule:8 hour shiftSupplemental Pay:Bonus payWork Location:One locationCompany's website:https://www.wonderful.com/careers/Work Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview process",la,de
7,Headspace,Information Technology,3.7,"Senior Software Engineer, Machine Learning","Santa Monica, CA",$128K - $147K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=1206777&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_90a65ad1&cb=1618161634084&jobListingId=4056353639,"About the Senior Software Engineer, Machine Learning at Headspace:Headspace AI Engineering is a dynamic and innovative group whose mission is to enhance overall engineering capabilities for the purpose of improving efficiency, productivity, and impact of AI practitioners. In this team, you’ll be tasked with owning and delivering cutting edge platforms, frameworks, and services that power AI at Headspace. You’ll have the opportunity to lead the vision, alignment, development, deployment, and evangelization of these solutions, helping to bring Headspace to the forefront of AI and to realize its mission to improve health and happiness of the world. You’ll initially be building for top Data Scientists, but with the goal to also scale to engineers, analysts, and other AI enthusiasts, thereby helping to democratize AI at Headspace.How your skills and passion will come to life at Headspace:Drive significant technology initiatives end to end and across multiple layers of architecture and businessLead the development of complex, multi-component, scalable AI platforms and servicesBuild continuous automated retraining framework for models in production to enable online learningAlign design and technical decisions across internal organizationsProvide technical leadership and be a role model for those pursuing technical career path in AI/ML engineeringIncrease internal and external company visibility in the AI community through open source, talks/presentations, etc.What you’ve accomplished:MS or higher in Computer Science or a related field3+ years of software engineering experience (with at least 2 years for large businesses or enterprises)2+ years of experience with AI/ML technologies such as supervised, unsupervised machine learning, deep learning and reinforcement learning2+ years of experience designing, developing, and maintaining complex distributed systems2+ years of experience with distributed processing systems (Hadoop, Spark, Kafka, Kinesis, or HPC)2+ years of experience with Cloud Infrastructure (preferably AWS)Strong experience in OO design and programming (strong proficiency in at least one of Java, Scala, Spark or Python)Proven track record of leading cross-team initiatives and driving initiatives end-to-end from inception to productionStrong problem solving and communication skills and ability to influence across internal organizationsStrong experience leading design and implementation of robust and highly scalable servicesExperience with distributed data storage systems (e.g. Vertica, HDFS, DynamoDB, Hive, Cassandra, etc)Experience with container and serverless technologies is also desired (e.g. Docker, Kubernetes)How we feel about Diversity & Inclusion:Headspace is committed to bringing together humans from different backgrounds and perspectives, providing employees with a safe and welcoming work environment free of discrimination and harassment. We strive to create a diverse & inclusive environment where everyone can thrive, feel a sense of belonging, and do impactful work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, gender, gender identity, gender expression, sexual orientation, national origin, family or parental status, disability*, age, veteran status, or any other status protected by the laws or regulations in the locations where we operate. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our workplace. *Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and certain state or local laws. A reasonable accommodation is a change in the way things are normally done which will ensure an equal employment opportunity without imposing undue hardship on Headspace. Please inform our Talent team if you need any assistance completing any forms or to otherwise participate in the application process.How to get started:If you’re excited by the idea of seeing yourself in this role at Headspace, please apply with your CV and a cover letter that best expresses your interest and unique qualifications.",la,de
8,Slickdeals,Media,3.9,Data Engineer,"Los Angeles, CA",$60K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=8095&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_b27248bd&cb=1618161634085&jobListingId=3821493513,"THE PURPOSE:

The Data Engineer works within the Data Solutions organization on critical reporting, visualization, and analysis initiatives. Reporting spans from custom ad-hoc requests to scheduled jobs to supporting our growing data warehouse, and building our future cloud analytics platform. The developer must be able to communicate to business users the exact scope of metrics as well as the confidence and quality of the data in reports.

THE ROLE:

Work directly with the business users to understand the reporting needs and lead business users to practical solutions
Help translate business requirements into specification documents to track and perform analysis of new and existing site features
Understand the necessity of data quality and requirement for confidence of accuracy of any reports
Develop/monitor/maintain new reports, dashboards, visualizations, procedures, data structures and databases
Design data pipelines and maintain data pipelines in cloud or on-premise environments
Design data schema, perform data transformations, enrichments, and manipulations with efficiency and reusability in mind
Planning, conducting and directing the analysis of complex business problems and projects

THE CANDIDATE:·


Understand data structures and algorithms. Understanding of basic statistics (confidence intervals, statistical significance, etc)
Experience in working with large size data sets (Billions of rows/Petabytes of data)
Experience in working with various data sources (ODBC, flat files, etc)
Experience working with and designing complex data schemas
Strong skills in SQL, Java and/or Python
Experience with SQL query performance optimization
Strong skills Experience with Apache Big Data Frameworks (Hadoop/EMR/Databricks, Spark, Hive)
Strong experience with Spark performance optimization and troubleshooting
Experience with Kafka and event driven architectures
Familiarity with workflow scheduling/orchestration tools (Airflow, Jenkins)
Experience with AWS
Experience with Tableau and or other Self Service Analytical tools.
Implemented Redshift, Snowflake, Azure Data Warehouse, ADLS, S3, Kafka, Presto, EMR, Databricks, or Data Lake Architecture in one or more public clouds in a Production Large Scale environment.

TO BE SUCCESSFUL YOU WILL BE:



Highly motivated with a great attitude and desire to dive into raw data to understand trends in behavior to find insights
Excellent at multitasking who can execute multiple requests and reports under tight timelines
Inquisitive, self-starter, able to work autonomously
Able to work in a fast-paced dynamic startup like environment
Detail-oriented tactician who strives for perfection
Strong verbal and written communication (and listening) skills
Excellent reading comprehension and attention to detail.
Strong problem-solving skills
Strong documentation skills as you code (Jira, Confluence)

As a Data Engineer, your day-to-day tasks will include:


Helping us leverage large-scale data stores and data infrastructure by building out data pipelines, streams, and utilities in Spark and other technologies for feedback to our business systems, partners, or users
Developing robust, low latency and fault tolerant pipelines to support business critical systems
Aggregating key metrics for business partners to inform key decisions
Working with cloud technologies to build and deploy your applications

Environment

Can work effectively on a small and nimble team, no trouble context-switching

Education

B.S./M.S. in Computer Science or Computer Engineering or 3+ years of equivalent experience",la,de
9,Twitter,Information Technology,4.2,Cloud Data Engineer,"Los Angeles, CA",$116K - $213K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_186c02a9&cb=1618161634085&jobListingId=3823015881,"Company DescriptionAs data engineers in Revenue Science, our mission is to build real-time and offline solutions to make data accessible and reliable while leveraging the largest-scale data processing technologies in the world - and then apply them to the Revenue’s most critical and fundamental data problems.Learn more about some of the challenges we tackle on this team:Building a Petabyte-scale Data Warehouse (Google Cloud Next '18) https://youtu.be/APBF9Z3uBCcHow Twitter Migrated its On-Prem Analytics to Google Cloud (Google Cloud Next '18) https://youtu.be/sitnQxyejUgJob DescriptionYou are passionate about data and driven to take the data organization challenges at the scope of entire Twitter’s Revenue.As a member of the Data Engineering team, you will build and own mission-critical data pipelines that are ‘source of truth’ for Twitter’s fundamental revenue data, as well as modern data warehouse solutions, while collaborating closely with Ads Data Science team.You will be a part of an early stage team and have a significant stake in defining its future with a considerable potential to impact all of Twitter’s revenue and hundreds of millions of users.You will be among the earliest adopters of bleeding-edge data technologies, working directly with Revenue Science and Revenue Platforms teams to integrate your services at scale.Your efforts will reveal invaluable business and user insights, leveraging vast amounts of Twitter revenue data to fuel numerous Revenue teams including Ads Analytics, Ads Experience, Ads Data Science, Marketplace, Targeting, Prediction, and many others.QualificationsStrong programming and algorithmic skillsExperience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce etc).Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica)Nice to have:Experience writing Big Data pipelines, as well as custom or structured ETL, implementation and maintenanceExperience with large-scale data warehousing architecture and data modelingProficiency with Java, Scala, or PythonExperience with GCP (BigQuery, BigTable, DataFlow)Experience with Druid or Apache FlinkExperience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming)Ability in managing and communicating data warehouse project plans to internal clientsAdditional InformationAll your information will be kept confidential according to EEO guidelines.",la,de
10,NBCUniversal,Media,4.1,Data Engineer,"Burbank, CA",$98K - $172K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_3b727b53&cb=1618161634086&jobListingId=4028994209,"59394BRTechnology & EngineeringOperations & TechnologyResponsibilitiesThe Data & Analytics team (D&A) at NBCUniversal is looking for a passionate problem solver who’s looking to build the next generation of data pipelines and applications. Working across one or more of our main subject areas – research, marketing, engineering frameworks – the Data Engineer role is right for you if you’re a “hands-on” coder who can build and cleanse large datasets in order to report out actionable insights.As part of the global Operations & Technology organization, the D&A is focused on data and analytics strategies for the future. We support NBCU’s vast portfolio of brands - from broadcast, cable, news, and sports networks to film studios, world-renowned theme parks, and a diverse suite of digital properties. We take pride in supplying our business groups with data to advise and shape strategic business decisions related to our content.In the Data Engineer role, you’ll be working with internal stakeholders, data engineers, visualization experts, data scientists, and other technologists across the business. If you’re someone who loves to take large, disparate data sets and build them into flexible and scalable analytics applications and databases, you’ve come to the right place. Here you can create the extraordinary. Join us.Collaborate with business leaders, engineers, and product managers to understand data needs.Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using cloud-native data engineering principlesDesign, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed/elastic environments, and downstream applications and/or self-service solutionsIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Implement the appropriate design patterns while optimizing performance, cost, security, and scale and end user experienceParticipate in development sprints, demos, and retrospectives, as well as release and deploymentBuild and manage relationships with supporting IT teams in order to effectively deliver work products to productionQualifications:5+ years of experience in a data engineering roleDirect experience with data modeling, ETL/ELT development principles, and data warehousing conceptsKnowledge of data management fundamentals and data storage principlesExperience in building data pipelines using Python/SQL or similar programming languagesDemonstratable experience in Airflow, Luigi or similar orchestration enginesGeneral understanding of cloud data engineering design patterns and use casesBachelor's degree in Computer Science, Data Science, Statistics, Informatics, Information Systems or related field.Desired Characteristics:Analytical – You have experience in delivering data analytics solutions that promote data discoveryExperience with Snowflake, Amazon Web Services, or related cloud platforms a plusUnderstanding of big data technology stacks (Hive / Spark etc) is a plusMedia-focused – Strong knowledge/passion for media including broadcast TV, digital, and filmDirect experience working with sources like Nielsen, Adobe Analytics, comScore, and other media/entertainment industry datasets a plusCommunicator – You have excellent verbal and written skills with the ability to communicate ideas effectively across all levels of the organization, both technical and non-technicalAction-oriented – You're constantly figuring out new problems and are regularly showing results with a positive attitude, always displaying ethical behavior, integrity, and building trustStrong understanding of Agile principles and best practicesYou’ve dealt with ambiguity and can make quality decisions in a dynamic, fast-paced environmentQualifications/Requirements#LI-DNPSub-BusinessEngineeringCareer LevelExperiencedCitySee List BelowState/ProvinceMultiple LocationsCountryUnited StatesMultiple LocationsBurbank - California, New York - New York, Universal City - CaliforniaAbout UsAt NBCUniversal, we believe in the talent of our people. It’s our passion and commitment to excellence that drives NBCU’s vast portfolio of brands to succeed. From broadcast and cable networks, news and sports platforms, to film, world-renowned theme parks and a diverse suite of digital properties, we take pride in all that we do and all that we represent. It’s what makes us uniquely NBCU. Here you can create the extraordinary. Join us.NoticesNBCUniversal’s policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.",la,de
11,Age of Learning,Education,3.9,Product Analyst/Data Scientist (Senior or Midlevel),"Glendale, CA",$140K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=1205501&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_2cebe2db&cb=1618161634087&jobListingId=3749766786,"Company Overview:Age of Learning is a leading education technology innovator based in Glendale, California, with a talented team of more than 600 individuals comprised of nationally-renowned educators, curriculum experts, developers, artists, writers, designers, engineers, producers, product managers, analysts and marketing experts! Together we develop engaging, effective digital learning technology and content to help children build a strong academic foundation for lifelong success.  Our flagship product ABCmouse.com Early Learning Academy® is a comprehensive online curriculum and the #1 digital learning product for young children. To-date, more than 30 million children worldwide have completed over 8 billion Learning Activities on ABCmouse. We recently launched Adventure Academy, the first massively multiplayer online (MMO) game designed specifically to help elementary- and middle-school-aged children learn. It features thousands of engaging Learning Activities—including minigames, books, original animated and live action series, and more—in a fun and safe virtual world. Other Age of Learning programs include immersive English language learning products for children in China and Japan; ReadingIQ, a digital library and literacy platform; and a groundbreaking personalized, adaptive digital learning system that individualizes math instruction for every child through AI-driven technology. We are committed to helping all children succeed. We provide our educational programs at no cost to teachers, Head Start programs, public libraries, and other community organizations, and have served millions of children through these initiatives. We recently established the Age of Learning Foundation to expand this work globally. As we expand our global reach and increase the educational impact of our programs, we’re looking for passionate, ambitious, and collaborative leaders to become a part of our growing team.Summary:We are looking for two experienced (mid to Senior) Product Analysts or Data Scientists who will work on our centralized Data & Analytics team and collaborate closely with one of the following teams: Adventure Academy or International Products. You will bring to light key data insights that drive decisions for our learning software and games, delighting kids and parents alike. You have a passion for video games and education. You are a rare breed of analytics powerhouse and business-savvy — a proactive, intellectually curious, and entrepreneurial Product Analyst, who will own and deliver in-depth analyses of large-scale data problems to influence numerous aspects of business performance. You will have a strong impact in influencing product management and senior executives through actionable business/roadmap recommendations.  Contribution will come in the form of defining data capture requirements, verifying data integrity, data manipulation, business monitoring, data visualization, and in-depth analyses. Responsibilities: You willPartner closely with product stakeholders to solve key product challengesConduct product analyses to understand how user behavior impacts KPIs, such as retention and long-term valueCreate, report, and interpret key metrics to assess performance, measure the impact of strategic initiatives and identify ways to grow revenue and reduce costsDevelop statistical analyses to understand customer behavior and product performanceCreate beautiful and informative automated/real-time dashboards and visualizationsDrive A/B and multivariate testing strategy and implementation across desktop and mobile platforms to inform product strategy, engagement, retention, lifetime value, product and content recommendations, and personalized experiencesIdentify actionable insights that positively affect both company revenue and learning outcomes for childrenCommunicate results to technical and non-technical stakeholdersDrive data capture and data integrity requirements; partner with product and engineering teams so that the right data is capturedMaintain a vigilant eye on data qualityMaintain knowledge of competitive and related productsRequired Qualifications: 2+ years in an analytical/product-focused role; B2C digital products preferred; video game experience strongly preferred for Adventure Academy role Strong analytical and reporting skillsFluent in complex SQL queries on big data setsFluent in Tableau and Excel (Additional data visualization capabilities a plus) Able to manipulate and explore data, perform analysis and create visualizations using R or PythonComfortable defining analytics architecture that meets product management requirementsCollaborative problem-solving skills with an entrepreneurial attitude and results-oriented mindsetBachelor's or Master’s degree in a quantitative field (e.g., analytics, statistics, applied math, data science, economics or computer science); OR if no quantitative degree, 2-4 additional years related experience and/or training Experience with testing and optimization a plus, ideally in a digital environmentAge of Learning currently provides: • 90% - 100% of health and welfare benefit premiums• A 401(k) program with employer match• 15 paid vacation days plus 11 observed national paid holidays• Team bonding events and a highly collaborative environment• Commitment to Equal Opportunity Employment in addition to an inclusive and supportive company culture • Access to our internal DEI Task Force that focuses on ensuring our products represent all children on a global scale• Opportunities for professional growth through professional learning and development programs • A temporary 100% remote work environment, due to COVID restrictions, to help ensure the safety of our employees • Monthly internet stipend provided due to temporary remote work environment",la,de
12,MotorTrend Group,Media,3.1,Data Engineer,"El Segundo, CA",$79K - $133K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_3f563d12&cb=1618161634088&jobListingId=4029000506,"Machines that Move Us.People who Inspire Us.Stories that Drive Us.Check us out: http://bit.ly/MotorTrendGAbout UsWe are MotorTrend.With a monthly reach of more than 131 million, MTG is the largest automotive media company in the world. With franchises including MotorTrend, Hot Rod, Automobile, Wheeler Dealers, Roadkill, Best Driver's Car, and dozens of other world-class brands, we are reimagining storytelling around mobility. Our portfolio brings together Discovery's #1 TV network for automotive super fans, with our vast automotive digital platform that includes direct-to-consumer products, websites, apps, connected TVs, social, and live events.Our PeopleThe people who work at MotorTrend embody the passion of our content, and wake up every day intent on embracing, entertaining, and empowering the motoring world.The RoleJob Summary & Responsibilities:We are looking for a Data Engineer (full-time, salary, regular) to join our team. At Motor Trend Group data is central to measuring all aspects of the business, and critical to its operations and growth. The BI data engineering team is responsible for collecting, analyzing and distributing data using public cloud and open source technologies and offers transparency into customer behavior and business performanceResponsibilities:Collaborate with product teams and data analysts to design and build data-forward solutionsBuild and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliablyIntegrate with a variety of data metric providers ranging from advertising, web analytics, and consumer devicesBuild and maintain dimensional data warehouses in support of business intelligence toolsDevelop data catalogs and data validations to ensure clarity and correctness of key business metricsDrive and maintain a culture of quality, innovation and experimentationDeliver strong Python and SQL development and maintenance techniques surrounding data movement to include technologiesInvestigate and understand different data sources and ability to connect to a wide variety of 3rd party APIsDesign, enhance and implement ETL/data ingestion platform on the cloudDevelopment of ETL source and target mapping design/specifications based on the business requirements. Create ETLs/ELTs to take data from various operational systems and create a unified/enterprise data model for analytics and reportingDevelop load and transformation processes in support of the requirements, validate that they meet business and technical specifications, manage ongoing maintenance of the system and data, and make recommendations for process improvements to optimize data movement from source to targetProvide production and operational support to existing ETL jobs. Monitor and manage production ETL jobs to verify execution and measure performance to assure ongoing data quality and optimization of the system to manage scalability and performance and identify improvement opportunities for key ETL processes.Strong troubleshooting and problem-solving skills in large data environmentCapable of investigating, familiarizing and mastering new data sets quicklySupervisory Responsibility:This position will not include supervising one or more employees where applicable.Education/Experience:Bachelor's degree – Computer Science or equivalentStrong background in scripting language using Python, Bash, Perl, PHP or any other language to solving data problemsExperience with relational SQL and NoSQL databases, including Postgres, ,Neo4j and MongoDbExperience with Big Data tools; Hadoop, Spark, Kafka, Hive etcProficiency with the AWS cloud services : EC2, EMR, RDS, S3, Redshift (spectrum)Proficiency with data exchange types and protocols (json, xml, soap, rest)Experience with Stream Processing systems: Storm ,Spark-Streaming etcExperience with BI tools like Tableau or any other open source BI tools etc.Knowledge, Skills, & Abilities:Knowledge of the Python data ecosystem using pandas and numpyData integration toolsProficiency in SQL, data modeling, and data warehousingExcellent problem solving skillsExposure to cloud platforms (preferably AWS)Equipment/Software Used:Microsoft Office Suite (Outlook, Word, Excel, PowerPoint)SQL, MySQL or other relational databasesLinux, Python, AWS Stack (EC2,EMR S3, Redshift)Tableau or any other data visualization toolSiteCatalyst (Omniture)/Google Analytics or any other web analytics tools experience (Nice to have)Work Environment:Work is performed in an office environment that is well lit and ventilated.NOTE: This position description reflects management's assignment of essential functions; it does not prescribe or restrict any other tasks that may be assigned.",la,de
13,Intuit,Information Technology,4.3,"Staff Software Engineer, Big Data","Los Angeles, CA",$110K - $202K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_edb07615&cb=1618161634088&jobListingId=3750152277,"OverviewThe Intuit Data Engineering team is looking for a Staff Software Engineer, Big Data with a winning track record in Big Data and Distributed Systems. We’re using data in groundbreaking ways to uncover customer insights, personalize customer experiences through AI/ML, and provide a unified customer view across all Intuit products.Note: By applying to this position your application is automatically submitted to the following locations: Mountain View, Los Angeles, San Diego and the following teams at Intuit.What you'll bringBS in Computer Science. MS Preferred.Strong CS fundamentals including data structures, algorithms and distributed systems.Strong database fundamentals including SQL, performance and schema design.8+ years of strong Object Oriented Programming (Java, Scala, or Python)8+ years of hands-on Software Engineering experience.8+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.Strong project leadership experience, including being a technical lead for multiple complex software development projects using agile methodologies.Experience in people management or interest in people management is a plus.Experience with Hadoop, Hive, HBase, Spark, Kafka, Storm, Druid, Cassandra, Columnar Databases and Graph Databases.2+ years working with Cloud Technologies.Experience with varios offerings from AWS, including S3, EMR, Redshift, Data Pipeline, Athena and Kinesis is a plus.History of contributing to open source projects is a plus.5+ years DevOps experience including configuration, optimization, backup, high reliability, monitoring and systems version control.Track record working with data from multiple sources – willingness to dig-in and understand the data and to leverage creative thinking and problem-solving.Excellent interpersonal and communication skills, including business writing and presentations. Ability to communicate objectives, plans, status and results clearly, focusing on critical few key points. Demonstrated ability to work in a matrix environment, ability to influence at all levels, and build strong relationships.Knowledge of enacting service level agreements and the appropriate escalation and communication plans to maintain them.How you will leadDesign and develop big data and real-time analytics solutions using industry standard technologies.Develop web services that make big data available in real-time for in-product applications.Work with data architects to ensure that Big Data solutions are aligned with company-wide technology directions.Lead fast moving development teams using agile methodologies.Lead by example, demonstrating best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting, and incident response.Communicate progress across organizations and levels from individual contributor to senior executive. Identify and clarify the critical few issues that need action and drive appropriate decisions and actions. Communicate results clearly and in actionable form.Serve as technical “go to” person for our core technologies – Hadoop, Spark, AWS, Vertica, Tableau, Cassandra, Graph Databases and others.Demonstrate strong implementation aptitude to translate objectives into a scalable solution to meet the needs of the end customer while meeting deadlines.Demonstrate commitment to your professional development by attending conferences, taking classes, giving technical presentations, and participating in developer communities inside and outside of Intuit.",la,de
14,Valley Presbyterian,Health Care,3.9,"Systems and Server Engineer (Full Time, 8HR, Days - Information Technology Unit / #3720)","Van Nuys, CA",$46K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_84865546&cb=1618161634088&jobListingId=3796257197,"Employment Status:Full Time (72-80 Hours Per Pay Period)Job Category:Administrative & ProfessionalJOB SUMMARY:The Systems and Server Engineer is responsible for executing maintenance and project tasks to support the Windows, VMWare, Microsoft/Office 365, Security, Connectivity, and Storage environment that support the Clinical, Business, and Infrastructure applications supported by the Information Systems department.The Systems and Server Engineer acts as a subject matter expert in almost every Information Technology project. As such, this position is responsible for configuration and processes in accordance with approved technical architecture standards and support processes. He or she will be responsible for implementing and monitoring server based security and will provide input to the overall security plan. This role will also work with other Information Technology team members and vendors to ensure the operation is in accordance with organizational needs and established procedures and practices.EXPERIENCE/QUALIFICATIONS:Two (2) or more years work experience supporting MS servers, VMWare, Image deployment, Desktop systems or storageWorking experience of VMWare installation, configuration, and use of associated toolsDemonstrated competence with Windows Server Family, Exchange, and client operating systemsExperience in Active Directory Services maintenance and troubleshootingKnowledge of DNS, DDNS, and DHCPBackup design and maintenanceAbility to work with 1st and 2nd level support personalAbility to learn and implement 3rd party tools for environmental supportVMware vSphere and vCenter experienceVMware Horizon and VDI infrastructureProven track record for comprehensive, systematic troubleshooting, and problem-solving skillsExperience with Patch Management of servers and PCs using tools such as WSUS, MDT or Microsoft SCCMIntermediate knowledge of Active Directory and enterprise user/endpoint management using GPO’s, scripts, profiles, etc.Ability to work as a team player in a fast-paced, critical service delivery environmentMust be a self-starter that can work independently and deliver according to expectationsDemonstrated ability to achieve high level of customer satisfactionAbility to exercise good judgment in determining work and problem resolution priorities and approachesEnsures documentation is available and up-to-date for all assigned procedures in accordance with department standardsWillingness to exercise hands-on system administration tasks to achieve service delivery according to standards.Ability to work under a process-centric ITIL FrameworkEDUCATION:Some College level courses but no specific degree requirementsREQUIRED LICENSURES/CERTIFICATION:Current MCSE, MCSP, or similar professional certification (e.g. MCTP, MCSA, MCTS, CompTIAServer+, LPIC, CCNP, EMCSA)DUTIES AND RESPONSIBILITIES ( These are the essential job functions for this position. The essential functions of this job include, but may not be limited to those listed in this job description. Employees hired for this position must be able to perform the essential function of this job without imposing significant risk of substantial harm to the health or safety of themselves or others) :Utilize monitoring and management software tools to effectively administer systems and maintain environment for optimal performance.Work with senior engineers and consulting subject matter experts to deploy technology across the hospital environmentImplement technical standardization projects.Analyze infrastructure system performance and implement improvements and upgrades as required to maintain an optimal operationsExecute projects as directed.Utilize excellent customer service skills to build service-based relationships with Information Technology customers.Interface with users, managers, directors, and executives as needed.Be able to exercise good judgment in resolving problems and making decisions.Be available 24x7 for emergencies involving technical problems that affect the ability to provide patient care and business continuity.Be available for rotation assignments for on-call support duties.Adhere and abide to the hospitals confidentiality agreements, policies and proceduresAdhere to organizational change management processesMaintain the integrity of network security systems to ensure data is appropriately protected.Perform regular security patches, updates, data backup and restore processes as requestedProvide resolution on complex issues following standard incident, change request and problem management processesAs directed, assist the support of network applications such as DNS, DHCP, Certificate Authority, Intrusion Protection, Web Filtering, Virus detection and preventionManage Microsoft Server operating systems including patches, upgrades, backups, and best practices for virtualization with VM WareMaintain Active Directory, Web server security certificates, and Exchange eMail systemAssist in endpoint architecture design and help desktop teamsSupport data center migration efforts and transition to Cloud based infrastructure as a serviceTroubleshoot and resolve complex problems.Maintain current knowledge of relevant hardware and software applicationsPerform special duties, tasks, or projects as requiredThe following job accountabilities are not unique to this particular job but are common to all jobs at VPH:Complies with VPH policies and procedures on customer satisfaction and service excellence. Demonstrates professionalism and cultural sensitivity in coordinating activities and communicating with all customers, peers, and the community at large. Conducts self in a professional, respectful and courteous manner during all interactions. Works effectively and collaboratively with others toward common goals.Communicates accurately, honestly, supportively and in a timely manner with department and interdepartmental team members. Demonstrates effective business writing and oral communication skills, handwriting is clear and legible.Participates in operational aspects of the department, and maintains/participates in performance improvement activities within the department.Participates in all departmental specific training, Environment of Care (injury/illness prevention, fire/life safety, hazardous materials, emergency preparedness, utilities management, medical equipment management, safety and security management), infection control (standard precautions, TB Exposure Control Plan, Bloodborne Pathogen Exposure Control Plan).Demonstrates knowledge of and follows safety practices. Understands the importance of safety, including patient safety in the work place. Maintains a safe environment for self and others.Actively participates in the Patient Safety Program, including event reporting. Identifies sentinel events/near misses and responds per defined organization processes. Participates in education activities and process implementation. Demonstrates advocacy for the patient/customer and appropriately acknowledges patients, customers and visitors.The above statements reflect the essential functions considered necessary to describe the principle content of the job. They are not intended to be a complete statement of all work requirements or duties that may be inherent in the job.WORK ENVIRONMENT:Primarily an inside building/office environment, well lighted and ventilated, which may consist of multiple treatment and/or work sites.Fast and continuous work pace with variable workload.Frequent contact with staff and public under a variety of circumstances. Requires ability to communicate clearly (in English) verbally and in writing for effective communication with other staff members, physicians, vendors, community members, patients and patient families, employees and applicants of all socio-economic levels from a diverse cultural and ethnic population.Subject to many interruptions from multiple calls and inquiries and potentially emotional situations involving accidents, injuries, illness and/or death.Handles emergency/crisis situations in accordance with Hospital policy.Answers phones or pages; may carry a beeper/pager, and/or use a two-way radio.Occasional travel may be required.Potential risk of exposure to hazards from chemicals (toxic and non-toxic), flammable materials, gas or electrical or radiant energy or equipment with/without moving parts.PHYSICAL DEMANDS:Key for Physical DemandsContinuous66 to 100% of the timeFrequent33 to 65% of the timeOccasional0 to 32% of the time Clerical/Administrative Non-Patient CareFrequent/continuous sitting with occasional, intermittent standing/walking.Continuous use of bilateral upper extremities in fine motor activities requiring fingering, grasping, and forward reaching between waist and chest level.Occasional/intermittent reaching at or above shoulder level.Occasional/intermittent bending, squatting, kneeling, pushing/pulling, twisting and climbing.Occasional/intermittent lifting and carrying objects/equipment weighing up to 25 pounds.Continuous use of near vision, hearing and verbal communication skills in handling telephone calls, interacting with customers and co-workers and performing job duties.Back ShareApply Now",la,de
15,"Bluebeam, Inc.",Information Technology,3.8,Senior Software Engineer (AWS),"Pasadena, CA",$125K - $145K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_0be55ee7&cb=1618161634089&jobListingId=4028341956,"At Bluebeam, we empower people to advance the way the world is built. We create smart software solutions that make construction sites more efficient, connected and safe and improve the lives of design and construction professionals everywhere.*This role is a full-time, onsite position. Due to COVID-19, all new employees will be required to start work remotely until we are able to return to the office. More information will be provided in the interview process.*About YOU:Bluebeam is looking for an accomplished cloud software developer with an ambition for making great applications. You have a passion for architecting distributed and scalable solutions that are testable, performant and easy to maintain. You have knowledge in the construction of generic services and REST endpoints with C# and MVC. You are well versed in SQL databases and understand the principles and application of NoSQL. Our applications are built on AWS, and you have experience developing and deploying on that platform using a variety of tools and services like EC2, SNS, SQS, ELB, Kinesis You should excel in mentoring other software engineers and help us bring a culture of attention to quality, maintainability, and. You will enjoy the opportunity for full stack development, so an ability to code UI components in JavaScript and React.About the TEAM:Want a peek at what you'll do? As part of a development team charged with taking our flagship product into the future, you will design and implement cloud-based solutions to power our vision of a connected future. You will also contribute to our technical roadmap and help to mentor and share your knowledge. Working at Bluebeam will give you exposure to a wide array of technologies such as large-scale image rendering, real-time collaboration services, and 3D Image Processing, just to name a few.About YOU:7+ years of progressive experience as a Senior Level Engineer5+ years building high performing/data intensive applications running in the Cloud.Bachelor's degree or higher - Computer Science or equivalent fieldDevelopment experience in .NET technologies, particularly C#, MVC, WebAPIAmazon AWS experience (EC2, S3, Lambda)Experience designing, creating microservices and delivering to market.Experience implementing infrastructure as code, including building and integrating into CI / CD pipelines.Experience deploying services in containers and using container orchestration.Use APIs and understanding of HTTP and REST architectureExperience with relational databases. Experience designing, creating APIs and delivering to marketPartner with business and technology team members, to understand requirements and translate them into value-add technology solutionsWillingness to learn and expand skills and repertoireA positive mindset, team-oriented, results driven, and organized.Exceptional written and oral communication skills.Familiarity with OAuth and OIDC.Familiarity with .NET Core.Familiarity with Go Programming Language (GoLang), Rust, Or WASMIf you think you are a good match for the Bluebeam team, please send us the following:Your Resume(Optional) Some sort of personalized introduction for us. This could be a cover letter, a few bullet points about yourself, a comic strip you've drawn - anything that tells us a bit about you AND why you want to work here.What We OfferPeople-focused, entrepreneurial start-up culture with the backing of a stable, global, corporate entity - NemetschekCompetitive compensation and benefits package (medical, dental, education reimbursement, 401k, wellness resources)Work-life balance fostered through a culture of diversity, inclusion, and appreciation of individual lifestyle needsYou will have the opportunity for continuous professional developmentAbout BluebeamThe construction industry is adopting new technology at a feverish pace. Tablets and cell phones are replacing paper blueprints, drones are surveying jobsites in 3D, and cloud collaboration is changing the way teams work together. Bluebeam plays a crucial role in this transformation. The key to our success is a customer-focused approach to product development: we work with the industry to create solutions for the industry. Today, over 2 million people throughout the world use Bluebeam. In the US, we're a critical partner for the majority of top AEC firms, and rapidly expanding our presence globally, with offices in Sweden, Germany and the UK.Come design and build your future with us.Bluebeam is proud to be an equal opportunity workplace. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, or veteran status.#LI-CT1",la,de
16,Spokeo,Information Technology,4,"Data Engineer, Analytics","Pasadena, CA",$58K - $112K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=117&ao=37049&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_ab93679e&cb=1618161634089&jobListingId=4055476067,"Spokeo is a people search engine that both enlightens and empowers our customers. With over 12 billion records and 14 million visitors per month, we reconnect friends, reunite families, prevent fraud, and more.

We are looking for a Data Engineer, Analytics who has an eye for building and optimizing big data systems to join our team. Working in an AWS ecosystem, this role will work closely with the data science and analytics team to direct the flow of data within the pipeline and ensure consistency of data delivery and utilization.

Responsibilities:

Design and build the infrastructure for data extraction, preparation, and loading of data from backend services and web browser clients to data lake for business and product analytics.
Build and manage existing analytics tools to provide deeper insight into the pipeline and capture key metrics.
Monitor technical performance and ensure that identified bugs are routed and resolved.
Mentor team members on working with highly scalable distributed systems and cluster architectures and maintain up-to-date knowledge of technological advances.
Work with large, complex SQL/NoSQL databases.
Create and maintain technical documentation.
Create unit and stress test scripts/modules.
Write well-abstracted, reusable, and efficient code.

Requirements:

5+ years of experience in backend software development.
Strong scripting, programming, and SQL skills; preferably using Python, Ruby, and ANSI SQL.
Basic understanding of JavaScript to maintain web analytics tracking infrastructure, not for front-end feature development.
Preferred experience with and understanding of event data collection tools like Snowplow, Segment, Google Tag Manager, Tealium, and mParticle, etc.
Preferred experience with and understanding of ETL tools.
Experience with AWS services like EMR Spark, Redshift, Kinesis, Lambda, Glue, Athena, etc.
Experience working with large data sets.
Strong organizational skills and detail-oriented mindset.
BS in Computer Science, Information Systems, or a related field.

Privacy Notice for Candidates: https://www.spokeo.com/recruiting-policy

Spokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products, and be relevant in a rapidly changing world.

Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file and 2) being assigned to the open position (as a search) via our applicant tracking solution.]]>",la,de
17,GoodRx,Biotech & Pharmaceuticals,4.7,"Full-Stack Engineer (multiple levels: mid, senior, staff)","Santa Monica, CA",$91K - $157K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_66e342ca&cb=1618161634089&jobListingId=4057117781,"At GoodRx, we believe that all Americans should have access to convenient and affordable healthcare. As a nation, we spend about $3.5 trillion annually on our healthcare, but too many Americans struggle to get the care they need, and prices just keep rising. Our marketplaces for prescription medicines and telehealth have helped Americans save $25 billion since 2011. GoodRx is a public company; we're based in Santa Monica with additional offices around the country. We're a low-key and tight-knit group that likes to find new ways to fix big problems. If you share our belief that you can do well by doing good, let's talk.We’re committed to growing and empowering a more inclusive community within our company and industry. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.With that said, research shows that women and other minority groups apply only if they meet 100% of the criteria. GoodRx is committed to leveling the playing field, and we encourage women, people of color, and those in the LGBTQ+ communities to apply for positions even if they don’t necessarily check every box outlined in the job description. Please still get in touch – we’d love to connect and see if you could be good for the role!Our Engineering Values:GoodRx engineers put our customers first and have a deep sense of ownership of our products and services from design, to implementation and throughout ongoing operations. We believe “it can be done” and succeed through continuous learning. GoodRx engineers balance craftsmanship and speed-to-market employing unit testing, end-to-end automation, and service telemetry to enable safe and fast product delivery, system visibility and ease of operations. The ideal candidate will be able to quickly turn ideas into production-ready solutions in a fast-paced and friendly environment. You should also be comfortable learning new technologies as needed.About the Role:GoodRx is looking for an experienced Full Stack Software Engineer to join the engineering team.As a Full-Stack Software Engineer, you will be collaborating with the rest of our engineering, product, design, data, and analytics team to transform ideas into exceptional products to help our users find affordable therapy solutions. You’ll be responsible for developing, prototyping, and designing front-end React/Typescript web applications while ensuring responsiveness and reusability of various components. You are passionate about innovation and playing around with the latest technologies and assisting the team in innovating and pushing the boundaries of our backend services and web technologies. As part of this role, you’ll also be responsible for developing and maintaining backend services and APIs that power our products. The ideal candidate will be able to quickly turn ideas from inception to final product in a fast-paced and friendly environment. You should be comfortable learning new technologies as needed.Responsibilities:Collaborate with Product Designers, Product Managers, and Engineers to deliver compelling cross platform (desktop/mobile web + native devices) user-facing products.Design, build, ship, and maintain reusable systems that drive our complex web applications.Own, create, review, and provide feedback on technical design proposals and proof of concepts.Write clean, fast, compatible, easy-to-use, and testable code to turn ideas into production quality products.Improve our design system and make other cross cutting architecture improvements to our overall architecture in both the Front-end and Back-end codebases.Mentor and be mentored by other engineers by leading and collaborating in all engineering discussions and evangelizing engineering best practices.Promote a culture of operational excellence by meticulously testing and monitoring our systems and code, writing documentation, and being on-call to support the health of our services.Collaborate, learn, and grow.Skills & Qualifications:5+ years of real product experience - you have shipped products.Experience with our front-end technologies – React, TypeScript, NextJS, Redux, NodeJS, ES6, Webpack.Proven experience building server side APIs both RESTful and GraphQL.High degree of fluency in Type and/or JavaScript – you are a strong coder and know how to write clean, effective code at scale.Experience with AWS technologies including AppSync, Lambda, StepFunctions, EventBridge.Writing standards-compliant, accessible markup and styling using CSS preprocessor or css-in-js.Proven experience taking features from inception to production.Experience with writing robust and maintainable unit, integration, and end-to-end tests.Ability to work effectively in teams of technical and non-technical individuals – you will work closely with other non-technical folks to get things done. Collaboration is key.Ability and desire to be a polyglot. Adapting to the tools and technologies appropriate for the job at hand.You are product minded with experience contributing to the definition of the products delivered by defining value propositions through the lens of the customer.Good To Have:Experience with our back-end technologies – GoLang and/or Python.Experience building and maintaining responsive and/or isomorphic web applications.Knowledge of how performance on the web is measured and experience with tools like Lighthouse, Runscope, Sentry, and/or Datadog.WCAG 2.0+ AA and/or accessibility standards for web.Familiarity with Content Delivery Network (CDNs) level caching for static assets and static/dynamic web pages.Knowledge with continuous integration, automated testing, and deployment tools like CodeFresh (preferable), Circle, Drone, AppEngine, or similar.Experience with multi-package manager tools like Lerna.Knowledge or experience with React Hydration similar to Gatsby.Proven history of keeping up with cutting edge technologies.GoodRx is America's healthcare marketplace. The company offers the most comprehensive and accurate resource for affordable prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast, as well as a telehealth marketplace for online doctor visits and lab tests. Since 2011, Americans with and without health insurance have saved $25 billion using GoodRx and 15 million consumers visit goodrx.com each month to find discounts and information related to their healthcare. GoodRx is the #1 most downloaded medical app on the iOS and Android app stores. For more information, visit www.goodrx.com.",la,de
18,Team Rubicon,Non-Profit,4,Data Engineer,"Los Angeles, CA",$101K - $130K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=8095&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4a56b410&cb=1618161634089&jobListingId=4030663724,"Team Rubicon (TR) is seeking a Data Engineer. The Data Engineer will serve disaster survivors through their passion for and understanding of data and all of the related tools, platforms, and knowledge. This will require hands-on experience designing and implementing analytical data environments, data modeling and ETL / ETL workflows, semantic layer of architecture. This Data Engineer will be responsible for creating and maintaining an optimal data pipeline architecture while assembling and analyzing large, and complex data sets.

Every day will be a challenge, but every month brings new opportunities for an organization that is quickly becoming a household name in disaster response. This position reports to TR'sSr. Manager, Technology and is a position based out of TR's National Headquarters in Los Angeles, CA.

Duties:

Data architecture and data modeling for key subject areas and business domains to generate curated business-ready data for reporting and analytics
Data integration (ETL / ELT) design and implementation
Build the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies
Implement and manage analytics tools that utilize the data pipeline to provide actionable insights
Use data to create an engaging, informative, compelling story, and provide analytic insights that inform and influence TR's strategic direction and key performance metrics
Identify, design, and implement internal process improvements around automation, optimizing data delivery, and re-designing infrastructure for greater scalability
Work with stakeholders across the - Executive, Data, Tech and Ops teams, assisting with data-related projects, and supporting technical issues and data infrastructure needs, develop data tools, as needed, to support and enhance the use of data across the organization

Experience and Background:

2 - 3 years of experience in a Data Engineer or Full-Stack Developer roles with proficiency in SQL, Python and other ETL languages
Bachelor's degree in Computer Science, Statistics, Informatics, Information - Systems or any other relevant field
Hands-on experience designing and implementing analytical data environments, data modeling and ETL / ELT workflows, semantic layer architecture and BI schema
Strong background working with Relational and Non-Relational Databases
Solid understanding of data modeling and data warehousing techniques
Demonstrated ability working with business users to define data and analytics requirements, analyze and profile data and define a solution

Job Type:

Full-time, salary, exempt

Cultural Principles:

Mission First, Greyshirt Always: Anyone joining TR must understand that our mission to provide disaster response comes first
Step into the Arena: TR needs leaders who aren't afraid to dare to be great
Everyone Has A Role Know It: Ability to successfully navigate a fast-paced, high-growth environment and solve problems in the face of ambiguity
GSD: We are entrepreneurial, resourceful and determined no matter how chaotic the situation.
Change Your Socks: We take care of ourselves and each other so we are best equipped to serve those in greatest need
Adults Only: Every team member is an adult until proven otherwise
Your Mother's A Donor: Every leader must be committed to fiduciary responsibility, transparency and financial stewardship

Perks of the Team:

Professional development, leadership development and events/conferences
100% company-paid health benefits for employees and their dependents
Matching 401k contributions up to 4%
Annual 5day National Leadership Conference
Paid time off to volunteer with the non-profit of your choice
Generous vacation and sick time
Generous holiday schedule (including a paid week off between winter holidays)
Holiday parties

Learn more about Team Rubicon:

Website: TeamRubiconUSA.org
Facebook: Facebook.com/TeamRubicon
Twitter: @TeamRubicon
",la,de
19,Pluralsight,Information Technology,3.9,Data Engineer,"Los Angeles, CA",$93K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_7179e134&cb=1618161634090&jobListingId=4058019600,"This position is also available for employment in these areas:Remote - California (Bay Area), Remote - California (Los Angeles), Remote - Illinois (Chicago), Remote - New Jersey (NYC Metro Area), Remote - New York, Remote - New York (New York City), Remote - Washington (Seattle)Job Description:Our Data Engineering & Operations team is a force multiplier for data practitioners at Pluralsight. We provide tooling and data sets to make Pluralsight a data-driven organization. Our work includes: building pipelines which curate and land data, deploying data science models, and maintaining data infrastructure. You’ll have the opportunity to work with data tools, like Python and Spark, as well as web analytics and streaming data from our data platform.Who you’re committed to being:You utilize a multidisciplinary approach to providing solutions for the business, combining technical, analytical, and domain knowledge.You have strong development skills, experience transforming and profiling dataYou understand the benefits and risks of a variety of data technology solutions, which guide your implementation decisions.You love interfacing with data scientists and analysts to understand their needs.You have an eagerness to dive in to data sources to understand availability, utility, and integrity of our dataWhat you’ll own:Building and maintaining production data pipelines for data science and analyticsDeveloping tooling and solutions for data practitioners using a deep understanding of their objectives and pain pointsModeling and curating product data sets, such as web analytics and kafka topicsImproving observability in our data environment, including uptime, usage, data quality, and data freshnessBuilding production applications from data science research and exploratory analytical workExperience you’ll need:5+ years of taking a multidisciplinary approach to data development: we emphasize picking the right tool for the jobDeep experience with a number of data tools: e.g. SQL, Spark, Hadoop, PythonManaged systems with complex dependency management and orchestration requirementsStrong capability to manipulate and analyze complex, high-volume data from a variety of sourcesEffective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward languageAbility to problem solve independently and prioritize work based on the anticipated business value#LI-Remote",la,de
20,InMarket,N/A,3.8,Data Engineer,"Los Angeles, CA",$93K - $163K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_9c7fa84c&cb=1618161634090&jobListingId=3821516045,"Job Title: Data EngineerLocation: Anywhere USAbout inMarketSince 2010, InMarket has been the leader in 360-degree consumer intelligence, real-time marketing and attribution for thousands of major brands. Through InMarket's data-driven advertising suite, brands can build targeted audiences, activate real-time, omni-channel campaigns and measure their success in driving real-world visits and sales. InMarket's proprietary Moments offering has been proven to outperform traditional mobile advertising by 5.6*.InMarket holds more than 24 patents across location, attribution and digital marketing, and it's GeoLink self-service location marketing platform was awarded Best Location Platform at the 2020 Digiday Technology Awards. It has teams in major cities and distributed across more than 20 states. For more info, visit www.InMarket.com.Google ad mobile benchmark for avg. CTR, 2019About YouYou build real products in the real world. You understand that off the shelf solutions vs building them yourself have tradeoffs and when to make the right decision. You have the ability to mentor junior engineers, and understand tradeoffs for scale, elegance of solution and time. You may have a preferred programming language but you're not afraid to tackle problems in other languages you've never used before. You love the fact that code is continuously tested and released for fast feedback. You are great at communicating and making sure decisions are made that satisfy multiple stakeholders.Job DescriptionWe are looking for a top notch experienced Data Engineer geared towards working with data to help us transform the advertising industry using the latest innovations in technology.You will design well-constructed datasets and work cross-functionally with analysts, product managers, and other engineers to effectively deliver actionable results. You will work in multiple cloud environments to help support data and insight needs across a wide range of functions and activities to help us better understand our data. The ideal candidate has a proven track record of working with large datasets.In this role you will have the opportunity to work with Redshift, BigQuery, Hadoop, Spark, EMR, Ruby, NodeJS/React, and other technologies.Requirements:Solid CS fundamentals3+ full time years experience in software development (in at least one of Python, Scala, Javascript, Java, or Ruby)Experience working with large databases, distributed systems, data structures, concurrencyExperience working with Cloud IaaS (AWS, GCP)Experience with large scale data processing (Hive, Hadoop, Redshift, BigQuery)Benefits SummaryCompetitive salary, stock options, flexible vacationMedical, dental and Flexible Spending Account (FSA)Company Matched 401(k)Unlimited PTO (Within reason)Talented co-workers and managementAgile Development Program (For continued learning/professional development)Paid Paternity & Maternity LeaveinMarket is an Equal Opportunity Employer (EOE). Qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, disability, or veteran status.",la,de
21,Centerfield,Business Services,3.7,Data Engineer,"Los Angeles, CA",$71K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=122&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_e7ce9336&cb=1618161634090&jobListingId=3717193771,"Hi, We're Centerfield.Centerfield is a cutting-edge digital marketing and sales technology company headquartered in the heart of Silicon Beach with additional offices in New York, Boston, Florida, and Jamaica. Our growing organization continues to impact the AdTech space by providing end-to-end customer acquisition services and analytics for our high-profile clients, while also successfully tailoring every step of the customer's shopping experience.How do we do this? Centerfield develops intelligent Big Data driven marketing and sales technology which drives more than two million sales each year for brands such as AT&T, Sprint, ADT, Spectrum, and CenturyLink. Our technology platform, Dugout, combined with our leading consumer guides and 1500 person sales and retention center deliver new customers at scale to top residential services, business services, and telecommunications brands worldwide.We’re always interested in expanding our team with top talent. Our creative work environment allows for innovative ideas and encourages a collaborative team culture... make sure to check out our perks below!The Opportunity...Centerfield is looking for a talented Data Engineer to join our LA team in building innovative advertising technology. We’re looking for someone who is highly motivated, web-focused, and has experience with the full data life cycle. You will help design the data collection infrastructure in support of Centerfield’s Data Architecture. You must have practical experience working with large data sets in the website lead generation & search engine marketing, SaaS, or cloud computing domains.How You'll Contribute...Help to implement maintenance strategy for all datasetsWork with relevant stakeholders to deliver appropriate BI, data warehousing, reporting, and analytical infrastructure required to support Centerfield’s assetsOwn problems from end-to-end, so that you can best collect, extract, and clean the dataWhat We're Looking For...2-4 years working in a Data Engineer, BI Engineer, or Data Warehousing Engineer roleStrong experience with any ETL tool like Talend or SSIS or Informatica, etc.Experience with Google BigQuery and Google AnalyticsAbility to lead projects individually and deliver them on timeStrong experience in performance tuning techniquesExperience with real-time streaming implementation and architectureExperience building reports and data visualization with any BI tools like Tableau, Power BI, etc.Strong foundation in SQL coding and experience with ETL processesBonus Points…BI tools like Tableau, PowerBI, or Microstrategy, etc.Experience with NoSQL databases like MongoDB, DynamoDB, Druid, etc.Amazon Web Services (S3, SQS, Redshift, DocumentDB, etc.)Experience with PythonLife at Centerfield...Competitive salary + quarterly bonusUnlimited PTO – take a break when you need it!Industry leading medical, dental, and vision plans + generous parental leave401(k) company match plan – fully vested day 1Outside patio overlooking Playa Vista + cabanas, firepits & working grillsMonthly happy hours, catered lunches + daily food trucksAward winning culture & unprecedented team spirit (featured in LA Business Journal & Built In LA)Fully stocked kitchens with snacks & drinksBreakroom supplied with games, couches, workout equipment + weekly in-office exercise classes hosted by professional instructors (yoga, kickboxing & circuit training)Free onsite gym + locker roomsPaid charity and volunteer days (local mentor programs, adopt a pet, beach cleanup, etc.)Monthly team outings (ball games, casino night, hikes, etc.)Career growth – we enjoy promoting from within!To learn more, visit us Here.Interviews will take place after resumes have been screened for minimum requirements. Please note that this position is not restricted solely to the responsibilities listed above and that the job scope and responsibilities are subject to change.For more information about our collection, use, and disclosure of your personal information in connection with our evaluating your candidacy, please visit our Privacy Policy at https://www.centerfield.com/privacy-policy/.Centerfield Media is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected under federal, state or local law.",la,de
22,Capital Group,Finance,4.3,Senior Data Engineer,"Los Angeles, CA",$74K - $141K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=210124&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_9cfca8e7&cb=1618161634090&jobListingId=3746693476,"Req ID: 37821Location: Los Angeles, CAOther location(s): Irvine (CA); Los Angeles (CA); Seattle (WA)Relocation benefits offered: YesTravel required: a. Up to 25%“I can be myself at work.”You define yourself by more than just a job title, and we want you to feel comfortable bringing your true self to work. We value your talents, your traditions and your take on the world ̶ everything that makes you unique. We’re working hard to advance diversity, equity and inclusion in our organization and our communities because we know that what makes us different makes us better.We want you to feel a strong sense of belonging. We value and welcome your experiences, ideas and identity. Over 40 employee resource groups unite our people and help to develop our collective empathy through unfiltered conversations about race, ethnicity, gender, gender identity, sexual orientation, faith, disabilities, mental health and so much more.“I can influence my income.”You want to feel recognized at work. Your performance will be reviewed annually, and your compensation will be designed to motivate and reward the value that you provide. You’ll receive a competitive salary, bonuses and benefits. Your company-funded retirement contribution will be the equivalent of 15% of your annual pay (including bonuses).“I can lead a full life.”You bring unique goals and interests to your job and your life. Whether you’re raising a family, you’re passionate about where you volunteer, or you want to explore different career paths, we’ll give you the resources that can set you up for success.Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work optionsReceive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you loveAccess on-demand professional development resources that allow you to hone existing skills and learn new onesCOVID-19 HIRING: Our recruiting and onboarding activities are virtual during the pandemic and we’ve transitioned to a work-from-home environment until further notice. We are offering generous work-from-home benefits to improve our associate’s ability to work remotely.As a Senior Data Engineer within the Investment Group Technologies organization, you will lead the design, implementation, and successful delivery of large-scale, critical and complex data architecture, storage and pipelines that improve the lives of tens of millions of people every single day. You will design, implement and automate data pipelines, sourcing data from many internal and external systems. You will build ETL processes to process large amounts of data in AWS, drive architectural plans, and implementation for future data storage, reporting, and analytic solutions. You will own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.You will design data models, operate cloud-based data warehouses, and SQL/NoSQL/temporal database systems. you will be working closely with information security teams to adopt and implement security best practices for data pipelines and data servers. You will also provide insightful code reviews, receive code reviews constructively, and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely with the team to deliver the right data for the UI through web services.Qualifications:BS in Computer Science or related field7+ yrs of experience implementing big data processing pipelines (SQL / NoSQL) technology: Hadoop, Apache Spark, AWS Glue/Athena, Airflow, Serverless etc.Coding proficiency in at least one modern programming language (Node, Python, Java, etc.).Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.Experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.).Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL, DynamoDB, RDS Aurora), SQL and DDD/ER/ORM design.Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc.Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.Your background and who you are:You have a background in data and software engineering and a passion to learn.You've made mistakes in the past and have learned a lot from them. You apply this fail-fast-forward learning regularly.You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.You believe that a team is strongest when it is diverse and includes multiple perspectives.You are able to put yourself into your customers’ shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them.You have some experience in managing dependencies and uncertainty in large, long-term multi-team programs.“I can apply in less than 4 minutes.”You’ve reviewed this job posting and you’re ready to start the candidate journey with us. Apply now to move to the next step in our recruiting process. If this role isn’t what you’re looking for, check out our other opportunities and join our talent community.“I can learn more about Capital Group.”At Capital Group, the success of the people who invest with us depends on the people in whom we invest. That’s why we offer a culture, compensation and opportunities that empower our associates to build successful and prosperous careers. Through nine decades, our goal has been to improve people’s lives through successful investing. We know that our history is a testament to the strength of the people we hire. More than 7,800 associates in 30+ offices around the world help our clients and each other grow and thrive every day. Find us on LinkedIn, Glassdoor, FairyGodBoss, DiversityJobs and Instagram.We are an equal opportunity employer, which means we comply with all federal, state and local laws that prohibit discrimination when making all decisions about employment. As equal opportunity employers, our policies prohibit unlawful discrimination on the basis of race, religion, color, national origin, ancestry, sex (including gender and gender identity), pregnancy, childbirth and related medical conditions, age, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, citizenship status, AIDS/HIV status, political activities or affiliations, military or veteran status, status as a victim of domestic violence, assault or stalking or any other characteristic protected by federal, state or local law.",la,de
23,"Bluebeam, Inc.",Information Technology,3.8,Sr. DevOps Engineer,"Pasadena, CA",$130K - $150K (Employer est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1044074&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_fec8f80f&cb=1618161634090&jobListingId=4028341786,"At Bluebeam, we empower people to promote the way the world is built. We create smart software solutions that make construction sites more efficient, connected and safe and improve the lives of design and construction professionals everywhere.You will be a full-time, onsite position based in Pasadena. Due to COVID-19, all new employees will start work remotely until we can return to the office. More information will be provided in the interview process.*About the role:Bluebeam is looking for a Senior DevOps Engineer to join our team. You'll help us better our software engineering practice. You will help develop solutions, and allow our engineering team to build our next generation of cloud native applications.What you'll do:Develop automation frameworks (Infrastructure as code, CI/CD pipelines) and tooling that will be consumed by the entire engineering organization.Support and mentor engineer teams to own their own configurations, parameters, and application secretsIdentify roadblocks and inefficiencies in the current workflow, and work with teams to plan and remediate improvements.Manage incidents and incident responses to ensure proper follow-up and mitigation.Consult with architecture in analyzing and identifying the right pieces in building our unified cloud platform. Be involved in decision-making, such as time estimation, build vs. buy.Drive project progress and communicate project status to partnersSupport legacy technologies and be a part of the solution in migrating them to cloud native solutions.What we'd like to see in you:5+ years of experience with building, deploying, administration and monitoring of SaaS applications and related infrastructure on both Windows (.NET) and Linux platforms.Experience with AWS, with emphasis on components such as autoscaling, lambda functions, Kinesis, SQS, IAM, and secrets manager.Experience with infrastructure tools like Terraform and CloudFormation.Experience scripting with languages like Python, PowerShell, bash.Experience with Kubernetes (EKS or self managed)Experience with configuration management tools such as Puppet, Chef, Ansible.Knowledge of both RDBMS and NoSQL data platforms such as like MySQL, MSSQL, MongoDB, ElasticSearch, Redis, and Elasticsearch..Experience with build systems such as Jenkins, Bamboo.Understanding of different types of git workflows and the differences between them.Experience with monitoring and APM tools such as New Relic, AppDynamics, SolarWinds,Experience with system hardening and implementing security controls.Web development experience (frontend or backend) would be a great plusPositive attitude and ability to work in a fast-paced environment.If you think you are a good match for the Bluebeam team, please send the following:Resume(Optional) Cover Letter - be creative! We wanna know why Bluebeam, why you and what makes you a great addition to the team!If you move further in the process - you will complete a take-home test exercise at a later stageWhat We Offer:People-focused, entrepreneurial start-up culture with the backing of a stable, global, corporate entity – NemetschekCompetitive compensation and benefits package (medical, dental, education reimbursement, 401k, wellness resources)Work-life balance fostered through a culture of diversity, inclusion, and appreciation of individual lifestyle needsYou will have the opportunity for continuous professional developmentAbout BluebeamThe construction industry is adopting new technology at a feverish pace. Tablets and cell phones are replacing paper blueprints, drones are surveying jobsites in 3D, and cloud collaboration is changing the way teams work together. Bluebeam plays a crucial role in this transformation. The key to our success is a customer-focused approach to product development: we work with the industry to create solutions for the industry. Today, over 2 million people throughout the world use Bluebeam. In the US, we're a critical partner for the majority of top AEC firms, and rapidly expanding our presence globally, with offices in Sweden, Germany and the UK.Come design and build your future with us.Bluebeam is proud to be an equal opportunity workplace. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, or veteran status.#LI-CT1",la,de
24,Cambridge Systematics,Transportation & Logistics,4.2,Data Engineer/Software Developer,"Los Angeles, CA",$97K - $172K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=4128&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_0faff255&cb=1618161634090&jobListingId=4001305222,"Cambridge Systematics, Inc. is shaping the future of transportation. We are industry leaders, transportation specialists dedicated to ensuring that transportation investments can deliver the best possible results. By providing innovative policy and planning solutions, objective analyses and technology applications, we help our clients anticipate and meet future transportation needs while improving the performance of existing infrastructure and operations. Above all, we are committed to our clients’ success in making transportation better for future generations.

The Modeling or Travel Demand Forecasting (TDF) business line works to research, develop, and apply innovative and practical decision support tools, including transportation models. Our practice is built on a foundation of expert skills, quality assurance, customer service, and effective teamwork. We successfully leverage a variety of planning, engineering, market research, statistical analysis, visualization, and software development and application techniques to provide insights into existing conditions and problems, forecast alternative outcomes, and explain complex traveler (and consumer) behavior mechanisms.

Our Data Analytics group is developing the next generation of location/mobility/transportation software/data products using large transportation and travel behavior datasets. We are looking for a back-end Data Engineer/Software Developer. They will be comfortable using state-of-the-art data analytics platforms such as Apache Spark and customized algorithms. The Data Engineer/Software Developer will require expertise and a strong interest in algorithms, database design and management, performance optimization, parallel processing, and computational geometry. To solve challenging problems, they should enjoy reading the relevant literature and open-source code and devising practical solutions that can be implemented at scale. The Data Engineer/Software Developer’s work will contribute to a new generation of data products in mobility analytics that address traffic congestion and transit optimization for cities large and small across the US.

Essential Duties and Responsibilities

Software/Data Engineering/Project Delivery

•Analyzes requirements to understand technical and business implications •Designs software/data engineering methods to meet today's needs, while providing for likely future needs •Experience developing production ready code and applying in the cloud • Applies (or willing to learn) supervised and unsupervised ML algorithms at scale •Integrates and deploys using automated tools and frameworks •Tests throughout lifecycle, including unit, integration, story, and acceptance tests •Ruthlessly refactors code for maintainability and to support new features •Provides clear, concise, lightweight documentation as required •Produces and delivers exceptional quality work that is thorough, polished, and reflects well on CS •Learns new tools and technologies as appropriate •Possesses the technical skill necessary to complete assignments effectively and efficiently

Research and Development

•Identifies opportunities to address client requirements through the development of innovative data engineering/software solutions •Develops a comprehensive, long term technical vision for products and platforms •Effectively communicates the capabilities, limitations, and potential value of product platforms to other CS staff •Conceives, communicates, and manages a product technical implementation agenda that informs the BD and sales process •Develops functional prototypes to illustrate the potential for new software products, platforms, and technologies •Advances the commercial viability of products and platforms through technical innovation and advanced implementation

Position Requirements

Bachelor’s degree in Computer Science, Data Analytics, Data Science or related field3-5 years of work experience as a software engineer1+ year of experience with Java, Scala, or Apache Spark

Preferred Qualifications

Master’s degree in Computer Science, Data Analytics, Data Science or related fieldPrior work experience at a transit agency or private mobility providerDegree in transportationPassion for transportation and location data


Cambridge Systematics is an equal opportunity employer. We strive to create a culture in which every voice is valued, where employees have a sense of belonging and connection with one another and to the organization, and they feel empowered to do their best work. We are committed to increasing diversity at all levels within the firm and we encourage people of all backgrounds to apply to our open positions.

If you think you have what it takes but aren’t sure you meet all the requirements of this job, we invite you to connect with us. We value all perspectives and life experiences and want to hear about yours.

EOE AA M/F/VET/DISABILITY
",la,de
25,Accenture,Business Services,4,Big Data Engineer,"Los Angeles, CA",$89K - $109K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_fd003690&cb=1618161634090&jobListingId=4054735210,"Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements, in conjunction with the way we collaborate, operate and deliver value, provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career.As part of our Data Business Group, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. Come grow your career in Technology at Accenture!You AreA Big Data engineering maestro who knows how to build modern data architectures to provide mountains of data to data analysts and scientists. Your not-s0-secret talent? Developing, maintaining, testing, and evaluating Big Data solutions to help organizations make smarter decisions. You’re familiar with the systems side of Hadoop-based technologies such as MapReduce, Hive, MongoDB, and Cassandra, and you’re a wizard in data warehousing solutions. You thrive in a team setting where you can use your formidable creative and analytical powers to annihilate problems. Communication and people skills? You have both in spades, along with strong leadership and management chops. You’re a natural at bringing out the best in teams, and working in an information systems environment makes you more than happy.The WorkWork with clients to grasp their business philosophy and IT strategy; act as a beacon of our vision that the purpose of data pipelines is to help clients make better decisions by giving them the right data at the right timeDesign, build, and implement advanced data pipelines that bring together data from a range of sources. Make sure the data is accessible to data scientists, analysts, and other users via a variety of programming languagesCarry out complex Big Data projects that collect, parse, manage, analyze, and visualize large data sets, providing insights that clients can act on across their customer-facing platformsUnderstand the challenges being addressed by an engagement and collaborate with team members and clients to deliver a technical solution that meets the unique needs of our clientsDescribe technical solutions to appropriate audiences by creating high-quality contentMentor and lead more junior team membersFor now, all Accenture business travel, international and domestic, is currently restricted to client-essential sales/delivery activity only.Please note: The safety and well-being of our people continues to be the top priority, and our decisions around travel are informed by government COVID-19 response directives, recommendations from leading health authorities and guidance from a number of infectious disease experts.Here’s What You NeedMinimum of 2 years of hands-on technical experience implementing or supporting Big Data solutions utilizing Hadoop, Hive and PythonExperience developing solutions utilizing at least two of the following:Kafka based streaming servicesR StudioCassandra , MongoDBMapReduce, Pig, HiveScala, SparkKnowledge on Jenkins, Chef, PuppetBachelor's degree or equivalent (minimum 12 years work experience). If Associate’s Degree, must have equivalent minimum 6 years work experienceBonus Points IfYou’ve got experience of full life-cycle developmentYou have experience with delivering Big Data Solutions in the cloud with AWS or AzureYou can configure and support API and Open Source integrationsYou have experience administering Hadoop or other Data Science and Analytics platforms using the technologies above [LC1]You’re no newbie when it comes to working in a DevOps environmentYou’re familiar with designing ingestion, low-latency, visualization clusters to sustain data loadsOur consulting professionals receive comprehensive training covering business acumen, technical and professional skills development. You'll also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.What We BelieveWe have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more hereEqual Employment Opportunity StatementAccenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. Our rich diversity makes us more innovative, more competitive and more creative, which helps us better serve our clients and our communities.All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.Accenture is committed to providing veteran employment opportunities to our service men and women.For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy StatementRequesting An AccommodationAccenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.Other Employment StatementsApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States. Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.Unless expressly indicated, this role is not open in the State of Colorado.",la,de
26,Siemens,Manufacturing,4.1,Big Data Software Engineer- SISW 238504,"Cypress, CA",$84K - $156K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_63b07724&cb=1618161634090&jobListingId=4000349542,"Siemens Software, a business unit of the Siemens Digital Industries, is a leading global provider of software solutions to drive the digital transformation of industry, creating new opportunities for manufacturers to realize innovation.At Siemens we are always challenging ourselves to build a better future. We need the most innovative and diverse Digital Minds to develop tomorrow’s reality. Find out more about the Digital world of Siemens here: www.siemens.com/careers/digitalmindsDo you want to build the data lake and analytics platforms that will drive our next generation marketing automation systems?Position Overview:The big data software engineer is responsible for building and contributing to our next generation data platform. This individual will be working on a development team focused on the ingestion, normalization and enrichment of marketing data as it flows into a data lake. This position will also work on piping that data to many of internal consumers and marketing automation tools. The ideal candidate will have had experience with data modeling, data access and data storage techniques from within big data ecosystems like Apache Spark.Key functions:Migrate and ingest data from many data sources including legacy platforms.Develop and implement data flows and pipelines into various consumers and 3rd party tools.Implement data normalization and transformation algorithms ensuring data consistency and searchabilityBuild large-scale batch and real-time data pipelines with data processing frameworks such as Spark on AWS infrastructureUtilize cloud-based RDBMS and NoSQL databases services such as Snowflake and RedShift.Implement unit tests and conduct code reviews with other team members to ensure code is properly designed, developed for scale and tuned for performance needs.Collaborate closely with other data engineers, engineering managers and product owners and deliver cloud-based data solutions that meet our marketing and sales objectives.Skills and abilities:Experience with a cloud-based implementation of the Apache Spark ecosystem.Experience with columnar data storage such as Parquet on Amazon S3.Experience with both RDBMS and NoSQL Data Modeling and an understanding of the differences between structured data versus unstructured data.Knowledge of agile software development lifecycles such as Scrum and Kanban.Excellent software programming skills in one of the following programming languages: Python, Java or NodeJS.Minimum qualifications:Bachelor’s degree in Computer Science or related field.2+ years’ work experience showing proficiency in at least one of the following: Python, Java, NodeJS2+ years’ work experience in big data technologies such as Spark, Hadoop, MongoDB, Redshift, or Snowflake2+ years’ work experience with AWS, Google Cloud or AzurePreferred qualifications:3+ years’ work experience in building/maintaining data lake using Apache Spark or similar3+ years’ work experience writing Spark processing jobs using Python, Java or similar language2+ years’ work experience with ASWS RedShift or Snowflake2+ years’ experience with NoSQL database implementations (MongoDB, Cassandra)2+ years’ experience working in an Agile development environment2+ years’ experience with UNIX/Linux including basic commands and shell scripting#LI-PLM #LI-AA1Organization: Digital IndustriesCompany: Siemens Industry Software Inc.Experience Level: Experienced ProfessionalJob Type: Full-timeEqual Employment Opportunity StatementSiemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.EEO is the LawApplicants and employees are protected under Federal law from discrimination. To learn more, Click here.Pay Transparency Non-Discrimination ProvisionSiemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.California Privacy NoticeCalifornia residents have the right to receive additional notices about their personal information. To learn more, click here.",la,de
27,Beautycounter,Consumer Services,3.8,Business Intelligence Engineer,"Santa Monica, CA",$94K - $156K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_e533ded6&cb=1618161634091&jobListingId=4056732234,"One by one, we are leading a movement to a future where all beauty is clean beauty. We are powered by people, and our collective mission is to get safer products into the hands of everyone. Formulate, advocate & educate-that's our motto for creating products that truly perform while holding ourselves to unparalleled standards of safety.Why? It's really this simple: beauty should be good for you.We are looking for a fantastic Data/BI Engineer I who can help support the businesses needs for analytics and data. The ideal candidate has a great background of working with data warehouses, data flows, Data Modelling and working hand-in-hand with analysts from the business to meet their data needs.We are looking for someone that is passionate about the data and patient when dealing with data issues.In this role you will:Work hand-in-hand with Analysts and Data Stewards to help solve their data needsWork with Data Engineers to maintain high level of Data Quality through validations and business requirementsDevelop Views and Models in our Reporting tool (Looker), enabling the generation of comprehensive dashboards and reports for Business consumptionSupport the development and maintenance of our new Data Datawarehouse in SnowflakeWork with our Data Lake in Google Cloud Storage (GCS)Maintain the company’s legacy SQL Server 2017 analytical DataMartWrite System Requirement documentation (SRD) and work with Project Manager to create Business Requirement Documents (BRD)Assist with delivering the company’s Data Management Program as guided by DAMAWe are looking for someone who has:Experience with Building Models in BI tools, preferably LookerExperience with SQL Server Integration Services, SQL Server AgentExperience with Relational and Dimensional modeling specifically using Kimball Methodology for Star SchemaAdvance SQL programming is a mustExperience with Snowflake and Big QueryGreat communication and prioritization skills in order to work with the business and understand their needsExperience with Data Governance Principles and TechniquesExperience with delivering quality under high pressureWho we are:Beautycounter is a disruptive beauty brand that creates and sells safer, high-performing skin care and color cosmetic products. Our mission is to get safer products into the hands of everyone. We work toward this mission by creating best-in-class products with ingredients that have passed our rigorous ingredient selection process. We also work on market and policy initiatives to raise the bar of safety for the entire cosmetics industry. We pride ourselves on our commitment to transparency.At Beautycounter we are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.#LI-TJ1",la,de
28,Siemens,Manufacturing,4.1,Big Data Software Engineer- SISW,"Cypress, CA",$94K - $175K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=37049&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_a69514a1&cb=1618161634091&jobListingId=3823429388,"Siemens

Software, a business unit of the Siemens Digital Industries, is a leading

global provider of software solutions to drive the digital transformation of

industry, creating new opportunities for manufacturers to realize

innovation.

At Siemens we

are always challenging ourselves to build a better future. We need the most innovative and diverse

Digital Minds to develop tomorrows reality. 

Find out more about the Digital world of Siemens here: www.siemens.com/careers/digitalminds

Do you want

to build the data lake and analytics platforms that will drive our next

generation marketing automation systems?

Position

Overview:

The big data

software engineer is responsible for building and contributing to our next

generation data platform. This individual will be working on a development team

focused on the ingestion, normalization and enrichment of marketing data as it

flows into a data lake. This position

will also work on piping that data to many of internal consumers and marketing

automation tools. The ideal candidate will have had experience with data

modeling, data access and data storage techniques from within big data ecosystems

like Apache Spark.

Key

functions:

Migrate

and ingest data from many data sources including legacy platforms. Develop

and implement data flows and pipelines into various consumers and 3rd party

tools. Implement

data normalization and transformation algorithms ensuring data consistency and

searchability Build

large-scale batch and real-time data pipelines with data processing frameworks

such as Spark on AWS infrastructure Utilize

cloud-based RDBMS and NoSQL databases services such as Snowflake and RedShift. Implement

unit tests and conduct code reviews with other team members to ensure code is

properly designed, developed for scale and tuned for performance needs. Collaborate

closely with other data engineers, engineering managers and product owners and

deliver cloud-based data solutions that meet our marketing and sales

objectives.

Skills and

abilities:

Experience

with a cloud-based implementation of the Apache Spark ecosystem. Experience

with columnar data storage such as Parquet on Amazon S3. Experience

with both RDBMS and NoSQL Data Modeling and an understanding of the differences

between structured data versus unstructured data. Knowledge

of agile software development lifecycles such as Scrum and Kanban. Excellent

software programming skills in one of the following programming languages:

Python, Java or NodeJS.

Minimum

qualifications:

Bachelors

degree in Computer Science or related field. 2+

years work experience showing proficiency in at least one of the

following: Python, Java, NodeJS 2+

years work experience in big data technologies such as Spark, Hadoop, MongoDB,

Redshift, or Snowflake 2+

years work experience with AWS, Google Cloud or Azure

Preferred

qualifications:

3+

years work experience in building/maintaining data lake using Apache Spark or

similar 3+

years work experience writing Spark processing jobs using Python, Java or

similar language 2+

years work experience with ASWS RedShift or Snowflake 2+

years experience with NoSQL database implementations (MongoDB, Cassandra) 2+

years experience working in an Agile development environment 2+

years experience with UNIX/Linux including basic commands and shell scripting

#LI-PLM #LI-AA1
Organization: Digital Industries

Company: Siemens Industry Software Inc.

Experience Level: Experienced Professional

Job Type: Full-time

Equal Employment Opportunity Statement

Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law

Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision

Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice

California residents have the right to receive additional notices about their personal information. To learn more, click here.",la,de
29,Dignity Health,Health Care,3.9,Data Engineer Healthcare,"Glendale, CA",$97K - $128K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1020558&s=58&guid=00000178c1f3088da0f5787c46c3b3b8&src=GD_JOB_AD&t=SR&vt=w&cs=1_99309565&cb=1618161634091&jobListingId=4056803740,"Who We Are CommonSpirit Health was created in early 2019 when Catholic Health Initiatives and Dignity Health came together as one ministry. Drawing on our combined resources, CommonSpirit is dedicated to building healthy communities, advocating for the poor and vulnerable, and innovating how and where healing can happen—both inside our hospitals and out in the community. We are doing this through the dedicated work of thousands of physicians, advanced practice clinicians, nurses, and staff; through clinical excellence delivered across a system of hospitals and other care centers covering 21 states and accessible to nearly one in four Americans; and through more than $4 billion annually in charity care, community benefits, and government program services. The CommonSpirit name was inspired by scripture: ""Now to each one the manifestation of the Spirit is given for the common good."" Those words motivate and guide us every day. They celebrate the healing gift of compassion that God gives to us all, and they remind us of our calling to serve the common good. Learn more at commonspirit.org. What You'll Do The Data Engineer I develops data models and maintains foundational data architecture supporting Payer Strategy & Relationships (PSR) initiatives. This role manages information using relational databases, database management systems and tools. The Data Engineer I acts as a liaison between super users, data architects, programmers, and analysts to implement and enforce data integrity standards and procedures to ensure data is managed consistently and appropriately integrated within data marts and databases. Additionally, the Data Engineer I manipulates and integrates data from various sources to enlarge and enhance the data repository and is responsible for coding/engineering and documenting procedures, programming, testing and debugging.  Make the biggest impact by meeting these requirements:Bachelor of Science in Computer Science or related technical field. Education and experience may be considered in lieu of degree.Work experience with Microsoft development tools and technologies including: SQL Server 2008 R2/2012/2014/2016Strong SSIS/T-SQL troubleshooting and debugging skills.Proven experience developing scripts to automate routine and repetitive database SQL tasks using standard integration processes. Develop stored procedures, triggers, functions and views to support PSR initiatives. Develop SQL queries in the creation of business applications and SQL reports from corporate data sources.Provide production support as required to ensure the availability and performance of developed applications for both external and internal users.Proven ETL development and data integration between multiple data source systems.Detailed analytic problem-solving skills, documentation, communication and flexibility with strong attention to detail in high pressure situations. Benefits Include: Benefits include Medical, Dental, Vision, Paid Time Off, Holidays, Retirement Program, Disability Plans, Tuition Reimbursement, Employee Assistance Program (EAP), Discount Programs, Life Insurance Plans, Voluntary Benefits. ~LI-DHSQL Developer, healthcare, Managed Care, database developer, payer contract modeling, application developer, software developer, software engineer, reverse engineering, application engineer, VBARequired EducationBachelor of Science in Computer Science or related technical field. Education and experience may be considered in lieu of degree.Required ExperienceMinimum of three (3) years of Information Technology (IT) experience in a fast-paced, complex business environment.Work experience with relational database management systems (RDBMS) such as SQL Server, Oracle, DB2, MySQL, PostgreSQL.Work experience developing SQL queries in the creation of business applications and SQL reports from corporate data sources.Preferred Qualifications:Work experience with Python, JavaScript, C# or R strongly preferredExperience in payer contract analysis and payer process preferredExperience with healthcare claims and remit data preferredExperience in medical and billing data preferredWorking knowledge of Power BI, Tableau, and SAS preferred ",la,de
0,Compunnel Inc.,Information Technology,3.7,Big Data Engineer,"San Francisco, CA",$78K - $146K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044076&s=149&guid=00000178c1fe7611be5165ff56eb3fe5&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_2665cc60&cb=1618162382978&jobListingId=4053980852,"Primary Manager: Lavakumar Baskaran Job Title: Big Data Engineer Location: Remote is ok during this pandemic situation. Preferred SF Bay area candidate. We will add more locations as required. Duration: 12-18 months The Federal Reserve Bank of San Francisco is looking for a Big Data Engineer to join the Advanced Data and Analytics Capabilities Team. We are a team based out of San Francisco that partners with business lines across the Federal Reserve System to deliver big data and advanced analytics products and solutions. In this role, you will have the opportunity to contribute to several high-quality data solutions and enhance your technical skills across many disciplines. Key Responsibilities * Design, develop, and maintain end to end data solutions using open source, modern data lake, and enterprise data warehouse technologies (Hadoop, Spark, Cloud, etc.) * Contribute to multiple data solutions throughout their entire lifecycle (conception to launch) * Partner with business stakeholders to understand and meet their data requirements * Design, build, and maintain machine learning data pipelines * Maintain security in accordance with Bank security policies * Participate in an Agile development environment Cloud/AWS is a nice to haveThis person: Java is importantCloudera detailed hands-on experienceBig Data platform components hands-on experienceNo machine learning exp needed, AWS experience is good to have but don't give devops engineers who setup cloudera in AWS.Fine with senior engineers, but they need to be hands-on.Python is good to have - they need java right now.Agile env – use JIRA to track workAM8890Q98Job Types: Full-time, ContractSchedule:8 hour shiftExperience:AWS: 1 year (Required)Cloudera: 1 year (Required)BigData: 1 year (Required)Java: 1 year (Required)COVID-19 Precaution(s):Remote interview processPersonal protective equipment provided or requiredPlastic shield at work stationsTemperature screeningsSocial distancing guidelines in placeVirtual meetingsSanitizing, disinfecting, or cleaning procedures in place",sf,de
1,TargetCW,Business Services,4.3,Software/Data Engineer (W2),"San Francisco, CA",$51K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044072&s=149&guid=00000178c1fe7611be5165ff56eb3fe5&src=GD_JOB_AD&t=SRFJ&vt=w&ea=1&cs=1_bbc2e7b5&cb=1618162382979&jobListingId=4027584336,"Overview:Software/Data Engineer (W2 ONLY)Full TimeSan Francisco, CA (remote for now)$150-200/hr DOE18 Month DurationW2 ONLY, NO VISA SPONSORSHIPWe are the world's leading live streaming platform for gamers and the things we love. We make it possible to watch, play and chat with millions of other fans from around the world. We are looking for a Software/Data Engineer to join our team ASAP!Our Ad Prod team is looking to hire an experienced data engineer. This position is focused on empowering staff throughout our organization to use and trust our advertisement data for financial reports. Your responsibilities may range from maintaining and enhancing our data warehouse which acts as sources of truth across the company, driving data quality across product departments and teams, building self-service business intelligence infrastructure for reporting, and connecting into data interfaces that allow finance and other functions to discover and analyze the data. In the process, you will work with technical and non-technical staff members throughout the company.You Will:Keep existing data sources fresh against data quality issues, design, develop and maintain data quality assurance framework and improve the processes for developing new ones raising the level of quality expected from our work.Conduct unit, integration, and system tests on our data sources to validate data against source systems, and optimize performance to improve query speed and reduce cost.Design, build and maintain a set of trusted data assets for a product or a group of products.Act as our team’s thought leader for defining data telemetry, storage and ETL processes.Partner with Analytics, Product and Engineering teams to understand data needs.Write software code and data solutions that are high quality and comprehensible.Have rigor around data architecture best practices:Balance customer requirements with technology requirements.Be proficient in a broad range of data design approaches.Be judicious about introducing dependencies.Create flexible data solutions without over-engineering.Understand how to be efficient with resource usage (e.g., system hardware, data storage, query optimization, AWS infrastructure etc.)Have knowledge of engineering and operational excellence best practices. Be able to make enhancements that improve data processes (e.g., data auditing solutions, management of manually maintained tables, automating, ad-hoc or manual operation steps).You Have:5+ years of experience in data engineering, software engineering, or other related roles.Preferably in the consumer internet or gaming space, or working with a high-velocity, high-growth product / business.3+ years in relational database concepts with a solid knowledge of star schema, SQL, SQL Tuning, OLAP, Big Data technologies3+ years of experience maintaining data pipelines from multiple data sources, in collaboration with diverse partners.Experience with best practices for development including query optimization, version control, code reviews, and documentation.Proficient in SQL - comfortable working with complex joins, window functions and writing SQL for aggregations.Experience working with Amazon Webservices, S3, EMR, Redshift etc.Experience in coding languages like Python/Java/ScalaExperience building aggregates, optimizing data workstreams and maintaining data pipelinesComfort working independently, prioritizing projects, and managing stakeholder expectations across teams.Strong written and verbal communication skills.Obsessed with data quality and a strong belief in test driven developmentExperience in SAP integration is a big plusPLEASE SUBMIT YOUR RESUME TO BE CONSIDERED!#4",sf,de
2,Blizzard Entertainment,Media,3.5,Staff Data Engineer - Activision Blizzard Media,"Foster City, CA",$107K - $127K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=101&ao=1044074&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_9f094be6&cb=1618162382979&jobListingId=4057712325,"Team Name:Job Title:Staff Data Engineer - Activision Blizzard MediaRequisition ID:15463Job Description:Activision Blizzard Media is the gateway for brands to the #1 cross-platform gaming company in the western world, with hundreds of millions of players across over 190 countries.Our legendary portfolio includes iconic mobile game franchises such as Candy Crush™, esports opportunities like the Call of Duty® and Overwatch® Leagues, and some of the top PC and console gaming franchises such as World of Warcraft®, Call of Duty®, and StarCraft®.The idea is simple: great game experiences offer great marketing experiences.If you want to create amazing user experiences using the latest technologies, then this is the right job for you. You're an excellent communicator, happy to work with people from several different business units. You can translate business needs into technical requirements and implementation. We are problem solvers, constantly reviewing how and why we do things and learning from each other. We are experimental, trying out new tech and ideas and willing to take risks to drive the entire industry forward. We are sociable and fun, and we like to hang out together. We are passionate, some might even say quirky, and while we love what we do, our lives are about more than work. We love games, and are obsessed with creating the best player experience.ResponsibilitiesPartner with senior engineers, architects and product owners to build scalable data pipeline and services.Work with the product team to understand the business requirements and translate them into the development/design tasks.Be a role model in engineering best practices and design/coding standard.Choose the right technology stack to align with the use cases and scalability.Collaborate with the other team members across different teams.Provide technical directions and mentor other engineers.Game Changer - What You Bring To The RoleBA/BS degree in Computer Science, similar technical field of study or equivalent practical experience.7+ years of hands-on experience in software design and development.Advance level expertise in Java Development.2+ years of experience in working with relational databases such as MySQL, Postgres etc.2+ years of experience in NoSQL databases like Bigtable, Cassandra, HBase etc.Experience with schema design and data modeling.Strong understanding of large-scale distributed data processing.Experience with developing extract-transform-load (ETL).Experience with distributed messaging systems like Kafka and RabbitMQExperience with distributed computing framework like Apache Spark and Flink.Bonus PointsExperience working with AWS or Google Cloud Platform (GCP)Understanding of machine learning concepts and some experience in working with machine Learning libraries.Experience in building data warehouse and data lake.Knowledge of advertising platform.",sf,de
3,Verizon,Telecommunications,4,Data Platform Engineer - Internet Of Things,"Walnut Creek, CA",$69K - $116K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=102&ao=1044074&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_010d7c87&cb=1618162382979&jobListingId=4055393845,"When you join VerizonVerizon is a leading provider of technology, communications, information and entertainment products, transforming the way we connect across the globe. We’re a diverse network of people driven by our ambition and united in our shared purpose to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward – and you can too. Dream it. Build it. Do it here.What you’ll be doing...You will be a senior member of the Verizon IoT solutions and platform development team, focusing on design-driven development and front-end delivery. As a data solution design engineer, you will be responsible for the design and implementation of a highly scalable IOT developer platform and applications whose core tenants include an independent UI layer integrated viaAPI with telemetry infrastructure using messaging queues (MQTT/Rabbit/Other lightweight M2M), data ingestion and streaming platforms like Kafka/Kinesis and horizontally scalable micro services that use a variety of data persistence(NoSql, Relational, In-memory).All team members play a vital role in delivering high value and high quality solutions that meet business objectives, and delivering end-to-end performance and scale of complex video based analytic applications that can support millions of IoT devices in the field.The position is part of an agile, cross-functional team that delivers value to the business with high frequency. A continuous delivery / continuous integration (CICD) approach is followed to ensure tight integration and early detection of issues for quick delivery cycle-time.Design and develop well-architected and scalable end to end applications and development platformtouch points for video analytics based applications and IoT telemetry for various verticals like Smart Cities, Industrial IoT, Utilities, and 5G/MEC.Understand thetarget domain personas and the user experience requirements. Design user experiences that are highly scalable and targeted for cloud deployment/Software-as-a-Service (SaaS) model. Ensure applications meet the objectives of the business.Contribute to analysis and design of low latency Microservices APIs that will be consumed by a Cloud IOT platform as well as external developers/third party vendors.Design, review, and optimize data ingestion and transformation processes in streaming, relational databases, and/or NoSQL in cloud environments, to deliver the value of the data to customers.Conduct iterative application tuning and performance baselining.Participate in Agile development, daily scrum, and sprints.Develop high level and detail level designs with cross functional input. Work closely with product managers and other external stakeholders to ensure that the final solution will meet business objectives.Develop features with quality and integrated with continuous integration and delivery infrastructure.Implement and champion best practices in solution design and delivery to optimize business investments.What we’re looking for...Bachelors in Computer Science or 10+ years relevant work experience.6+ years in IOT and/or Computer Vision domain.Experience designing and developing complex-domain applications and highly scalable ingestion and data processing applications.Even better if you have:Strong foundation in Scala/CSS/Java /JS/Go/HTML and other programming languages. Familiar with industry best practices and design patterns.Experience with designing and using horizontally scalable UI layer component systems in Typescript/React16+/JS/ESlint/API/micro services architecture.Hands-on experience of Kafka/Kinesis/Spark streaming platform to build API’s utilizing real-time data pipelines.Hands-on experience on database management system and Query language.Experience with Messaging Systems and protocols (MQTT/CoAP/RabbitMQ).Debugging and monitoring experience of cloud application using Graphite/Grafana, ELK, Google Prometheus, Datadog.Ability to work within an agile, scrum-based team that utilizes Continuous Integration/Continuous Delivery processes.Equal Employment OpportunityWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best.Check out our diversity and inclusion page to learn more.",sf,de
4,Nuna,Information Technology,4,Data Engineer - Integrations,"San Francisco, CA",$126K - $223K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=103&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ac85e315&cb=1618162382980&jobListingId=3771697443,"At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass.

Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.

Nuna partners with healthcare payers, including government agencies, health plans, and employers, to turn data into learnings and information into meaning.YOUR TEAMData Engineering is at the core of Nuna's promise to deliver exceptional and actionable data insights to our clients. We are responsible for the scalable comprehension, ingestion, cleaning, and deploying of client data on schedule - think of us as the heart muscle that pumps data throughout Nuna. And because quality and consistency are our hallmarks, we're more than a little obsessed with detail and process.YOUR IMPACTData Engineering is a cross-functional team that supports Nuna's Enterprise Product Suite. We untangle messy and complex healthcare data and enable our Data Science and Analytics teams to perform and deliver exceptional analytics to our clients.YOUR OPPORTUNITIES

Map, extract, transform and load data from source to target through multiple stages
Perform data quality assessment, measurement, and reporting
Collaborate with product managers, data scientists, data analysts and engineers to define user requirements and database design specifications for our clients' needs.
Analyze data feed requirements received from vendors, translate business requirements into technical design specifications.
Build out new API and functionality for data ingress/egress with our customers systems.
Use your knowledge of SQL to perform data analysis based on business requirements and data profiling reports.
Maintain and ensure monthly data updates are delivered on-time to our customers
Serve as a technical resource in resolving client issues related to database or other data issues
Work closely with client-facing teams
Work directly with clients and lead client calls when needed
Construction and automation of data pipelines

YOU BRING

Ability to use SQL for developing robust and scalable ETL pipelines.
Experience working with Python for API integrations and pipeline automation.
Experience working with data, preferably healthcare data, and databases.
Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement.
Ability to construct and debug complex SQL queries.
Ability to operate with cross-functional teams (e.g., implementation managers, data science, engineers, etc.).
Strong communication and teamwork skills.

BONUSES

Healthcare experience is preferred.
Demonstrated track record working with data warehouse and ETL architectures and concepts plus.
Experience with cloud infrastructure (AWS, Azure, GCP) is preferred.
BA/BS in statistics, math, data science, or computer science preferred.

Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.",sf,de
5,Penumbra US,Health Care,3.7,Biomedical Data Engineer / Researcher / Analyst,"Alameda, CA",$55K - $108K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_7e05f3f0&cb=1618162382981&jobListingId=3795097838,"As the Biomedical Data Engineer / Researcher / Analyst, you will perform data collection studies following good research practices for algorithm development, as well as prepare, clean, and analyze study data, presenting findings to key team members and departments. This role requires experience working with complex datasets, time syncing multisensory data, and reporting systems for analytics. In addition, this role requires a deep technical and scientific understanding collaborating with clinical experts and internal teams to provide clinical insights and business intelligence.What You'll Work OnYou'll prioritize work in the following areas:Data CollectionPerform literature reviews and work with clinical experts to identify gold standard clinical devices and technically evaluate ground truth devicesDesign and develop data collection plans and protocols with clinical expertsExecute data collection studies following standard research guidelines and proceduresDevelop data collection tools to pull, sync and organize data from ground truth devices and the REAL SystemCoordinate and manage multiple data collection projects simultaneouslyData PreparationClean, label, sync and prepare data from multiple sources for algorithm developmentIntegrate structured and unstructured data into existing infrastructure and test data integrity and qualityData Analytics and PresentationResearch clinical data presentation and gold standard requirementsInterpret and analyze data (using statistical techniques, identifying patterns and trends, etc.) with analytics, clinical affairs, and business teamsPresent findings through white papers, publications, etc., translate findings into actionable results for engineering teams and integrate into product and SDK deliverables where applicableWhat You BringBachelor’s degree in STEM field or equivalent work experience in related fieldStrong programming skills in at least one of the following: Python, SQL, JavaProficient in at least one statistical analysis tool such as MATLAB, R, SAS, STATA, SPSSExperience with experimental designs and writing protocolsExperience working with large datasetsExperience with collection and analysis of human data (e.g. wearable sensors, motion capture, medical devices, etc.) preferredExperience with processing time series data from multimodal inputs and sensors preferredUnderstanding of clinical science preferredUnderstanding of basic data structures and algorithms preferredFamiliarity with data modeling and machine learning preferredExperience with data quality review, pre-processing and algorithm development preferredExperience with cloud-based services such as Microsoft Azure, Kubernetes, Docker, Node.js., React, PostgreSQL, GraphQL preferredExperience with game engine pipelines and technology stacks, including Unreal and Unity preferredWhat We OfferA collaborative teamwork environment where learning and growth are constantThe opportunity to be at the forefront of technology that is revolutionizing the treatment of some of the world's most devastating diseasesA generous benefits package that includes medical, dental, vision, and life insurance; a 401(k) match; and an Employee Stock Purchase PlanPenumbra, Inc., headquartered in Alameda, California, is a global healthcare company focused on innovative therapies. Penumbra designs, develops, manufactures and markets novel products and has a broad portfolio that addresses challenging medical conditions in markets with significant unmet need. Penumbra sells its products to hospitals and healthcare providers primarily through its direct sales organization in the United States, most of Europe, Canada and Australia, and through distributors in select international markets. The Penumbra logo is a trademark of Penumbra, Inc.Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status.If you reside in the State of California, please also refer to Penumbra’s Privacy Notice for California Residents.",sf,de
6,Emerson,Manufacturing,3.7,Senior Industrial Engineer,"Berkeley, CA",$78K - $98K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=105&ao=1044074&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_c7f02531&cb=1618162382981&jobListingId=4058101570,"If you are a Senior Industrial Engineer professional looking for an opportunity to grow, Emerson has an exciting opportunity for you! You will work at our Emerson Real-Time Modeling System (RTMS) / Bio-G division, which specializes in process simulation and finite scheduling.AS A SENIOR INDUSTRIAL ENGINEER, YOU WILL:Lead RTMS projectsPresent results and have the ability to make recommendations for our clientsAbility to guide clients to successful implementations and set customer expectationsUsing discrete event simulation to model complex processes (modelling experience required)Debottlenecking and capacity engineering of manufacturing systemsCreation of statistical models for use in process engineering, supply chain, etc.Managemement of corporate data sources such as SAP, Oracle, DeltaV, OSISoft PI, Maximo, etc. and integrating these sources into softwareSupporting the software and working with clientsGood communication skills to implement client changes into the modelsDeveloping algorithms for design of experiment, display of data, optimization and efficiency methodsAbility to work on a timeline with deliverables with a project teamAssisting in debugging the software and developing product features and enhancementsWHO YOU ARE:You anticipate customer needs and provide services that are beyond customer expectations. You readily distinguish between what is relevant and what is unimportant to make sense of complex situations. You achieve and are consistently known as a top performer. You view talent development as an organizational imperative.REQUIRED EDUCATION, EXPERIENCE & SKILLS:A Bachelor's degree in Industrial Engineering or Computer Science5+ years of relevant experienceUsing discrete event simulation to model complex processses; modelling experience requiredCreation of statistical models for use in process engineering, supply chain, etc.VBA programming skills, Excel, SQL and databasesGood communication skills PREFERRED EDUCATION, EXPERIENCE & SKILLS:A background in biotech or pharma is a plusWHY EMERSON?Our Commitment to Our PeopleWe invest in our employees to ensure they have the marketplace knowledge, skills and competencies to compete and lead in a global economy. Our training programs focus on end-to-end development from onboarding through senior leadership.Flexible and competitive benefits plans offer you the right options to meet your individual/family needs: medical insurance plans, dental and vision coverage, 401(k), tuition reimbursement, and more. We provide employees flexible time off plans including paid parental leave (maternal and paternal), vacation and holiday leave.Our success is measured by the positive impact we make on people, our communities and the world in which we live. Learn more about us!.Our Commitment to Diversity & InclusionAt Emerson, we are committed to fostering a culture where every employee is valued and respected for their experiences and perspectives. We believe a diverse and inclusive work environment contributes to the rich exchange of ideas that inspires innovation and brings the best solutions to our customers. This philosophy is fundamental to living our company’s values and our responsibility to leave the world in a better place.Diversity and Inclusion at Emerson is about welcoming, respecting, and valuing the differences each employee possesses. Inclusion is creating a real sense of engagement, belonging and connection for all employees. Learn more about our Culture & Values and about Diversity & Inclusion at Emerson.Work AuthorizationEmerson will only employ those who are legally authorized to work in the United States. This is not a position for which sponsorship will be provided. Individuals with temporary visas such as E, F-1, H-1, H-2, L, B, J, or TN or who need sponsorship for work authorization now or in the future, are not eligible for hire.Equal Opportunity EmployerEmerson is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, race, color, religion, national origin, age, marital status, political affiliation, sexual orientation, gender identity, genetic information, disability or protected veteran status. We are committed to providing a workplace free of any discrimination or harassment.If you have a disability and are having difficulty accessing or using this website to apply for a position, you can request help by sending an email to idisability.administrator@emerson.com.",sf,de
7,Capital One - US,Finance,4.1,Data Engineer,"San Francisco, CA",$95K - $167K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=106&ao=133055&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_60709193&cb=1618162382982&jobListingId=4030719348,"201 Third Street (61049), United States of America, San Francisco, CaliforniaData EngineerDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.We are seeking Data Engineers who will be a part of a team that’s building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.What You’ll Do:Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologiesWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systemsUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as SnowflakeShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering communityCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowermentPerform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performanceBasic Qualifications:Bachelor’s DegreeAt least 2 years of experience in application developmentAt least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)Preferred Qualifications:Master's Degree3+ years of experience in application development1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)1+ years of experience with Ansible / Terraform2+ years of experience with Agile engineering practices2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)2+ years of experience with NoSQL implementation (Mongo, Cassandra)2+ years of experience developing Java based software solutions2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)2+ years of experience developing software solutions to solve complex business problems2+ years of experience with UNIX/Linux including basic commands and shell scriptingAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.",sf,de
8,Cricut,Retail,4.2,Data Engineer,"San Francisco, CA",$79K - $91K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=107&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_f51bc42a&cb=1618162382983&jobListingId=4058257648,"Company DescriptionTogether we make. Come make with us.OverviewAt Cricut®, we believe that we’re all born makers. When we built our first cutting machine, we saw the potential for a simple yet powerful tool to completely transform the way people craft, design, and DIY. Since then, we continue to innovate with new machines, platforms, materials, and tools, but that’s just what we do. Who we are is a bustling worldwide community, a means for connection, and an outlet for unbridled creativity. Join us as we place the power of handmade into the hands of ALL.LifeLove your work. And your coworkers.Our company is made up of A+ human beings. We ask tough questions, entertain ideas outside of our own, and work together to make something bigger than ourselves. With Cricut® growing in China, the U.K., Australia, New Zealand, as well as Europe and South America, we’re on an unstoppable roll, satisfying that innate creative itch around the world. We train, develop, and celebrate great work with hallway high fives and promotions within. We also throw the world’s best Halloween party.Enjoy incredible perks.We take care of our team. We offer medical, dental, vision, and retirement benefits, as well as pet insurance, 401K match, life insurance, incentive programs, paid time off, on-site massages, phenomenal work-life balance, and employee discounts.Like what you see? We can’t wait to meet you!Job DescriptionCricut® is looking for a Data Engineer to join our Data Platform team supporting the future of AI/ML. The ideal candidate will design, build, and integrate data from various resources, and manage big data pipelines that are easily accessible with optimized performance of Cricut®'s big data ecosystem.The ideal candidate is an experienced data wrangler who will support our software developers, database architects and data analysts on business initiatives. You must be self-directed and comfortable supporting the data needs of cross-functional teams, systems and technical solutions.QualificationsCS or CE degree or commensurate experience requiredMS SQL Server, MySQL (Aurora), MSSQL, REST API, etc.Strong understanding of scalability, performance, and reliabilityExperience with OOP frameworks, languages, design patterns, concepts and data sources such as C#/.NET, Java, Python, Kafka, SparkAbility to work on multiple areas including data pipeline ETL, data modeling & design, writing complex SQL queries, etc.Preferred Skills:Hands-on expertise in one or more Amazon Web Services (AWS) technologies, such as Kinesis, S3, Redshift, Athena, LambdaExperience in Kanban methodologiesExperience in Test Driven Development and CI/CD.Demonstrated ability to develop and support large-sized international-scale software systemsExperience in expanding and optimizing data pipeline architectureOptimize data flow and data collection for cross functional teamsAdditional InformationWhat to Do Next:Please attach your resume including links to your portfolio where applicable. If you want to show your super powers in other ways – include that information too. You can be sure that Cricut® is an employer who values individuality, equality and diversity, so tell us what you’re all about. If you are a Maker or a DIY enthusiast, whether you think you are a good one or not, we would love to hear about it when you send us your information!At Cricut®, we celebrate inclusion and diversity. Cricut is an equal opportunity employer and makes employment decisions based on merit. Cricut prohibits discrimination based on race, color, religion, sex, sexual identity, gender identity, marital status, veteran status, nationality, citizenship, age, disability, medical condition, pregnancy, or any other unlawful consideration. All your information will be kept confidential according to EEO guidelines. Cricut participates in E-Verify.",sf,de
9,Twitch,Information Technology,3.9,Data Engineer,"San Francisco, CA",$148K - $185K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=108&ao=133043&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_bad160ed&cb=1618162382983&jobListingId=4058192054,"About UsLaunched in 2011, Twitch is a global community that comes together each day to create multiplayer entertainment: unique, live, unpredictable experiences created by the interactions of millions. We bring the joy of co-op to everything, from casual gaming to world-class esports to anime marathons, music, and art streams. Twitch also hosts TwitchCon, where we bring everyone together to celebrate, learn, and grow their personal interests and passions. We're always live at Twitch. Stay up to date on all things Twitch on LinkedIn, Twitter and on our Blog.About the RoleData is central to Twitch's decision-making process, and data engineers operate at the forefront of this by creating datasets that drive decisions across all of Twitch. You will shape the way that performance is measured, establish how we transform our data, and scale analytics methods and tools to support our growing business, leading the way for high-quality, high velocity decisions.We're looking for an experienced data engineer to join our Monetization Business and BI team, which is focused on making trusted, reusable data assets for data analysts, data scientists, and applied scientists in Ads, Commerce, and throughout Twitch to use. Your responsibilities will include developing and enhancing our data warehouse and datamarts which act as sources of truth across the company, working with data producers to ensure data coverage partnering with other data tool creators driving data quality, and connecting into data interfaces that allow everyone at Twitch to use the data. In the process, you will work with technical and non-technical staff members throughout Twitch.You Will:Delight data consumers throughout Twitch by ensuring they have the data they need to inform decisions, where and when they need it.Define and own organization-level data architecture for a trusted, governed, dimensionally-modeled repository of data that enables Twitch staff to quickly and reliably answer their questions.Prioritize projects from a diverse set of partnersProtect data sources against data quality issues: work with data producers to ensure data passes acceptance tests; design, develop and maintain data quality monitoring and assurance framework; and continuously improve the processes for developing new ones, raising the level of quality expected from our work.Improve data discovery: create data exploration processes and promote adoption of data sources across the company.Optimize business, engineering, and data processes via data architecture, engineering, testing, and operational excellence best practices.You Have:3+ years of experience in data engineering, software engineering, or other related roles3+ years using relational database concepts with a working knowledge of SQL, SQL Tuning, data modeling best principles, OLAP, Big Data technologies3+ years of experience generating data pipelines from multiple data sources, in collaboration with diverse team membersExperience with development best practices, including query optimization, version control, code reviews, and documentationExperience with Amazon Web Services: Redshift, S3, Glue, EMR, or AthenaExperience with PythonPerksMedical, Dental, Vision & Disability Insurance401(k), Maternity & Parental LeaveFlexible PTOCommuter BenefitsAmazon Employee DiscountMonthly Contribution and Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages),Breakfast, Lunch & Dinner Served DailyFree Snacks and BeveragesPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",sf,de
10,Asana,Information Technology,4.8,Data Engineer,"San Francisco, CA",$108K - $192K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=109&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_1a8121e6&cb=1618162382983&jobListingId=3635454443,"Data Engineer

The data team designs, implements and scales data pipelines that transform raw data into actionable models and metrics that enable insight. This team owns the pipelines that transport and process database data from all of Asana's product surfaces. We build and operate the infrastructure and services that ensure data accuracy and data availability for data scientists, analysts, and business and product teams.

We are looking for a data engineer to support our product data engineering team. This team will have ownership of the core data pipelines powering Asana's metrics and partner with our existing data infrastructure team, data science team, and cross-functional partners to help evolve our analytic data model as data volume grows and new needs arise to support the growth of the business.

What you'll achieve

Architect, build, and launch scalable data pipelines to support Asana's growing data processing and analytics needs
Produce foundational data tables and metrics with clear definitions, lineage, and test coverage to ensure that data is reliable, intelligible, and maintainable
Understand and influence logging frameworks and practices to support our data flow, architecting logging best practices where needed
Implement systems to track data quality and consistency
Partner with business domain experts, data scientists and analysts, and engineering teams to build a roadmap for foundational data sets that are aligned with business goals and that enable self-service

About you

Bachelor's degree in Computer Science, Math, Statistics, Engineering, or a related quantitative field, or equivalent experience
5+ years of industry experience in software engineering or data engineering
Interest in building scalable data pipelines
Ability to communicate cross-functionally, derive requirements and architect shared datasets
An inquisitive nature in diving into data inconsistencies to pinpoint issues
Being autonomous in taking projects to successful completion
Desire to build team practices and ceremonies
Experience using coding languages Python, Java, Scala

About us

At Asana, we're building a better way to work, fueled by transparency, inclusion, and technology that is a force for positive change. Asana is a work management platform that helps teams orchestrate their work, from daily tasks to strategic initiatives, so they can move faster and accomplish more with less. For the past 5 years, we've been named a top workplace, including top 10 Great Place to Work Best Small & Medium Workplaces, #1 Fortune Best Workplace in the Bay Area for four years in a row, #8 Fortune Best Workplaces for Women, #14 Glassdoor Best Place to Work, #15 Fast Company World's Most Innovative Companies, and one of Ireland's Best Workplaces. With offices all over the world, we are always looking for curious, collaborative, and mission-driven people to help us enable the world's teams to work together effortlessly.

We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We welcome applicants of any educational background, gender identity and expression, sexual orientation, religion, ethnicity, age, citizenship, socioeconomic status, disability, and veteran status.",sf,de
11,Snowflake,Information Technology,4.1,Data Engineer,"San Mateo, CA",$116K - $205K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=110&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_1f60a369&cb=1618162382984&jobListingId=4052825160,"There is only one Data Cloud. Snowflake's founders started from scratch and designed a data platform built for the cloud that is effective, affordable, and accessible to all data users. But it didn't stop there. They engineered Snowflake to power the Data Cloud, where thousands of organizations unlock the value of their data with near-unlimited scale, concurrency, and performance. This is our vision: a world with endless insights to tackle the challenges and opportunities of today and reveal the possibilities of tomorrow.[ - ADD JOB DESCRIPTION ONLY - ]
ROLE DESCRIPTION



Interface with data scientists, product managers, and business stakeholders to understand data needs and help build data products that scale across the company
Drive the design, building, and launching of new data models and data pipelines in production
Build data expertise and own data quality for allocated areas of ownership

MINIMUM QUALIFICATIONS5 years of experience with:


SQL
schema design and dimensional data modeling
custom ETL design, implementation and maintenance
object-oriented programming languages
analyzing data to identify deliverables, gaps and inconsistencies
working with either a MapReduce or an MPP system
ETL tooling, especially Airflow
the data warehouse space

PREFERRED QUALIFICATIONS:



MS or PhD in Computer Science, Math, Physics, or other technical field
Experience with data visualization
5+ years experience using Python



Snowflake is growing fast, and we're scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",sf,de
12,Citi,Finance,3.9,Data Engineer,"San Francisco, CA",$74K - $139K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=111&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_eac506c2&cb=1618162382984&jobListingId=3822055399,"Company DescriptionCiti Ventures’ mission is to drive customer-focused innovation and cultural transformation that delivers new growth and value for Citi. At Citi Ventures, we invest in startups, pilot new technologies, and test new solutions and business models with the potential to transform the future of financial services. The Studio team in Citi Ventures develops digital products and services that foster economic vitality for people and communities. Based in San Francisco and New York, the team includes designers, ux researchers, product managers, software engineers, data scientists, and strategists working in a fast-paced, collaborative, startup environment with the backing of a major financial institution.Job DescriptionWe are building a new team in Citi Ventures Studio to promote the use of technology in reducing bias and delivering more equitable outcomes to communities of color. This team will have a dual focus on inclusive user experience and the role of data in reducing bias and creating equity, and will be a key part of Citi’s Action for Racial Equity initiative. We are looking for a Data Engineer to join this group and help build solutions that empower people and communities of color and establish a center of excellence on technology, data, and racial equity. This role will report to a Senior Data Scientist in Citi Ventures Studio.Learn more about our workVentures Studio mission and team: https://citi.com/ventures/studio.htmlOur products: Worthi http://www.helloworthi.com/Our products: City Builder http://citi.com/citybuilderRacial Equity Action at Citi: https://www.citigroup.com/citi/racial-equity/How you’ll contributeSit at the intersection between product, engineering, and leadership to inform, influence, support, and execute our product decisionsWork within the bank to help find and reduce bias in financial services and help define best practices and standardsCreate visualizations to represent data for consumption by our Product and Marketing teamsParticipate on a cross-functional team using agile methodologiesWork on all Studio products including but not limited to City Builder and Worthi to help extract, clean, analyze new data sources and potential new featuresCreate, maintain, optimize and build ETL (Extract Transform Load) processes for all Studio products including but not limited to City Builder and WorthiBuild robust data quality checks in PostgreSQL databaseWork with API’s and other sources to integrate new data sets into current pipelineDefines strategies to drive data quality measurement, produce data quality dashboards and reports, and implement data quality strategies to effectively govern data and improve data quality.What we’re looking forBachelor’s degree in a computer science discipline: computer science, informatics, engineering, data science, etc. or equivalent experienceYou have 2+ years of experience working as a Data Engineer (or similar role i.e. Database Architect, etc.) on a software teamWorking experience of SQL (MySQL, Postgres, etc.) and relational databasesWorking experience of Google Cloud Platform (Cloud Composer/Airflow, Cloud Storage, Cloud Scheduler, Cloud Functions, etc.) or equivalent (AWS, Azure)Strong proficiency in PythonStrong foundation in software engineering and computer scienceExperience building, scheduling and operating data pipelines (e.g. using Google Cloud Composer/Airflow)Experience in devops, i.e. Linux, Docker, Kibernetes, CircleCIProven track-record of solving complex data processing and storage challenges through scalable, fault-tolerant architectureExperience with version control systems such as gitYou have excellent written and verbal skillsYou have an entrepreneurial mindsetYou are highly motivated and a standout teammateYou are curious about learning new things – our team requires skills in a variety of domains and encourages learning in and outside your field-Job Family Group:Technology-Job Family:Data Quality-Time Type:-Citi is an equal opportunity and affirmative action employer.Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.View the EEO Policy Statement.View the Pay Transparency Posting",sf,de
13,Epic,Information Technology,4.7,Data Engineer,"Redwood City, CA",$72K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=112&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_2acda403&cb=1618162382984&jobListingId=4029537641,"About Us:

Designed for unlimited discovery and unmatched safety, Epic is the leading digital library for kids. With tens of thousands of high-quality books, audiobooks, and videos from the world's best publishers, every year millions of kids read, learn and explore on Epic.

To learn more about our vision to unlock the potential of every child, visit us at www.getepic.com.

About the job

We are looking for a Data Engineer to join our Data Engineering Team that delivers on key data initiatives. You will be working on developing data infrastructure and pipelines for a variety of heterogeneous data sources, including user content interaction, natural language content, impressions and click logs, for product features that use Artificial Intelligence (AI) and Machine Learning (ML) as well as for key business reports and analytics.

You will be part of the core engineering team whose contributions help create a better world through learning and unlock the potential of every child on the planet.

What you will be doing

Develop scalable real time streaming and batch infrastructure for various data streams and pipelines
Develop data observability systems to monitor data quality and data downtime
Develop data feeds for reporting and analytic needs
Develop automated AI and ML feature and model training pipelines for models developed by data scientists

What you should have

Experience in one of the following programming languages - Python, Java, or Scala
Experience working on distributed computing and stream processing involving technologies such as Kafka Streams, Spark streaming, Pub/Sub, and Google Cloud Dataflow
Experience with at least one relational database system such as PostgreSQL or MySQL
Bachelor's degree in CS, EE/ECE or a related field with at least 3 years relevant industry experience or M.S./ PhD degree in CS, EE/ECE or a related field with at least 1 years of relevant industry experience in data engineering
Curious, collaborative, and always willing to learn new things
Good communication skills
Passionate about data

Nice to have

Experience with a NoSQL database like Cassandra or MongoDB
Experience with Docker, Kubernetes, and Jenkins for CI/CD pipelines

Benefits

Full medical, dental and vision coverage
401(k) plan
Take as you need vacation
Home office stipend
Lifestyle allowance
In office perks (virtual for now)
Unlimited access to our product!
",sf,de
14,Clockwise,Information Technology,5,Data Engineer,"San Francisco, CA",$120K - $125K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=113&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_bb787158&cb=1618162382984&jobListingId=3748877201,"Clockwise is currently working & interviewing candidates remotely. We are actively hiring for this position and will review your application.Who we areClockwise is an intelligent calendar system that frees up your time so you can work on what matters. We want to help people escape the chaos of work and find their focus. As the world's first company powering time, Clockwise creates, detects, protects and negotiates Focus Time to help individuals and teams anywhere in the world be more productive at work.Clockwise is headquartered in San Francisco, CA. We're proud to have the backing of Accel, Greylock Partners and Bain Capital. Our team has decades of experience from places like Twitter, Asana, Salesforce, and Google. Join us as we help the world make time for what matters.The RoleClockwise is looking to hire our first Data Engineer to join our growing engineering team. We value engineers who build for the end user, find fun in difficult problems, sweat the details, and love pushing code. We're a humble, fast-moving, and fun team building a consumer-centric culture with empathy, authenticity, focus, drive, curiosity, and enthusiasm.What you'll doHave a huge impact as our first data engineerArchitect and own data pipelines that deliver product analytics and insights across the companyCreate scalable and optimized self-service data infrastructureModel data to aggregate raw fact/dimensional data into elegant and consistent data frames that can power self-service of analyticsPartner with company leadership to drive product and business insightsCollaborate heavily across data science and engineeringAbout youExpertise modeling data (relational and non-relational) as well as processing information at scaleExperience working with multiple stakeholders and functions, delivering rock-solid analytics for many consumersStrong curiosity which drives discovery of new tools, frameworks and iteration of approachA deep desire to learn and hone the craft of engineeringPassionate about productivity tools and workflowsOur stackJava, Postgres, Kubernetes, Airflow, Rust, Node, GraphQL and moreWork locationClockwise is currently working remotely in accordance with San Francisco's ""Stay Home"" ordinance.Clockwise is accelerating the comfort & normalcy of remote work for our users as well as our employees. We've designed a remote work experience that exemplifies our values-driven culture and velocity by modifying our weekly rituals and adopting new technologies.The Clockwise HQ is in the South of Market neighborhood of San Francisco; 3 minutes from CalTrain & 10 minutes from BART.What we offer (non-exhaustive)Competitive total compensation package with generous equityPremium medical, dental and vision plans401(k) planWellness stipendVirtual happy hours & eventsGenerous, flexible vacation policyPaid maternity and paternity leaveIn the Presswww.getclockwise.com/pressWhat drives ClockwiseEmpathy - we work to fully understand our customers and teammates, especially when we disagreeAuthenticity - we speak openly and candidly while embracing our teammates' individualityFocus - we spend our time deliberately and don't wait to do the things that matterDrive - we relentlessly pursue success and aren't afraid to get outside our comfort zoneCuriosity - we seek out opportunities to learn and continuously question how we can improveEnthusiasm - we love what we do and are excited to share it with the worldClockwise is looking to build a diverse team of individuals that share our core values. If these values resonate with you, please apply below or email us at careers@getclockwise.com.",sf,de
15,Pinterest,Information Technology,4.1,"Data Engineer, People Insights & Analytics","San Francisco, CA",$116K - $200K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=114&ao=134566&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_dcd82401&cb=1618162382985&jobListingId=3820535115,"The People Insights and Analytics team is looking for a data engineer to build and maintain a data platform to help Pinterest make better decisions about its employees using data. You’ll own the flow of data between multiple systems that track data for our employees and employee data warehouse systems, which fuels analytics, dashboards, surveys and other tools that help our leaders and managers build a world-class people experience at Pinterest. The successful candidate will have experience working with enterprise data warehouses, be passionate about empowering people to make data driven decisions and be excited to own and build a data platform.What you’ll do:Architect the data strategy for the People Team. We’re just getting started building a system that can scale with our business and analytics needsEstablish relationships across People team, Engineering and the Business to understand our data landscape, and create a strategy to bridge the gapsUtilization of data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insightsDesign, develop, and implement data processing pipelines at scalePresent programming documentation and design to team members and convey complex information in a clear and concise mannerExtract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processesMaintain suite of data tools platforms and dashboards in Tableau, Django, d3, Jupyter, R and other analytical tools.What we’re looking for:Hands-on experience in data modeling, data visualization and pipeline design and developmentHands-on experience with data platforms (Hadoop, Hive, Presto, Snowflake, Cloudera ) and familiarity with data visualization (Tableau, D3) technologiesStrong in at least one of these programming languages: Python, Java, GoComfortable working across a wide array of technologies, project types, and business requirements. Strength in AWS and cloud data technology strongly preferredExperienced at organizing and executing against sprintsAbility to handle confidential material discreetly#LI-MJ1",sf,de
16,Retain.ai,Information Technology,5,Data Engineer,"San Francisco, CA",$107K - $143K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=115&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_f57b2b66&cb=1618162382985&jobListingId=4056960917,"About Retain:Retain enables enterprises to understand their return on customer investment by combining data from 250+ tools (CRM, calendar, email, Slack, Zoom, internal apps) to deliver a single Source of Record™ view of the customers, processes, and systems where teams focus effort. Retain identifies customers that are being underserved and processes that are slowing teams down to increase customer revenue, scale customer processes, and reduce churn through connected data.Retain is a team of talented, friendly people headquartered in San Francisco. Our leadership team is composed of experienced founders from LiveRamp ($15M funding to $5B NYSE: RAMP), and early employees from Uber (NYSE: UBER), PagerDuty (NYSE: PD), and Drawbridge (acquired by LinkedIn). Backed by Baseline Ventures / Steve Anderson (first investor in Instagram, SoFi, PagerDuty, Heroku, StitchFix, and many others), Steve Anderson led our last round of funding and sits on our board.You can learn more about our team and values here: https://www.retain.ai/careersAbout the RoleThe Retain product has found a strong product/market fit, and as one of the first data engineers on the team you will have full ownership and autonomy to define and implement the next generation of our data platform. The tools and technologies you work with will directly drive our core product offerings and revenue numbers, enabling the company to keep up with its dramatic customer growth.You will be responsible for technology that transforms billions of raw data points into meaningful, actionable insights that help people and companies get smarter with how they spend their time. We are a privacy-first company, and our customers trust us because we are able to provide these insights by only collecting a small amount of strictly work-related information.This is a great opportunity to experience exponential personal and professional growth while working with a supportive team that values ownership, empathy, and humility.ResponsibilitiesYou will be responsible for the data that powers a rapidly growing SaaS product already serving Fortune-500 customers.You will work in a cloud (AWS) environment to implement changes across all stages of our data lifecycle: ingestion, processing, storage, analytics, and exports.You will contribute to strategic technical decisions.You will take calculated risks and experiment with technology to create the most trusted and insightful time management tool for large enterprises.This is a great role for you if...You want to build a robust data platform from the ground up.You want to have a major impact on the product and company culture. Your work will directly unlock new product capabilities.You want to solve challenging technical problems.You enjoy automating manual work through smart applications of data concepts.You want to move quickly and have virtually unlimited ownership. We build features, iterate, and respond to customer feedback multiple times a day.You want to start your own company in the future, or want to be highly involved in the direction of a company from its earliest stages.Proficiency with data processing concepts such as map reduce, stream processing, warehousing, lambda architectures, and online analytics processing.Experience working with and deploying data processing tools and frameworks such as Hadoop, Airflow, Spark, Flink, Druid, or similar technologies.Great teammate and collaborator. Openness to giving and receiving honest feedback.Comfort with a high degree of uncertainty - there’s a lot we don’t know, and we need your help to figure it out!Ability to proactively deliver results without a QA team or a 10-page spec.Above all, our goal is to build a community of thoughtful team players who are enthusiastic about learning, sharing their expertise, and getting things done. If that resonates with you, we would love for you to apply.",sf,de
17,Replica,Information Technology,5,Data Engineer,"San Francisco, CA",$110K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=116&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_ac083fbb&cb=1618162382985&jobListingId=4056303951,"Replica is an enterprise data platform that delivers critical insights about the built environment. With better data, human-context and an intuitive design, Replica helps public and private sectors make informed, effective, and responsive decisions. By showing how people live, move and work, we contextualize hard choices, allowing our clients to see around corners and understand the trade-offs surrounding their decisions. Whether for a city planner increasing public transit to underserved neighborhoods or for a grocery chain evaluating where to open a new location, Replica's insights lets clients make more informed, people-centered decisions.

We spun out of Alphabet in 2019 when we secured series A funding from venture firms such as Innovation Endeavors, Firebrand Ventures, and Revolution's Rise of the Rest Seed Fund. Today, we are a team of ~30 employees with offices in San Francisco, CA and Overland Park, KS.

We value our customers, believe in being resourceful, and work in service of each other to scale our product. As we build our team, we are committed to pursuing and bringing together a diverse workforce and creating an environment of inclusion. We value our differences and we encourage all to apply. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, Veteran status, or any other status protected by the laws or regulations in the locations where we operate.The TeamReplica's engineering and research team consists of industrial veterans from Google, Uber, Lyft, Dropbox, as well as academic researchers from top research institutes that push the frontier of movement analysis forward. The team is heavily mission-driven, with deep technical expertise on big data processing at scale, production software engineering micro-services, and domain knowledge in the field of movement patterns.The RoleAs our engineering team grows, we are looking for a data engineer working on geo data related data pipelines and data products. As an early member on the team, you will balance speed and quality as you build out new features for our customers.

You will collaborate with engineers, design, research and development, and customers to enable additional methods of querying and create valuable data visualizations for every customer. More specifically, here's what you can expect to do in the role:


Work closely with the customer success team to fully understand their needs and respond quickly to their feedback.
Own the process and automation for data intake, QA and data delivery.
Identify gaps and invent processes, automated scripts, and tools to efficiently carry out geo data processing tasks in a scalable fashion.
Establish testing strategy and best practices.
Add logging, observability, and notification for data workflows.
Actively contribute to company culture by mentoring engineers, contributing to documentation, and actively collaborating with cross-functional groups.
Technologies: Python, PostGIS, Pandas, Big Query, Java, Python, JTS, Cron.

Minimum Requirements

5+ years of experience working with data engineering projects.
3+ years as a software engineer.
Efficiency with automation and tooling languages like python to build reusable components/tools.
Proven experience working with data pipelines at scale and knowledge of common big data frameworks, such as hadoop/bigquery.
Experience with common geo format (e.g., geojson, geodatabases like postgresql/postgis) is a plus

What We Value

Empathy. You are curious and eager to learn more about our users and understand their needs.
Balance. You weigh speed and quality carefully and understand the tradeoffs.
A collaborative approach to problem solving. You've worked with cross functional teams before and you enjoy the process.
Active participation. You jump in and actively engage with the team and customers to build products people use.
Ability to navigate ambiguity. Things get blurry, but you persevere to find clarity and communicate effectively with your teammates to ensure clarity for all.
Passion. You are driven to improve the quality of life in urban environments.

Benefits

Our people! We work as a team and are excited to contribute to city planning.
Competitive salary based on experience and potential for impact.
Equity at an early stage startup.
Health benefits including medical, dental, vision, and HSA option.
401k account + employer contribution.
Offices in San Francisco, CA, Overland Park, KS, and remote.
Flexible PTO.

If you don't think you meet all of the criteria above, but still are interested in the job, please apply. Nobody checks every box, and we're looking for someone excited to join the team.",sf,de
18,Sigma Computing,Information Technology,4.7,Data Engineer,"San Francisco, CA",$116K - $152K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=118&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_4e3a2f6f&cb=1618162382985&jobListingId=4053109051,"About the RoleAs the first hire in the Data Engineering team you will be on the ground floor to make sure Sigma is successful in meeting its goals. Manage our many data sources, structures and platforms creating a data arcadia that allows our business and our product to function and perform well. You will be encouraged to blog, speak, and join events to talk about the work you are doing and how other companies can follow our lead.You Will:Do you like puzzles? We do and we think unstructured data is one big puzzle. Put the pieces together and help us build the data picture for our company and our customers.People are our strongest asset and we need you to work with your team members to get them the data they need to support the business.Manage our cloud data warehouses from availability, performance and architecture perspective. (Snowflake, Redshift, BigQuery, Postgres)Scotty, beam us up! We need you to manage the ETL process and pipelines for our data.There are three types of metrics; metrics, bad metrics and no metrics. Ensure we only have the first.You like reading about the latest technology and trying it out? Come get paid for it!You Are:Data is beautiful and we need you to be our Monet and paint a beautiful picture with it. You need to have a passion for structuring data and managing it.You are extremely service oriented and view your role as providing a service in the company that your peers consume.You speak three languages; English, Bad English and SQL.You have a working knowledge of relational databases and query authoring.You are experienced with at least one of the following programming languages - Python / Java / Scala.You have a solid understanding and working experience with batch and stream processing and applying such methodologies to meet the latency requirements for the business.Thou shall not pass! Be our gatekeeper around who has what access to what data.You want things to go just right down to the smallest detail. Your level of organization would be described as meticulous.They named the curiosity rover after you because you have so many questions you like getting the answers to.About us:Sigma is a SaaS, next-generation business intelligence and data exploration platform that is changing the analytics landscape. Sigma offers a spreadsheet-like interface that enables all decision makers to securely analyze up to billions of rows of live data with the unlimited scale and speed of the cloud. With Sigma, everyone can quickly answer their own questions to make and visualize accurate, data-driven decisions.At Sigma, we believe every person has unique domain expertise that they bring to the table. Our mission is to give everyone the technical abilities to leverage their expertise to drive their business decisions. This idea is fundamental to who we are and how we collaborate and treat each other. We believe we are Smarter Together and what each person brings to the table helps make us (and our company) stronger. How we do this internally is through transparency and Fearless Communication. We explain, we speak up, and we all have the opportunity to contribute to the company. With that communication, we Assume Best Intent and know what how we approach each other and our customers is with a common goal. We are Curious & Constructive in looking at how we can make our product, company, and community better. With all of these Company Values, we Aim for Greatness, we have big goals that we keep hitting and we continue to reassess how we can set those goals even higher. Come join us to help us be smarter and grow together!Benefits For Our Full-Time Employees:EquityGenerous health benefitsFlexible time off policy. Take the time off you need!Flexible schedule, do the work you need to get done in the time you have to get it doneAt least 12 weeks of paid bonding time for all new parentsTraditional and Roth 401kCommuter and FSA benefitsSigma Computing is an equal opportunity employer. We are committed to building a smart and strong team regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We look forward to learning how your experience can enable all of us to grow.",sf,de
19,Asana,Information Technology,4.8,"Software Engineer, Data Infrastructure","San Francisco, CA",$112K - $200K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=119&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_fbabee55&cb=1618162382985&jobListingId=3687686661,"Software Engineer, Data Infrastructure

The Data Infrastructure team builds the infrastructure responsible for consuming, exposing and creating product and product-derived datasets. Our team owns the pipelines that transport and process database data from all of Asana's product surfaces. We build and operate the infrastructure and services that ensure data accuracy and data availability for stakeholders in Data Science, Business and feature teams.

We're looking for an Infrastructure Engineer to build and operate software to make Asana secure, scalable and fast. You will work with the team on deploying and operating existing systems, and build and support platforms and tools that provide high leverage to data consumers.You will guide users of Asana data to use these platforms effectively and champion adopting best practices and better technologies to improve the efficiency, scalability, and stability of our offerings.

What you'll do

Design, build, and operate streaming and batch services used by all of Asana
Build infrastructure to enable evaluation and reporting on product experiments
Co-create secure patterns/practices for data systems
Collaborate with infrastructure and data science to scale up data processing to meet the rapid data growth at Asana
Design and implement tooling and automation for clustering, scaling, monitoring, data access and alerting
Participate in the on-call rotation, investigate and resolve production problems

About you

A strong interest in building scalable and performant distributed systems with a focus on eliminating risks
Interest in building scalable and performant distributed systems with a focus on eliminating risks
Can think intuitively about systems and services and write high quality code; we care much more about your general engineering skills than knowledge of a particular language or framework.
Take pride in working on projects to successful completion involving a wide variety of technologies and systems.
You are comfortable helping the team build cohesion and team processes
Experience working in large, high-quality codebases
Experience with our tech stack - Scala, Python, Spark, Airflow, Kubernetes, AWS-based infrastructure

Does the above sound like it might be you? Then we'd love to hear from you. Our goal is to provide a hiring and working experience in which all people know they are equally respected and valued. So whatever it is that makes you unique—your gender identity or expression, sexual orientation, religion, ethnicity, age, citizenship, educational background, socioeconomic status—we value it, and we'd love to see what you might add to our team.
About us

At Asana, we're building a better way to work, fueled by transparency, inclusion, and technology that is a force for positive change. Asana is a work management platform that helps teams orchestrate their work, from daily tasks to strategic initiatives, so they can move faster and accomplish more with less. For the past 5 years, we've been named a top workplace, including top 10 Great Place to Work Best Small & Medium Workplaces, #1 Fortune Best Workplace in the Bay Area for four years in a row, #8 Fortune Best Workplaces for Women, #14 Glassdoor Best Place to Work, #15 Fast Company World's Most Innovative Companies, and one of Ireland's Best Workplaces. With offices all over the world, we are always looking for curious, collaborative, and mission-driven people to help us enable the world's teams to work together effortlessly.

We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We welcome applicants of any educational background, gender identity and expression, sexual orientation, religion, ethnicity, age, citizenship, socioeconomic status, disability, and veteran status.",sf,de
20,Wish,Retail,3.4,Data Engineer,"San Francisco, CA",$167K - $205K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=120&ao=4134&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_e1414377&cb=1618162382986&jobListingId=4057310910,"Company DescriptionWish is a mobile e-commerce platform that flips traditional shopping on its head. We connect hundreds of millions of people with the widest selection of delightful, surprising, and—most importantly—affordable products delivered directly to their doors. Each day on Wish, millions of customers in more than 160 countries around the world discover new products. For our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market.

We're fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. If you’ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place.Job DescriptionOur engineers move extremely fast, while solving unique and challenging problems. Our team is small and nimble. We release every day to ensure that engineers are able to iterate quickly, and make an impact immediately. We’re looking for engineers to work on our massive semi-structured datasets.

You'll develop software to process, transform and analyze the data to identify signals from billions of events we collect every day. You'll provide insights that improve the experience of hundreds of millions of users worldwide. You should be results-driven, highly motivated, and have a track record of using data analytics to drive the understanding, growth, and success of a product.

What you'll be doing:

Design and Develop data collecting and processing systems to handle large data sets. You’ll have the opportunity to design innovative data solutions and solve challenging problems.
Design, Develop and Support highly-parallel, and fault-tolerant applications.
Build and integrate scalable backend systems, services, platforms, and tools
Contribute to the design and code of complex data pipelines operating on production data
Optimize current approaches to efficiently handle ever-increasing volumes of data
Build proof of concept using modern technologies and convert them into production-grade implementation.
Create best-practice reports and dashboards based on data mining, analysis, and visualization

Qualifications

5 + years of experience as a Software Engineer or Data Engineer using Python, java or any other programming language
Expertise with SQL and data storage systems
Experience and knowledge of modern data warehouse, pipeline and reporting/analytic techniques and tools such as Airflow, Presto/Hive, Spark, or any other scheduling frameworks, Tableau or other reporting tools
Experience working on Amazon Web Services or other cloud computing platforms
Bachelor's degree in Computer Science or related field.

Preferred Qualifications:

Experience in data visualization a plus.

#LI-BD1Additional InformationWish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.

Individuals applying for positions at Wish, including California residents, can see our privacy policy here.",sf,de
21,Trianz,Information Technology,3.2,Data Engineer,"San Francisco, CA",$101K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=121&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_0365e0d1&cb=1618162382986&jobListingId=4058258137,"Data Engineers, Full-time, Menlo Park, CA and Houston, TX (U.S Citizens, GC candidates) About the Role:Trianz is looking for passionate Data Engineers who are looking to tackle challenges and build solutions.We are looking for a Data Engineer to not only build data pipelines but also extend the next generation of our data tools. As a Data Engineer, you will develop a clear sense of connection with our organization and leadership - as Data Engineering is the eyes through which they see the product.This is a partnership-heavy role. As a member of Infrastructure Strategy Data Engineering, you will belong to a centralized Data Science/Data Engineering team who partners closely with teams in Facebook’s Infrastructure organization. Through the consulting-nature of our team, you will contribute to a variety of projects and technologies, depending on partner needs. Projects include analytics, ML modeling, tooling, services, and more. The broad range of partners equates to a broad range of projects and deliverables: ML Models, datasets, measurements, services, tools and process.ResponsibilitiesManage data warehouse plans for a business vertical or a group of business verticals.Build data expertise and own data quality for allocated areas of ownership.Design, build, optimize, launch, and support new and existing data models and analytical solutions.Partner with internal stakeholders to understand business requirements, work with cross-functional data and products teams and build efficient and scalable data solutions.Conduct design and code reviews.Work with data infrastructure to triage infra issues and drive to resolution.Manage the delivery of high impact dashboards, tools and data visualizations.Minimum Qualifications:BS/B.Tech. /M. Tech in Computer Science, Math or related field2+ years of experience in the data warehouse space, custom ETL design, implementation and maintenance2+ years of experience in SQL or similar languages, and development experience in at least one language (Python, PHP etc.)Experience with data architecture, data modeling, schema design and software developmentExperience in leading data driven projects from definition through interpretation and execution.Experience with large data sets, Hadoop, and data visualization toolsExperience initiating and driving projects and communicating data warehouse plans to internal clients/stakeholders.Need more details?Trianz is growing at a faster pace than the industry for the last five years. Read through some of the key industry recognitions we have received for our innovative execution and strategic client initiatives here.About TrianzTrianz simplifies digital evolutions through effective strategies and excellence in execution. Collaborating with business and technology leaders, we help formulate and execute operational strategies to achieve intended business outcomes by bringing the best of consulting, technology experiences and execution models. Powered by knowledge, research, and perspectives, we enable clients to transition to a digital enterprise by leveraging Cloud, Analytics, Digital, Infrastructure and Security paradigms. With offices in Silicon Valley, Washington DC Metro, Rosemont, Chicago, Austin, Boston, Denver, Irvine, Raleigh, San Francisco, Seattle, New York, Dubai, Bengaluru, Hyderabad and Chennai, we serve Fortune 1000 and emerging organizations across industries globally. For more information, visit www.trianz.com.Trianz is an Equal Opportunity Employer and does not discriminate on the basis of race, color, creed, national or ethnic origin, gender, religion, disability, age, political affiliation or belief, disabled veteran, veteran of the Vietnam Era, or citizenship status (except in those special circumstances permitted or mandated by law).",sf,de
22,Unify Consulting,Business Services,4.2,Data Engineer,"San Francisco, CA",$98K - $177K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=123&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_85ee72cd&cb=1618162382986&jobListingId=4030221983,"About the jobWe are seeking experienced mid to senior-level data engineering consultants (5+ years) with management consulting experience, who are versatile in skillset and are passionate about bringing value to our clients. We look for technology and data analytic leaders who are experts in their fields who also want to make a meaningful impact for local clients in the San Francisco, CA area.Individual contributor with the ability to execute specialized data solutions and make departures from traditional approaches if needed. They will possess skills in design, development, implementation, documentation, and management of data solutions, and be expected to clearly articulate and present technical information to clients and stakeholders.*Only accepting local candidates at this time.__*Responsibilities: *· Build complex and scalable production level data pipelines; from source to data products ready for end-user consumption (e.g. multi-dimensional model)· Understanding of how to model data for scalability and optimized performance· Drive the design, building, and launching of new data models and data pipelines in production.· Collaborate with business users to understand the need / problem, break down requirements, and maintain communication through delivery· Collaborate with BI developers, Data Scientists, Product Managers, Software Engineers, Data Modelers and/or Platform owners to define the scope, design and implement the correct solution· Produces detailed and high-quality documentation detailing design and behaviors of data pipelines· Instill comprehension of technical concepts for non-technical audiences through presentations (executive leadership and large groups), email, and meetings· Participate in architectural evolution of data engineering patterns, frameworks, systems, and platforms including defining best practices, standards, principles, and policies· Working knowledge of data quality approaches and techniques· Familiarity implementing good security practices for sensitive data· Bring a positive energy every day and work within a team to deliver the best possible solutions· Learn the business and the data that supports the business; doesn’t just implement technologyRequired Qualifications: · 5+ years experience in data integration and data warehousing (preferably cloud datawarehouses)· 5+ years experience with relational database technologies (SQL Server, MySQL, Oracle, Teradata, or similar)· 5+ years experience with ETL/ELT tools such as Apache Spark, Smartstream, Fivetran, Talend, Matillion, AWS Glue, HVR or similar· 3+ years experience Experience with custom ETL/ELT and programming/scripting language experience: Pyspark, Python, Scala (Python required)· Experience with developing dynamic data pipeline frameworks (with Apache Airflow, Control M for instance)· Current experience with developing on a Public Cloud Environment (AWS, Azure, GCP for instance)· Experience working in an Agile team and delivery capability· Familiarity with common security measures for analytical systems· Familiarity with performance tuning and optimization· BS Degree or equivalent required in Computer Science or similar area of studyPreferred Qualifications: · Experience in development, design, and application of data modeling (on star-schema model), data mining and data architecture concepts and techniques· Excellent communication skills with the ability to relay information between technical and non-technical teams· Management consulting experience strongly preferred· Demonstrated presentation skills· Experience working with large datasets and big data technologies, preferably cloud-based, such as Redshift, Snowflake, Databricks, Azure SQL Data Warehouse, MongoDB, Cosmos, or similar· Proficient with NoSQL, Object-Oriented, Distributed databases· Proficient with data preparation tools (i.e. Alteryx)· Experience with source control tools· Proficient in project management and system reliabilityUnify Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Job Type: Full-timePay: $160,000.00 - $190,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programFlexible scheduleFlexible spending accountHealth insuranceHealth savings accountLife insurancePaid time offParental leaveRetirement planTuition reimbursementVision insuranceSchedule:8 hour shiftMonday to FridaySupplemental Pay:Bonus payCOVID-19 considerations:All of our consultants are currently working remote temporarily until COVID-19 allows for working onsite again.Ability to Commute/Relocate:San Francisco, CA (Preferred)Application Question(s):How many years of pyspark do you have?How many years of AWS experience do you have?Education:Bachelor's (Preferred)Experience:SQL: 4 years (Preferred)Data Warehouse: 4 years (Preferred)Data Engineering: 4 years (Preferred)Work Location:One locationThis Job Is:A job for which military experienced candidates are encouraged to applyCompany's website:https://www.unifyconsulting.com/Benefit Conditions:Only full-time employees eligibleWork Remotely:Temporarily due to COVID-19COVID-19 Precaution(s):Remote interview processVirtual meetings",sf,de
23,Plum Lending,Finance,4.1,Senior Machine Learning Engineer (US Remote),"San Francisco, CA",$162K - $191K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=124&ao=1044074&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_c0ed3838&cb=1618162382986&jobListingId=4053856277,"Senior Machine Learning EngineerJOB SUMMARYWe are looking for a data-driven problem solver who can automatically discover and extract information from multiple data sources and who enjoys working with new data science technologies. The senior machine learning engineer will work to recognize patterns and productize your solutions and techniques for integration into our products and our processes. You will have a high degree of authority and autonomy, be capable of managing multiple high-priority tasks in a timely manner, and collaborate across the business. A successful machine learning engineer at Plum needs to be innovative, detail-oriented, team-focused, strategic and effective in new and changing environments.We are looking for the candidate to start immediately.Plum employees work full time from their US based home.RESPONSIBILITIES Participate heavily in architecture, design and implementation of machine learning pipelines Develop, refine and scale data management and analytics procedures, systems, workflows, best practices and other issues. Development of data-driven products. Visualize and communicate data clearly for use both internally and externally. Collaborate with our engineers to produce excellent products for Plum clients as well as streamline internal processes.REQUIRED QUALIFICATIONS Bachelor’s degree in Mathematics, Statistics, Engineering, Computer Science or related discipline 2+ years of production-level machine learning model deployment Experience in working with big data technologies Spark, MapReduce, NoSQL databases Experience with AWS infrastructure such as EC2, S3 and Glue Hands-on Industry experience with machine learning frameworks like SageMaker, TensorFlow High proficiency in Java Knowledge of both neural networks and traditional ML techniques Experience with data visualization tools like Tableau An entrepreneurial spirit as well as passion for solving difficult challenges through innovation and creativity, with a strong focus on results Conscientious and well organized Eager to produce results and drive forward progress while managing deadlinesPREFERRED QUALIFICATIONS Experience in working with graph database such as TigerGraph or Neo4j Have worked in a fast paced startup environment Experience with finance technology/analytics and commercial real estateBENEFITS Early equity in a startup that is revolutionizing commercial real estate lending.Fully Remote Role Generous health, dental and vision coverage for employees and family members, along with commuter pre-tax program. Unlimited vacation policy. Opportunity to make a meaningful impact on the disruption of an industry and to shape the building of a company and culture. Chance for your direct input to be realized and put into action. Freedom to stretch the boundaries of your past work experience, learn skills outside of your immediate job description and grow your career. Autonomy, flexibility and a flat corporate structure.ABOUT PLUMPlum is leading the transformation of commercial real estate lending through innovative and breakthrough technology, pioneering the fintech revolution within the $3.3 trillion CRE loan market. We deliver to our clients expedited execution, improved transaction visibility and an unparalleled client experience.The team includes former senior level executives and talent from Wells Fargo, KKR, Starwood Capital, Goldman Sachs and AMD. We have extensive experience with CRE sourcing, underwriting and funding processes, as well as deep networks of institutional financing channels. The team has a combined 75 years of CRE lending experience in the U.S. with deal volume totaling over $50 billion, and team members have sourced and underwritten 1,570 CRE loans across virtually all property types and geographic markets. Our founder and CEO, Bill Fisher, has had decades of experience building successful startup businesses including GetSmart.com, Xing and Trivago.In August 2015 Plum secured our Series A funding led by Renren Inc., who has built an exceptional record of backing fintech companies including SoFi, LendingHome and Motif Investing. Renren’s decision follows an earlier seed investment by QED Investors, a pre-eminent VC firm led by the founders of Capital One, whose portfolio includes Prosper, Orchard and ApplePie Capital.We are an early stage, high growth company with endless opportunities for advancement for individuals that are driven to deliver tangible results and do whatever it takes to move Plum forward. We seek to build Plum into a new national financial services brand as well as a fantastic place to come to work. Must be authorized to work in the US. Plum does not sponsor employee visas.",sf,de
24,Backblaze,Information Technology,4.9,Data Engineer,"San Mateo, CA",$154K - $196K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=125&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_746851a9&cb=1618162382986&jobListingId=4058525461,"About BackblazeBackblaze originated in a founder’s one-bedroom apartment where five people committed to helping people save their data. Backblaze provides backup and cloud storage that’s astonishingly easy to use and inexpensive. Our customers use our services so they can pursue dreams like curing cancer (genome mapping is data intensive), archiving the work of some of the greatest artists on the planet (learn more about how Austin City Limits uses Backblaze B2 Cloud Storage), or simply sleeping well at night (anyone that’s spilled a cup of coffee on a laptop knows the relief that comes with complete, secure backups). We are entrusted with almost an exabyte of data from customers in more than 150 countries. We exited 2020 growing quickly and cash flow positive, and we’ve done all this with just $3M of funding.We’ve managed to nurture a team-oriented culture with amazingly low turnover. Our approach is guided by honesty, transparency, and a commitment to doing the right thing for our customers and coworkers. Our customers are happy, and so are our coworkers: In the most recent “Great Place to Work” survey, 99% of our team rated Backblaze as “a great place to work.” Check out what our employees are saying on Glassdoor!But while there is a lot to celebrate in our past, there is almost as much opportunity ahead of us. We are seeking a Data Engineer!This position is located in San Mateo, California but will also consider remote work as long as you're no more than three time zones away and can come to San Mateo now and then (most teams are currently remote until mid-next year).What You’ll Do:Build scalable, efficient and high-performance pipelines/ workflows that are capable of processing large amounts of batch and real-time dataBuild out our data service architecture to support internal and customer facing application use casesMultidisciplinary work supporting real-time streams, ETL pipelines, data warehouses and reporting servicesBring new and innovative solutions to the table to resolve challenging performance and load issuesIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalabilityBuild out the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Java, Python, and SQLRespond quickly to bug fixes and enhancement requests and be able to take directions and complete tasks on-time with minimal supervision.Collaborate with business analytics team to optimize complex queries needed by regular Tableau reportsThe Right Fit:5+ years of Java or Python3+ years in designing relational database, data modeling and ETLStrong experience with SQL databasesExperience in operational data stores and real time data integrationExperience with RESTful APIs and server-side APIs integrationProficient with development on Linux and Macintosh platformsBonus points for:Maria DBNoSQL DBCassandra experienceSalesforceLooking for an attitude of:Passionate about building friendly, easy to use Interfaces and APIs.Likes to work closely with other engineers, support, and sales to help customers.Believes the whole world needs backup, not just English speakers in the USA.Customer Focused (!!) — always focus on the customer’s point of view and how to solve their problem!Required for all Backblaze Employees:Good attitude and willingness to do whatever it takes to get the job doneStrong desire to work for a small, fast-paced companyDesire to learn and adapt to rapidly changing technologies and work environmentRigorous adherence to best practicesRelentless attention to detailExcellent interpersonal skills and good oral/written communicationExcellent troubleshooting and problem-solving skillsBackblaze Perks:100% healthcare for familyCompetitive compensation and 401kFull-time employees receive option grantsFlexible vacation policyMacBook Pro to use for work plus a generous stipend to personalize your workstationChildcare bonus (human children only)Pet-friendly officeGenerous skills training policy to continue your professional developmentCulture that supports healthy work-life balanceBackblaze is an Equal Opportunity Employer.",sf,de
25,iRhythm,Biotech & Pharmaceuticals,3.5,"Senior System Engineer, Manufacturing Tools","San Francisco, CA",$66K - $132K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=126&ao=1128220&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_6d20450e&cb=1618162382986&jobListingId=3798631295,"About iRhythm:

iRhythm is a leading digital healthcare company focused on the way cardiac arrhythmias are clinically diagnosed by combining our wearable biosensing technology with powerful cloud-based data analytics and machine- learning capabilities. Our goal is to be the leading provider of first-line ambulatory ECG monitoring for patients at risk for arrhythmias. iRhythm's continuous ambulatory monitoring has already put over 3 million patients and their doctors on a shorter path to what they both need – answers.

About this role:

The Product Development team is a close-knit, collaborative group of talented engineers representing a wide range of engineering disciplines. Most of all, we are passionate about delivering innovations that improve the quality of health care and the patient experience.

This is an excellent growth opportunity with significant responsibility and ownership, especially for someone interested in both engineering and project management.

This engineer will be responsible for designing electrical PCB test equipment provided to Manufacturing. They will:


Deliver elegant and efficient manufacturing test fixtures and systems that safeguard product quality of our very low power RF-enabled PCBs
Define requirements and architecture for fixtures and tooling, working closely with product design, mechanical, software and firmware engineers to measure critical product functions, working within design constraints.
Manage fixture vendors and coordinate internal programming resources to ensure delivery of systems that meet design requirements, on budget and on schedule
Drive integration and troubleshooting for complex, multi-component systems
Define, execute and document system-level testing for Verification and Validation (V&V), including GR&R.
Characterize process risks related to test fixture usage (PFMEA)
Foster a close relationship with the Manufacturing team to develop a deep understanding of process, business and user needs (requires up to 20% travel)

About you:

This position requires an agile, multi-tasking engineer with at least 5 years of relevant experience and strong project management, communication and problem-solving skills. Minimum qualifications include:


BS/MS in Electrical Engineering or other engineering discipline comfortable reading circuit board schematics
Familiarity with Bluetooth/BLE, LTE standards and RF test.
Excellent interpersonal skills; demonstrated ability to communicate and collaborate effectively in cross-functional teams
Technical experience in multi-disciplinary environments, particularly embedded systems
Strong organizational and time management instincts; able to coordinate resources to meet deadlines in the context of competing priorities and projects
Proven documentation and technical writing skills, including the ability to manage specifications, develop and maintain design documentation, author technical reports, test cases and test methodologies
Experience with manufacturing processes and automated test fixtures.
Medical device development experience a plus

What's in it for you:

This is a full-time position with competitive salary package and excellent benefits including medical, dental and vision insurance, paid holidays and paid time off.

iRhythm also provides additional benefits including 401K (w/ company match), an Employee Stock Purchase Plan, annual organizational/cultural committee events and more!

FLSA Status: Exempt

As a part of our core values, we ensure a diverse and inclusive workforce. We welcome and celebrate people of all backgrounds, experiences, skills and perspectives. iRhythm Technologies, Inc. is an Equal Opportunity Employer (M/F/V/D). Pursuant to San Francisco Fair Chance Ordinance, we will consider for employment all qualified applicants with arrest and conviction records.

Make iRhythm your path forward.",sf,de
26,Customer Lobby,Information Technology,3.9,Data Engineer,"Oakland, CA",$60K - $113K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=127&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_f371a400&cb=1618162382987&jobListingId=4056027285,"The Customer Lobby platform (CLP) integrates with over 150+ invoicing systems and processes on average 1.65M of transaction and other customer data daily for our clients. We have ambitions to build an integrated customer data strategy and management program while exponentially increasing the number of systems we integrate with and entities extracted; Using that data to improve our existing algorithms and power new algorithms, segments and marketing channels to deliver additional value to our customers and accelerate our growth.We’re looking for an experienced, analytical D ata Engineer to help build a holistic view of all customer and industry data using technologies including Python . This engineer will help with data acquisition, data integration, dataset creation, and how we make the data available for our clients and internal stakeholders across Marketing, Sales, Support and Ops teams. This program will require extensive engineering and business coordination to be successful.The right candidate brings world-class business understanding on the value of connecting all customer data along with the technical aptitude required to manage high volume transactional data sets. This candidate will have experience integrating and applying customer data for marketing segmentation, targeting, and personalization.This engineer will drive the technical implementation of Customer Lobby’s own customer data platform and partner closely with the Product team to inform the future roadmap. This involves organizing the data streams to be integrated into the Platform, designing and managing the identity resolution rules for each contact and account, defining and managing the attributes for each customer record, and creating analytical datasets that will empower segmentation and personalization across channels.Us:At Customer Lobby, an EverCommerce company, we provide the leading automated customer communication SaaS product focused on small businesses. Our automated retention & marketing software analyzes our clients’ data, uses artificial intelligence to predict customers who will need service soon, and reaches out to their customers with personalized postcards and emails. We are seeing explosive success in a market that technology has often left behind, and feel proud to be helping services businesses grow.Responsibilities:Build data pipelines to deliver a single view of our clients’ customers and prospects that includes their identities, key attributes (direct and computed), a record of all interactions, and campaign recommendations for our clients.Participate in/drive the data architecture, integration, and implementation of third party systems. Align product teams, technical teams, and business teams on a common roadmap and integration program.Be an expert in engineering data platforms, data model and data engineering to build a best in class data platform.Develop solutions for data acquisitionDevelop dataset processes for data modeling, mining, and productionDrive the collection of new data and refinement of existing data sourcesRecommend ways to improve data reliability, efficiency, and qualityDefine the data connectors for data ingestion, modeling, and metadata-based extensibility for the customer data platform.Develop, construct, test and maintain architectures and processing workflowsWork with multiple stakeholder teams across the business, clients and third party systems to understand the needs and build data products.Lead a team culture of critical thinking, creativity, innovation, experimentation, diversity, and inclusivity that aligns with Customer Lobby's core values and enriches the impact, careers, and learning opportunities of all employees and clients.Be a trusted advisor to the product and engineering teams and help influence the product roadmap.Requirements:Experience with customer data platforms (CDPs) and data management platforms (DMPs).Strong data engineering background - experience with data warehousing and big data technologies required. AWS platform experience is a huge plus.Expert knowledge of data modeling techniques and high-volume ETL/ELT design.Strong SQL optimization and performance tuning experience in a high volume data environment that utilizes parallel processing. AWS experience is a plus.Experience with scripting languages like Python,Experience with AI and Machine Learning preferred but not requiredExperience implementing MarTech tools for B2B such as reporting, ABM, data/CDP, attribution.Experience working with large datasets, data pipelines, and a strong understanding of segmentation best practices.Strong understanding of personalization technologies.You have a passion for MarTech Solutions and want to bring enterprise grade capabilities to small and medium businesses.Benefits & Perks:401K with Company match17 days off, 2 floating holidays and 8 standard holidays, plus a day off to volunteer each yearMonthly company paid activities (i.e. happy hour, parties, etc.)Free catered lunch every Friday (when the office is open)Kitchen stocked with snacks and drinksGym reimbursementPrime location in downtown Oakland, at City Center (12th St. Bart station)Please note that our team is working remotely through at least June 2021.EverCommerce is an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We look forward to reviewing your credentials and getting to know more about your experience!",sf,de
27,Calico,Biotech & Pharmaceuticals,4.2,Data Engineer,"South San Francisco, CA",$91K - $164K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=128&ao=1136006&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&cs=1_9eca3697&cb=1618162382987&jobListingId=4053109885,"Who we are:Calico is a research and development company whose mission is to harness advanced technologies to increase our understanding of the biology that controls lifespan, and to devise interventions that enable people to lead longer and healthier lives. Executing on this mission will require an unprecedented level of interdisciplinary effort and a long-term focus for which funding is already in place.Position Description:Great software engineering is increasingly crucial to biology. We are in the midst of an explosion of biological and medical data that will transform our understanding of biology and disease, but the tools to store, process, visualize, explore, and analyze these data are often primitive—and in some cases don’t yet exist. Calico is seeking an exceptional data engineer to join our computing group and be a part of changing that story.In this role, you will work closely with computational and research scientists to define strategies and implement robust systems for modeling, collecting, storing, and accessing diverse scientific data and metadata. Collaborating with other scientists and engineers, you will design, build, and maintain databases and data warehouses that underpin our scientific endeavors and accelerate our ability to ask new, sophisticated questions spanning multiple organisms, data modalities, and timescales. You will not only build tools to support existing scientific workflows, but also help set the vision for future data generation and collection efforts.If you are passionate about data, passionate about biology, and passionate about their intersection—this is the job for you.What you’ll do:Work with computational and research scientists to understand common analysis use cases and data access needsDesign strategies for data storage and integration across different data sources (both internal and external) for multiple use casesImplement, document, and maintain processing pipelines, databases, and data warehouse + data lake infrastructureWork closely with full-stack engineers to develop APIs and GUIs for accessing and visualizing scientific dataSet data engineering vision and drive both independent and collaborative software development projects end-to-endContribute to a range of projects, from one-off solutions to long-term, complex systemsBuild out core infrastructure, tooling, and software development processesPosition requirements:5+ years building Python-based backend systems3+ years working with contemporary ETL tools and frameworks (e.g., Airflow, Luigi, etc.)Strong understanding of the Python data ecosystem (NumPy, pandas, Jupyter, etc.)Fluent knowledge of SQL and relational database systems (PostgreSQL, MySQL)Experience implementing RESTful APIs, GraphQL, and other programmatic interfaces to complex multidimensional dataExperience deploying flexible + high-performance data backends and interfaces in the cloud with Google Cloud Platform, Amazon Web Services, or similar platformsFirm grasp on software testing and test-driven developmentDemonstrated success in owning projects end-to-end, including working with non-technical stakeholders to define requirements and seek feedbackNice to have:Worked in biology or life sciences, and have familiarity with databases and data types used by computational biologistsWorked with machine learning tools and infrastructure, e.g. TensorFlow and PyTorchBuilt backends for high-dimensional graph or network dataDesigned or worked with auditable data systems suitable for regulatory reviewExperience working with diverse and cutting-edge high-dimensional datasets (e.g., RNASeq, metabolomics, high-content imaging)Experience with on-prem high-performance computing clusters (e.g. SLURM)Some projects you may contribute to:Data warehouse — a system to extract, transform, and load public and private datasets into a single repository, then making these data available for analysis visually with either off-the-shelf or custom-built GUIsData lake — a system to leverage the wide variety and depth of Calico’s datasets to enable interoperability, repeatability, and to serve as a foundation for cross-functional analytic toolsExploratory data visualization & analysis tools — apps to help scientists explore and understand diverse, complex, and multidimensional dataData platform — a modern React (front-end) and Python (back-end) application that our scientists use to manage and process experimental dataAutomation — software to ingest and transform data from custom high-throughput instrumentation",sf,de
28,Vouch Insurance,Insurance,5,Data Analytics Engineer,"San Francisco, CA",$116K - $147K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=129&ao=8095&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_9ee0c2cb&cb=1618162382987&jobListingId=4028440595,"About Vouch:

Insurance... sounds slow, old-fashioned, and unexciting. Exactly. Insurance is broken, and it's failing fast-moving, innovative startups.

Vouch is a new, technology-first insurance company, backed with $100M in funding from world-class investors. Like Stripe for payments or Brex for credit cards, Vouch is creating the go-to business insurance for high growth companies.

We're doing this by making insurance fast, responsive, and focused on our customer -high growth and innovative companies. Instead of printed PDF applications and week-long waits, Vouch is building new technology to solve real problems, writing policies that actually cover relevant startup scenarios, and designing simple experiences in an otherwise frustrating industry.

The Job:

Vouch is looking for a Data Analytics Engineer to join our team. We're looking for someone who lives and breathes data and gets excited about data warehouses, building novel data sets, and maintaining data quality. You will have the opportunity to quickly contribute critical to Vouch's data assets and help to shape fundamental aspects of our data-driven culture.

You will be responsible for:

Working with our sales, marketing, product, and insurance teams to design and build data sets to drive Vouch's business
Setting up and maintaining timely and reliable ingestion of external data sources via our data loading platforms.
Providing clean, transformed data that is ready to be piped to our product, CRM, Finance, Underwriting, and other relevant systems
Clearly documenting data models with source, description and field definitions for better collaboration, maintainability and usability.
Establishing engineering best practices and methodologies to ensure data transformations and computations are accurate, efficient, and tested.
Working with dbt, Snowflake, Airflow, Python, Stitch, and git, and we welcome new ideas.

About You:

3+ years experience developing ETL workflows as a data analytics engineer, data engineer, or data analyst
Expert in SQL, capable in Python, and experience with Business Intelligence tools such as Looker, Mode Analytics or Tableau
Experience building business reporting processes (e.g. for finance, sales, or business operations)
Uses software development best practices with a focus on testing, reliability and maintainability
Experience working with cloud-based data warehouses like Snowflake, Redshift, or BigQuery
Experience with data transformation tooling (dbt is preferred), data pipeline services like Stitch and Fivetran, and orchestration tools like Airflow
You can effectively talk (and listen) to engineers, designers, executives, and other stakeholders.

Nice to Have:

Experience building executive level slide decks
Exposure to and passion for early-stage startups and/or high growth environments
A background in insurance or other regulated categories

Vouch believes in putting our people first and building a diverse team is at the front of everything that we do. We welcome people from different backgrounds, experiences, and perspectives. We are an equal opportunity employer and celebrate the diversity of our growing team.",sf,de
29,Tron,Information Technology,3.3,"Frontend Engineer, BitTorrent","San Francisco, CA",$77K - $186K (Glassdoor est.),https://www.glassdoor.com/partner/jobListing.htm?pos=130&ao=1165511&s=58&guid=00000178c1fe76119106e95a8b2a0de7&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_54dfb57c&cb=1618162382987&jobListingId=3775701975,"Frontend Engineer
at TRONAbout Us:

TRON-BitTorrent offers a unique and compelling work environment. We are proponents of the open Internet and we serve one of the largest user demographics in history. We take these responsibilities seriously and hire accordingly. We work with only the brightest engineers and the most talented business people we can find. Everyone on our team is here to do meaningful work with broad reaching impact. We have a fun yet challenging work environment that fosters diversity, creativity, and teamwork.

The Role:

As a Frontend Engineer you will be responsible for developing and maintaining BitTorrent's web products, API's, and servers, as well as implementing UI/UX design wireframes into working code. You will help modernize the overall architecture of the web properties and evolve them to ensure ease of development and scalability. You will work closely with Product Management, Design, and Engineering teams to provide web development support for the company's business initiatives.

Responsibilities

Implementing a web-based UI for BitTorrent applications including BitTorrent, µTorrent, BT Web, UT Web, BitTorrent Speed
Translate UI/UX wireframes into visual elements
Understand and operate third-party tools such as Amazon Web Services S3, and Lambda, GitHub Action, Jenkins.
Measure success & make decisions (Analytics, A/B testing)
Suggest & implement web based solutions for business needs

Skills and Qualifications

5+ years professional engineering experience with 3+ years of Web Dev experiences
CS and software engineering fundamentals
Strong JavaScript skills
Proficiency in Vuejs. Strong understanding of major JS frameworks: React, Angular, Backbone.
Strong knowledge of HTML & CSS
GitHub, Git and npm skills
Experience with troubleshooting and debugging cross-browser compatibility issues
Passionate about writing clean and refactorable code through unit tests
Strong communication skills
Apache/NGINX basics.
Experience with Google Analytics, Google Optimize etc.
Comfortable writing unit tests, preferably with Jest
Understanding of webpack

Nice to have

Experience with CSS precompilers such as SASS or SCSS
Experience with modern Frontend Tools such as Webpack, Jest, Express etc.
Experience with Node.js, and Express.js.
Experience with Amazon web services (e.g. EC2, S3, ELB, SQS, DynamoDB, Lambda, SNS)
Understanding of RESTful APIs
Familiarity with principles of good user experience and data-driven decision making
Microservices Infrastructure.

What We Offer

Competitive salary and 401K. 100% paid health coverage (for you and your family) that includes dental and vision plans.
Flexible working hours, including the ability to work from home (on occasion or as needed)
Unlimited paid time off
Up to $50/month wellness benefit at a gym or wellness group of your choice & up to $100/month for work from home expenses
Your choice of the latest, top-of-the-line equipment and tools to work with.

TRON-BitTorrent is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status or disability status.",sf,de
